{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"MongooseIM platform Home: https://github.com/esl/MongooseIM Product page: https://www.erlang-solutions.com/products/mongooseim.html Documentation: https://esl.github.io/MongooseDocs/ Get to know MongooseIM MongooseIM is a robust and efficient chat (or instant messaging) platform aimed at large installations. Designed for enterprise, it is fault-tolerant, can utilise the resources of multiple clustered machines, and easily scales for more capacity by simply adding a box or VM. MongooseIM can accept client sessions over vanilla XMPP, REST API and SSE, as well as Websockets, and BOSH (HTTP long-polling). As a platform, MongooseIM includes several server-side (backend) and client-side (frontend) components. We provide a test suite, metrics, a load testing platform, and a monitoring server. We recommend third-party, open source client libraries for XMPP and REST API. MongooseIM is brought to you by Erlang Solutions . MongooseIM platform components Server-side components We offer a set of server-side components: WombatOAM is a powerful monitoring platform that comes with a dedicated MongooseIM plugin Test suite - here are some useful tools to test and validate your XMPP servers: escalus : Erlang XMPP client amoc : a load testing tools MongooseICE : is a STUN and TURN server written for traversing NATs and relaying streams MongoosePush : is a flexible push notification server with APNS and FCM support Client-side components XMPP client libraries - we recommend the following client libraries: iOS, Objective-C: XMPPframework Android, Java: Smack Web, JavaScript: Stanza.io , Strophe.js REST API client libraries - we recommend the following client libraries: iOS, Swift: Jayme Android, Java: Retrofit Download packages For a quick start just download: The pre-built packages that suit your platform (Ubuntu, Debian, CentOS, and macOS) The Docker image ( source code repository ) Public testing Check out our test results: CI testing: GH Actions CircleCI Code coverage: Codecov - reported by CircleCI. Coveralls - reported by GH Actions. Versions See the documentation for the latest releases: Master 4.2.0 4.1.0 4.0.1 3.7.1 3.6.2 3.5.0 3.4.1 3.3.0 3.2.0 3.1.1 3.0.1 When developing new features/modules, please make sure you add basic documentation to the doc/ directory, and add a link to your document in doc/README.md. Participate! Suggestions, questions, thoughts? Contact us directly: Raise a GitHub issue Email us at mongoose-im@erlang-solutions.com Follow our Twitter account Like our Facebook page Subscribe to our mailing list to receive no more than two monthly emails as well as access to the free and open archives.","title":"Home"},{"location":"#mongooseim-platform","text":"Home: https://github.com/esl/MongooseIM Product page: https://www.erlang-solutions.com/products/mongooseim.html Documentation: https://esl.github.io/MongooseDocs/","title":"MongooseIM platform"},{"location":"#get-to-know-mongooseim","text":"MongooseIM is a robust and efficient chat (or instant messaging) platform aimed at large installations. Designed for enterprise, it is fault-tolerant, can utilise the resources of multiple clustered machines, and easily scales for more capacity by simply adding a box or VM. MongooseIM can accept client sessions over vanilla XMPP, REST API and SSE, as well as Websockets, and BOSH (HTTP long-polling). As a platform, MongooseIM includes several server-side (backend) and client-side (frontend) components. We provide a test suite, metrics, a load testing platform, and a monitoring server. We recommend third-party, open source client libraries for XMPP and REST API. MongooseIM is brought to you by Erlang Solutions .","title":"Get to know MongooseIM"},{"location":"#mongooseim-platform-components","text":"","title":"MongooseIM platform components"},{"location":"#server-side-components","text":"We offer a set of server-side components: WombatOAM is a powerful monitoring platform that comes with a dedicated MongooseIM plugin Test suite - here are some useful tools to test and validate your XMPP servers: escalus : Erlang XMPP client amoc : a load testing tools MongooseICE : is a STUN and TURN server written for traversing NATs and relaying streams MongoosePush : is a flexible push notification server with APNS and FCM support","title":"Server-side components"},{"location":"#client-side-components","text":"XMPP client libraries - we recommend the following client libraries: iOS, Objective-C: XMPPframework Android, Java: Smack Web, JavaScript: Stanza.io , Strophe.js REST API client libraries - we recommend the following client libraries: iOS, Swift: Jayme Android, Java: Retrofit","title":"Client-side components"},{"location":"#download-packages","text":"For a quick start just download: The pre-built packages that suit your platform (Ubuntu, Debian, CentOS, and macOS) The Docker image ( source code repository )","title":"Download packages"},{"location":"#public-testing","text":"Check out our test results: CI testing: GH Actions CircleCI Code coverage: Codecov - reported by CircleCI. Coveralls - reported by GH Actions.","title":"Public testing"},{"location":"#versions","text":"See the documentation for the latest releases: Master 4.2.0 4.1.0 4.0.1 3.7.1 3.6.2 3.5.0 3.4.1 3.3.0 3.2.0 3.1.1 3.0.1 When developing new features/modules, please make sure you add basic documentation to the doc/ directory, and add a link to your document in doc/README.md.","title":"Versions"},{"location":"#participate","text":"Suggestions, questions, thoughts? Contact us directly: Raise a GitHub issue Email us at mongoose-im@erlang-solutions.com Follow our Twitter account Like our Facebook page Subscribe to our mailing list to receive no more than two monthly emails as well as access to the free and open archives.","title":"Participate!"},{"location":"Contributions/","text":"Our contributions to the ecosystem. Third-party opensource projects XMPPframework for iOS Available on: robbiehanson/XMPPFramework XEP-0363: HTTP File Upload XEP-0313: Message Archive Management XEP-0030: Service Discovery MUC light Token-based reconnection Revamped README: making people feel like this is a well mantained and up to date framework Created a way to Mock a piece of the framework to improve the way we write tests Smack for Android Available on: igniterealtime/Smack XEP-0357: Push Notifications XEP-0191: Blocking Command XEP-0313: Message Archive Management XEP-0308: Last Message Correction MUC light Token-based reconnection Instant Stream Resumption XEP-0231: Bits of Binary XEP-0333: Chat Markers MAM documentation Movim See movim/movim on GitHub for more details. Docker image for Movim Software by Erlang Solutions escalus See esl/escalus on GitHub for more details. An XMPP client library in Erlang for conveniently testing XMPP servers Apache license 2.0 amoc See esl/amoc on GitHub for more details. amoc is a simple tool for running massively parallel XMPP tests Apache license 2.0 Note: amoc stands for \"A Murder of Crows\" exml See esl/exml on GitHub for more details. XML parsing library in Erlang Apache license 2.0 MongooseICE: ICE (STUN/TURN) server See MongooseICE on GitHub for more details. MongoosePush: Push notifications server (APNS/FCM) See MongoosePush on GitHub for more details. Open standards MUC light MUC stands for Multi-User Chat. MUC light is a presenceless and subscription-based group chat, relying on a simplified version of MUC. Token-based reconnection Token-based reconnection (TBR) Reconnection mechanism, for temporary disconnections, using tokens instead of passwords","title":"Contributions to ecosystem"},{"location":"Contributions/#third-party-opensource-projects","text":"","title":"Third-party opensource projects"},{"location":"Contributions/#xmppframework-for-ios","text":"Available on: robbiehanson/XMPPFramework XEP-0363: HTTP File Upload XEP-0313: Message Archive Management XEP-0030: Service Discovery MUC light Token-based reconnection Revamped README: making people feel like this is a well mantained and up to date framework Created a way to Mock a piece of the framework to improve the way we write tests","title":"XMPPframework for iOS"},{"location":"Contributions/#smack-for-android","text":"Available on: igniterealtime/Smack XEP-0357: Push Notifications XEP-0191: Blocking Command XEP-0313: Message Archive Management XEP-0308: Last Message Correction MUC light Token-based reconnection Instant Stream Resumption XEP-0231: Bits of Binary XEP-0333: Chat Markers MAM documentation","title":"Smack for Android"},{"location":"Contributions/#movim","text":"See movim/movim on GitHub for more details. Docker image for Movim","title":"Movim"},{"location":"Contributions/#software-by-erlang-solutions","text":"","title":"Software by Erlang Solutions"},{"location":"Contributions/#escalus","text":"See esl/escalus on GitHub for more details. An XMPP client library in Erlang for conveniently testing XMPP servers Apache license 2.0","title":"escalus"},{"location":"Contributions/#amoc","text":"See esl/amoc on GitHub for more details. amoc is a simple tool for running massively parallel XMPP tests Apache license 2.0 Note: amoc stands for \"A Murder of Crows\"","title":"amoc"},{"location":"Contributions/#exml","text":"See esl/exml on GitHub for more details. XML parsing library in Erlang Apache license 2.0","title":"exml"},{"location":"Contributions/#mongooseice-ice-stunturn-server","text":"See MongooseICE on GitHub for more details.","title":"MongooseICE: ICE (STUN/TURN) server"},{"location":"Contributions/#mongoosepush-push-notifications-server-apnsfcm","text":"See MongoosePush on GitHub for more details.","title":"MongoosePush: Push notifications server (APNS/FCM)"},{"location":"Contributions/#open-standards","text":"","title":"Open standards"},{"location":"Contributions/#muc-light","text":"MUC stands for Multi-User Chat. MUC light is a presenceless and subscription-based group chat, relying on a simplified version of MUC.","title":"MUC light"},{"location":"Contributions/#token-based-reconnection","text":"Token-based reconnection (TBR) Reconnection mechanism, for temporary disconnections, using tokens instead of passwords","title":"Token-based reconnection"},{"location":"Differentiators/","text":"Differentiators MongooseIM provides: Massive scalability: for greater and faster growth, costs-effectiveness as well as resource utilisation Platform approach: designed with consistency, end-to-end battle testing across the whole ecosystem (all server and client components, and tools) Code quality: extensive refactoring, substantial optimisations, continuous integration and deployment Extensive testing: automated continuous functional code coverage, integration testing, end-to-end testing with real clients Continuous load testing Unique version: no proprietary extensions, fully open source, fully open standards Contributions to ( XMPP Standards Foundation ): implementations of XEPs, innovations contributed Professional support, and flexible customer service Contributions to third party open source codebases: strenghthening the ecosystem Initial differences from the parent project This project began its life as a fork of ejabberd v.2.1.8 back in 2011, and later underwent major cleanup, refactoring and optimization. Major steps performed at the time: Bringing the project source tree to compliance with OTP project structure recommendations Swapping autotools for the Erlang community-standard build tool rebar Removal of obsolete and/or rarely used modules to reduce maintenance burden Reduction of runtime memory consumption by refactoring the code to use Erlang's binary data type for string manipulation and storage instead of operating on linked lists of characters Functional test coverage of the system according to corresponding RFCs and XEPs","title":"Differentiators"},{"location":"Differentiators/#differentiators","text":"MongooseIM provides: Massive scalability: for greater and faster growth, costs-effectiveness as well as resource utilisation Platform approach: designed with consistency, end-to-end battle testing across the whole ecosystem (all server and client components, and tools) Code quality: extensive refactoring, substantial optimisations, continuous integration and deployment Extensive testing: automated continuous functional code coverage, integration testing, end-to-end testing with real clients Continuous load testing Unique version: no proprietary extensions, fully open source, fully open standards Contributions to ( XMPP Standards Foundation ): implementations of XEPs, innovations contributed Professional support, and flexible customer service Contributions to third party open source codebases: strenghthening the ecosystem","title":"Differentiators"},{"location":"Differentiators/#initial-differences-from-the-parent-project","text":"This project began its life as a fork of ejabberd v.2.1.8 back in 2011, and later underwent major cleanup, refactoring and optimization. Major steps performed at the time: Bringing the project source tree to compliance with OTP project structure recommendations Swapping autotools for the Erlang community-standard build tool rebar Removal of obsolete and/or rarely used modules to reduce maintenance burden Reduction of runtime memory consumption by refactoring the code to use Erlang's binary data type for string manipulation and storage instead of operating on linked lists of characters Functional test coverage of the system according to corresponding RFCs and XEPs","title":"Initial differences from the parent project"},{"location":"History/","text":"MongooseIM history 2011: Fork of ejabberd MongooseIM's birthplace is a private Erlang Solutions' branch of ProcessOne's ejabberd - an XMPP/Jabber server written in Erlang. What would later become a leading, highly customisable and scalable XMPP platform, originated in a strong idea - storing all internal strings in binaries instead of lists, among other significant improvements. The change was introduced in 0.1.0 proto-MongooseIM release and 3.0.0-alpha-X series of ejabberd. This opened the door for achieving higher performance, lower latency and introducing other subsequent improvements building up to a plaform we are truly proud of. 2012-2015: Fully independent project growing fast The next steps were achieving full OTP and rebar compliance, removal of obsolete and/or rarely used modules, reduction of the runtime memory consumption and functional test coverage. MongooseIM 1.0.0 was released on July 10th of 2012. MongooseIM XMPP server fully independently went through multiple versions, following its own path with its own resources: 1.1.x in 2012, 1.2.x in 2013, 1.3.x , 1.4.x , 1.5.x in 2014, and 1.6.x in 2015. 2016: Pivot to fullstack messaging platform MongooseIM Platform appeared in 2016, with the release of MongooseIM XMPP server 2.0.0 . The MongooseIM platform components were: MongooseIM XMPP server, featuring a unique REST API for client developers and MUC light WombatOAM, for monitoring and operations escalus, an Erlang XMPP client for test automation amoc, for load generation Smack for Android in Java (third party) XMPPFramework for iOS in Objective-C (third party) Retrofit by Square for Android in Java (third party) Jayme by Inaka for iOS in Swift 2017: Platform expansion and strengthening We also introduced some MongooseIM platform components that are independent of the XMPP server. So far the list includes: Mangosta iOS Mangosta Android MongoosePush MongooseICE 2018-2019: Planetary architecture, to welcome IoT-scale and chatbots The next step on our journey with the MongooseIM platform is to enable building planetary scale architectures. This is necessary to welcome the massive influx of users that come with a full stack IoT and chatbot solution. The ability to connect robots and humans is the requirement of the next technological breakthrough. Erlang Solution's goal is to utilise XMPP features suited for chatbots, and build open standards for completeness of solution.","title":"History"},{"location":"History/#mongooseim-history","text":"","title":"MongooseIM history"},{"location":"History/#2011-fork-of-ejabberd","text":"MongooseIM's birthplace is a private Erlang Solutions' branch of ProcessOne's ejabberd - an XMPP/Jabber server written in Erlang. What would later become a leading, highly customisable and scalable XMPP platform, originated in a strong idea - storing all internal strings in binaries instead of lists, among other significant improvements. The change was introduced in 0.1.0 proto-MongooseIM release and 3.0.0-alpha-X series of ejabberd. This opened the door for achieving higher performance, lower latency and introducing other subsequent improvements building up to a plaform we are truly proud of.","title":"2011: Fork of ejabberd"},{"location":"History/#2012-2015-fully-independent-project-growing-fast","text":"The next steps were achieving full OTP and rebar compliance, removal of obsolete and/or rarely used modules, reduction of the runtime memory consumption and functional test coverage. MongooseIM 1.0.0 was released on July 10th of 2012. MongooseIM XMPP server fully independently went through multiple versions, following its own path with its own resources: 1.1.x in 2012, 1.2.x in 2013, 1.3.x , 1.4.x , 1.5.x in 2014, and 1.6.x in 2015.","title":"2012-2015: Fully independent project growing fast"},{"location":"History/#2016-pivot-to-fullstack-messaging-platform","text":"MongooseIM Platform appeared in 2016, with the release of MongooseIM XMPP server 2.0.0 . The MongooseIM platform components were: MongooseIM XMPP server, featuring a unique REST API for client developers and MUC light WombatOAM, for monitoring and operations escalus, an Erlang XMPP client for test automation amoc, for load generation Smack for Android in Java (third party) XMPPFramework for iOS in Objective-C (third party) Retrofit by Square for Android in Java (third party) Jayme by Inaka for iOS in Swift","title":"2016: Pivot to fullstack messaging platform"},{"location":"History/#2017-platform-expansion-and-strengthening","text":"We also introduced some MongooseIM platform components that are independent of the XMPP server. So far the list includes: Mangosta iOS Mangosta Android MongoosePush MongooseICE","title":"2017: Platform expansion and strengthening"},{"location":"History/#2018-2019-planetary-architecture-to-welcome-iot-scale-and-chatbots","text":"The next step on our journey with the MongooseIM platform is to enable building planetary scale architectures. This is necessary to welcome the massive influx of users that come with a full stack IoT and chatbot solution. The ability to connect robots and humans is the requirement of the next technological breakthrough. Erlang Solution's goal is to utilise XMPP features suited for chatbots, and build open standards for completeness of solution.","title":"2018-2019: Planetary architecture, to welcome IoT-scale and chatbots"},{"location":"advanced-configuration/Erlang-cookie-security/","text":"In order for MongooseIM nodes to communicate with each other, they have to share a common secret - i.e. a cookie - which is a feature of the underlying Erlang VM. The cookie itself is an UTF-8 string that is up to 255 characters in size. Thanks to the cookie, MongooseIM nodes can determine if they are allowed to communicate with each other and with no cookie no communication would flow between the nodes - a feature especially useful when you are running more than one applications on a single machine. For ease of deployment and staging, each MongooseIM node is configured with a predefined erlang cookie. However, one should remember that for production environments this cookie should be reconfigured to a new secret cookie, as this will secure your system from intrusion. You can change the cookie by changing the parameters of the -setcookie parameter in the vm.args file. Nonetheless, one should remember that communication between Erlang nodes is unencrypted by default, hence, the cookie is vulnerable to sniffing. If one has access to a MongooseIM cookie and figures out the hostname of a node, one can execute shell commands remotely on that node. Therefore, one should either provide privacy at the network layer (strongly recommended) or disable port 4369 for ultimate security.","title":"Erlang Cookie Security"},{"location":"advanced-configuration/Modules/","text":"MongooseIM provides a wide range of pluggable and configurable modules, that implement various features including XEPs. For instance mod_muc enables Multi-User Chat (group chat), mod_mam gives us Message Archive Management, and mod_stream_management is for stanza acknowledgement and stream resumption. This modular architecture provides great flexibility for everyday operations and feature development. A module configuration generally looks like this: 1 2 3 4 [modules.mod_muc] host = \"muc.@HOST@\" access = \"muc\" access_create = \"muc_create\" IQ processing policies Some of the modules feature an iqdisc parameter. It defines the method for handling incoming IQ stanzas. The server may use one of the following strategies to handle incoming IQ stanzas: modules.*.iqdisc.type Syntax: string, one of \"one_queue\" , \"no_queue\" , \"queues\" , or \"parallel\" Example: iqdisc.type = \"one_queue\" Note: In the \"queues\" case alone, the following key becomes mandatory: modules.*.iqdisc.workers Syntax: positive integer Example: iqdisc.workers = 50 Their semantics works as follow: no_queue registers a new IQ handler, which will be called in the context of the process serving the connection on which the IQ arrives. one_queue spawns a new process by which the incoming IQ stanzas will be handled. queues spawns N worker processes, as provided by the iqdisc.workers key. Every incoming stanza will be then handled by one of those processes. parallel registers the handler without spawning any process: a new process will be spawned in place, for each incoming stanza. Modules list mod_adhoc Implements XEP-0050: Ad-Hoc Commands for advertising and executing application-specific commands, such as those related to a configuration workflow, using XEP-0004: Data Forms in order to structure the information exchange. This is extremely useful for use cases such as remote administration, user engagement via polls, and ChatBots. mod_amp Implements a subset of XEP-0079: Advanced Message Processing functionality, that enables entities to request, and servers to perform advanced processing of XMPP message stanzas, including reliable data transport, time-sensitive delivery, and expiration of transient messages. mod_auth_token A module used by SASL X-OAUTH mechanism. It provides an API to manage custom OAuth tokens . It requires mod_keystore as an actual key database. mod_blocking Implements XEP-0191: Blocking Command , a simplified interface to privacy lists. mod_bosh Allows users to connect to MongooseIM using BOSH (Bidirectional-streams Over Synchronous HTTP), the HTTP long-polling technique described in XEP-0124: Bidirectional-streams Over Synchronous HTTP (BOSH) and XEP-0206: XMPP Over BOSH . mod_caps Implements XEP-0115: Entity Capabilities . It queries clients for their supported functionalities and caches them in Mnesia. This module tightly cooperates with mod_pubsub in order to deliver PEP events to user's subscribers. mod_carboncopy Implements XEP-0280: Message Carbons in order to keep all IM clients for a user engaged in a real-time conversation by carbon-copying all inbound and outbound messages to all interested resources (Full JIDs). mod_commands A central gateway providing access to a subset of MongooseIM functions by channels other than XMPP. Commands defined there are currently accessible via REST API. mod_csi Enables the XEP-0352: Client State Indication functionality. mod_disco Implements XEP-0030: Service Discovery for discovering information (capabilities, protocols, features) about other XMPP entities. mod_event_pusher A framework module to build other notification-based modules on. mod_event_pusher_sns Allows sending online/offline notifications, chat and groupchat messages as events to Amazon Simple Notification Service . mod_event_pusher_rabbit Allows sending presence changes (to available/unavailable), chat and groupchat messages as events to a RabbitMQ server. mod_event_pusher_push Implements XEP-0357: Push Notifications to provide push notifications to clients that are temporary unavailable. mod_event_pusher_http Forward events to an external HTTP service. This applies to situations such as sending messages or presences to mobile/SMS/email push service, big data, or an analytics service. mod_extdisco Implements XEP-0215: External Service Discovery for discovering information about services external to the XMPP network. The main use-case is to help discover STUN/TURN servers to allow for negotiating media exchanges. mod_http_upload Implements XEP-0363: HTTP File Upload for coordinating with an XMPP server to upload files via HTTP and receive URLs that can be shared in messages. mod_inbox Implements custom inbox XEP mod_global_distrib Enables sharing a single XMPP domain between distinct datacenters ( experimental ). mod_jingle_sip Enables Jingle to SIP and SIP to Jingle translator. mod_keystore Serves as a storage for crypto keys for mod_auth_token . mod_last Implements XEP-0012: Last Activity for communicating information about the last activity associated with an XMPP entity (most recent presence information from an offline contact). mod_mam Implements XEP-0313: Message Archive Management , that defines a protocol to query and control an archive of messages stored on a server. mod_muc Implements XEP-0045: Multi-User Chat , for a featureful multi-user text chat (group chat), whereby multiple XMPP users can exchange messages in the context of a chat room. It is tightly coupled with user presence in chat rooms. mod_muc_commands Provides mod_muc related mongoose_commands , accessible via the client REST API. mod_muc_log Implements a logging subsystem for mod_muc . mod_muc_light Implements XEP Multi-User Chat Light . mod_muc_light_commands Provides mod_muc_light related mongoose_commands , accessible via client REST API. mod_offline Provides an offline messages storage that is compliant with XEP-0160: Best Practices for Handling Offline Messages . mod_offline_stub Prevents <service-unavailable/> error when the message recipient is offline. mod_ping Implements XEP-0199: XMPP Ping , enabling periodic XMPP pings sent to clients and responds to those sent from clients. mod_privacy This module implements XEP-0016: Privacy Lists , for enabling or disabling communication with other entities on a network. mod_private Implements XEP-0049: Private XML Storage to store and query private user data in XML format. mod_pubsub This extension implements XEP-0060: Publish-Subscribe . It is a pluggable implementation using behaviours provided by node_*.erl and nodetree_*.erl modules. mod_push_service_mongoosepush Handles push notifications generated by mod_pubsub 's node_push and passes them to MongoosePush service. mod_register Implements XEP-0077: In-Band Registration , that enables creating an account and changing the password once connected. This does not provide a solution to the forgotten password use case via SMS or email. mod_revproxy With this extension, MongooseIM may serve as a reverse proxy. Warning: This module is deprecated and can only be configured with the older, .cfg configuration file. Please refer to the older versions of the documentation to see how to do this. mod_roster Roster support, specified in RFC 6121 . Includes support for XEP-0237: Roster Versioning . mod_shared_roster_ldap This module, when enabled, will inject roster entries fetched from LDAP. mod_sic Implements XEP-0279: Server IP Check that enables a client to discover its external IP address. mod_stream_management Enables XEP-0198: Stream Management functionality that defines the active management of an XML stream between two XMPP entities, including features for stanza acknowledgements and stream resumption. mod_time XEP-0202: Entity Time implementation. With this extensions, clients can get the current server time. mod_vcard Provides support for vCards, as specified in XEP-0054: vcard-temp and XEP-0055: Jabber Search . mod_version This module provides the functionality specified in XEP-0092: Software Version .","title":"Options: Extension Modules"},{"location":"advanced-configuration/Modules/#iq-processing-policies","text":"Some of the modules feature an iqdisc parameter. It defines the method for handling incoming IQ stanzas. The server may use one of the following strategies to handle incoming IQ stanzas:","title":"IQ processing policies"},{"location":"advanced-configuration/Modules/#modulesiqdisctype","text":"Syntax: string, one of \"one_queue\" , \"no_queue\" , \"queues\" , or \"parallel\" Example: iqdisc.type = \"one_queue\" Note: In the \"queues\" case alone, the following key becomes mandatory:","title":"modules.*.iqdisc.type"},{"location":"advanced-configuration/Modules/#modulesiqdiscworkers","text":"Syntax: positive integer Example: iqdisc.workers = 50 Their semantics works as follow: no_queue registers a new IQ handler, which will be called in the context of the process serving the connection on which the IQ arrives. one_queue spawns a new process by which the incoming IQ stanzas will be handled. queues spawns N worker processes, as provided by the iqdisc.workers key. Every incoming stanza will be then handled by one of those processes. parallel registers the handler without spawning any process: a new process will be spawned in place, for each incoming stanza.","title":"modules.*.iqdisc.workers"},{"location":"advanced-configuration/Modules/#modules-list","text":"","title":"Modules list"},{"location":"advanced-configuration/Modules/#mod_adhoc","text":"Implements XEP-0050: Ad-Hoc Commands for advertising and executing application-specific commands, such as those related to a configuration workflow, using XEP-0004: Data Forms in order to structure the information exchange. This is extremely useful for use cases such as remote administration, user engagement via polls, and ChatBots.","title":"mod_adhoc"},{"location":"advanced-configuration/Modules/#mod_amp","text":"Implements a subset of XEP-0079: Advanced Message Processing functionality, that enables entities to request, and servers to perform advanced processing of XMPP message stanzas, including reliable data transport, time-sensitive delivery, and expiration of transient messages.","title":"mod_amp"},{"location":"advanced-configuration/Modules/#mod_auth_token","text":"A module used by SASL X-OAUTH mechanism. It provides an API to manage custom OAuth tokens . It requires mod_keystore as an actual key database.","title":"mod_auth_token"},{"location":"advanced-configuration/Modules/#mod_blocking","text":"Implements XEP-0191: Blocking Command , a simplified interface to privacy lists.","title":"mod_blocking"},{"location":"advanced-configuration/Modules/#mod_bosh","text":"Allows users to connect to MongooseIM using BOSH (Bidirectional-streams Over Synchronous HTTP), the HTTP long-polling technique described in XEP-0124: Bidirectional-streams Over Synchronous HTTP (BOSH) and XEP-0206: XMPP Over BOSH .","title":"mod_bosh"},{"location":"advanced-configuration/Modules/#mod_caps","text":"Implements XEP-0115: Entity Capabilities . It queries clients for their supported functionalities and caches them in Mnesia. This module tightly cooperates with mod_pubsub in order to deliver PEP events to user's subscribers.","title":"mod_caps"},{"location":"advanced-configuration/Modules/#mod_carboncopy","text":"Implements XEP-0280: Message Carbons in order to keep all IM clients for a user engaged in a real-time conversation by carbon-copying all inbound and outbound messages to all interested resources (Full JIDs).","title":"mod_carboncopy"},{"location":"advanced-configuration/Modules/#mod_commands","text":"A central gateway providing access to a subset of MongooseIM functions by channels other than XMPP. Commands defined there are currently accessible via REST API.","title":"mod_commands"},{"location":"advanced-configuration/Modules/#mod_csi","text":"Enables the XEP-0352: Client State Indication functionality.","title":"mod_csi"},{"location":"advanced-configuration/Modules/#mod_disco","text":"Implements XEP-0030: Service Discovery for discovering information (capabilities, protocols, features) about other XMPP entities.","title":"mod_disco"},{"location":"advanced-configuration/Modules/#mod_event_pusher","text":"A framework module to build other notification-based modules on.","title":"mod_event_pusher"},{"location":"advanced-configuration/Modules/#mod_event_pusher_sns","text":"Allows sending online/offline notifications, chat and groupchat messages as events to Amazon Simple Notification Service .","title":"mod_event_pusher_sns"},{"location":"advanced-configuration/Modules/#mod_event_pusher_rabbit","text":"Allows sending presence changes (to available/unavailable), chat and groupchat messages as events to a RabbitMQ server.","title":"mod_event_pusher_rabbit"},{"location":"advanced-configuration/Modules/#mod_event_pusher_push","text":"Implements XEP-0357: Push Notifications to provide push notifications to clients that are temporary unavailable.","title":"mod_event_pusher_push"},{"location":"advanced-configuration/Modules/#mod_event_pusher_http","text":"Forward events to an external HTTP service. This applies to situations such as sending messages or presences to mobile/SMS/email push service, big data, or an analytics service.","title":"mod_event_pusher_http"},{"location":"advanced-configuration/Modules/#mod_extdisco","text":"Implements XEP-0215: External Service Discovery for discovering information about services external to the XMPP network. The main use-case is to help discover STUN/TURN servers to allow for negotiating media exchanges.","title":"mod_extdisco"},{"location":"advanced-configuration/Modules/#mod_http_upload","text":"Implements XEP-0363: HTTP File Upload for coordinating with an XMPP server to upload files via HTTP and receive URLs that can be shared in messages.","title":"mod_http_upload"},{"location":"advanced-configuration/Modules/#mod_inbox","text":"Implements custom inbox XEP","title":"mod_inbox"},{"location":"advanced-configuration/Modules/#mod_global_distrib","text":"Enables sharing a single XMPP domain between distinct datacenters ( experimental ).","title":"mod_global_distrib"},{"location":"advanced-configuration/Modules/#mod_jingle_sip","text":"Enables Jingle to SIP and SIP to Jingle translator.","title":"mod_jingle_sip"},{"location":"advanced-configuration/Modules/#mod_keystore","text":"Serves as a storage for crypto keys for mod_auth_token .","title":"mod_keystore"},{"location":"advanced-configuration/Modules/#mod_last","text":"Implements XEP-0012: Last Activity for communicating information about the last activity associated with an XMPP entity (most recent presence information from an offline contact).","title":"mod_last"},{"location":"advanced-configuration/Modules/#mod_mam","text":"Implements XEP-0313: Message Archive Management , that defines a protocol to query and control an archive of messages stored on a server.","title":"mod_mam"},{"location":"advanced-configuration/Modules/#mod_muc","text":"Implements XEP-0045: Multi-User Chat , for a featureful multi-user text chat (group chat), whereby multiple XMPP users can exchange messages in the context of a chat room. It is tightly coupled with user presence in chat rooms.","title":"mod_muc"},{"location":"advanced-configuration/Modules/#mod_muc_commands","text":"Provides mod_muc related mongoose_commands , accessible via the client REST API.","title":"mod_muc_commands"},{"location":"advanced-configuration/Modules/#mod_muc_log","text":"Implements a logging subsystem for mod_muc .","title":"mod_muc_log"},{"location":"advanced-configuration/Modules/#mod_muc_light","text":"Implements XEP Multi-User Chat Light .","title":"mod_muc_light"},{"location":"advanced-configuration/Modules/#mod_muc_light_commands","text":"Provides mod_muc_light related mongoose_commands , accessible via client REST API.","title":"mod_muc_light_commands"},{"location":"advanced-configuration/Modules/#mod_offline","text":"Provides an offline messages storage that is compliant with XEP-0160: Best Practices for Handling Offline Messages .","title":"mod_offline"},{"location":"advanced-configuration/Modules/#mod_offline_stub","text":"Prevents <service-unavailable/> error when the message recipient is offline.","title":"mod_offline_stub"},{"location":"advanced-configuration/Modules/#mod_ping","text":"Implements XEP-0199: XMPP Ping , enabling periodic XMPP pings sent to clients and responds to those sent from clients.","title":"mod_ping"},{"location":"advanced-configuration/Modules/#mod_privacy","text":"This module implements XEP-0016: Privacy Lists , for enabling or disabling communication with other entities on a network.","title":"mod_privacy"},{"location":"advanced-configuration/Modules/#mod_private","text":"Implements XEP-0049: Private XML Storage to store and query private user data in XML format.","title":"mod_private"},{"location":"advanced-configuration/Modules/#mod_pubsub","text":"This extension implements XEP-0060: Publish-Subscribe . It is a pluggable implementation using behaviours provided by node_*.erl and nodetree_*.erl modules.","title":"mod_pubsub"},{"location":"advanced-configuration/Modules/#mod_push_service_mongoosepush","text":"Handles push notifications generated by mod_pubsub 's node_push and passes them to MongoosePush service.","title":"mod_push_service_mongoosepush"},{"location":"advanced-configuration/Modules/#mod_register","text":"Implements XEP-0077: In-Band Registration , that enables creating an account and changing the password once connected. This does not provide a solution to the forgotten password use case via SMS or email.","title":"mod_register"},{"location":"advanced-configuration/Modules/#mod_revproxy","text":"With this extension, MongooseIM may serve as a reverse proxy. Warning: This module is deprecated and can only be configured with the older, .cfg configuration file. Please refer to the older versions of the documentation to see how to do this.","title":"mod_revproxy"},{"location":"advanced-configuration/Modules/#mod_roster","text":"Roster support, specified in RFC 6121 . Includes support for XEP-0237: Roster Versioning .","title":"mod_roster"},{"location":"advanced-configuration/Modules/#mod_shared_roster_ldap","text":"This module, when enabled, will inject roster entries fetched from LDAP.","title":"mod_shared_roster_ldap"},{"location":"advanced-configuration/Modules/#mod_sic","text":"Implements XEP-0279: Server IP Check that enables a client to discover its external IP address.","title":"mod_sic"},{"location":"advanced-configuration/Modules/#mod_stream_management","text":"Enables XEP-0198: Stream Management functionality that defines the active management of an XML stream between two XMPP entities, including features for stanza acknowledgements and stream resumption.","title":"mod_stream_management"},{"location":"advanced-configuration/Modules/#mod_time","text":"XEP-0202: Entity Time implementation. With this extensions, clients can get the current server time.","title":"mod_time"},{"location":"advanced-configuration/Modules/#mod_vcard","text":"Provides support for vCards, as specified in XEP-0054: vcard-temp and XEP-0055: Jabber Search .","title":"mod_vcard"},{"location":"advanced-configuration/Modules/#mod_version","text":"This module provides the functionality specified in XEP-0092: Software Version .","title":"mod_version"},{"location":"advanced-configuration/Services/","text":"Some functionalities in MongooseIM are provided by \"services\". A service is similar to a module, but while a module is started for every virtual host and may have global or host-specific configuration, a service is started only once with global configuration. Currently, only two modules are categorised as \"service providers\". Eventually the modules which are not host-specific will be refactored to be services. Scope: global Syntax: Both services are specified in their own sections, either [services.service_admin_extra] or [services.service_mongoose_system_metrics] . Default: None - each service needs to be enabled explicitly. Typical services are already specified in the example configuration file. Example: A configuration of the service_admin_extra service. 1 2 3 [services.service_admin_extra] submods = [ \"node\" , \"account\" , \"sessions\" , \"vcard\" , \"gdpr\" , \"upload\" , \"roster\" , \"last\" , \"private\" , \"stanza\" , \"stats\" ] service_admin_extra services.service_admin_extra.submods Syntax: Array of strings representing function groups added by service_admin_extra . Default: All submodules: [\"node\", \"account\", \"sessions\", \"vcard\", \"gdpr\", \"upload\", \"roster\", \"last\", \"private\", \"stanza\", \"stats\"] Example: submods = [\"stats\", \"gdpr\"] This service provides additional commands to the mongooseimctl script. They are bundled in the following groups: accounts : Adds change_password , check_password_hash , delete_old_users , delete_old_users_vhost , ban_account , num_active_users , check_account , check_password last : Adds set_last node : Adds load_config , get_cookie , remove_node private : Adds private_get , private_set roster : Adds add_rosteritem , delete_rosteritem , process_rosteritems , get_roster , push_roster , push_roster_all , push_roster_alltoall sessions : Adds num_resources , resource_num , kick_session , status_num_host , status_num , status_list_host , status_list , connected_users_info , connected_users_vhost , user_sessions_info , set_presence stanza : Adds send_message_chat , send_message_headline , send_stanza_c2s stats : Adds stats , stats_host vcard : Adds get_vcard , get_vcard2 , get_vcard2_multi , set_vcard , set_vcard2 , set_vcard2_multi gdpr : Adds retrieve_personal_data upload : Adds http_upload service_mongoose_system_metrics MongooseIM system metrics are being gathered to analyse the trends and needs of our users, improve MongooseIM, and get to know where to focus our efforts. See System Metrics Privacy Policy for more details. services.service_mongoose_system_metrics.report Syntax: boolean Default: not specified Example: report = true Explicit acknowledgement that the metrics are gathered and reported. When this option is not specified, the reports are gathered and a notification appears in logs on startup. Enabling this option silences the notification reminder that metrics are gathered. When this option is set to false , System Metrics Service is not started and metrics are not collected. services.service_mongoose_system_metrics.intial_report Syntax: non-negative integer Default: 300_000 (milliseconds - 5 minutes). Example: intial_report = 300_000 Time delay counted when the service is started after which the first metrics report is created and sent. services.service_mongoose_system_metrics.periodic_report Syntax: non-negative integer Default: 108_000_000 (milliseconds - 3 hours) Example: periodic_report = 108_000_000 Time delay for a periodic update report to be created and sent. services.service_mongoose_system_metrics.tracking_id : Syntax: string Default: no default. Example: tracking_id = \"UA-123456789\" Tracking ID to forward the reported metrics so that they can be viewed in the Google Analytics dashboard. Removing the services.service_mongoose_system_metrics entry will result in the service not being started. Metrics will not be collected and shared. It will generate a notification that the feature is not being used. The notification can be silenced by setting the no_report option explicitly. Example configuration 1 2 3 4 5 6 7 8 9 [services.service_admin_extra] submods = [ \"node\" , \"account\" , \"sessions\" , \"vcard\" , \"gdpr\" , \"upload\" , \"roster\" , \"last\" , \"private\" , \"stanza\" , \"stats\" ] [services.service_mongoose_system_metrics] report = true initial_report = 300 _000 periodic_report = 108 _000_000 tracking_id = \"UA-123456789\"","title":"Options: Services"},{"location":"advanced-configuration/Services/#service_admin_extra","text":"","title":"service_admin_extra"},{"location":"advanced-configuration/Services/#servicesservice_admin_extrasubmods","text":"Syntax: Array of strings representing function groups added by service_admin_extra . Default: All submodules: [\"node\", \"account\", \"sessions\", \"vcard\", \"gdpr\", \"upload\", \"roster\", \"last\", \"private\", \"stanza\", \"stats\"] Example: submods = [\"stats\", \"gdpr\"] This service provides additional commands to the mongooseimctl script. They are bundled in the following groups: accounts : Adds change_password , check_password_hash , delete_old_users , delete_old_users_vhost , ban_account , num_active_users , check_account , check_password last : Adds set_last node : Adds load_config , get_cookie , remove_node private : Adds private_get , private_set roster : Adds add_rosteritem , delete_rosteritem , process_rosteritems , get_roster , push_roster , push_roster_all , push_roster_alltoall sessions : Adds num_resources , resource_num , kick_session , status_num_host , status_num , status_list_host , status_list , connected_users_info , connected_users_vhost , user_sessions_info , set_presence stanza : Adds send_message_chat , send_message_headline , send_stanza_c2s stats : Adds stats , stats_host vcard : Adds get_vcard , get_vcard2 , get_vcard2_multi , set_vcard , set_vcard2 , set_vcard2_multi gdpr : Adds retrieve_personal_data upload : Adds http_upload","title":"services.service_admin_extra.submods"},{"location":"advanced-configuration/Services/#service_mongoose_system_metrics","text":"MongooseIM system metrics are being gathered to analyse the trends and needs of our users, improve MongooseIM, and get to know where to focus our efforts. See System Metrics Privacy Policy for more details.","title":"service_mongoose_system_metrics"},{"location":"advanced-configuration/Services/#servicesservice_mongoose_system_metricsreport","text":"Syntax: boolean Default: not specified Example: report = true Explicit acknowledgement that the metrics are gathered and reported. When this option is not specified, the reports are gathered and a notification appears in logs on startup. Enabling this option silences the notification reminder that metrics are gathered. When this option is set to false , System Metrics Service is not started and metrics are not collected.","title":"services.service_mongoose_system_metrics.report"},{"location":"advanced-configuration/Services/#servicesservice_mongoose_system_metricsintial_report","text":"Syntax: non-negative integer Default: 300_000 (milliseconds - 5 minutes). Example: intial_report = 300_000 Time delay counted when the service is started after which the first metrics report is created and sent.","title":"services.service_mongoose_system_metrics.intial_report"},{"location":"advanced-configuration/Services/#servicesservice_mongoose_system_metricsperiodic_report","text":"Syntax: non-negative integer Default: 108_000_000 (milliseconds - 3 hours) Example: periodic_report = 108_000_000 Time delay for a periodic update report to be created and sent.","title":"services.service_mongoose_system_metrics.periodic_report"},{"location":"advanced-configuration/Services/#servicesservice_mongoose_system_metricstracking_id","text":"Syntax: string Default: no default. Example: tracking_id = \"UA-123456789\" Tracking ID to forward the reported metrics so that they can be viewed in the Google Analytics dashboard. Removing the services.service_mongoose_system_metrics entry will result in the service not being started. Metrics will not be collected and shared. It will generate a notification that the feature is not being used. The notification can be silenced by setting the no_report option explicitly.","title":"services.service_mongoose_system_metrics.tracking_id:"},{"location":"advanced-configuration/Services/#example-configuration","text":"1 2 3 4 5 6 7 8 9 [services.service_admin_extra] submods = [ \"node\" , \"account\" , \"sessions\" , \"vcard\" , \"gdpr\" , \"upload\" , \"roster\" , \"last\" , \"private\" , \"stanza\" , \"stats\" ] [services.service_mongoose_system_metrics] report = true initial_report = 300 _000 periodic_report = 108 _000_000 tracking_id = \"UA-123456789\"","title":"Example configuration"},{"location":"advanced-configuration/TLS-hardening/","text":"OTP TLS vs. Fast TLS Before we explain the TLS hardening in MongooseIM, we need to describe the TLS libraries used in the project. These are \"OTP TLS\" and \"Fast TLS\". The former is provided by (as the name suggests) OTP as the ssl application. Large part of the logic is implemented in Erlang but it calls OpenSSL API for some operations anyway. The latter is a community-maintained driver, which is implemented as NIFs (native C code). It uses OpenSSL API for all operations. Most MongooseIM components use the TLS library provided by OTP. However, some of them choose to integrate with fast_tls library instead. The former one is used primarily by MIM dependencies, while the latter is used only by MIM modules. None of them is strictly better than the other. Below you may find a summary of the differences between them. fast_tls is faster There are options that OTP TLS (a.k.a just_tls in the ejabberd_c2s configuration) supports exclusively: Immediate connection drop when the client certificate is invalid Certificate Revocation Lists More flexible certificate verification options Allowed protocol versions may be configured: Globally for OTP TLS via an environment variable Per socket in Fast TLS via OpenSSL cipher string Deprecations MongooseIM is configured to allow only TLS 1.2 or higher, due to known vulnerabilities in TLS 1.0 and 1.1. It is still possible to enable earlier versions, however it is strongly discouraged. OTP TLS hardening Protocol list for OTP TLS is set via the protocol_version environment variable. It's an Erlang runtime variable, so it is not configured in the OS but rather in the app.config file. It may be found in etc/ folder inside MongooseIM release and in [repository root]/rel/files/ . In order to change the list, please find the following lines: 1 2 3 {protocol_version, ['tlsv1.2' %, 'tlsv1.3' % supported in OTP >= 22 ]} By default only TLS 1.2 is enabled, as 1.3 is not supported by OTPs older than 22.0. If you are using OTP 22.0 or newer, you may remove leading % before 'tlsv1.3' . The remaining valid values are: 'tlsv1.1' , tlsv1 , sslv3 . This setting affects the following MongooseIM components: Raw XMPP over TCP connections, if ejabberd_c2s listener is configured to use just_tls All outgoing connections (databases, AMQP, SIP etc.) HTTP endpoints Fast TLS hardening Fast TLS expects an OpenSSL cipher string as one of optional connection parameters. This string is configured individually for every module that uses it. By default, MongooseIM sets this option to TLSv1.2:TLSv1.3 for each component. The list below enumerates all components that use Fast TLS and describes how to change this string. listen.c2s - main user session abstraction + XMPP over TCP listener Please consult the respective section in Listener modules . listen.s2s - incoming S2S connections (XMPP Federation) Please consult the respective section in Listener modules . s2s - outgoing S2S connections (XMPP Federation) Please check the documentation for s2s_ciphers option. mod_global_distrib - Global Distribution module Please add connections.tls.ciphers = \"string\" to modules.mod_global_distrib module, as described in the documentation .","title":"TLS hardening"},{"location":"advanced-configuration/TLS-hardening/#otp-tls-vs-fast-tls","text":"Before we explain the TLS hardening in MongooseIM, we need to describe the TLS libraries used in the project. These are \"OTP TLS\" and \"Fast TLS\". The former is provided by (as the name suggests) OTP as the ssl application. Large part of the logic is implemented in Erlang but it calls OpenSSL API for some operations anyway. The latter is a community-maintained driver, which is implemented as NIFs (native C code). It uses OpenSSL API for all operations. Most MongooseIM components use the TLS library provided by OTP. However, some of them choose to integrate with fast_tls library instead. The former one is used primarily by MIM dependencies, while the latter is used only by MIM modules. None of them is strictly better than the other. Below you may find a summary of the differences between them. fast_tls is faster There are options that OTP TLS (a.k.a just_tls in the ejabberd_c2s configuration) supports exclusively: Immediate connection drop when the client certificate is invalid Certificate Revocation Lists More flexible certificate verification options Allowed protocol versions may be configured: Globally for OTP TLS via an environment variable Per socket in Fast TLS via OpenSSL cipher string","title":"OTP TLS vs. Fast TLS"},{"location":"advanced-configuration/TLS-hardening/#deprecations","text":"MongooseIM is configured to allow only TLS 1.2 or higher, due to known vulnerabilities in TLS 1.0 and 1.1. It is still possible to enable earlier versions, however it is strongly discouraged.","title":"Deprecations"},{"location":"advanced-configuration/TLS-hardening/#otp-tls-hardening","text":"Protocol list for OTP TLS is set via the protocol_version environment variable. It's an Erlang runtime variable, so it is not configured in the OS but rather in the app.config file. It may be found in etc/ folder inside MongooseIM release and in [repository root]/rel/files/ . In order to change the list, please find the following lines: 1 2 3 {protocol_version, ['tlsv1.2' %, 'tlsv1.3' % supported in OTP >= 22 ]} By default only TLS 1.2 is enabled, as 1.3 is not supported by OTPs older than 22.0. If you are using OTP 22.0 or newer, you may remove leading % before 'tlsv1.3' . The remaining valid values are: 'tlsv1.1' , tlsv1 , sslv3 . This setting affects the following MongooseIM components: Raw XMPP over TCP connections, if ejabberd_c2s listener is configured to use just_tls All outgoing connections (databases, AMQP, SIP etc.) HTTP endpoints","title":"OTP TLS hardening"},{"location":"advanced-configuration/TLS-hardening/#fast-tls-hardening","text":"Fast TLS expects an OpenSSL cipher string as one of optional connection parameters. This string is configured individually for every module that uses it. By default, MongooseIM sets this option to TLSv1.2:TLSv1.3 for each component. The list below enumerates all components that use Fast TLS and describes how to change this string. listen.c2s - main user session abstraction + XMPP over TCP listener Please consult the respective section in Listener modules . listen.s2s - incoming S2S connections (XMPP Federation) Please consult the respective section in Listener modules . s2s - outgoing S2S connections (XMPP Federation) Please check the documentation for s2s_ciphers option. mod_global_distrib - Global Distribution module Please add connections.tls.ciphers = \"string\" to modules.mod_global_distrib module, as described in the documentation .","title":"Fast TLS hardening"},{"location":"advanced-configuration/access/","text":"The access section is used to define access rules which return specific values for specific access classes. Scope: global Syntax: each access rule is a key-value pair, where: Key is the name of the rule, Value is a TOML array of rule clauses - TOML tables, whose format is described below. Default: no default - each access rule needs to be specified explicitly. Example: see the examples below. Access rule clauses Whenever a rule is checked to obtain the resulting value for a user, the clauses are traversed one by one until a matching one is found or the list is exhausted (in which case the special value deny is returned). Each clause has to contain the following keys: access.*.acl Syntax: string Example: acl = \"local\" The access class defined in the acl section. The user is matched against it. The special name all is a catch-all value that matches any user. If the class does not exist, the clause does not match (there is no error). access.*.value Syntax: string or integer Example: value = \"allow\" For rules determining access, the value will be \"allow\" or \"deny\" . For other rules it can be an integer or a string. Rule examples The following access rules are already defined in the example configuration file. C2S Access The c2s rule is used to allow/deny the users to establish C2S connections: 1 2 3 4 c2s = [ { acl = \"blocked\" , value = \"deny\" }, { acl = \"all\" , value = \"allow\" } ] It has the following logic: if the access class is blocked , the returned value is \"deny\" , otherwise, the returned value is \"allow\" . The blocked access class can be defined in the acl section and match blacklisted users. For this rule to take effect, it needs to be referenced in the options of a C2S listener . C2S Shaper The c2s_shaper rule is used to determine the shaper used to limit the incoming traffic on C2S connections: 1 2 3 4 c2s_shaper = [ { acl = \"admin\" , value = \"none\" }, { acl = \"all\" , value = \"normal\" } ] It has the following logic: if the access class is admin , the returned value is \"none\" , otherwise, the returned value is \"normal\" . The admin access class can be defined in the acl to specify admin users who will bypass the normal shaper. For this rule to take effect, it needs to be referenced in the options of a C2S listener . S2S Shaper The s2s_shaper rule is used to determine the shaper used to limit the incoming traffic on C2S connections: 1 2 3 s2s_shaper = [ { acl = \"all\" , value = \"fast\" } ] It assigns the fast shaper to all S2S connections. For this rule to take effect, it needs to be referenced in the options of an S2S listener . MUC The following rules manage the permissions of MUC operations: 1 2 3 4 5 6 7 8 9 10 11 muc_admin = [ { acl = \"admin\" , value = \"allow\" } ] muc_create = [ { acl = \"local\" , value = \"allow\" } ] muc = [ { acl = \"all\" , value = \"allow\" } ] They are referenced in the options of the mod_muc module. Registration This rule manages the permissions to create new users with mod_register . 1 2 3 register = [ { acl = \"all\" , value = \"allow\" } ] It needs to be referenced in the options of the mod_register module. MAM permissions These rules set the permissions for MAM operations triggered by IQ stanzas and handled by the mod_mam module. 1 2 3 4 5 6 7 8 9 10 11 mam_set_prefs = [ { acl = \"all\" , value = \"default\" } ] mam_get_prefs = [ { acl = \"all\" , value = \"default\" } ] mam_lookup_messages = [ { acl = \"all\" , value = \"default\" } ] They can return \"allow\" , \"deny\" or \"default\" . The last value uses the default setting for the operation, which is to allow the operation when the sender and recipient JID's are the same. MAM for MUC permissions has muc_ prefix: 1 2 3 4 5 6 7 8 9 10 11 muc_mam_set_prefs = [ { acl = \"all\" , value = \"default\" } ] muc_mam_get_prefs = [ { acl = \"all\" , value = \"default\" } ] muc_mam_lookup_messages = [ { acl = \"all\" , value = \"default\" } ] MAM shapers These rules limit the rate of MAM operations triggered by IQ stanzas. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 mam_set_prefs_shaper = [ { acl = \"all\" , value = \"mam_shaper\" } ] mam_get_prefs_shaper = [ { acl = \"all\" , value = \"mam_shaper\" } ] mam_lookup_messages_shaper = [ { acl = \"all\" , value = \"mam_shaper\" } ] mam_set_prefs_global_shaper = [ { acl = \"all\" , value = \"mam_global_shaper\" } ] mam_get_prefs_global_shaper = [ { acl = \"all\" , value = \"mam_global_shaper\" } ] mam_lookup_messages_global_shaper = [ { acl = \"all\" , value = \"mam_global_shaper\" } ] For each operation there are two rules: *_shaper - limits the number of operations per user connection per second, *_global_shaper - limits the number of operations per server node per second. The values returned by the rules ( mam_shaper , mam_global_shaper ) are shaper names, which need to be defined in the shaper section . MAM for MUC shapers has muc_ prefix. Maximum number of sessions The max_user_sessions rule is used to determine the maximum number of sessions a user can open. 1 2 3 max_user_sessions = [ { acl = \"all\" , value = 10 } ] By default all users can open at most 10 concurrent sessions. Maximum number of offline messages The max_user_offline_messages rule is used to determine the maximum number of messages that is stored for a user by the mod_offline module . 1 2 3 4 max_user_offline_messages = [ { acl = \"admin\" , value = 5000 }, { acl = \"all\" , value = 100 } ] It has the following logic: if the access class is admin , the returned value is 5000 , otherwise, the returned value is 100 . This means that the admin users can have 5000 messages stored offline, while the others can have at most 100. The admin access class can be defined in the acl section . For developers To access the rule functionality, one has to use the acl:match_rule/3 function. Given the following rule: 1 2 3 register = [ { acl = \"all\" , value = \"deny\" } ] One can call: acl:match_rule(<<\"localhost\">>, register, jid:make(<<\"p\">>, <<\"localhost\">>, <<>>)). Which in our case will return deny . If the rule is not host specific, one can use global instead of <<\"localhost\">> .","title":"Options: Access"},{"location":"advanced-configuration/access/#access-rule-clauses","text":"Whenever a rule is checked to obtain the resulting value for a user, the clauses are traversed one by one until a matching one is found or the list is exhausted (in which case the special value deny is returned). Each clause has to contain the following keys:","title":"Access rule clauses"},{"location":"advanced-configuration/access/#accessacl","text":"Syntax: string Example: acl = \"local\" The access class defined in the acl section. The user is matched against it. The special name all is a catch-all value that matches any user. If the class does not exist, the clause does not match (there is no error).","title":"access.*.acl"},{"location":"advanced-configuration/access/#accessvalue","text":"Syntax: string or integer Example: value = \"allow\" For rules determining access, the value will be \"allow\" or \"deny\" . For other rules it can be an integer or a string.","title":"access.*.value"},{"location":"advanced-configuration/access/#rule-examples","text":"The following access rules are already defined in the example configuration file.","title":"Rule examples"},{"location":"advanced-configuration/access/#c2s-access","text":"The c2s rule is used to allow/deny the users to establish C2S connections: 1 2 3 4 c2s = [ { acl = \"blocked\" , value = \"deny\" }, { acl = \"all\" , value = \"allow\" } ] It has the following logic: if the access class is blocked , the returned value is \"deny\" , otherwise, the returned value is \"allow\" . The blocked access class can be defined in the acl section and match blacklisted users. For this rule to take effect, it needs to be referenced in the options of a C2S listener .","title":"C2S Access"},{"location":"advanced-configuration/access/#c2s-shaper","text":"The c2s_shaper rule is used to determine the shaper used to limit the incoming traffic on C2S connections: 1 2 3 4 c2s_shaper = [ { acl = \"admin\" , value = \"none\" }, { acl = \"all\" , value = \"normal\" } ] It has the following logic: if the access class is admin , the returned value is \"none\" , otherwise, the returned value is \"normal\" . The admin access class can be defined in the acl to specify admin users who will bypass the normal shaper. For this rule to take effect, it needs to be referenced in the options of a C2S listener .","title":"C2S Shaper"},{"location":"advanced-configuration/access/#s2s-shaper","text":"The s2s_shaper rule is used to determine the shaper used to limit the incoming traffic on C2S connections: 1 2 3 s2s_shaper = [ { acl = \"all\" , value = \"fast\" } ] It assigns the fast shaper to all S2S connections. For this rule to take effect, it needs to be referenced in the options of an S2S listener .","title":"S2S Shaper"},{"location":"advanced-configuration/access/#muc","text":"The following rules manage the permissions of MUC operations: 1 2 3 4 5 6 7 8 9 10 11 muc_admin = [ { acl = \"admin\" , value = \"allow\" } ] muc_create = [ { acl = \"local\" , value = \"allow\" } ] muc = [ { acl = \"all\" , value = \"allow\" } ] They are referenced in the options of the mod_muc module.","title":"MUC"},{"location":"advanced-configuration/access/#registration","text":"This rule manages the permissions to create new users with mod_register . 1 2 3 register = [ { acl = \"all\" , value = \"allow\" } ] It needs to be referenced in the options of the mod_register module.","title":"Registration"},{"location":"advanced-configuration/access/#mam-permissions","text":"These rules set the permissions for MAM operations triggered by IQ stanzas and handled by the mod_mam module. 1 2 3 4 5 6 7 8 9 10 11 mam_set_prefs = [ { acl = \"all\" , value = \"default\" } ] mam_get_prefs = [ { acl = \"all\" , value = \"default\" } ] mam_lookup_messages = [ { acl = \"all\" , value = \"default\" } ] They can return \"allow\" , \"deny\" or \"default\" . The last value uses the default setting for the operation, which is to allow the operation when the sender and recipient JID's are the same. MAM for MUC permissions has muc_ prefix: 1 2 3 4 5 6 7 8 9 10 11 muc_mam_set_prefs = [ { acl = \"all\" , value = \"default\" } ] muc_mam_get_prefs = [ { acl = \"all\" , value = \"default\" } ] muc_mam_lookup_messages = [ { acl = \"all\" , value = \"default\" } ]","title":"MAM permissions"},{"location":"advanced-configuration/access/#mam-shapers","text":"These rules limit the rate of MAM operations triggered by IQ stanzas. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 mam_set_prefs_shaper = [ { acl = \"all\" , value = \"mam_shaper\" } ] mam_get_prefs_shaper = [ { acl = \"all\" , value = \"mam_shaper\" } ] mam_lookup_messages_shaper = [ { acl = \"all\" , value = \"mam_shaper\" } ] mam_set_prefs_global_shaper = [ { acl = \"all\" , value = \"mam_global_shaper\" } ] mam_get_prefs_global_shaper = [ { acl = \"all\" , value = \"mam_global_shaper\" } ] mam_lookup_messages_global_shaper = [ { acl = \"all\" , value = \"mam_global_shaper\" } ] For each operation there are two rules: *_shaper - limits the number of operations per user connection per second, *_global_shaper - limits the number of operations per server node per second. The values returned by the rules ( mam_shaper , mam_global_shaper ) are shaper names, which need to be defined in the shaper section . MAM for MUC shapers has muc_ prefix.","title":"MAM shapers"},{"location":"advanced-configuration/access/#maximum-number-of-sessions","text":"The max_user_sessions rule is used to determine the maximum number of sessions a user can open. 1 2 3 max_user_sessions = [ { acl = \"all\" , value = 10 } ] By default all users can open at most 10 concurrent sessions.","title":"Maximum number of sessions"},{"location":"advanced-configuration/access/#maximum-number-of-offline-messages","text":"The max_user_offline_messages rule is used to determine the maximum number of messages that is stored for a user by the mod_offline module . 1 2 3 4 max_user_offline_messages = [ { acl = \"admin\" , value = 5000 }, { acl = \"all\" , value = 100 } ] It has the following logic: if the access class is admin , the returned value is 5000 , otherwise, the returned value is 100 . This means that the admin users can have 5000 messages stored offline, while the others can have at most 100. The admin access class can be defined in the acl section .","title":"Maximum number of offline messages"},{"location":"advanced-configuration/access/#for-developers","text":"To access the rule functionality, one has to use the acl:match_rule/3 function. Given the following rule: 1 2 3 register = [ { acl = \"all\" , value = \"deny\" } ] One can call: acl:match_rule(<<\"localhost\">>, register, jid:make(<<\"p\">>, <<\"localhost\">>, <<>>)). Which in our case will return deny . If the rule is not host specific, one can use global instead of <<\"localhost\">> .","title":"For developers"},{"location":"advanced-configuration/acl/","text":"The acl section is used to define access classes to which the connecting users are assigned. These classes are used in access rules . Scope: global Syntax: each access class is a key-value pair, where: Key is the name of the access class, Value is a TOML array of patterns - TOML tables, whose format is described below. Default: no default - each access class needs to be specified explicitly. Example: the local access class is used for the regular users connecting to the C2S listener . 1 2 3 local = [ { user_regexp = \"\" } ] When there are multiple patterns listed, the resulting pattern will be the union of all of them. Patterns The options listed below are used to assign the users to the access class. There are no default values for any of them. Note: the options can NOT be combined with each other unless the description says otherwise. acl.*.match Syntax: string, one of: \"all\" , \"none\" Example: match = \"all\" Matches either all users or none of them. The latter is useful for disabling access to some services. 1 2 3 everyone = [ { match = \"all\" } ] acl.*.user Syntax: string Example: user = \"admin\" Matches all JIDs with the specified user name. The following class includes alice@localhost , but not bob@localhost : 1 2 3 4 admin = [ { user = \"alice\" }, { user = \"charlie\" } ] acl.*.server Syntax: string Example: server = \"localhost\" Matches all JIDs with the specified domain name. The following class includes alice@localhost , but not alice@xmpp.org : 1 2 3 localhost_users = [ { server = \"localhost\" } ] This option can be combined with user - only alice@localhost belongs to the following class: 1 2 3 admin = [ { user = \"alice\" , server = \"localhost\" } ] acl.*.resource Syntax: string Example: resource = \"mobile\" Matches all JIDs with the specified resource name. The following class includes alice@localhost/mobile , but not alice@localhost/home : 1 2 3 mobile_users = [ { resource = \"mobile\" } ] acl.*.user_regexp Syntax: string, regular expression Example: user_regexp = \"^user.*\" Matches all JIDs with the user name matching the regular expression. The following class includes alice@localhost and albert@jabber.org , but not bob@localhost : 1 2 3 ae = [ { user_regexp = \"^a.*e\" } ] This option can be combined with server - here albert@jabber.org is excluded: 1 2 3 localhost_ae = [ { user_regexp = \"^a.*e\" , server = \"localhost\" } ] acl.*.server_regexp Syntax: string, regular expression Example: server = \"localhost\" Matches all JIDs with the domain name matching the regular expression. The following class includes alice@host1 , but not alice@xmpp.org : 1 2 3 host_users = [ { server_regexp = \"host\" } ] This option can be combined with user_regexp , e.g. we can require the user name to contain 'a' and the domain name to start with 'a': 1 2 3 a = [ { user_regexp = \"a\" , server_regexp = \"^a\" } ] acl.*.resource_regexp Syntax: string, regular expression Example: resource_regexp = \"^res\" Matches all JIDs with the resource name matching the regular expression. This class includes bob@xmpp.org/res123 , but not bob@xmpp.org/home : 1 2 3 digital_resources = [ { resource_regexp = '^res\\d+$' } ] Note the use of a literal string (single quotes) to prevent \\d from being escaped. acl.*.user_glob Syntax: string, glob pattern Example: user_glob = \"^user.*\" Matches all JIDs with the user name matching the pattern: The following class includes alice@localhost and albert@jabber.org , but not bob@localhost : 1 2 3 ae_users = [ { user_glob = \"a*e*\" } ] This option can be combined with server - here albert@jabber.org is excluded: 1 2 3 localhost_ae_users = [ { user_glob = \"a*e*\" , server = \"localhost\" } ] acl.*.server_glob Syntax: string, glob pattern Example: server = \"localhost\" Matches all JIDs with the domain name matching the pattern. The following class includes alice@host1 , but not alice@xmpp.org : 1 2 3 localhost_users = [ { server_glob = \"host*\" } ] This option can be combined with user_glob , e.g. we can require the user name to contain 'a' and the domain name to start with 'a': 1 2 3 a = [ { user_glob = \"*a*\" , server_glob = \"a*\" } ] acl.*.resource_glob Syntax: string, glob pattern Example: resource_glob = \"^res\" Matches all JIDs with the resource name matching the pattern. This class includes bob@xmpp.org/res123 , but not bob@xmpp.org/home : 1 2 3 limited_resources = [ { resource_glob = \"res???\" } ]","title":"Options: Acl"},{"location":"advanced-configuration/acl/#patterns","text":"The options listed below are used to assign the users to the access class. There are no default values for any of them. Note: the options can NOT be combined with each other unless the description says otherwise.","title":"Patterns"},{"location":"advanced-configuration/acl/#aclmatch","text":"Syntax: string, one of: \"all\" , \"none\" Example: match = \"all\" Matches either all users or none of them. The latter is useful for disabling access to some services. 1 2 3 everyone = [ { match = \"all\" } ]","title":"acl.*.match"},{"location":"advanced-configuration/acl/#acluser","text":"Syntax: string Example: user = \"admin\" Matches all JIDs with the specified user name. The following class includes alice@localhost , but not bob@localhost : 1 2 3 4 admin = [ { user = \"alice\" }, { user = \"charlie\" } ]","title":"acl.*.user"},{"location":"advanced-configuration/acl/#aclserver","text":"Syntax: string Example: server = \"localhost\" Matches all JIDs with the specified domain name. The following class includes alice@localhost , but not alice@xmpp.org : 1 2 3 localhost_users = [ { server = \"localhost\" } ] This option can be combined with user - only alice@localhost belongs to the following class: 1 2 3 admin = [ { user = \"alice\" , server = \"localhost\" } ]","title":"acl.*.server"},{"location":"advanced-configuration/acl/#aclresource","text":"Syntax: string Example: resource = \"mobile\" Matches all JIDs with the specified resource name. The following class includes alice@localhost/mobile , but not alice@localhost/home : 1 2 3 mobile_users = [ { resource = \"mobile\" } ]","title":"acl.*.resource"},{"location":"advanced-configuration/acl/#acluser_regexp","text":"Syntax: string, regular expression Example: user_regexp = \"^user.*\" Matches all JIDs with the user name matching the regular expression. The following class includes alice@localhost and albert@jabber.org , but not bob@localhost : 1 2 3 ae = [ { user_regexp = \"^a.*e\" } ] This option can be combined with server - here albert@jabber.org is excluded: 1 2 3 localhost_ae = [ { user_regexp = \"^a.*e\" , server = \"localhost\" } ]","title":"acl.*.user_regexp"},{"location":"advanced-configuration/acl/#aclserver_regexp","text":"Syntax: string, regular expression Example: server = \"localhost\" Matches all JIDs with the domain name matching the regular expression. The following class includes alice@host1 , but not alice@xmpp.org : 1 2 3 host_users = [ { server_regexp = \"host\" } ] This option can be combined with user_regexp , e.g. we can require the user name to contain 'a' and the domain name to start with 'a': 1 2 3 a = [ { user_regexp = \"a\" , server_regexp = \"^a\" } ]","title":"acl.*.server_regexp"},{"location":"advanced-configuration/acl/#aclresource_regexp","text":"Syntax: string, regular expression Example: resource_regexp = \"^res\" Matches all JIDs with the resource name matching the regular expression. This class includes bob@xmpp.org/res123 , but not bob@xmpp.org/home : 1 2 3 digital_resources = [ { resource_regexp = '^res\\d+$' } ] Note the use of a literal string (single quotes) to prevent \\d from being escaped.","title":"acl.*.resource_regexp"},{"location":"advanced-configuration/acl/#acluser_glob","text":"Syntax: string, glob pattern Example: user_glob = \"^user.*\" Matches all JIDs with the user name matching the pattern: The following class includes alice@localhost and albert@jabber.org , but not bob@localhost : 1 2 3 ae_users = [ { user_glob = \"a*e*\" } ] This option can be combined with server - here albert@jabber.org is excluded: 1 2 3 localhost_ae_users = [ { user_glob = \"a*e*\" , server = \"localhost\" } ]","title":"acl.*.user_glob"},{"location":"advanced-configuration/acl/#aclserver_glob","text":"Syntax: string, glob pattern Example: server = \"localhost\" Matches all JIDs with the domain name matching the pattern. The following class includes alice@host1 , but not alice@xmpp.org : 1 2 3 localhost_users = [ { server_glob = \"host*\" } ] This option can be combined with user_glob , e.g. we can require the user name to contain 'a' and the domain name to start with 'a': 1 2 3 a = [ { user_glob = \"*a*\" , server_glob = \"a*\" } ]","title":"acl.*.server_glob"},{"location":"advanced-configuration/acl/#aclresource_glob","text":"Syntax: string, glob pattern Example: resource_glob = \"^res\" Matches all JIDs with the resource name matching the pattern. This class includes bob@xmpp.org/res123 , but not bob@xmpp.org/home : 1 2 3 limited_resources = [ { resource_glob = \"res???\" } ]","title":"acl.*.resource_glob"},{"location":"advanced-configuration/auth/","text":"The auth section is used to choose and configure the methods which are used by MongooseIM to authenticate connecting users. The following methods are supported: internal - stores the user accounts in an internal Mnesia database, rdbms - stores the user accounts in a SQL database, external - uses an external program to authenticate the user, anonymous - allows anonymous connections, ldap - checks the user credentials in LDAP, jwt - authenticates the users with JSON Web Tokens, riak - stores the user accounts in a Riak database, http - uses an external HTTP service to authenticate the user, pki - uses the certificate provided by the user to authenticate them, dummy - no authentication, only for development and testing. To enable user connections, you need to set up at least one of the methods listed above (see auth.methods below). Some methods have more complex setup procedures - the method names above are links to their descriptions, which list their specific configuration options. The general options are described below. General Options The options listed here are used to configure the authentication methods. auth.methods Syntax: array of strings. Allowed values: \"internal\" , \"rdbms\" , \"external\" , \"anonymous\" , \"ldap\" , \"jwt\" , \"riak\" , \"http\" , \"pki\" , \"dummy\" Default: not set Example: methods = [\"internal\", \"anonymous\"] Specifies the methods used to authenticate connecting users. Methods from the list are queried one after another until one of them replies positively. By default there are no methods, so nobody can authenticate. Warning: Make sure that the compatible SASL mechanisms are enabled, see capabilities . auth.sasl_mechanisms Syntax: array of strings. Allowed values: \"scram_sha512_plus\" , \"scram_sha512\" , \"scram_sha384_plus\" , \"scram_sha384\" , \"scram_sha256_plus\" , \"scram_sha256\" , \"scram_sha224_plus\" , \"scram_sha224\" , \"scram_sha1_plus\" , \"scram_sha1\" , \"plain\" , \"anonymous\" , \"oauth\" , \"external\" , \"digest\" Default: [\"scram_sha512_plus\", \"scram_sha512\", \"scram_sha384_plus\", \"scram_sha384\", \"scram_sha256_plus\", \"scram_sha256\", \"scram_sha224_plus\", \"scram_sha224\", \"scram_sha1_plus\", \"scram_sha1\", \"plain\", \"anonymous\", \"oauth\"] Example: sasl_mechanisms = [\"external\", \"plain\"] Specifies the list of allowed SASL mechanisms, which are announced during stream negotiation and eventually enforced (users can't pick a mechanism not listed here). Notes: This list is still filtered by capabilities . Configuring the sasl_mechanisms replaces the default list entirely. The order in which the mechanisms are listed in the config will be taken as the order in which they are advertised. All SCRAM-SHA-* mechanisms (specified as scram_sha* ) have their counterparts which support channel binding and are advertised as separate authentication mechanisms suffixed by -PLUS (specified as scram_sha*_plus ). The DIGEST-MD5 mechanism (specified as digest ) is deprecated and will be removed in the next release. Authentication method capabilities The table below shows the supported SASL mechanisms (columns) for each authentication method (row). plain digest scram_sha* anonymous external internal x x x rdbms x x x external x anonymous x x x x ldap x x jwt x riak x x x http x x x pki x auth.sasl_external Syntax: list of strings, allowed values: \"standard\" , \"common_name\" , \"auth_id\" Default: [\"standard\"] Example: sasl_external = [\"standard\", \"common_name\"] There are three possible ways of using the SASL EXTERNAL mechanism: standard - do not accept a certificate with no xmpp_addrs field (default), common_name - use the common_name field if it is provided in the certificate, auth_id - accept a certificate without xmpp_addrs and use the user identity from the authentication request. This option allows you to list the enabled ones in the order of preference (they are tried until one succeeds or the list is exhausted). Password-related options These options are common to the http , rdbms , internal and riak methods. auth.password.format Syntax: string, one of: \"plain\" , \"scram\" Default: \"scram\" Example: password.format = \"plain\" Decide whether user passwords will be kept plain or hashed in the database. Currently, popular XMPP clients support the SCRAM method and it is strongly recommended to use the hashed version. The older XMPP clients can still use the PLAIN mechanism. Note: The DIGEST-MD5 mechanism is not available with the scram password format. auth.password.hash Syntax: list of strings, allowed values: \"sha\" , \"sha224\" , \"sha256\" , \"sha384\" , \"sha512\" Default: not set - all hash functions supported Example: password.hash = [\"sha384\", \"sha512\"] MongooseIM supports SHA-1, SHA-224, SHA-256, SHA-384 and SHA-512 for SCRAM hashing. You can use this option to limit the supported hash functions by listing them explicitly. The value \"sha\" stands for the SHA-1 algorithm. auth.scram_iterations Syntax: positive integer Default: 10000, as recommended in this XEP and this NIST Guidelines Example: scram_iterations = 20_000 Hash function round count. This is a tradeoff between latency and security. The higher the value, the more difficult breaking the hashes is: increasing the count increases the work it requires to compute a full derivation, which effectively slows down brute-force attacks. But it adds load on both client and server, so this parameter should be tuned as high as the business-rules allow. Note that increasing the security of a password has a higher impact over the security of the algorithm, without impacting its load. See more information in this NIST guide, Appendix A.2.2 Example This minimal authentication setup uses the internal Mnesia database to store users and their passwords: 1 2 [auth] methods = [\"internal\"] According to the capabilities of the internal method, the PLAIN , DIGEST-MD5 and SCRAM-SHA-* mechanisms will be supported. However, for production systems other methods like rdbms are recommended, as using an external database offers easier maintenance, flexibility, scalability and configurability in a typical setup. Method-specific options See the links below for options related to the particular methods: RDBMS method options Anonymous method options External method options LDAP method options JWT method options Riak method options HTTP method options","title":"Options: Auth"},{"location":"advanced-configuration/auth/#general-options","text":"The options listed here are used to configure the authentication methods.","title":"General Options"},{"location":"advanced-configuration/auth/#authmethods","text":"Syntax: array of strings. Allowed values: \"internal\" , \"rdbms\" , \"external\" , \"anonymous\" , \"ldap\" , \"jwt\" , \"riak\" , \"http\" , \"pki\" , \"dummy\" Default: not set Example: methods = [\"internal\", \"anonymous\"] Specifies the methods used to authenticate connecting users. Methods from the list are queried one after another until one of them replies positively. By default there are no methods, so nobody can authenticate. Warning: Make sure that the compatible SASL mechanisms are enabled, see capabilities .","title":"auth.methods"},{"location":"advanced-configuration/auth/#authsasl_mechanisms","text":"Syntax: array of strings. Allowed values: \"scram_sha512_plus\" , \"scram_sha512\" , \"scram_sha384_plus\" , \"scram_sha384\" , \"scram_sha256_plus\" , \"scram_sha256\" , \"scram_sha224_plus\" , \"scram_sha224\" , \"scram_sha1_plus\" , \"scram_sha1\" , \"plain\" , \"anonymous\" , \"oauth\" , \"external\" , \"digest\" Default: [\"scram_sha512_plus\", \"scram_sha512\", \"scram_sha384_plus\", \"scram_sha384\", \"scram_sha256_plus\", \"scram_sha256\", \"scram_sha224_plus\", \"scram_sha224\", \"scram_sha1_plus\", \"scram_sha1\", \"plain\", \"anonymous\", \"oauth\"] Example: sasl_mechanisms = [\"external\", \"plain\"] Specifies the list of allowed SASL mechanisms, which are announced during stream negotiation and eventually enforced (users can't pick a mechanism not listed here). Notes: This list is still filtered by capabilities . Configuring the sasl_mechanisms replaces the default list entirely. The order in which the mechanisms are listed in the config will be taken as the order in which they are advertised. All SCRAM-SHA-* mechanisms (specified as scram_sha* ) have their counterparts which support channel binding and are advertised as separate authentication mechanisms suffixed by -PLUS (specified as scram_sha*_plus ). The DIGEST-MD5 mechanism (specified as digest ) is deprecated and will be removed in the next release.","title":"auth.sasl_mechanisms"},{"location":"advanced-configuration/auth/#authentication-method-capabilities","text":"The table below shows the supported SASL mechanisms (columns) for each authentication method (row). plain digest scram_sha* anonymous external internal x x x rdbms x x x external x anonymous x x x x ldap x x jwt x riak x x x http x x x pki x","title":"Authentication method capabilities"},{"location":"advanced-configuration/auth/#authsasl_external","text":"Syntax: list of strings, allowed values: \"standard\" , \"common_name\" , \"auth_id\" Default: [\"standard\"] Example: sasl_external = [\"standard\", \"common_name\"] There are three possible ways of using the SASL EXTERNAL mechanism: standard - do not accept a certificate with no xmpp_addrs field (default), common_name - use the common_name field if it is provided in the certificate, auth_id - accept a certificate without xmpp_addrs and use the user identity from the authentication request. This option allows you to list the enabled ones in the order of preference (they are tried until one succeeds or the list is exhausted).","title":"auth.sasl_external"},{"location":"advanced-configuration/auth/#password-related-options","text":"These options are common to the http , rdbms , internal and riak methods.","title":"Password-related options"},{"location":"advanced-configuration/auth/#authpasswordformat","text":"Syntax: string, one of: \"plain\" , \"scram\" Default: \"scram\" Example: password.format = \"plain\" Decide whether user passwords will be kept plain or hashed in the database. Currently, popular XMPP clients support the SCRAM method and it is strongly recommended to use the hashed version. The older XMPP clients can still use the PLAIN mechanism. Note: The DIGEST-MD5 mechanism is not available with the scram password format.","title":"auth.password.format"},{"location":"advanced-configuration/auth/#authpasswordhash","text":"Syntax: list of strings, allowed values: \"sha\" , \"sha224\" , \"sha256\" , \"sha384\" , \"sha512\" Default: not set - all hash functions supported Example: password.hash = [\"sha384\", \"sha512\"] MongooseIM supports SHA-1, SHA-224, SHA-256, SHA-384 and SHA-512 for SCRAM hashing. You can use this option to limit the supported hash functions by listing them explicitly. The value \"sha\" stands for the SHA-1 algorithm.","title":"auth.password.hash"},{"location":"advanced-configuration/auth/#authscram_iterations","text":"Syntax: positive integer Default: 10000, as recommended in this XEP and this NIST Guidelines Example: scram_iterations = 20_000 Hash function round count. This is a tradeoff between latency and security. The higher the value, the more difficult breaking the hashes is: increasing the count increases the work it requires to compute a full derivation, which effectively slows down brute-force attacks. But it adds load on both client and server, so this parameter should be tuned as high as the business-rules allow. Note that increasing the security of a password has a higher impact over the security of the algorithm, without impacting its load. See more information in this NIST guide, Appendix A.2.2","title":"auth.scram_iterations"},{"location":"advanced-configuration/auth/#example","text":"This minimal authentication setup uses the internal Mnesia database to store users and their passwords: 1 2 [auth] methods = [\"internal\"] According to the capabilities of the internal method, the PLAIN , DIGEST-MD5 and SCRAM-SHA-* mechanisms will be supported. However, for production systems other methods like rdbms are recommended, as using an external database offers easier maintenance, flexibility, scalability and configurability in a typical setup.","title":"Example"},{"location":"advanced-configuration/auth/#method-specific-options","text":"See the links below for options related to the particular methods: RDBMS method options Anonymous method options External method options LDAP method options JWT method options Riak method options HTTP method options","title":"Method-specific options"},{"location":"advanced-configuration/configuration-files/","text":"The following files are used to configure MongooseIM: mongooseim.toml for MongooseIM settings, vm.args to affect the Erlang VM behaviour (performance tuning, node name), app.config to change low-level logging parameters and settings of other Erlang applications. mongooseim.toml This TOML file contains the configuration options for the MongooseIM server. It is located at [MongooseIM repo root]/rel/files/ if you are building from source or [MongooseIM install root]/etc/ if you are using a pre-built version. The file is divided into the following sections: general - Served XMPP domains, log level, server language and some other miscellaneous settings. listen - Configured listeners, receiving incoming XMPP and HTTP connections. auth - Supported client authentication methods and their options. outgoing_pools - Outgoing connections to external services, including databases, message queues and HTTP services. services - Internal services like an administration API and system metrics. modules - XMPP extension modules, which extend the basic functionality provided by XMPP. shaper - Traffic shapers that limit the incoming XMPP traffic, providing a safety valve to protect the server. acl - Access classes to which connecting users are assigned. access - Access rules, specifying the privileges of the defined access classes. s2s - Server-to-server connection options, used for XMPP federation. host_config - Configuration options that need to be different for a specific XMPP domain. The section names above are links to the detailed documentation of each section. Option scope Each configuration option has its scope , which is one of the following: local - configured separately for each node in the cluster - each node can have a different value, global - configured for the entire cluster - all nodes share the same value. The scope of each option is defined in the documentation above - either at the top of the section page or for each option individually. vm.args This file contains parameters passed directly to the Erlang VM. To configure it, go to [MongooseIM root]/rel/files/ . Let's explore the default options. Options -sname - Erlang node name. Can be changed to name , if necessary -setcookie - Erlang cookie. All nodes in a cluster must use the same cookie value. +K - Enables kernel polling. It improves the stability when a large number of sockets is opened, but some systems might benefit from disabling it. Might be a subject of individual load testing. +A 5 - Sets the asynchronous threads number. Async threads improve I/O operations efficiency by relieving scheduler threads of IO waits. +P 10000000 - Process count limit. This is a maximum allowed number of processes running per node. In general, it should exceed the tripled estimated online user count. -env ERL_MAX_PORTS 250000 - Open port count. This is a maximum allowed number of ports opened per node. In general, it should exceed the tripled estimated online user count. Keep in mind that increasing this number also increases the memory usage by a constant amount, so finding the right balance for it is important for every project. -env ERL_FULLSWEEP_AFTER 2 - affects garbage collection. Reduces memory consumption (forces often full g.c.) at the expense of CPU usage. -sasl sasl_error_logger false - MongooseIM's solution for logging is Lager, so SASL error logger is disabled. app.config A file with Erlang application configuration. To configure it, go to [MongooseIM root]/rel/files/ . By default only the following applications can be found there: logger - check Logger's documentation for more information. ssl session_lifetime (default specified in the file: 600 seconds) - This parameter says for how long should the ssl session remain in the cache for further re-use, should ssl session resumption happen. Configuring TLS: Certificates & Keys TLS is configured in one of two ways: some modules need a private key and certificate (chain) in separate files, while others need both in a single file. This is because recent additions use OTP's ssl library, while older modules use p1_tls , respectively. Client-to-server connections need both in the same .pem file Server-to-server connections need both in the same .pem file BOSH, WebSockets and REST APIs need them in separate files In order to create private key & certificate bundle, you may simply concatenate them. More information about configuring TLS for these endpoints is available in the listen section configuration page.","title":"Configuration files"},{"location":"advanced-configuration/configuration-files/#mongooseimtoml","text":"This TOML file contains the configuration options for the MongooseIM server. It is located at [MongooseIM repo root]/rel/files/ if you are building from source or [MongooseIM install root]/etc/ if you are using a pre-built version. The file is divided into the following sections: general - Served XMPP domains, log level, server language and some other miscellaneous settings. listen - Configured listeners, receiving incoming XMPP and HTTP connections. auth - Supported client authentication methods and their options. outgoing_pools - Outgoing connections to external services, including databases, message queues and HTTP services. services - Internal services like an administration API and system metrics. modules - XMPP extension modules, which extend the basic functionality provided by XMPP. shaper - Traffic shapers that limit the incoming XMPP traffic, providing a safety valve to protect the server. acl - Access classes to which connecting users are assigned. access - Access rules, specifying the privileges of the defined access classes. s2s - Server-to-server connection options, used for XMPP federation. host_config - Configuration options that need to be different for a specific XMPP domain. The section names above are links to the detailed documentation of each section.","title":"mongooseim.toml"},{"location":"advanced-configuration/configuration-files/#option-scope","text":"Each configuration option has its scope , which is one of the following: local - configured separately for each node in the cluster - each node can have a different value, global - configured for the entire cluster - all nodes share the same value. The scope of each option is defined in the documentation above - either at the top of the section page or for each option individually.","title":"Option scope"},{"location":"advanced-configuration/configuration-files/#vmargs","text":"This file contains parameters passed directly to the Erlang VM. To configure it, go to [MongooseIM root]/rel/files/ . Let's explore the default options.","title":"vm.args"},{"location":"advanced-configuration/configuration-files/#options","text":"-sname - Erlang node name. Can be changed to name , if necessary -setcookie - Erlang cookie. All nodes in a cluster must use the same cookie value. +K - Enables kernel polling. It improves the stability when a large number of sockets is opened, but some systems might benefit from disabling it. Might be a subject of individual load testing. +A 5 - Sets the asynchronous threads number. Async threads improve I/O operations efficiency by relieving scheduler threads of IO waits. +P 10000000 - Process count limit. This is a maximum allowed number of processes running per node. In general, it should exceed the tripled estimated online user count. -env ERL_MAX_PORTS 250000 - Open port count. This is a maximum allowed number of ports opened per node. In general, it should exceed the tripled estimated online user count. Keep in mind that increasing this number also increases the memory usage by a constant amount, so finding the right balance for it is important for every project. -env ERL_FULLSWEEP_AFTER 2 - affects garbage collection. Reduces memory consumption (forces often full g.c.) at the expense of CPU usage. -sasl sasl_error_logger false - MongooseIM's solution for logging is Lager, so SASL error logger is disabled.","title":"Options"},{"location":"advanced-configuration/configuration-files/#appconfig","text":"A file with Erlang application configuration. To configure it, go to [MongooseIM root]/rel/files/ . By default only the following applications can be found there: logger - check Logger's documentation for more information. ssl session_lifetime (default specified in the file: 600 seconds) - This parameter says for how long should the ssl session remain in the cache for further re-use, should ssl session resumption happen.","title":"app.config"},{"location":"advanced-configuration/configuration-files/#configuring-tls-certificates-keys","text":"TLS is configured in one of two ways: some modules need a private key and certificate (chain) in separate files, while others need both in a single file. This is because recent additions use OTP's ssl library, while older modules use p1_tls , respectively. Client-to-server connections need both in the same .pem file Server-to-server connections need both in the same .pem file BOSH, WebSockets and REST APIs need them in separate files In order to create private key & certificate bundle, you may simply concatenate them. More information about configuring TLS for these endpoints is available in the listen section configuration page.","title":"Configuring TLS: Certificates &amp; Keys"},{"location":"advanced-configuration/database-backends-configuration/","text":"Database Backends MongooseIM can work with several databases, both RDBMS (SQL) and NOSQL ones. Some of them require extra work before they can be used. For example the SQL databases require defining a schema. MongooseIM is tested with TravisCI, so the travis scripts can be used as a reference. A Brief Overview Data in MongooseIM is either transient or persistent: transient : volatile data changing often, such as session data, stream management data, and other in-memory data. These don't need any backup, since after a potential failure, they will naturally rebuild as clients reconnect. persistent : long-lived data, such as roster items, credentials, and chat archives. These absolutely need regular and tested backups. Choosing a database for MongooseIM Here is some general advice on the use of databases. Subsequent sections go into more depth on each database: what they are suitable for and how to set them up. Transient data: Mnesia - we highly recommend Mnesia (a highly available and distributed database) over Redis for storing transient data. Being an Erlang-based database, it's the default persistence option for most modules in MongooseIM. Warning : we strongly recommend keeping persistent data in an external DB (RDBMS or Riak) for production. Mnesia is not suitable for the volumes of persistent data which some modules may require. Sooner or later a migration will be needed which may be painful. It is possible to store all data in Mnesia, but only for testing purposes, not for any serious deployments. Redis - A fantastic choice for storing live data. It's highly scalable and it can be easily shared by multiple MongooseIM nodes. Additionally, Redis' great performance makes it an excellent choice for storing user session data. We recommend caution, since it has not yet been widely tested in production. Persistent Data: RDBMS - MongooseIM has a strong backend support for relational databases. Reliable and battle proven, they are a great choice for regular MongooseIM use cases and features like privacy lists , vcards , roster , private storage , last activity and message archive . Never loose your data. Use MySQL, MariaDB, PostgreSQL, or MS SQL Server. Riak KV - If you're planning to deploy a massive cluster, consider Riak KV as a potential storage backend solution. It offers high availability and fault tolerance which is exactly what you need for your distributed MongooseIM architecture. Use Riak KV with privacy lists , vcards , roster , private storage , last activity and message archive . Erlang Solutions commercially supports Riak KV. Cassandra - Only for MAM (Message Archive Management). ElasticSearch - Only for MAM (Message Archive Management). User Data: LDAP - Used for: users, shared rosters, vCards RDBMS MySQL Can be used for : users (credentials) vcards roster private storage privacy/block lists last activity mam (message archive management) muc_light rooms Setup The schema files can be found in the priv directory. The default schema is defined in the mysql.sql file. You can use the following command to apply it on localhost: 1 2 mysql -h localhost -u user -p -e 'create database mongooseim' mysql -h localhost -u user -p mongooseim < mysql.sql You should also configure the MySQL database in the mongooseim.toml file. Please refer to the RDBMS options for more information. Version notice The required minimum version of MySQL is 5.7.9 . This is mainly to benefit from the JSON data type and the default settings which works out of the box with MongooseIM. MySQL 8 In case of using MySQL version 8 and MongooseIM 3.6.2 or older the mysql_native_password authentication plugin must be used as the default one. Newer versions of MongooseIM works correctly with MySQL 8 and its default auth plugins. PostgreSQL Can be used for: users (credentials) vcards roster private storage privacy/block lists last activity mam (message archive management) muc_light rooms Setup The schema files can be found in the priv directory. The default schema is defined in the pg.sql file. You can use the following command to apply it on localhost: 1 2 psql -h localhost -U user -c \"CREATE DATABASE mongooseim;\" psql -h localhost -U user -q -d mongooseim -f pg.sql You should also configure the Postgres database in the mongooseim.toml file. Please refer to the RDBMS options and general database options for more information. Microsoft SQL Server Microsoft SQL Server, sometimes called MSSQL, or Azure SQL Database. Warning: MongooseIM can only connect to MSSQL on Ubuntu Xenial x64 . This can be used for: users (credentials) vcards roster private storage privacy/block lists last activity mam (message archive management) muc_light rooms Setup MSSQL can be used from MongooseIM through the ODBC layer with FreeTDS driver, so you need them installed on your system. 1 2 3 4 5 6 7 8 # Ubuntu $ sudo apt install freetds-dev tdsodbc # CentOS $ sudo yum install freetds # macOS $ brew install freetds Then you need to configure the connection. Add your database ( mongooseim here) to the /etc/odbc.ini or $HOME/.odbc.ini file: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 [mongoose-mssql] ; Ubuntu Driver = /usr/lib/x86_64-linux-gnu/odbc/libtdsodbc.so Setup = /usr/lib/x86_64-linux-gnu/odbc/libtdsS.so ; CentOS ; Driver = /usr/lib64/libtdsodbc.so.0 ; Setup = /usr/lib64/libtdsS.so ; macOS ; Driver = /usr/local/Cellar/freetds/[current version]/lib/libtdsodbc.so Server = 127.0.0.1 Port = 1433 Database = mongooseim Charset = UTF-8 TDS_Version = 7.2 client_charset = UTF-8 Please amend the paths above to match your current OS if necessary. For more details, please refer to the freetds.conf documentation and unixodbc documentation . MongooseIM is built with ODBC support by default. Deadlocks notice If muc_light's backend is set to ODBC and there are many rooms created in parallel in your system, there may be some deadlocks due to the READ_COMMITTED_SNAPSHOT set to OFF by default. In this case we recommend to set this database property to ON , this will enable row level locking which significantly reduces deadlock chances around muc_light operations. This property can be set by the following ALTER DATABASE query: 1 ALTER DATABASE $ name_of_your_db SET READ_COMMITTED_SNAPSHOT ON The command above may take some time. Then you need to import the SQL schema from mssql2012.sql . You can use a Microsoft's GUI tool (the provided .sql files should work with it) or isql, but after a slight modification of the dump file: 1 2 cat mssql2012.sql | tr -d '\\r' | tr '\\n' ' ' | sed 's/GO/\\n/g' | isql mongoose-mssql username password -b The final step is to configure mongooseim.toml appropriately. Set the following option in the general section: 1 2 [general] rdbms_server_type = \"mssql\" Configure the outgoing_pools.rdbms section as follows: 1 2 3 4 5 6 [outgoing_pools.rdbms.default] workers = 5 [outgoing_pools.rdbms.default.connection] driver = \"odbc\" settings = \"DSN=mongoose-mssql;UID=username;PWD=password\" NOSQL Riak KV Riak KV, for Key-Value, is technically supported by MongooseIM for versions upper than Riak KV 2.0. Erlang Solutions commercially supports Riak KV. Can be used for: users (credentials) vcards roster private storage privacy/block lists last activity mam (message archive management) Setup We are using the Riak data types, so the minimal supported version is 2.0. To be able to store above persistent date one have to run the following command: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 RIAK_HOST = \"http://localhost:8098\" curl -XPUT $RIAK_HOST /search/schema/vcard \\ -H 'Content-Type:application/xml' \\ --data-binary @tools/vcard_search_schema.xml curl -XPUT $RIAK_HOST /search/index/vcard \\ -H 'Content-Type: application/json' \\ -d '{\"schema\":\"vcard\"}' #MAM curl -XPUT $RIAK_HOST /search/schema/mam \\ -H 'Content-Type:application/xml' \\ --data-binary @tools/mam_search_schema.xml curl -XPUT $RIAK_HOST /search/index/mam \\ -H 'Content-Type: application/json' \\ -d '{\"schema\":\"mam\"}' # user base riak-admin bucket-type create users '{\"props\":{\"datatype\":\"map\"}}' riak-admin bucket-type activate users # rosters riak-admin bucket-type create rosters '{\"props\":{\"datatype\":\"map\"}}' riak-admin bucket-type activate rosters riak-admin bucket-type create roster_versions '{\"props\":{\"last_write_wins\":true, \"dvv_enabled\":false}}' riak-admin bucket-type activate roster_versions # private storage riak-admin bucket-type create private '{\"props\":{\"last_write_wins\":true, \"dvv_enabled\":false}}' riak-admin bucket-type activate private # vCard riak-admin bucket-type create vcard '{\"props\":{\"last_write_wins\":true, \"search_index\":\"vcard\", \"dvv_enabled\":false}}' riak-admin bucket-type activate vcard riak-admin bucket-type create mam_yz '{\"props\":{\"datatype\":\"map\", \"search_index\":\"mam\"}}' riak-admin bucket-type activate mam_yz # Last activity riak-admin bucket-type create last '{\"props\":{\"last_write_wins\":true, \"dvv_enabled\":false}}' riak-admin bucket-type activate last # Offline messages riak-admin bucket-type create offline '{\"props\":{\"last_write_wins\":true, \"dvv_enabled\":false}}' riak-admin bucket-type activate offline # Privacy/blocking lists riak-admin bucket-type create privacy_defaults '{\"props\":{\"last_write_wins\":true, \"dvv_enabled\":false}}' riak-admin bucket-type activate privacy_defaults riak-admin bucket-type create privacy_lists_names '{\"props\":{\"datatype\":\"set\"}}' riak-admin bucket-type activate privacy_lists_names riak-admin bucket-type create privacy_lists '{\"props\":{\"last_write_wins\":true,\"dvv_enabled\":false}}' riak-admin bucket-type activate privacy_lists This will create bucket types, search schemas and indexes required for storing the above persitent data and it will activate them. You should also configure Riak in the mongooseim.toml file. Please refer to the RDBMS options and Riak options for more information. Cassandra Setup This will prepare Cassandra for connection from MongooseIM. Make sure Cassandra is running, open a new terminal window and enter the following commands: 1 2 $ cqlsh $ cqlsh> source '$REPO/priv/casssandra.cql'; ElasticSearch Can be used for: MAM (Message Archive Management) Setup Please note that MongooseIM has been tested to work properly with ElasticSearch version 5.6.9. In order to use ElasticSearch as a MAM backend, you'll need to create required indexes and mappings. From the root of MongooseIM's repository run: 1 2 curl -X PUT $ELASTICSEARCH_URL /messages -d '@priv/elasticsearch/pm.json' curl -X PUT $ELASTICSEARCH_URL /muc_messages -d '@priv/elasticsearch/muc.json' where $ELASTICSEARCH_URL is a URL pointing to your ElasticSearch node's HTTP API endpoint. Please refer to the advanced configuration page to check how to configure MongooseIM to connect to ElasticSearch node. Redis Can be used for: users sessions Setup Please refer to the Redis options for more information. LDAP Can be used for: users (credentials) shared roster vcard Setup Please refer to the LDAP options for more information.","title":"Database backends configuration"},{"location":"advanced-configuration/database-backends-configuration/#database-backends","text":"MongooseIM can work with several databases, both RDBMS (SQL) and NOSQL ones. Some of them require extra work before they can be used. For example the SQL databases require defining a schema. MongooseIM is tested with TravisCI, so the travis scripts can be used as a reference.","title":"Database Backends"},{"location":"advanced-configuration/database-backends-configuration/#a-brief-overview","text":"Data in MongooseIM is either transient or persistent: transient : volatile data changing often, such as session data, stream management data, and other in-memory data. These don't need any backup, since after a potential failure, they will naturally rebuild as clients reconnect. persistent : long-lived data, such as roster items, credentials, and chat archives. These absolutely need regular and tested backups.","title":"A Brief Overview"},{"location":"advanced-configuration/database-backends-configuration/#choosing-a-database-for-mongooseim","text":"Here is some general advice on the use of databases. Subsequent sections go into more depth on each database: what they are suitable for and how to set them up. Transient data: Mnesia - we highly recommend Mnesia (a highly available and distributed database) over Redis for storing transient data. Being an Erlang-based database, it's the default persistence option for most modules in MongooseIM. Warning : we strongly recommend keeping persistent data in an external DB (RDBMS or Riak) for production. Mnesia is not suitable for the volumes of persistent data which some modules may require. Sooner or later a migration will be needed which may be painful. It is possible to store all data in Mnesia, but only for testing purposes, not for any serious deployments. Redis - A fantastic choice for storing live data. It's highly scalable and it can be easily shared by multiple MongooseIM nodes. Additionally, Redis' great performance makes it an excellent choice for storing user session data. We recommend caution, since it has not yet been widely tested in production. Persistent Data: RDBMS - MongooseIM has a strong backend support for relational databases. Reliable and battle proven, they are a great choice for regular MongooseIM use cases and features like privacy lists , vcards , roster , private storage , last activity and message archive . Never loose your data. Use MySQL, MariaDB, PostgreSQL, or MS SQL Server. Riak KV - If you're planning to deploy a massive cluster, consider Riak KV as a potential storage backend solution. It offers high availability and fault tolerance which is exactly what you need for your distributed MongooseIM architecture. Use Riak KV with privacy lists , vcards , roster , private storage , last activity and message archive . Erlang Solutions commercially supports Riak KV. Cassandra - Only for MAM (Message Archive Management). ElasticSearch - Only for MAM (Message Archive Management). User Data: LDAP - Used for: users, shared rosters, vCards","title":"Choosing a database for MongooseIM"},{"location":"advanced-configuration/database-backends-configuration/#rdbms","text":"","title":"RDBMS"},{"location":"advanced-configuration/database-backends-configuration/#mysql","text":"Can be used for : users (credentials) vcards roster private storage privacy/block lists last activity mam (message archive management) muc_light rooms Setup The schema files can be found in the priv directory. The default schema is defined in the mysql.sql file. You can use the following command to apply it on localhost: 1 2 mysql -h localhost -u user -p -e 'create database mongooseim' mysql -h localhost -u user -p mongooseim < mysql.sql You should also configure the MySQL database in the mongooseim.toml file. Please refer to the RDBMS options for more information. Version notice The required minimum version of MySQL is 5.7.9 . This is mainly to benefit from the JSON data type and the default settings which works out of the box with MongooseIM.","title":"MySQL"},{"location":"advanced-configuration/database-backends-configuration/#mysql-8","text":"In case of using MySQL version 8 and MongooseIM 3.6.2 or older the mysql_native_password authentication plugin must be used as the default one. Newer versions of MongooseIM works correctly with MySQL 8 and its default auth plugins.","title":"MySQL 8"},{"location":"advanced-configuration/database-backends-configuration/#postgresql","text":"Can be used for: users (credentials) vcards roster private storage privacy/block lists last activity mam (message archive management) muc_light rooms Setup The schema files can be found in the priv directory. The default schema is defined in the pg.sql file. You can use the following command to apply it on localhost: 1 2 psql -h localhost -U user -c \"CREATE DATABASE mongooseim;\" psql -h localhost -U user -q -d mongooseim -f pg.sql You should also configure the Postgres database in the mongooseim.toml file. Please refer to the RDBMS options and general database options for more information.","title":"PostgreSQL"},{"location":"advanced-configuration/database-backends-configuration/#microsoft-sql-server","text":"Microsoft SQL Server, sometimes called MSSQL, or Azure SQL Database. Warning: MongooseIM can only connect to MSSQL on Ubuntu Xenial x64 . This can be used for: users (credentials) vcards roster private storage privacy/block lists last activity mam (message archive management) muc_light rooms Setup MSSQL can be used from MongooseIM through the ODBC layer with FreeTDS driver, so you need them installed on your system. 1 2 3 4 5 6 7 8 # Ubuntu $ sudo apt install freetds-dev tdsodbc # CentOS $ sudo yum install freetds # macOS $ brew install freetds Then you need to configure the connection. Add your database ( mongooseim here) to the /etc/odbc.ini or $HOME/.odbc.ini file: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 [mongoose-mssql] ; Ubuntu Driver = /usr/lib/x86_64-linux-gnu/odbc/libtdsodbc.so Setup = /usr/lib/x86_64-linux-gnu/odbc/libtdsS.so ; CentOS ; Driver = /usr/lib64/libtdsodbc.so.0 ; Setup = /usr/lib64/libtdsS.so ; macOS ; Driver = /usr/local/Cellar/freetds/[current version]/lib/libtdsodbc.so Server = 127.0.0.1 Port = 1433 Database = mongooseim Charset = UTF-8 TDS_Version = 7.2 client_charset = UTF-8 Please amend the paths above to match your current OS if necessary. For more details, please refer to the freetds.conf documentation and unixodbc documentation . MongooseIM is built with ODBC support by default. Deadlocks notice If muc_light's backend is set to ODBC and there are many rooms created in parallel in your system, there may be some deadlocks due to the READ_COMMITTED_SNAPSHOT set to OFF by default. In this case we recommend to set this database property to ON , this will enable row level locking which significantly reduces deadlock chances around muc_light operations. This property can be set by the following ALTER DATABASE query: 1 ALTER DATABASE $ name_of_your_db SET READ_COMMITTED_SNAPSHOT ON The command above may take some time. Then you need to import the SQL schema from mssql2012.sql . You can use a Microsoft's GUI tool (the provided .sql files should work with it) or isql, but after a slight modification of the dump file: 1 2 cat mssql2012.sql | tr -d '\\r' | tr '\\n' ' ' | sed 's/GO/\\n/g' | isql mongoose-mssql username password -b The final step is to configure mongooseim.toml appropriately. Set the following option in the general section: 1 2 [general] rdbms_server_type = \"mssql\" Configure the outgoing_pools.rdbms section as follows: 1 2 3 4 5 6 [outgoing_pools.rdbms.default] workers = 5 [outgoing_pools.rdbms.default.connection] driver = \"odbc\" settings = \"DSN=mongoose-mssql;UID=username;PWD=password\"","title":"Microsoft SQL Server"},{"location":"advanced-configuration/database-backends-configuration/#nosql","text":"","title":"NOSQL"},{"location":"advanced-configuration/database-backends-configuration/#riak-kv","text":"Riak KV, for Key-Value, is technically supported by MongooseIM for versions upper than Riak KV 2.0. Erlang Solutions commercially supports Riak KV. Can be used for: users (credentials) vcards roster private storage privacy/block lists last activity mam (message archive management) Setup We are using the Riak data types, so the minimal supported version is 2.0. To be able to store above persistent date one have to run the following command: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 RIAK_HOST = \"http://localhost:8098\" curl -XPUT $RIAK_HOST /search/schema/vcard \\ -H 'Content-Type:application/xml' \\ --data-binary @tools/vcard_search_schema.xml curl -XPUT $RIAK_HOST /search/index/vcard \\ -H 'Content-Type: application/json' \\ -d '{\"schema\":\"vcard\"}' #MAM curl -XPUT $RIAK_HOST /search/schema/mam \\ -H 'Content-Type:application/xml' \\ --data-binary @tools/mam_search_schema.xml curl -XPUT $RIAK_HOST /search/index/mam \\ -H 'Content-Type: application/json' \\ -d '{\"schema\":\"mam\"}' # user base riak-admin bucket-type create users '{\"props\":{\"datatype\":\"map\"}}' riak-admin bucket-type activate users # rosters riak-admin bucket-type create rosters '{\"props\":{\"datatype\":\"map\"}}' riak-admin bucket-type activate rosters riak-admin bucket-type create roster_versions '{\"props\":{\"last_write_wins\":true, \"dvv_enabled\":false}}' riak-admin bucket-type activate roster_versions # private storage riak-admin bucket-type create private '{\"props\":{\"last_write_wins\":true, \"dvv_enabled\":false}}' riak-admin bucket-type activate private # vCard riak-admin bucket-type create vcard '{\"props\":{\"last_write_wins\":true, \"search_index\":\"vcard\", \"dvv_enabled\":false}}' riak-admin bucket-type activate vcard riak-admin bucket-type create mam_yz '{\"props\":{\"datatype\":\"map\", \"search_index\":\"mam\"}}' riak-admin bucket-type activate mam_yz # Last activity riak-admin bucket-type create last '{\"props\":{\"last_write_wins\":true, \"dvv_enabled\":false}}' riak-admin bucket-type activate last # Offline messages riak-admin bucket-type create offline '{\"props\":{\"last_write_wins\":true, \"dvv_enabled\":false}}' riak-admin bucket-type activate offline # Privacy/blocking lists riak-admin bucket-type create privacy_defaults '{\"props\":{\"last_write_wins\":true, \"dvv_enabled\":false}}' riak-admin bucket-type activate privacy_defaults riak-admin bucket-type create privacy_lists_names '{\"props\":{\"datatype\":\"set\"}}' riak-admin bucket-type activate privacy_lists_names riak-admin bucket-type create privacy_lists '{\"props\":{\"last_write_wins\":true,\"dvv_enabled\":false}}' riak-admin bucket-type activate privacy_lists This will create bucket types, search schemas and indexes required for storing the above persitent data and it will activate them. You should also configure Riak in the mongooseim.toml file. Please refer to the RDBMS options and Riak options for more information.","title":"Riak KV"},{"location":"advanced-configuration/database-backends-configuration/#cassandra","text":"Setup This will prepare Cassandra for connection from MongooseIM. Make sure Cassandra is running, open a new terminal window and enter the following commands: 1 2 $ cqlsh $ cqlsh> source '$REPO/priv/casssandra.cql';","title":"Cassandra"},{"location":"advanced-configuration/database-backends-configuration/#elasticsearch","text":"Can be used for: MAM (Message Archive Management) Setup Please note that MongooseIM has been tested to work properly with ElasticSearch version 5.6.9. In order to use ElasticSearch as a MAM backend, you'll need to create required indexes and mappings. From the root of MongooseIM's repository run: 1 2 curl -X PUT $ELASTICSEARCH_URL /messages -d '@priv/elasticsearch/pm.json' curl -X PUT $ELASTICSEARCH_URL /muc_messages -d '@priv/elasticsearch/muc.json' where $ELASTICSEARCH_URL is a URL pointing to your ElasticSearch node's HTTP API endpoint. Please refer to the advanced configuration page to check how to configure MongooseIM to connect to ElasticSearch node.","title":"ElasticSearch"},{"location":"advanced-configuration/database-backends-configuration/#redis","text":"Can be used for: users sessions Setup Please refer to the Redis options for more information.","title":"Redis"},{"location":"advanced-configuration/database-backends-configuration/#ldap","text":"Can be used for: users (credentials) shared roster vcard Setup Please refer to the LDAP options for more information.","title":"LDAP"},{"location":"advanced-configuration/general/","text":"The general section contains basic settings as well as some miscellaneous options. You can start with providing only the basic options, configuring the loglevel, a single host (XMPP domain) and setting the default server language: 1 2 3 4 [general] loglevel = \"warning\" hosts = [\"my-xmpp-domain.com\"] language = \"en\" All options are described below. General options These are the basic settings that you should configure before running your MongooseIM server. general.loglevel Scope: local Syntax: string, one of \"none\" , \"emergency\" , \"alert\" , \"critical\" , \"error\" , \"warning\" , \"notice\" , \"info\" , \"debug\" , \"all\" . Default: \"warning\" Example: loglevel = \"error\" Verbosity level of the logger. Values recommended for production systems are \"error\" and \"warning\" . The \"debug\" level is good for development. general.hosts Scope: global Syntax: array of strings representing the domain names. Default: there is no default, you have to provide at least one host name. Example: hosts = [\"localhost\", \"domain2\"] Mandatory option, specifying the XMPP domains served by this cluster. Warning: Extension modules and database backends will be started separately for every domain. When increasing the number of domains, please make sure you have enough resources available (e.g. connection limit set in the DBMS). general.language Scope: global Syntax: string representing the two-letter language code. Default: \"en\" Example: language = \"pl\" Default language for messages sent by the server to users. You can get a full list of supported codes by executing cd [MongooseIM root] ; ls priv/*.msg | awk '{split($0,a,\"/\"); split(a[4],b,\".\"); print b[1]}' ( en is not listed there) Database settings RDBMS connection pools are set using outgoing connections configuration . There are some additional options that influence all database connections in the server: general.rdbms_server_type Scope: local Syntax: string, \"mssql\" or \"pgsql\" Default: not set Example: rdbms_server_type = \"mssql\" When using MSSQL or PostgreSQL databases, this option allows MongooseIM to optimize some queries for these DBs (e.g. mod_mam_rdbms_user uses different queries for mssql ). Access management User access rules are configured mainly in the acl and access sections. Here you can find some additional options. general.mongooseimctl_access_commands Scope: local Syntax: TOML table, whose keys are the names of the access rules defined in the access config section and values specify allowed administration commands. Each value is a table with the following nested options: commands : optional, a list of strings representing the allowed commands. When not specified, all commands are allowed. argument_restrictions : optional, a table whose keys are the argument names and the values are strings representing the allowed values. When not specified, there are no restrictions. Default: not set By default all admin operations are permitted with the mongooseimctl command without authentication. You can change that by setting this option for a specific access rule. When the rule returns the value \"allow\" , the user is permitted to use the specified commands with the optional restrictions. Example 1. Allow administrators to execute all commands without any restrictions: 1 [general.mongooseimctl_access_commands.admin] The admin rule needs to be defined in the access section. Example 2. Allow local users to execute the join_cluster command, but only if the node argument is equal to mongooseim@prime : 1 2 3 [general.mongooseimctl_access_commands.local] commands = [\"join_cluster\"] argument_restrictions . node = \"mongooseim@prime\" The local rule needs to be defined in the access section. Security Here you can find some additional options related to system security. general.registration_timeout Scope: local Syntax: the string \"infinity\" or a number of seconds (positive integer) Default: 600 Example: registration_timeout = \"infinity\" Limits the registration frequency from a single IP address. The special value infinity means no limit. general.hide_service_name Scope: local Syntax: boolean Default: false Example: hide_service_name = true According to RFC 6210, even when a client sends invalid data after opening a connection, the server must open an XML stream and return a stream error anyway. For extra security, this option may be enabled. It changes MIM behaviour to simply close the connection without any errors returned (effectively hiding the server's identity). User session management These options can be used to configure the way MongooseIM manages user sessions. general.sm_backend Scope: global Syntax: string, \"mnesia\" or \"redis\" Default: \"mnesia\" Example: sm_backend = \"redis\" Backend for storing user session data. All nodes in a cluster must have access to a complete session database. Mnesia is sufficient in most cases, use Redis only in large deployments when you notice issues with the mnesia backend. Requires a redis pool with the default tag defined in the outgoing_pools section. See the section about redis connection setup for more information. general.replaced_wait_timeout Scope: local Syntax: positive integer, representing time in milliseconds Default: 2000 Example: replaced_wait_timeout = 5000 When a user's session is replaced (due to a full JID conflict) by a new one, this parameter specifies the time MongooseIM waits for the old sessions to close. The default value is sufficient in most cases. If you observe replaced_wait_timeout warning in logs, then most probably the old sessions are frozen for some reason and it should be investigated. Message routing The following options influence the way MongooseIM routes incoming messages to their recipients. general.route_subdomains Scope: local Syntax: string, the only accepted value is \"s2s\" Default: not set Example: route_subdomains = \"s2s\" If a stanza is addressed to a subdomain of the served domain and this option is set to s2s , such a stanza will be transmitted over a server-to-server connection. Without it, MongooseIM will try to route the stanza to one of its internal services. general.routing_modules Scope: local Syntax: a list of strings representing the routing module names. Default: [\"mongoose_router_global\", \"mongoose_router_localdomain\", \"mongoose_router_external_localnode\", \"mongoose_router_external\", \"ejabberd_s2s\"] Example: routing_modules = [\"mongoose_router_global\", \"mongoose_router_localdomain\"] Provides an ordered list of modules used for routing messages. If one of the modules accepts packet for processing, the remaining ones are not called. Allowed module names: mongoose_router_global - calls the filter_packet hook. mongoose_router_localdomain - routes packets addressed to a domain supported by the local cluster. mongoose_router_external_localnode - delivers packets to an XMPP component connected to the node, which processes the request. mongoose_router_external - delivers packets to an XMPP component connected to the local cluster. ejabberd_s2s - forwards packets to another XMPP cluster over XMPP Federation. Miscellaneous The options listed below are used to configure more specific settings, that do not need to be changed in usual use cases. general.all_metrics_are_global Scope: local Syntax: boolean Default: false Example: all_metrics_are_global = true When enabled, all per-host metrics are merged into global equivalents. It means it is no longer possible to view individual host1, host2, host3, ... metrics, only sums are available. This option significantly reduces CPU and (especially) memory footprint in setups with exceptionally many domains (thousands, tens of thousands). general.http_server_name Scope: local Syntax: string Default: \"Cowboy\" Example: http_server_name = \"Apache\" Replaces Cowboy 's default name returned in the server HTTP response header. It may be used for extra security, as it makes it harder for the malicious user to learn what HTTP software is running under a specific port. This option applies to all configured HTTP listeners. general.override Scope: local Syntax: array of strings: \"global\" , \"local\" , \"acls\" Default: not set Example: override = [\"global\", \"local\"] Will cause MongooseIM to erase all global/local/acl configuration options in database respectively. This ensures that ALL settings of a specific type will be reloaded on startup. general.max_fsm_queue Scope: local Syntax: positive integer Default: not set Example: max_fsm_queue = 5000 When specified, will terminate certain processes (e.g. client handlers) that have more messages accumulated in the queue than the specified limit, to prevent resource exhaustion. This option is set for C2S, outgoing S2S and component connections and can be overridden for particular s2s or service listeners in their configurations. Use with caution!","title":"Options: General"},{"location":"advanced-configuration/general/#general-options","text":"These are the basic settings that you should configure before running your MongooseIM server.","title":"General options"},{"location":"advanced-configuration/general/#generalloglevel","text":"Scope: local Syntax: string, one of \"none\" , \"emergency\" , \"alert\" , \"critical\" , \"error\" , \"warning\" , \"notice\" , \"info\" , \"debug\" , \"all\" . Default: \"warning\" Example: loglevel = \"error\" Verbosity level of the logger. Values recommended for production systems are \"error\" and \"warning\" . The \"debug\" level is good for development.","title":"general.loglevel"},{"location":"advanced-configuration/general/#generalhosts","text":"Scope: global Syntax: array of strings representing the domain names. Default: there is no default, you have to provide at least one host name. Example: hosts = [\"localhost\", \"domain2\"] Mandatory option, specifying the XMPP domains served by this cluster. Warning: Extension modules and database backends will be started separately for every domain. When increasing the number of domains, please make sure you have enough resources available (e.g. connection limit set in the DBMS).","title":"general.hosts"},{"location":"advanced-configuration/general/#generallanguage","text":"Scope: global Syntax: string representing the two-letter language code. Default: \"en\" Example: language = \"pl\" Default language for messages sent by the server to users. You can get a full list of supported codes by executing cd [MongooseIM root] ; ls priv/*.msg | awk '{split($0,a,\"/\"); split(a[4],b,\".\"); print b[1]}' ( en is not listed there)","title":"general.language"},{"location":"advanced-configuration/general/#database-settings","text":"RDBMS connection pools are set using outgoing connections configuration . There are some additional options that influence all database connections in the server:","title":"Database settings"},{"location":"advanced-configuration/general/#generalrdbms_server_type","text":"Scope: local Syntax: string, \"mssql\" or \"pgsql\" Default: not set Example: rdbms_server_type = \"mssql\" When using MSSQL or PostgreSQL databases, this option allows MongooseIM to optimize some queries for these DBs (e.g. mod_mam_rdbms_user uses different queries for mssql ).","title":"general.rdbms_server_type"},{"location":"advanced-configuration/general/#access-management","text":"User access rules are configured mainly in the acl and access sections. Here you can find some additional options.","title":"Access management"},{"location":"advanced-configuration/general/#generalmongooseimctl_access_commands","text":"Scope: local Syntax: TOML table, whose keys are the names of the access rules defined in the access config section and values specify allowed administration commands. Each value is a table with the following nested options: commands : optional, a list of strings representing the allowed commands. When not specified, all commands are allowed. argument_restrictions : optional, a table whose keys are the argument names and the values are strings representing the allowed values. When not specified, there are no restrictions. Default: not set By default all admin operations are permitted with the mongooseimctl command without authentication. You can change that by setting this option for a specific access rule. When the rule returns the value \"allow\" , the user is permitted to use the specified commands with the optional restrictions. Example 1. Allow administrators to execute all commands without any restrictions: 1 [general.mongooseimctl_access_commands.admin] The admin rule needs to be defined in the access section. Example 2. Allow local users to execute the join_cluster command, but only if the node argument is equal to mongooseim@prime : 1 2 3 [general.mongooseimctl_access_commands.local] commands = [\"join_cluster\"] argument_restrictions . node = \"mongooseim@prime\" The local rule needs to be defined in the access section.","title":"general.mongooseimctl_access_commands"},{"location":"advanced-configuration/general/#security","text":"Here you can find some additional options related to system security.","title":"Security"},{"location":"advanced-configuration/general/#generalregistration_timeout","text":"Scope: local Syntax: the string \"infinity\" or a number of seconds (positive integer) Default: 600 Example: registration_timeout = \"infinity\" Limits the registration frequency from a single IP address. The special value infinity means no limit.","title":"general.registration_timeout"},{"location":"advanced-configuration/general/#generalhide_service_name","text":"Scope: local Syntax: boolean Default: false Example: hide_service_name = true According to RFC 6210, even when a client sends invalid data after opening a connection, the server must open an XML stream and return a stream error anyway. For extra security, this option may be enabled. It changes MIM behaviour to simply close the connection without any errors returned (effectively hiding the server's identity).","title":"general.hide_service_name"},{"location":"advanced-configuration/general/#user-session-management","text":"These options can be used to configure the way MongooseIM manages user sessions.","title":"User session management"},{"location":"advanced-configuration/general/#generalsm_backend","text":"Scope: global Syntax: string, \"mnesia\" or \"redis\" Default: \"mnesia\" Example: sm_backend = \"redis\" Backend for storing user session data. All nodes in a cluster must have access to a complete session database. Mnesia is sufficient in most cases, use Redis only in large deployments when you notice issues with the mnesia backend. Requires a redis pool with the default tag defined in the outgoing_pools section. See the section about redis connection setup for more information.","title":"general.sm_backend"},{"location":"advanced-configuration/general/#generalreplaced_wait_timeout","text":"Scope: local Syntax: positive integer, representing time in milliseconds Default: 2000 Example: replaced_wait_timeout = 5000 When a user's session is replaced (due to a full JID conflict) by a new one, this parameter specifies the time MongooseIM waits for the old sessions to close. The default value is sufficient in most cases. If you observe replaced_wait_timeout warning in logs, then most probably the old sessions are frozen for some reason and it should be investigated.","title":"general.replaced_wait_timeout"},{"location":"advanced-configuration/general/#message-routing","text":"The following options influence the way MongooseIM routes incoming messages to their recipients.","title":"Message routing"},{"location":"advanced-configuration/general/#generalroute_subdomains","text":"Scope: local Syntax: string, the only accepted value is \"s2s\" Default: not set Example: route_subdomains = \"s2s\" If a stanza is addressed to a subdomain of the served domain and this option is set to s2s , such a stanza will be transmitted over a server-to-server connection. Without it, MongooseIM will try to route the stanza to one of its internal services.","title":"general.route_subdomains"},{"location":"advanced-configuration/general/#generalrouting_modules","text":"Scope: local Syntax: a list of strings representing the routing module names. Default: [\"mongoose_router_global\", \"mongoose_router_localdomain\", \"mongoose_router_external_localnode\", \"mongoose_router_external\", \"ejabberd_s2s\"] Example: routing_modules = [\"mongoose_router_global\", \"mongoose_router_localdomain\"] Provides an ordered list of modules used for routing messages. If one of the modules accepts packet for processing, the remaining ones are not called. Allowed module names: mongoose_router_global - calls the filter_packet hook. mongoose_router_localdomain - routes packets addressed to a domain supported by the local cluster. mongoose_router_external_localnode - delivers packets to an XMPP component connected to the node, which processes the request. mongoose_router_external - delivers packets to an XMPP component connected to the local cluster. ejabberd_s2s - forwards packets to another XMPP cluster over XMPP Federation.","title":"general.routing_modules"},{"location":"advanced-configuration/general/#miscellaneous","text":"The options listed below are used to configure more specific settings, that do not need to be changed in usual use cases.","title":"Miscellaneous"},{"location":"advanced-configuration/general/#generalall_metrics_are_global","text":"Scope: local Syntax: boolean Default: false Example: all_metrics_are_global = true When enabled, all per-host metrics are merged into global equivalents. It means it is no longer possible to view individual host1, host2, host3, ... metrics, only sums are available. This option significantly reduces CPU and (especially) memory footprint in setups with exceptionally many domains (thousands, tens of thousands).","title":"general.all_metrics_are_global"},{"location":"advanced-configuration/general/#generalhttp_server_name","text":"Scope: local Syntax: string Default: \"Cowboy\" Example: http_server_name = \"Apache\" Replaces Cowboy 's default name returned in the server HTTP response header. It may be used for extra security, as it makes it harder for the malicious user to learn what HTTP software is running under a specific port. This option applies to all configured HTTP listeners.","title":"general.http_server_name"},{"location":"advanced-configuration/general/#generaloverride","text":"Scope: local Syntax: array of strings: \"global\" , \"local\" , \"acls\" Default: not set Example: override = [\"global\", \"local\"] Will cause MongooseIM to erase all global/local/acl configuration options in database respectively. This ensures that ALL settings of a specific type will be reloaded on startup.","title":"general.override"},{"location":"advanced-configuration/general/#generalmax_fsm_queue","text":"Scope: local Syntax: positive integer Default: not set Example: max_fsm_queue = 5000 When specified, will terminate certain processes (e.g. client handlers) that have more messages accumulated in the queue than the specified limit, to prevent resource exhaustion. This option is set for C2S, outgoing S2S and component connections and can be overridden for particular s2s or service listeners in their configurations. Use with caution!","title":"general.max_fsm_queue"},{"location":"advanced-configuration/host_config/","text":"The host_config section is used to configure options for specific XMPP domains. For each domain requiring such options, a host_config section needs to be created with the following format: Scope: for each option the scope is the same as for the corresponding top-level option. Syntax: domain subsection starts with [[host_config]] and contains the options listed below. Default: none - all domain-level options need to be specified explicitly. Example: see the examples for each section below. Note: Each hosted domain needs to be included in the list of hosts in the general section. General options host_config.host Syntax: string, domain name Default: no default, this option is mandatory Example: host = \"my-xmpp-server.com\" This option specifies the XMPP domain that this section refers to. Configuration sections The following sections are accepted in host_config : host_config.general The options defined here override the ones defined in the top-level general section. The following options are allowed: route_subdomains replaced_wait_timeout Example The replaced_wait_timeout option is set to 2000 only for domain2.com . 1 2 3 4 5 6 7 8 9 10 [general] hosts = [\"domain1.com\", \"domain2.com\", \"domain3.com\"] loglevel = \"info\" replaced_wait_timeout = 1000 [[host_config]] host = \"domain2.com\" [host_config.general] replaced_wait_timeout = 2000 host_config.auth This section overrides the top-level auth section, all options are allowed. It is recommended to repeat all top-level options in the domain-specific section as the rule is quite complicated: If you specify any of the following options, all of the following options will be overridden: sasl_external password.* scram_iterations external.program rdbms.* ldap.* jwt.* riak.* http.* If you specify any of the following options, only these options will be overridden: methods sasl_mechanisms external.instances anonymous.* Example In the example below the number of scram_iterations is increased for domain2 . It is necessary to put the password.hash there as well, as otherwise it would be replaced with the default setting. However, specifying methods is not necessary as this value will not be changed. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 [general] hosts = [\"domain1.com\", \"domain2.com\", \"domain3.com\"] [auth] methods = [\"rdbms\"] password . hash = [\"sha256\"] [[host_config]] host = \"domain2.com\" [host_config.auth] methods = [\"rdbms\"] password . hash = [\"sha256\"] scram_iterations = 40 _000 The last section would work the same without methods : 1 2 3 [host_config.auth] password . hash = [\"sha256\"] scram_iterations = 40 _000 host_config.modules This section completely overrides the top-level modules section. All options are allowed. Example The modules enabled for domain2.com will be mod_disco and mod_stream_management . If we wanted to enable mod_roster , it would need to be repeated in host_config . 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 [general] hosts = [\"domain1.com\", \"domain2.com\", \"domain3.com\"] [modules.mod_disco] users_can_see_hidden_services = false [modules.mod_roster] backend = \"rdbms\" [[host_config]] host = \"domain2.com\" [host_config.modules.mod_disco] users_can_see_hidden_services = false [host_config.modules.mod_stream_management] host_config.acl The access classes defined here are merged with the ones defined in the top-level acl section - when a class is defined in both places, the result is a union of both classes. Example The blocked access class is extended for host_config by adding hacker2 . 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 [general] hosts = [\"domain1.com\", \"domain2.com\", \"domain3.com\"] [acl] blocked = [ { user = \"spammer\" }, { user = \"hacker1\" } ] [[host_config]] host = \"domain2.com\" [host_config.acl] blocked = [ { user = \"hacker2\" } ] host_config.access The access rules defined here are merged with the ones defined in the top-level access section: When a rule is defined in both places: If the top-level rule ends with a catch-all clause {acl = \"all\", value = \"allow\"} , the resulting domain-specific rule has the clauses from both rules with the domain-specific clauses inserted after the top-level ones, but before the catch-all clause. If the top-level rule does not end with a catch-all clause, the resulting domain-specific rule has the clauses from both rules with the domain-specific clauses inserted after the top-level ones. Example The c2s access rule defined at the top level allows anyone to connect. However, the rule for domain2.com is extended to prevent the blocked users from connecting: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 [general] hosts = [\"domain1.com\", \"domain2.com\", \"domain3.com\"] [access] c2s = [ { acl = \"admin\" , value = \"allow\" }, { acl = \"all\" , value = \"allow\" } ] [[host_config]] host = \"domain2.com\" [host_config.access] c2s = [ { acl = \"blocked\" , value = \"deny\" } ] register = [ { acl = \"all\" , value = \"deny\" } ] The resulting rule for domain2.com could be written as: 1 2 3 4 5 c2s = [ { acl = \"admin\" , value = \"allow\" }, { acl = \"blocked\" , value = \"deny\" }, { acl = \"all\" , value = \"allow\" } ] The register rule is defined only for domain2.com . Note: some access rules are checked outside of the context of any domain, e.g. the access rule for external components - defining them in host_config would have no effect. host_config.s2s The options defined here override the ones defined in the top-level s2s section. The following options are allowed: default_policy host_policy - overrides the top-level setting host by host shared max_retry_delay Example The host_policy option is changed for domain2.com : 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 [general] hosts = [\"domain1.com\", \"domain2.com\", \"domain3.com\"] [s2s] default_policy = \"deny\" host_policy = [ { host = \"good-xmpp.org\" , policy = \"allow\" }, { host = \"bad-xmpp.org\" , policy = \"deny\" } ] [[host_config]] host = \"domain2.com\" [host_config.s2s] host_policy = [ { host = \"bad-xmpp.org\" , policy = \"allow\" }, { host = \"evil-xmpp.org\" , policy = \"deny\" } ] The resulting host_policy for domain2.com is the following: 1 2 3 4 5 host_policy = [ { host = \"good-xmpp.org\" , policy = \"allow\" }, { host = \"bad-xmpp.org\" , policy = \"allow\" }, { host = \"evil-xmpp.org\" , policy = \"deny\" } ] The default_policy is still deny .","title":"Options: Host config"},{"location":"advanced-configuration/host_config/#general-options","text":"","title":"General options"},{"location":"advanced-configuration/host_config/#host_confighost","text":"Syntax: string, domain name Default: no default, this option is mandatory Example: host = \"my-xmpp-server.com\" This option specifies the XMPP domain that this section refers to.","title":"host_config.host"},{"location":"advanced-configuration/host_config/#configuration-sections","text":"The following sections are accepted in host_config :","title":"Configuration sections"},{"location":"advanced-configuration/host_config/#host_configgeneral","text":"The options defined here override the ones defined in the top-level general section. The following options are allowed: route_subdomains replaced_wait_timeout","title":"host_config.general"},{"location":"advanced-configuration/host_config/#example","text":"The replaced_wait_timeout option is set to 2000 only for domain2.com . 1 2 3 4 5 6 7 8 9 10 [general] hosts = [\"domain1.com\", \"domain2.com\", \"domain3.com\"] loglevel = \"info\" replaced_wait_timeout = 1000 [[host_config]] host = \"domain2.com\" [host_config.general] replaced_wait_timeout = 2000","title":"Example"},{"location":"advanced-configuration/host_config/#host_configauth","text":"This section overrides the top-level auth section, all options are allowed. It is recommended to repeat all top-level options in the domain-specific section as the rule is quite complicated: If you specify any of the following options, all of the following options will be overridden: sasl_external password.* scram_iterations external.program rdbms.* ldap.* jwt.* riak.* http.* If you specify any of the following options, only these options will be overridden: methods sasl_mechanisms external.instances anonymous.*","title":"host_config.auth"},{"location":"advanced-configuration/host_config/#example_1","text":"In the example below the number of scram_iterations is increased for domain2 . It is necessary to put the password.hash there as well, as otherwise it would be replaced with the default setting. However, specifying methods is not necessary as this value will not be changed. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 [general] hosts = [\"domain1.com\", \"domain2.com\", \"domain3.com\"] [auth] methods = [\"rdbms\"] password . hash = [\"sha256\"] [[host_config]] host = \"domain2.com\" [host_config.auth] methods = [\"rdbms\"] password . hash = [\"sha256\"] scram_iterations = 40 _000 The last section would work the same without methods : 1 2 3 [host_config.auth] password . hash = [\"sha256\"] scram_iterations = 40 _000","title":"Example"},{"location":"advanced-configuration/host_config/#host_configmodules","text":"This section completely overrides the top-level modules section. All options are allowed.","title":"host_config.modules"},{"location":"advanced-configuration/host_config/#example_2","text":"The modules enabled for domain2.com will be mod_disco and mod_stream_management . If we wanted to enable mod_roster , it would need to be repeated in host_config . 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 [general] hosts = [\"domain1.com\", \"domain2.com\", \"domain3.com\"] [modules.mod_disco] users_can_see_hidden_services = false [modules.mod_roster] backend = \"rdbms\" [[host_config]] host = \"domain2.com\" [host_config.modules.mod_disco] users_can_see_hidden_services = false [host_config.modules.mod_stream_management]","title":"Example"},{"location":"advanced-configuration/host_config/#host_configacl","text":"The access classes defined here are merged with the ones defined in the top-level acl section - when a class is defined in both places, the result is a union of both classes.","title":"host_config.acl"},{"location":"advanced-configuration/host_config/#example_3","text":"The blocked access class is extended for host_config by adding hacker2 . 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 [general] hosts = [\"domain1.com\", \"domain2.com\", \"domain3.com\"] [acl] blocked = [ { user = \"spammer\" }, { user = \"hacker1\" } ] [[host_config]] host = \"domain2.com\" [host_config.acl] blocked = [ { user = \"hacker2\" } ]","title":"Example"},{"location":"advanced-configuration/host_config/#host_configaccess","text":"The access rules defined here are merged with the ones defined in the top-level access section: When a rule is defined in both places: If the top-level rule ends with a catch-all clause {acl = \"all\", value = \"allow\"} , the resulting domain-specific rule has the clauses from both rules with the domain-specific clauses inserted after the top-level ones, but before the catch-all clause. If the top-level rule does not end with a catch-all clause, the resulting domain-specific rule has the clauses from both rules with the domain-specific clauses inserted after the top-level ones.","title":"host_config.access"},{"location":"advanced-configuration/host_config/#example_4","text":"The c2s access rule defined at the top level allows anyone to connect. However, the rule for domain2.com is extended to prevent the blocked users from connecting: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 [general] hosts = [\"domain1.com\", \"domain2.com\", \"domain3.com\"] [access] c2s = [ { acl = \"admin\" , value = \"allow\" }, { acl = \"all\" , value = \"allow\" } ] [[host_config]] host = \"domain2.com\" [host_config.access] c2s = [ { acl = \"blocked\" , value = \"deny\" } ] register = [ { acl = \"all\" , value = \"deny\" } ] The resulting rule for domain2.com could be written as: 1 2 3 4 5 c2s = [ { acl = \"admin\" , value = \"allow\" }, { acl = \"blocked\" , value = \"deny\" }, { acl = \"all\" , value = \"allow\" } ] The register rule is defined only for domain2.com . Note: some access rules are checked outside of the context of any domain, e.g. the access rule for external components - defining them in host_config would have no effect.","title":"Example"},{"location":"advanced-configuration/host_config/#host_configs2s","text":"The options defined here override the ones defined in the top-level s2s section. The following options are allowed: default_policy host_policy - overrides the top-level setting host by host shared max_retry_delay","title":"host_config.s2s"},{"location":"advanced-configuration/host_config/#example_5","text":"The host_policy option is changed for domain2.com : 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 [general] hosts = [\"domain1.com\", \"domain2.com\", \"domain3.com\"] [s2s] default_policy = \"deny\" host_policy = [ { host = \"good-xmpp.org\" , policy = \"allow\" }, { host = \"bad-xmpp.org\" , policy = \"deny\" } ] [[host_config]] host = \"domain2.com\" [host_config.s2s] host_policy = [ { host = \"bad-xmpp.org\" , policy = \"allow\" }, { host = \"evil-xmpp.org\" , policy = \"deny\" } ] The resulting host_policy for domain2.com is the following: 1 2 3 4 5 host_policy = [ { host = \"good-xmpp.org\" , policy = \"allow\" }, { host = \"bad-xmpp.org\" , policy = \"allow\" }, { host = \"evil-xmpp.org\" , policy = \"deny\" } ] The default_policy is still deny .","title":"Example"},{"location":"advanced-configuration/listen/","text":"The listen section specifies how MongooseIM handles incoming connections. Scope: local Syntax: Each listener is specified in a subsection starting with [[listen.type]] where type is one of the allowed listener types, handling different types of incoming connections: c2s - client-to-server XMPP connections, s2s - server-to-server XMPP connections, service - XMPP connections from external components, http - HTTP connections from clients or other services. The double-bracket syntax is used because there can be multiple listeners of a given type, so for each listener type there is a TOML array of one or more tables (subsections). Default: None - each listener needs to be enabled explicitly. Typical listeners are already specified in the example configuration file. Example: The simplest XMPP listener configuration, handling only incoming XMPP client connections: 1 2 [[listen.c2s]] port = 5222 General listener options The options listed below are the same for all listener types. They set the basic listening socket options. Only port is required, the rest can be used to change the default settings. listen.*.port Syntax: integer, port number Default: no default, this option is mandatory. Example: port = 5222 The port number to which the listening socket is bound. listen.*.ip_address Syntax: string with the IP address Default: all-zeros address (e.g. \"0.0.0.0\" for IPv4) Example: ip_address = \"127.0.0.1\" The IP address to which the listening socket is bound. listen.*.proto Syntax: string, \"udp\" or \"tcp\" Default: \"tcp\" Example: proto = \"udp\" The protocol, which is TCP by default. There is no reason to change this for XMPP or HTTP listeners. listen.*.ip_version Syntax: integer, 4 or 6 Default: if ip_address is specified, the IP version is determined from that address, otherwise it is 4 Example: ip_version = 6 Allows to set the IP version to IPv6. Does not need to be set if ip_address is defined. XMPP listener options The options listed below can be set for the c2s , s2s and service listeners to adjust their parameters. listen.*.backlog Syntax: positive integer Default: 100 Example: backlog = 1000 Overrides the default TCP backlog value. listen.*.proxy_protocol Syntax: boolean Default: false Example: proxy_protocol = true When set to true , Proxy Protocol is enabled and each connecting client has to provide a proxy header. Use only with a proxy (or a load balancer) to allow it to provide the connection details (including the source IP address) of the original client. Versions 1 and 2 of the protocol are supported. listen.*.hibernate_after Syntax: non-negative integer Default: 0 Example: hibernate_after = 10 Time in milliseconds after which a client process spawned by this listener will hibernate. Hibernation greatly reduces memory consumption of client processes, but may result in increased CPU consumption if a client is used very frequently. The default, recommended value of 0 means that the client processes will hibernate at every opportunity. listen.*.max_stanza_size Syntax: positive integer Default: not set, unlimited size Example: max_stanza_size = 10_000 Maximum allowed incoming stanza size in bytes. Warning: this limit is checked after the input data parsing, so it does not apply to the input data size itself. listen.*.num_acceptors Syntax: positive integer Default: 100 Example: num_acceptors = 200 The number of processes accepting new connections on the listening socket. listen.*.max_fsm_queue Syntax: positive integer Default: not set - no limit Example: max_fsm_queue = 1000 Message queue limit to prevent resource exhaustion; overrides the value set in the general section. This option does not work for s2s listeners - the general value is used for them. Client-to-server (C2S): [[listen.c2s]] Handles XMPP client-to-server (C2S) connections. The recommended port number for a C2S listener is 5222 as registered in the XMPP protocol . The following options are supported for each C2S listener: listen.c2s.access Syntax: string, rule name or \"all\" Default: \"all\" Example: access = \"c2s\" The rule that determines who is allowed to connect. By default the rule is \"all\" , which means that anyone can connect. The rule referenced here needs to be defined in the access configuration section. listen.c2s.shaper Syntax: string, rule name Default: \"none\" (no shaper) Example: shaper = \"c2s_shaper\" The rule that determines what traffic shaper is used to limit the incoming XMPP traffic to prevent the server from being flooded with incoming data. The rule referenced here needs to be defined in the access configuration section. The value of the access rule needs to be either the shaper name or the string \"none\" , which means no shaper. listen.c2s.zlib Syntax: positive integer Default: not set, disabled Example: zlib = 1024 Enables ZLIB support, the integer value is a limit for a decompressed output size in bytes (to prevent a successful ZLIB bomb attack ). TLS options for C2S The following options allow enabling and configuring TLS which makes the client-to-server conenctions secure. They all have the tls. prefix. listen.c2s.tls.mode Syntax: string, one of \"tls\" , \"starttls\" , \"starttls_required\" Default: not set Example: tls.mode = \"starttls\" By default there is no encryption for the incoming connections. You can change this by setting the tls.mode option to one of the following modes: tls - clients must initiate a TLS session immediately after connecting, before beginning the normal XML stream, starttls - enables StartTLS support; requires certfile , starttls_required - enables and enforces StartTLS usage. listen.c2s.tls.verify_peer Syntax: boolean Default: false Example: verify_peer = true Enforces verification of a client certificate. Requires a valid cacertfile . listen.c2s.tls.module Syntax: string, one of \"just_tls\" , \"fast_tls\" Default: \"fast_tls\" Example: tls.module = \"just_tls\" By default the TLS library used for C2S connections is fast_tls , which uses OpenSSL-based NIFs. It is possible to change it to just_tls - Erlang TLS implementation provided by OTP. Some TLS-related options described here have different formats for these two libraries. Requires setting tls.verify_mode . When set to false , it allows the client to connect even though the certificate verification failed. It is then up to the authentication layer to accept or reject the client connection. This behaviour mimics the FastTLS one. listen.c2s.tls.certfile Syntax: string, path in the file system Default: not set Example: tls.certfile = \"server.pem\" Path to the X509 PEM file with a certificate and a private key (not protected by a password). If the certificate is signed by an intermediate CA, you should specify here the whole CA chain by concatenating all public keys together and appending the private key after that. listen.c2s.tls.cacertfile Syntax: string, path in the file system Default: not set Example: tls.cacertfile = \"ca.pem\" Path to the X509 PEM file with a CA chain that will be used to verify clients. It won't have any effect if verify_peer is not enabled. listen.c2s.tls.dhfile Syntax: string, path in the file system Default: not set Example: tls.dhfile = \"dh.pem\" Path to the Diffie-Hellman parameter file. listen.c2s.tls.ciphers Syntax: string with the OpenSSL cipher suite specification Default: for fast_tls the default is \"TLSv1.2:TLSv1.3\" . For just_tls this option is not set by default - all supported suites are accepted. Example: tls.ciphers = \"ECDHE-RSA-AES256-GCM-SHA384:ECDHE-ECDSA-AES256-GCM-SHA384\" Cipher suites to use with StartTLS or TLS. Please refer to the OpenSSL documentation for the cipher string format. For fast_tls , this string can be used to specify versions as well. For just_tls , see the Erlang/OTP SSL documentation for allowed values. listen.c2s.tls.protocol_options - only for fast_tls Syntax: array of strings Default: [\"no_sslv2\", \"no_sslv3\", \"no_tlsv1\", \"no_tlsv1_1\"] Example: tls.protocol_options = [\"no_tlsv1\", \"no_tlsv1_1\"] A list of OpenSSL options for FastTLS. You can find the mappings between supported options and actual OpenSSL flags in the fast_tls source code . listen.c2s.tls.verify_mode - only for just_tls Syntax: string, one of \"peer\" , \"selfsigned_peer\" , \"none\" Default: not set (equivalent to \"peer\" in the current version of Erlang/OTP) Example: tls.verify_mode = \"selfsigned_peer\" Specifies the way certificate verification works: peer - makes sure the peer's certificate is valid and signed by a trusted CA, selfsigned_peer - makes sure the peer's certificate is valid, but allows self-signed certificates, none - any certificate is accepted. listen.c2s.tls.disconnect_on_failure - only for just_tls Syntax: boolean Default: true Example: tls.disconnect_on_failure = false listen.c2s.tls.versions - only for just_tls Syntax: array of strings Default: not set, all supported versions are accepted Example: tls.versions = [\"tlsv1.2\", \"tlsv1.3\"] TLS versions to use with StartTLS or TLS. For allowed values, see the Erlang/OTP SSL documentation listen.c2s.tls.crl_files - only for just_tls Syntax: array of strings, paths in the file system Default: not set Example: tls.crl_files = [\"certs.crl\"] Specifies the paths to Certificate Revocation Lists. C2S Example The following section configures two C2S listeners. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 [[listen.c2s]] port = 5222 zlib = 10000 access = \"c2s\" shaper = \"c2s_shaper\" max_stanza_size = 65536 tls . mode = \"starttls\" tls . certfile = \"server.pem\" tls . dhfile = \"dh_server.pem\" [[listen.c2s]] port = 5223 zlib = 4096 access = \"c2s\" shaper = \"c2s_shaper\" max_stanza_size = 65536 One at port 5222, which accepts a plain TCP connection and allows to use StartTLS for upgrading it to an encrypted one. The files containing the certificate and the DH parameter are also provided. One at port 5223, which accepts only encrypted TLS connections - this is the legacy method as StartTLS is preferred. Both listeners use ZLIB and the c2s and c2s_shaper rules for access management and traffic shaping, respectively. Server-to-server (S2S): [[listen.s2s]] Handles incoming server-to-server (S2S) connections (federation). The recommended port number for an S2S listener is 5269 as registered in the XMPP protocol . Note: Many S2S options are configured in the s2s section of the configuration file and they apply to both incoming and outgoing connections. listen.s2s.shaper Syntax: string, name of the shaper rule or \"none\" Default: \"none\" - no shaper Example: shaper = \"s2s_shaper\" Name of the rule that determines what traffic shaper is used to limit the incoming XMPP traffic to prevent the server from being flooded with incoming data. The rule referenced here needs to be defined in the access config section and it should return the shaper name or the value \"none\" . TLS options for S2S S2S connections do not use TLS encryption unless enabled with the use_starttls option in the s2s section. Here you can specify some additional options of the TLS encryption. listen.s2s.tls.cacertfile Syntax: string, path in the file system Default: not set Example: tls.cacertfile = \"ca.pem\" Path to the X509 PEM file with a CA chain that will be used to verify the connecting XMPP servers (acting as clients here). It won't have any effect if verify_peer is not enabled. listen.s2s.tls.dhfile Syntax: string, path in the file system Default: not set Example: tls.dhfile = \"dh.pem\" Path to the Diffie-Hellman parameter file. listen.s2s.tls.ciphers Syntax: string with the OpenSSL cipher suite specification Default: \"TLSv1.2:TLSv1.3\" Example: tls.ciphers = \"ECDHE-RSA-AES256-GCM-SHA384:ECDHE-ECDSA-AES256-GCM-SHA384\" Cipher suites to use with StartTLS. Please refer to the OpenSSL documentation for the cipher string format. S2S Example The following section configures an S2S listener with some basic settings set up. The s2s_shaper access rule is used, which requires a definition in the access section. 1 2 3 4 5 [[listen.s2s]] port = 5269 shaper = \"s2s_shaper\" max_stanza_size = 131072 tls . dhfile = \"dh_server.pem\" XMPP Components: [[listen.service]] Interface for external services acting as XMPP components ( XEP-0114: Jabber Component Protocol ), enabling communication between MongooseIM and external services over the XMPP network. The recommended port number for a component listener is 8888. According to XEP-0114: Jabber Component Protocol the component's hostname should be given in the element. listen.service.access Syntax: string, rule name or \"all\" Default: \"all\" Example: access = \"component\" Determines who is allowed to connect to the listener. By default the rule is all , which means that any external component can connect. The access rule referenced here needs to be defined in the access configuration section. listen.service.password Syntax: string Default: no default, this option is mandatory Example: password = \"secret\" The external component needs to authenticate with this password to connect. listen.service.shaper_rule Syntax: string, name of the shaper Default: \"none\" Example: shaper = \"component_shaper\" The traffic shaper used to limit the XMPP traffic to prevent the server from being flooded with incoming data. Contrary to the C2S and S2S shapers, here the shaper name directly references the shaper that needs to be defined in the shaper section. listen.service.check_from Syntax: boolean Default: true Example: check_from = false Specifies whether the server should verify the \"from\" field in stanzas from the component. listen.service.hidden_components Syntax: boolean Default: false Example: hidden_components = true All components connected to an endpoint with this option enabled will be considered \"hidden\". Hidden components have a special flag enabled in the internal component table. Alone, it doesn't change the server behaviour in any way, but it may be used by other modules and extensions to execute special logic. An example would be mod_disco , which may be configured to filter out hidden components from disco results, so they won't be discoverable by clients. A reason to do so could be reduced traffic - systems with many components could return very long disco responses. Also, some deployments would like to avoid revealing some services; not because it is a security threat (this method does not prevent clients from communicating with hidden components), but rather because they are not meant to interact with clients directly (e.g. helper components for other components). listen.service.conflict_behaviour Syntax: string, one of: \"disconnect\" , \"kick_old\" Default: \"disconnect\" Example: conflict_behaviour = \"kick_old\" By default, when a component tries to connect and a registration conflict occurs, the connection is dropped with the following error: 1 2 3 4 <stream:error> <conflict xmlns= 'urn:ietf:params:xml:ns:xmpp-streams' /> </stream:error> </stream:stream> It makes implementing the reconnection logic difficult, because the old connection would not allow any other connections. By setting this option to kick_old , we drop any old connections registered at the same host before accepting new ones. Custom extension to the protocol In order to register a component for all virtual hosts served by the server (see hosts in the general section), the component must add the attribute is_subdomain=\"true\" to the opening stream element. This maybe helpful if someone wants to have a single instance of a component serving multiple virtual hosts. The is_subdomain attribute is optional and the default behaviour is as described in XEP-0114: Jabber Component Protocol . Service listener example The following section configures a service listener, accepting connections from external components. The IP address is limited to loopback to prevent connections from different hosts. All components are allowed to connect, but they need to provide the password. The shaper named fast needs to be defined in the shaper section. 1 2 3 4 5 6 [[listen.service]] port = 8888 access = \"all\" shaper_rule = \"fast\" ip_address = \"127.0.0.1\" password = \"secret\" HTTP-based services: [[listen.http]] Manages all HTTP-based services, such as BOSH (HTTP long-polling), WebSocket and REST. It uses the Cowboy web server. Recommended port number: 5280 for BOSH/WS. There are the following options for each of the HTTP listeners: listen.http.handlers Syntax: each handler is specified in a subsection starting with [[listen.http.handlers.type]] where type is one of the allowed handler types, handling different connection types, e.g. mod_bosh - for BOSH connections, mod_websockets - for WebSocket connections, mongoose_api_* , mongoose_client_api_* , ... - for REST API. These types are described below in more detail. The double-bracket syntax is used because there can be multiple handlers of a given type, so for each type there is a TOML array of one or more tables (subsections). Default: there is no default, all handlers need to be specified explicitly. Example: two handlers, one for BOSH and one for WebSockets 1 2 3 4 5 6 7 [[listen.http.handlers.mod_bosh]] host = \"_\" path = \"/http-bind\" [[listen.http.handlers.mod_websockets]] host = \"_\" path = \"/ws-xmpp\" Common handler options listen.http.handlers.*.host Syntax: string Default: no default, mandatory option Example: host = \"localhost\" Host name for this handler or \"_\" for any host. listen.http.handlers.*.path Syntax: string Default: no default, mandatory option Example: path = \"/ws-xmpp\" Path for this handler. Handler types: BOSH - mod_bosh To handle incoming BOSH traffic you need to configure the mod_bosh module in the modules section as well. Handler types: WebSockets - mod_websockets Websocket connections as defined in RFC 7395 . You can pass the following optional parameters: listen.http.handlers.mod_websockets.timeout Syntax: positive integer or the string \"infinity\" Default: \"infinity\" Example: timeout = 60_000 The time (in milliseconds) after which an inactive user is disconnected. listen.http.handlers.mod_websockets.ping_rate Syntax: positive integer Default: not set - pings disabled Example: ping_rate = 10_000 The time between pings sent by server. By setting this option you enable server-side pinging. listen.http.handlers.mod_websockets.max_stanza_size Syntax: positive integer or the string \"infinity\" Default: \"infinity\" Example: max_stanza_size = 10_000 Maximum allowed incoming stanza size. Warning: this limit is checked after the input data parsing, so it does not apply to the input data size itself. listen.http.handlers.mod_websockets.service Syntax: an array of listen.service.* options Default: not set Example: 1 2 3 4 [listen.http.handlers.mod_websockets.service] access = \"all\" shaper_rule = \"fast\" password = \"secret\" This subsection enables external component connections over WebSockets. See the service listener section for details. Handler types: REST API - Admin - mongoose_api_admin For more information about the API, see the REST interface documentation. The following options are supported for this handler: listen.http.handlers.mongoose_api_admin.username Syntax: string Default: not set Example: username = \"admin\" When set, enables authentication for the admin API, otherwise it is disabled. Requires setting password . listen.http.handlers.mongoose_api_admin.password Syntax: string Default: not set Example: password = \"secret\" Required to enable authentication for the admin API. Handler types: REST API - Client To enable the REST API for clients, several handlers need to be added: mongoose_client_api_* - handles individual API endpoints. You can add and remove these to enable particular functionality. lasse_handler - provides the SSE handler which is required for the client HTTP API, should not be changed. cowboy_* - hosts the Swagger web-based documentation, should not be changed, but can be removed to disable the API docs. The recommended configuration is shown in Example 3 below. Please refer to REST interface documentation for more information. Handler types: Metrics API (obsolete) - mongoose_api REST API for accessing the internal MongooseIM metrics. Please refer to the REST interface to metrics page for more information. The following option is required: listen.http.handlers.mongoose_api.handlers Syntax: array of strings - Erlang modules Default: not set, this is a mandatory option for this handler Example: handlers = [\"mongoose_api_metrics\"] Transport options The options listed below are used to modify the HTTP transport settings. listen.http.transport.num_acceptors Syntax: positive integer Default: 100 Example: transport.num_acceptors = 10 Number of HTTP connection acceptors. listen.http.transport.max_connections Syntax: positive integer or the string \"infinity\" Default: 1024 Example: transport.max_connections = \"infinity\" Maximum number of open connections. The default value of 1024 is set by the Ranch library. TLS (HTTPS) options By default the HTTP listener does not use TLS. To use TLS (HTTPS), you need to add a TOML table (subsection) called tls to the config file with the certfile and keyfile options that specify the location of the certificate and private key files, respectively. If the keyfile is password-protected, password is required as well. If the certificate is signed by an intermediate CA, one will probably want to specify the CA chain with the cacertfile option. The library used for HTTP is the Erlang TLS implementation provided by OTP - see ranch_ssl for details. listen.http.tls.verify_peer Syntax: boolean Default: false Example: tls.verify_peer = true Enforces verification of a client certificate. Requires a valid cacertfile . listen.http.tls.verify_mode Syntax: string, one of \"peer\" , \"selfsigned_peer\" , \"none\" Default: not set (equivalent to \"peer\" in the current version of Erlang/OTP) Example: tls.verify_mode = \"selfsigned_peer\" Specifies the way certificate verification works: peer - makes sure the peer's certificate is valid and signed by a trusted CA, selfsigned_peer - makes sure the peer's certificate is valid, but allows self-signed certificates, none - any certificate is accepted. listen.http.tls.certfile Syntax: string, path in the file system Default: not set Example: tls.certfile = \"server.pem\" Path to the X509 PEM file with a certificate and a private key (not protected by a password). If the certificate is signed by an intermediate CA, you should specify here the whole CA chain by concatenating all public keys together and appending the private key after that. listen.http.tls.cacertfile Syntax: string, path in the file system Default: not set Example: tls.cacertfile = \"ca.pem\" Path to the X509 PEM file with a CA chain that will be used to verify clients. It won't have any effect if verify_peer is not enabled. listen.http.tls.dhfile Syntax: string, path in the file system Default: not set Example: tls.dhfile = \"dh.pem\" Path to the Diffie-Hellman parameter file. listen.http.tls.ciphers Syntax: string with the OpenSSL cipher suite specification Default: not set, all supported cipher suites are accepted Example: tls.ciphers = \"ECDHE-RSA-AES256-GCM-SHA384:ECDHE-ECDSA-AES256-GCM-SHA384\" Cipher suites to use. Please refer to the OpenSSL documentation for the cipher string format. For allowed values, see the Erlang/OTP OpenSSL documentation . listen.http.tls.versions Syntax: array of strings Default: not set, all supported versions are accepted Example: tls.versions = [\"tlsv1.2\", \"tlsv1.3\"] TLS versions to use. For allowed values, see the Erlang/OTP SSL documentation listen.http.tls.keyfile Syntax: string, path in the file system Default: not set Example: tls.keyfile = \"key.pem\" Path to the X509 PEM file with the private key. listen.http.tls.password Syntax: string Default: not set Example: tls.password = \"secret\" Password to the X509 PEM file with the private key. Protocol options These are some additional options of the HTTP protocol. listen.http.protocol.compress Syntax: boolean Default: false Example: protocol.compress = \"true\" Compresses response bodies automatically when the client supports it. HTTP listener examples The examples shown below are included in the provided default configuration file. Example 1. BOSH and WS The following listener accepts BOSH and WebSocket connections and has TLS configured. 1 2 3 4 5 6 7 8 9 10 11 12 13 [[listen.http]] port = 5285 tls . certfile = \"mycert.pem\" tls . keyfile = \"mykey.pem\" tls . password = \"secret\" [[listen.http.handlers.mod_bosh]] host = \"_\" path = \"/http-bind\" [[listen.http.handlers.mod_websockets]] host = \"_\" path = \"/ws-xmpp\" Example 2. Admin API REST API for administration, the listener is bound to 127.0.0.1 for increased security. The number of acceptors and connections is specified (reduced). 1 2 3 4 5 6 7 8 9 [[listen.http]] ip_address = \"127.0.0.1\" port = 8088 transport . num_acceptors = 5 transport . max_connections = 10 [[listen.http.handlers.mongoose_api_admin]] host = \"localhost\" path = \"/api\" Example 3. Client API REST API for clients. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 [[listen.http]] port = 8089 transport . max_connections = 1024 protocol . compress = true [[listen.http.handlers.lasse_handler]] host = \"_\" path = \"/api/sse\" module = \"mongoose_client_api_sse\" [[listen.http.handlers.mongoose_client_api_messages]] host = \"_\" path = \"/api/messages/[:with]\" [[listen.http.handlers.mongoose_client_api_contacts]] host = \"_\" path = \"/api/contacts/[:jid]\" [[listen.http.handlers.mongoose_client_api_rooms]] host = \"_\" path = \"/api/rooms/[:id]\" [[listen.http.handlers.mongoose_client_api_rooms_config]] host = \"_\" path = \"/api/rooms/[:id]/config\" [[listen.http.handlers.mongoose_client_api_rooms_users]] host = \"_\" path = \"/api/rooms/:id/users/[:user]\" [[listen.http.handlers.mongoose_client_api_rooms_messages]] host = \"_\" path = \"/api/rooms/[:id]/messages\" [[listen.http.handlers.cowboy_swagger_redirect_handler]] host = \"_\" path = \"/api-docs\" [[listen.http.handlers.cowboy_swagger_json_handler]] host = \"_\" path = \"/api-docs/swagger.json\" [[listen.http.handlers.cowboy_static]] host = \"_\" path = \"/api-docs/[...]\" type = \"priv_dir\" app = \"cowboy_swagger\" content_path = \"swagger\"","title":"Options: Listen"},{"location":"advanced-configuration/listen/#general-listener-options","text":"The options listed below are the same for all listener types. They set the basic listening socket options. Only port is required, the rest can be used to change the default settings.","title":"General listener options"},{"location":"advanced-configuration/listen/#listenport","text":"Syntax: integer, port number Default: no default, this option is mandatory. Example: port = 5222 The port number to which the listening socket is bound.","title":"listen.*.port"},{"location":"advanced-configuration/listen/#listenip_address","text":"Syntax: string with the IP address Default: all-zeros address (e.g. \"0.0.0.0\" for IPv4) Example: ip_address = \"127.0.0.1\" The IP address to which the listening socket is bound.","title":"listen.*.ip_address"},{"location":"advanced-configuration/listen/#listenproto","text":"Syntax: string, \"udp\" or \"tcp\" Default: \"tcp\" Example: proto = \"udp\" The protocol, which is TCP by default. There is no reason to change this for XMPP or HTTP listeners.","title":"listen.*.proto"},{"location":"advanced-configuration/listen/#listenip_version","text":"Syntax: integer, 4 or 6 Default: if ip_address is specified, the IP version is determined from that address, otherwise it is 4 Example: ip_version = 6 Allows to set the IP version to IPv6. Does not need to be set if ip_address is defined.","title":"listen.*.ip_version"},{"location":"advanced-configuration/listen/#xmpp-listener-options","text":"The options listed below can be set for the c2s , s2s and service listeners to adjust their parameters.","title":"XMPP listener options"},{"location":"advanced-configuration/listen/#listenbacklog","text":"Syntax: positive integer Default: 100 Example: backlog = 1000 Overrides the default TCP backlog value.","title":"listen.*.backlog"},{"location":"advanced-configuration/listen/#listenproxy_protocol","text":"Syntax: boolean Default: false Example: proxy_protocol = true When set to true , Proxy Protocol is enabled and each connecting client has to provide a proxy header. Use only with a proxy (or a load balancer) to allow it to provide the connection details (including the source IP address) of the original client. Versions 1 and 2 of the protocol are supported.","title":"listen.*.proxy_protocol"},{"location":"advanced-configuration/listen/#listenhibernate_after","text":"Syntax: non-negative integer Default: 0 Example: hibernate_after = 10 Time in milliseconds after which a client process spawned by this listener will hibernate. Hibernation greatly reduces memory consumption of client processes, but may result in increased CPU consumption if a client is used very frequently. The default, recommended value of 0 means that the client processes will hibernate at every opportunity.","title":"listen.*.hibernate_after"},{"location":"advanced-configuration/listen/#listenmax_stanza_size","text":"Syntax: positive integer Default: not set, unlimited size Example: max_stanza_size = 10_000 Maximum allowed incoming stanza size in bytes. Warning: this limit is checked after the input data parsing, so it does not apply to the input data size itself.","title":"listen.*.max_stanza_size"},{"location":"advanced-configuration/listen/#listennum_acceptors","text":"Syntax: positive integer Default: 100 Example: num_acceptors = 200 The number of processes accepting new connections on the listening socket.","title":"listen.*.num_acceptors"},{"location":"advanced-configuration/listen/#listenmax_fsm_queue","text":"Syntax: positive integer Default: not set - no limit Example: max_fsm_queue = 1000 Message queue limit to prevent resource exhaustion; overrides the value set in the general section. This option does not work for s2s listeners - the general value is used for them.","title":"listen.*.max_fsm_queue"},{"location":"advanced-configuration/listen/#client-to-server-c2s-listenc2s","text":"Handles XMPP client-to-server (C2S) connections. The recommended port number for a C2S listener is 5222 as registered in the XMPP protocol . The following options are supported for each C2S listener:","title":"Client-to-server (C2S): [[listen.c2s]]"},{"location":"advanced-configuration/listen/#listenc2saccess","text":"Syntax: string, rule name or \"all\" Default: \"all\" Example: access = \"c2s\" The rule that determines who is allowed to connect. By default the rule is \"all\" , which means that anyone can connect. The rule referenced here needs to be defined in the access configuration section.","title":"listen.c2s.access"},{"location":"advanced-configuration/listen/#listenc2sshaper","text":"Syntax: string, rule name Default: \"none\" (no shaper) Example: shaper = \"c2s_shaper\" The rule that determines what traffic shaper is used to limit the incoming XMPP traffic to prevent the server from being flooded with incoming data. The rule referenced here needs to be defined in the access configuration section. The value of the access rule needs to be either the shaper name or the string \"none\" , which means no shaper.","title":"listen.c2s.shaper"},{"location":"advanced-configuration/listen/#listenc2szlib","text":"Syntax: positive integer Default: not set, disabled Example: zlib = 1024 Enables ZLIB support, the integer value is a limit for a decompressed output size in bytes (to prevent a successful ZLIB bomb attack ).","title":"listen.c2s.zlib"},{"location":"advanced-configuration/listen/#tls-options-for-c2s","text":"The following options allow enabling and configuring TLS which makes the client-to-server conenctions secure. They all have the tls. prefix.","title":"TLS options for C2S"},{"location":"advanced-configuration/listen/#listenc2stlsmode","text":"Syntax: string, one of \"tls\" , \"starttls\" , \"starttls_required\" Default: not set Example: tls.mode = \"starttls\" By default there is no encryption for the incoming connections. You can change this by setting the tls.mode option to one of the following modes: tls - clients must initiate a TLS session immediately after connecting, before beginning the normal XML stream, starttls - enables StartTLS support; requires certfile , starttls_required - enables and enforces StartTLS usage.","title":"listen.c2s.tls.mode"},{"location":"advanced-configuration/listen/#listenc2stlsverify_peer","text":"Syntax: boolean Default: false Example: verify_peer = true Enforces verification of a client certificate. Requires a valid cacertfile .","title":"listen.c2s.tls.verify_peer"},{"location":"advanced-configuration/listen/#listenc2stlsmodule","text":"Syntax: string, one of \"just_tls\" , \"fast_tls\" Default: \"fast_tls\" Example: tls.module = \"just_tls\" By default the TLS library used for C2S connections is fast_tls , which uses OpenSSL-based NIFs. It is possible to change it to just_tls - Erlang TLS implementation provided by OTP. Some TLS-related options described here have different formats for these two libraries. Requires setting tls.verify_mode . When set to false , it allows the client to connect even though the certificate verification failed. It is then up to the authentication layer to accept or reject the client connection. This behaviour mimics the FastTLS one.","title":"listen.c2s.tls.module"},{"location":"advanced-configuration/listen/#listenc2stlscertfile","text":"Syntax: string, path in the file system Default: not set Example: tls.certfile = \"server.pem\" Path to the X509 PEM file with a certificate and a private key (not protected by a password). If the certificate is signed by an intermediate CA, you should specify here the whole CA chain by concatenating all public keys together and appending the private key after that.","title":"listen.c2s.tls.certfile"},{"location":"advanced-configuration/listen/#listenc2stlscacertfile","text":"Syntax: string, path in the file system Default: not set Example: tls.cacertfile = \"ca.pem\" Path to the X509 PEM file with a CA chain that will be used to verify clients. It won't have any effect if verify_peer is not enabled.","title":"listen.c2s.tls.cacertfile"},{"location":"advanced-configuration/listen/#listenc2stlsdhfile","text":"Syntax: string, path in the file system Default: not set Example: tls.dhfile = \"dh.pem\" Path to the Diffie-Hellman parameter file.","title":"listen.c2s.tls.dhfile"},{"location":"advanced-configuration/listen/#listenc2stlsciphers","text":"Syntax: string with the OpenSSL cipher suite specification Default: for fast_tls the default is \"TLSv1.2:TLSv1.3\" . For just_tls this option is not set by default - all supported suites are accepted. Example: tls.ciphers = \"ECDHE-RSA-AES256-GCM-SHA384:ECDHE-ECDSA-AES256-GCM-SHA384\" Cipher suites to use with StartTLS or TLS. Please refer to the OpenSSL documentation for the cipher string format. For fast_tls , this string can be used to specify versions as well. For just_tls , see the Erlang/OTP SSL documentation for allowed values.","title":"listen.c2s.tls.ciphers"},{"location":"advanced-configuration/listen/#listenc2stlsprotocol_options-only-for-fast_tls","text":"Syntax: array of strings Default: [\"no_sslv2\", \"no_sslv3\", \"no_tlsv1\", \"no_tlsv1_1\"] Example: tls.protocol_options = [\"no_tlsv1\", \"no_tlsv1_1\"] A list of OpenSSL options for FastTLS. You can find the mappings between supported options and actual OpenSSL flags in the fast_tls source code .","title":"listen.c2s.tls.protocol_options - only for fast_tls"},{"location":"advanced-configuration/listen/#listenc2stlsverify_mode-only-for-just_tls","text":"Syntax: string, one of \"peer\" , \"selfsigned_peer\" , \"none\" Default: not set (equivalent to \"peer\" in the current version of Erlang/OTP) Example: tls.verify_mode = \"selfsigned_peer\" Specifies the way certificate verification works: peer - makes sure the peer's certificate is valid and signed by a trusted CA, selfsigned_peer - makes sure the peer's certificate is valid, but allows self-signed certificates, none - any certificate is accepted.","title":"listen.c2s.tls.verify_mode - only for just_tls"},{"location":"advanced-configuration/listen/#listenc2stlsdisconnect_on_failure-only-for-just_tls","text":"Syntax: boolean Default: true Example: tls.disconnect_on_failure = false","title":"listen.c2s.tls.disconnect_on_failure - only for just_tls"},{"location":"advanced-configuration/listen/#listenc2stlsversions-only-for-just_tls","text":"Syntax: array of strings Default: not set, all supported versions are accepted Example: tls.versions = [\"tlsv1.2\", \"tlsv1.3\"] TLS versions to use with StartTLS or TLS. For allowed values, see the Erlang/OTP SSL documentation","title":"listen.c2s.tls.versions - only for just_tls"},{"location":"advanced-configuration/listen/#listenc2stlscrl_files-only-for-just_tls","text":"Syntax: array of strings, paths in the file system Default: not set Example: tls.crl_files = [\"certs.crl\"] Specifies the paths to Certificate Revocation Lists.","title":"listen.c2s.tls.crl_files - only for just_tls"},{"location":"advanced-configuration/listen/#c2s-example","text":"The following section configures two C2S listeners. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 [[listen.c2s]] port = 5222 zlib = 10000 access = \"c2s\" shaper = \"c2s_shaper\" max_stanza_size = 65536 tls . mode = \"starttls\" tls . certfile = \"server.pem\" tls . dhfile = \"dh_server.pem\" [[listen.c2s]] port = 5223 zlib = 4096 access = \"c2s\" shaper = \"c2s_shaper\" max_stanza_size = 65536 One at port 5222, which accepts a plain TCP connection and allows to use StartTLS for upgrading it to an encrypted one. The files containing the certificate and the DH parameter are also provided. One at port 5223, which accepts only encrypted TLS connections - this is the legacy method as StartTLS is preferred. Both listeners use ZLIB and the c2s and c2s_shaper rules for access management and traffic shaping, respectively.","title":"C2S Example"},{"location":"advanced-configuration/listen/#server-to-server-s2s-listens2s","text":"Handles incoming server-to-server (S2S) connections (federation). The recommended port number for an S2S listener is 5269 as registered in the XMPP protocol . Note: Many S2S options are configured in the s2s section of the configuration file and they apply to both incoming and outgoing connections.","title":"Server-to-server (S2S): [[listen.s2s]]"},{"location":"advanced-configuration/listen/#listens2sshaper","text":"Syntax: string, name of the shaper rule or \"none\" Default: \"none\" - no shaper Example: shaper = \"s2s_shaper\" Name of the rule that determines what traffic shaper is used to limit the incoming XMPP traffic to prevent the server from being flooded with incoming data. The rule referenced here needs to be defined in the access config section and it should return the shaper name or the value \"none\" .","title":"listen.s2s.shaper"},{"location":"advanced-configuration/listen/#tls-options-for-s2s","text":"S2S connections do not use TLS encryption unless enabled with the use_starttls option in the s2s section. Here you can specify some additional options of the TLS encryption.","title":"TLS options for S2S"},{"location":"advanced-configuration/listen/#listens2stlscacertfile","text":"Syntax: string, path in the file system Default: not set Example: tls.cacertfile = \"ca.pem\" Path to the X509 PEM file with a CA chain that will be used to verify the connecting XMPP servers (acting as clients here). It won't have any effect if verify_peer is not enabled.","title":"listen.s2s.tls.cacertfile"},{"location":"advanced-configuration/listen/#listens2stlsdhfile","text":"Syntax: string, path in the file system Default: not set Example: tls.dhfile = \"dh.pem\" Path to the Diffie-Hellman parameter file.","title":"listen.s2s.tls.dhfile"},{"location":"advanced-configuration/listen/#listens2stlsciphers","text":"Syntax: string with the OpenSSL cipher suite specification Default: \"TLSv1.2:TLSv1.3\" Example: tls.ciphers = \"ECDHE-RSA-AES256-GCM-SHA384:ECDHE-ECDSA-AES256-GCM-SHA384\" Cipher suites to use with StartTLS. Please refer to the OpenSSL documentation for the cipher string format.","title":"listen.s2s.tls.ciphers"},{"location":"advanced-configuration/listen/#s2s-example","text":"The following section configures an S2S listener with some basic settings set up. The s2s_shaper access rule is used, which requires a definition in the access section. 1 2 3 4 5 [[listen.s2s]] port = 5269 shaper = \"s2s_shaper\" max_stanza_size = 131072 tls . dhfile = \"dh_server.pem\"","title":"S2S Example"},{"location":"advanced-configuration/listen/#xmpp-components-listenservice","text":"Interface for external services acting as XMPP components ( XEP-0114: Jabber Component Protocol ), enabling communication between MongooseIM and external services over the XMPP network. The recommended port number for a component listener is 8888. According to XEP-0114: Jabber Component Protocol the component's hostname should be given in the element.","title":"XMPP Components: [[listen.service]]"},{"location":"advanced-configuration/listen/#listenserviceaccess","text":"Syntax: string, rule name or \"all\" Default: \"all\" Example: access = \"component\" Determines who is allowed to connect to the listener. By default the rule is all , which means that any external component can connect. The access rule referenced here needs to be defined in the access configuration section.","title":"listen.service.access"},{"location":"advanced-configuration/listen/#listenservicepassword","text":"Syntax: string Default: no default, this option is mandatory Example: password = \"secret\" The external component needs to authenticate with this password to connect.","title":"listen.service.password"},{"location":"advanced-configuration/listen/#listenserviceshaper_rule","text":"Syntax: string, name of the shaper Default: \"none\" Example: shaper = \"component_shaper\" The traffic shaper used to limit the XMPP traffic to prevent the server from being flooded with incoming data. Contrary to the C2S and S2S shapers, here the shaper name directly references the shaper that needs to be defined in the shaper section.","title":"listen.service.shaper_rule"},{"location":"advanced-configuration/listen/#listenservicecheck_from","text":"Syntax: boolean Default: true Example: check_from = false Specifies whether the server should verify the \"from\" field in stanzas from the component.","title":"listen.service.check_from"},{"location":"advanced-configuration/listen/#listenservicehidden_components","text":"Syntax: boolean Default: false Example: hidden_components = true All components connected to an endpoint with this option enabled will be considered \"hidden\". Hidden components have a special flag enabled in the internal component table. Alone, it doesn't change the server behaviour in any way, but it may be used by other modules and extensions to execute special logic. An example would be mod_disco , which may be configured to filter out hidden components from disco results, so they won't be discoverable by clients. A reason to do so could be reduced traffic - systems with many components could return very long disco responses. Also, some deployments would like to avoid revealing some services; not because it is a security threat (this method does not prevent clients from communicating with hidden components), but rather because they are not meant to interact with clients directly (e.g. helper components for other components).","title":"listen.service.hidden_components"},{"location":"advanced-configuration/listen/#listenserviceconflict_behaviour","text":"Syntax: string, one of: \"disconnect\" , \"kick_old\" Default: \"disconnect\" Example: conflict_behaviour = \"kick_old\" By default, when a component tries to connect and a registration conflict occurs, the connection is dropped with the following error: 1 2 3 4 <stream:error> <conflict xmlns= 'urn:ietf:params:xml:ns:xmpp-streams' /> </stream:error> </stream:stream> It makes implementing the reconnection logic difficult, because the old connection would not allow any other connections. By setting this option to kick_old , we drop any old connections registered at the same host before accepting new ones.","title":"listen.service.conflict_behaviour"},{"location":"advanced-configuration/listen/#custom-extension-to-the-protocol","text":"In order to register a component for all virtual hosts served by the server (see hosts in the general section), the component must add the attribute is_subdomain=\"true\" to the opening stream element. This maybe helpful if someone wants to have a single instance of a component serving multiple virtual hosts. The is_subdomain attribute is optional and the default behaviour is as described in XEP-0114: Jabber Component Protocol .","title":"Custom extension to the protocol"},{"location":"advanced-configuration/listen/#service-listener-example","text":"The following section configures a service listener, accepting connections from external components. The IP address is limited to loopback to prevent connections from different hosts. All components are allowed to connect, but they need to provide the password. The shaper named fast needs to be defined in the shaper section. 1 2 3 4 5 6 [[listen.service]] port = 8888 access = \"all\" shaper_rule = \"fast\" ip_address = \"127.0.0.1\" password = \"secret\"","title":"Service listener example"},{"location":"advanced-configuration/listen/#http-based-services-listenhttp","text":"Manages all HTTP-based services, such as BOSH (HTTP long-polling), WebSocket and REST. It uses the Cowboy web server. Recommended port number: 5280 for BOSH/WS. There are the following options for each of the HTTP listeners:","title":"HTTP-based services: [[listen.http]]"},{"location":"advanced-configuration/listen/#listenhttphandlers","text":"Syntax: each handler is specified in a subsection starting with [[listen.http.handlers.type]] where type is one of the allowed handler types, handling different connection types, e.g. mod_bosh - for BOSH connections, mod_websockets - for WebSocket connections, mongoose_api_* , mongoose_client_api_* , ... - for REST API. These types are described below in more detail. The double-bracket syntax is used because there can be multiple handlers of a given type, so for each type there is a TOML array of one or more tables (subsections). Default: there is no default, all handlers need to be specified explicitly. Example: two handlers, one for BOSH and one for WebSockets 1 2 3 4 5 6 7 [[listen.http.handlers.mod_bosh]] host = \"_\" path = \"/http-bind\" [[listen.http.handlers.mod_websockets]] host = \"_\" path = \"/ws-xmpp\"","title":"listen.http.handlers"},{"location":"advanced-configuration/listen/#common-handler-options","text":"","title":"Common handler options"},{"location":"advanced-configuration/listen/#listenhttphandlershost","text":"Syntax: string Default: no default, mandatory option Example: host = \"localhost\" Host name for this handler or \"_\" for any host.","title":"listen.http.handlers.*.host"},{"location":"advanced-configuration/listen/#listenhttphandlerspath","text":"Syntax: string Default: no default, mandatory option Example: path = \"/ws-xmpp\" Path for this handler.","title":"listen.http.handlers.*.path"},{"location":"advanced-configuration/listen/#handler-types-bosh-mod_bosh","text":"To handle incoming BOSH traffic you need to configure the mod_bosh module in the modules section as well.","title":"Handler types: BOSH - mod_bosh"},{"location":"advanced-configuration/listen/#handler-types-websockets-mod_websockets","text":"Websocket connections as defined in RFC 7395 . You can pass the following optional parameters:","title":"Handler types: WebSockets - mod_websockets"},{"location":"advanced-configuration/listen/#listenhttphandlersmod_websocketstimeout","text":"Syntax: positive integer or the string \"infinity\" Default: \"infinity\" Example: timeout = 60_000 The time (in milliseconds) after which an inactive user is disconnected.","title":"listen.http.handlers.mod_websockets.timeout"},{"location":"advanced-configuration/listen/#listenhttphandlersmod_websocketsping_rate","text":"Syntax: positive integer Default: not set - pings disabled Example: ping_rate = 10_000 The time between pings sent by server. By setting this option you enable server-side pinging.","title":"listen.http.handlers.mod_websockets.ping_rate"},{"location":"advanced-configuration/listen/#listenhttphandlersmod_websocketsmax_stanza_size","text":"Syntax: positive integer or the string \"infinity\" Default: \"infinity\" Example: max_stanza_size = 10_000 Maximum allowed incoming stanza size. Warning: this limit is checked after the input data parsing, so it does not apply to the input data size itself.","title":"listen.http.handlers.mod_websockets.max_stanza_size"},{"location":"advanced-configuration/listen/#listenhttphandlersmod_websocketsservice","text":"Syntax: an array of listen.service.* options Default: not set Example: 1 2 3 4 [listen.http.handlers.mod_websockets.service] access = \"all\" shaper_rule = \"fast\" password = \"secret\" This subsection enables external component connections over WebSockets. See the service listener section for details.","title":"listen.http.handlers.mod_websockets.service"},{"location":"advanced-configuration/listen/#handler-types-rest-api-admin-mongoose_api_admin","text":"For more information about the API, see the REST interface documentation. The following options are supported for this handler:","title":"Handler types: REST API - Admin - mongoose_api_admin"},{"location":"advanced-configuration/listen/#listenhttphandlersmongoose_api_adminusername","text":"Syntax: string Default: not set Example: username = \"admin\" When set, enables authentication for the admin API, otherwise it is disabled. Requires setting password .","title":"listen.http.handlers.mongoose_api_admin.username"},{"location":"advanced-configuration/listen/#listenhttphandlersmongoose_api_adminpassword","text":"Syntax: string Default: not set Example: password = \"secret\" Required to enable authentication for the admin API.","title":"listen.http.handlers.mongoose_api_admin.password"},{"location":"advanced-configuration/listen/#handler-types-rest-api-client","text":"To enable the REST API for clients, several handlers need to be added: mongoose_client_api_* - handles individual API endpoints. You can add and remove these to enable particular functionality. lasse_handler - provides the SSE handler which is required for the client HTTP API, should not be changed. cowboy_* - hosts the Swagger web-based documentation, should not be changed, but can be removed to disable the API docs. The recommended configuration is shown in Example 3 below. Please refer to REST interface documentation for more information.","title":"Handler types: REST API - Client"},{"location":"advanced-configuration/listen/#handler-types-metrics-api-obsolete-mongoose_api","text":"REST API for accessing the internal MongooseIM metrics. Please refer to the REST interface to metrics page for more information. The following option is required:","title":"Handler types: Metrics API (obsolete) - mongoose_api"},{"location":"advanced-configuration/listen/#listenhttphandlersmongoose_apihandlers","text":"Syntax: array of strings - Erlang modules Default: not set, this is a mandatory option for this handler Example: handlers = [\"mongoose_api_metrics\"]","title":"listen.http.handlers.mongoose_api.handlers"},{"location":"advanced-configuration/listen/#transport-options","text":"The options listed below are used to modify the HTTP transport settings.","title":"Transport options"},{"location":"advanced-configuration/listen/#listenhttptransportnum_acceptors","text":"Syntax: positive integer Default: 100 Example: transport.num_acceptors = 10 Number of HTTP connection acceptors.","title":"listen.http.transport.num_acceptors"},{"location":"advanced-configuration/listen/#listenhttptransportmax_connections","text":"Syntax: positive integer or the string \"infinity\" Default: 1024 Example: transport.max_connections = \"infinity\" Maximum number of open connections. The default value of 1024 is set by the Ranch library.","title":"listen.http.transport.max_connections"},{"location":"advanced-configuration/listen/#tls-https-options","text":"By default the HTTP listener does not use TLS. To use TLS (HTTPS), you need to add a TOML table (subsection) called tls to the config file with the certfile and keyfile options that specify the location of the certificate and private key files, respectively. If the keyfile is password-protected, password is required as well. If the certificate is signed by an intermediate CA, one will probably want to specify the CA chain with the cacertfile option. The library used for HTTP is the Erlang TLS implementation provided by OTP - see ranch_ssl for details.","title":"TLS (HTTPS) options"},{"location":"advanced-configuration/listen/#listenhttptlsverify_peer","text":"Syntax: boolean Default: false Example: tls.verify_peer = true Enforces verification of a client certificate. Requires a valid cacertfile .","title":"listen.http.tls.verify_peer"},{"location":"advanced-configuration/listen/#listenhttptlsverify_mode","text":"Syntax: string, one of \"peer\" , \"selfsigned_peer\" , \"none\" Default: not set (equivalent to \"peer\" in the current version of Erlang/OTP) Example: tls.verify_mode = \"selfsigned_peer\" Specifies the way certificate verification works: peer - makes sure the peer's certificate is valid and signed by a trusted CA, selfsigned_peer - makes sure the peer's certificate is valid, but allows self-signed certificates, none - any certificate is accepted.","title":"listen.http.tls.verify_mode"},{"location":"advanced-configuration/listen/#listenhttptlscertfile","text":"Syntax: string, path in the file system Default: not set Example: tls.certfile = \"server.pem\" Path to the X509 PEM file with a certificate and a private key (not protected by a password). If the certificate is signed by an intermediate CA, you should specify here the whole CA chain by concatenating all public keys together and appending the private key after that.","title":"listen.http.tls.certfile"},{"location":"advanced-configuration/listen/#listenhttptlscacertfile","text":"Syntax: string, path in the file system Default: not set Example: tls.cacertfile = \"ca.pem\" Path to the X509 PEM file with a CA chain that will be used to verify clients. It won't have any effect if verify_peer is not enabled.","title":"listen.http.tls.cacertfile"},{"location":"advanced-configuration/listen/#listenhttptlsdhfile","text":"Syntax: string, path in the file system Default: not set Example: tls.dhfile = \"dh.pem\" Path to the Diffie-Hellman parameter file.","title":"listen.http.tls.dhfile"},{"location":"advanced-configuration/listen/#listenhttptlsciphers","text":"Syntax: string with the OpenSSL cipher suite specification Default: not set, all supported cipher suites are accepted Example: tls.ciphers = \"ECDHE-RSA-AES256-GCM-SHA384:ECDHE-ECDSA-AES256-GCM-SHA384\" Cipher suites to use. Please refer to the OpenSSL documentation for the cipher string format. For allowed values, see the Erlang/OTP OpenSSL documentation .","title":"listen.http.tls.ciphers"},{"location":"advanced-configuration/listen/#listenhttptlsversions","text":"Syntax: array of strings Default: not set, all supported versions are accepted Example: tls.versions = [\"tlsv1.2\", \"tlsv1.3\"] TLS versions to use. For allowed values, see the Erlang/OTP SSL documentation","title":"listen.http.tls.versions"},{"location":"advanced-configuration/listen/#listenhttptlskeyfile","text":"Syntax: string, path in the file system Default: not set Example: tls.keyfile = \"key.pem\" Path to the X509 PEM file with the private key.","title":"listen.http.tls.keyfile"},{"location":"advanced-configuration/listen/#listenhttptlspassword","text":"Syntax: string Default: not set Example: tls.password = \"secret\" Password to the X509 PEM file with the private key.","title":"listen.http.tls.password"},{"location":"advanced-configuration/listen/#protocol-options","text":"These are some additional options of the HTTP protocol.","title":"Protocol options"},{"location":"advanced-configuration/listen/#listenhttpprotocolcompress","text":"Syntax: boolean Default: false Example: protocol.compress = \"true\" Compresses response bodies automatically when the client supports it.","title":"listen.http.protocol.compress"},{"location":"advanced-configuration/listen/#http-listener-examples","text":"The examples shown below are included in the provided default configuration file.","title":"HTTP listener examples"},{"location":"advanced-configuration/listen/#example-1-bosh-and-ws","text":"The following listener accepts BOSH and WebSocket connections and has TLS configured. 1 2 3 4 5 6 7 8 9 10 11 12 13 [[listen.http]] port = 5285 tls . certfile = \"mycert.pem\" tls . keyfile = \"mykey.pem\" tls . password = \"secret\" [[listen.http.handlers.mod_bosh]] host = \"_\" path = \"/http-bind\" [[listen.http.handlers.mod_websockets]] host = \"_\" path = \"/ws-xmpp\"","title":"Example 1. BOSH and WS"},{"location":"advanced-configuration/listen/#example-2-admin-api","text":"REST API for administration, the listener is bound to 127.0.0.1 for increased security. The number of acceptors and connections is specified (reduced). 1 2 3 4 5 6 7 8 9 [[listen.http]] ip_address = \"127.0.0.1\" port = 8088 transport . num_acceptors = 5 transport . max_connections = 10 [[listen.http.handlers.mongoose_api_admin]] host = \"localhost\" path = \"/api\"","title":"Example 2. Admin API"},{"location":"advanced-configuration/listen/#example-3-client-api","text":"REST API for clients. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 [[listen.http]] port = 8089 transport . max_connections = 1024 protocol . compress = true [[listen.http.handlers.lasse_handler]] host = \"_\" path = \"/api/sse\" module = \"mongoose_client_api_sse\" [[listen.http.handlers.mongoose_client_api_messages]] host = \"_\" path = \"/api/messages/[:with]\" [[listen.http.handlers.mongoose_client_api_contacts]] host = \"_\" path = \"/api/contacts/[:jid]\" [[listen.http.handlers.mongoose_client_api_rooms]] host = \"_\" path = \"/api/rooms/[:id]\" [[listen.http.handlers.mongoose_client_api_rooms_config]] host = \"_\" path = \"/api/rooms/[:id]/config\" [[listen.http.handlers.mongoose_client_api_rooms_users]] host = \"_\" path = \"/api/rooms/:id/users/[:user]\" [[listen.http.handlers.mongoose_client_api_rooms_messages]] host = \"_\" path = \"/api/rooms/[:id]/messages\" [[listen.http.handlers.cowboy_swagger_redirect_handler]] host = \"_\" path = \"/api-docs\" [[listen.http.handlers.cowboy_swagger_json_handler]] host = \"_\" path = \"/api-docs/swagger.json\" [[listen.http.handlers.cowboy_static]] host = \"_\" path = \"/api-docs/[...]\" type = \"priv_dir\" app = \"cowboy_swagger\" content_path = \"swagger\"","title":"Example 3. Client API"},{"location":"advanced-configuration/outgoing-connections/","text":"MongooseIM can be configured to talk to external services like databases or HTTP servers in order to get or set the required data. The interface for outgoing connections management was unified and is now available via the outgoing_pools config option for the following type of connections: cassandra - pool of connections to Cassandra cluster riak - pool of connections to Riak cluster redis - pool of connections to Redis server http - pool of connections to an HTTP(S) server MongooseIM can talk to, for example HTTP authentication backend or HTTP notifications elastic - pool of connections to ElasticSearch server rdbms - pool of connections to an RDBMS database rabbit - pool of connections to a RabbitMQ server ldap - pool of connections to an LDAP server Syntax: Each pool is specified in a subsection starting with [outgoing_pools.type.tag] , where type is one of available connection types and tag is an arbitrary value uniquely identifying the pool within its type. This allows you to create multiple dedicated pools of the same type. General pool options outgoing_pools.*.*.scope Syntax: string, one of: \"global\" , \"host\" , \"single_host\" Default: \"global\" Example: scope = \"host\" outgoing_pools.*.*.host Syntax: string Default: no default; required if \"single_host\" scope is specified Example: host = \"anotherhost.com\" scope can be set to: * global - meaning that the pool will started once no matter how many XMPP hosts are served by MongooseIM * host - the pool will be started for each XMPP host served by MongooseIM * single_host - the pool will be started for the selected host only (you must provide a host name). Worker pool options All pools are managed by the inaka/worker_pool library. Available options are: outgoing_pools.*.*.strategy Syntax: string, one of: \"best_worker\" , \"random_worker\" , \"next_worker\" , \"available_worker\" , \"next_available_worker\" Default: \"best_worker\" Example: strategy = \"available_worker\" Defines worker seletion strategy. Consult worker_pool documentation for details. outgoing_pools.*.*.workers Syntax: positive integer Default: 100 Example: workers = 10 Number of workers to be started by the pool. outgoing_pools.*.*.call_timeout Syntax: positive integer Default: 5000 Example: call_timeout = 5000 Number of milliseconds after which a call to the pool will time out. Connection options Options specific to a pool connection are defined in a subsection starting with [outgoing_pools.*.*.connection] . For example: 1 2 3 4 5 6 [outgoing_pools.rdbms.default] scope = \"global\" workers = 5 [outgoing_pools.rdbms.default.connection] ... RDBMS options outgoing_pools.rdbms.*.connection.driver Syntax: string, one of \"pgsql\" , \"mysql\" or \"odbc\" (a supported driver) Example: driver = \"psgql\" Selects driver for RDBMS connection. The choice of driver impacts the set of available options. outgoing_pools.rdbms.*.connection.call_timeout Syntax: positive integer Default: 60000 (msec) Example: call_timeout = 60000 RDBMS pool sets its own default value of this option. ODBC options outgoing_pools.rdbms.*.connection.settings Syntax: string Default: no default; required if the \"odbc\" driver is specified Example: settings = \"DSN=mydb\" ODBC - specific string defining connection parameters. ODBC SSL connection setup If you've configured MongooseIM to use an ODBC driver, then the SSL options, along other connection options, should be present in the ~/.odbc.ini file. To enable SSL connection the sslmode option needs to be set to verify-full . Additionally, you can provide the path to the CA certificate using the sslrootcert option. Example ~/.odbc.ini configuration 1 2 3 4 5 6 7 [mydb] Driver = ... ServerName = ... Port = ... ... sslmode = verify-full sslrootcert = /path/to/ca/cert Other RDBMS backends outgoing_pools.rdbms.*.connection.host Syntax: string Example: host = \"localhost\" outgoing_pools.rdbms.*.connection.database Syntax: string Example: database = \"mim-db\" outgoing_pools.rdbms.*.connection.username Syntax: string Example: username = \"mim-user\" outgoing_pools.rdbms.*.connection.password Syntax: string Example: password = \"mim-password\" outgoing_pools.rdbms.*.connection.keepalive_interval Syntax: positive integer Default: undefined (keep-alive not activated) Example: keepalive_interval = 30 When enabled, MongooseIM will send SELECT 1 query through every DB connection at given interval to keep them open. This option should be used to ensure that database connections are restarted after they became broken (e.g. due to a database restart or a load balancer dropping connections). Currently, not every network-related error returned from a database driver to a regular query will imply a connection restart. HTTP options outgoing_pools.http.*.connection.host Syntax: \"http[s]://string[:integer]\" Example: host = \"https://server.com:879\" outgoing_pools.http.*.connection.path_prefix Syntax: string Default: \"/\" Example: path_prefix = \"/api/auth/\" Initial part of path which will be common to all calls. Prefix will be automatically prepended to path specified by a call to the pool. outgoing_pools.http.*.connection.request_timeout Syntax: positive integer Default: 2000 (milliseconds) Example: request_timeout = 5000 Number of milliseconds after which http call to the server will time out. It should be lower than call_timeout set at the pool level. HTTP also supports all TLS-specific options described in the TLS section. Redis-specific options Redis can be used as a session manager backend. Global distribution (implemented in mod_global_distrib ) requires Redis pool. There are two important limitations: for a session backend, the Tag parameter has to be equal to default redis backend is not compatible with available_worker strategy. outgoing_pools.redis.*.connection.host Syntax: string Default: \"127.0.0.1\" Example: host = \"redis.local\" outgoing_pools.redis.*.connection.port Syntax: integer, between 0 and 65535, non-inclusive Default: 6379 Example: port = 9876 outgoing_pools.redis.*.connection.database Syntax: non-negative integer Default: 0 Example: database = 2 Logical database index (zero-based). outgoing_pools.redis.*.connection.password Syntax: string Default: \"\" Example: password = \"topsecret\" Riak options Currently only one Riak connection pool can exist for each supported XMPP host (the default pool). WARNING: riak backend is not compatible with available_worker strategy. outgoing_pools.riak.*.connection.address Syntax: string Example: address = \"127.0.0.1\" outgoing_pools.riak.*.connection.port Syntax: integer Example: port = 8087 outgoing_pools.riak.*.connection.credentials Syntax: {user = \"username\", password = \"pass\"} Default: none Example: credentials = {user = \"myuser\", password = \"tisismepasswd\"} This is optional - setting this option forces connection over TLS Riak also supports all TLS-specific options described in the TLS section. Cassandra options outgoing_pools.cassandra.*.connection.servers Syntax: a TOML array of tables containing keys \"ip_adddress\" and \"port\" Default: [{ip_address = \"localhost\", port = 9042}] Example: servers = [{ip_address = \"host_one\", port = 9042}, {ip_address = \"host_two\", port = 9042}] outgoing_pools.cassandra.*.connection.keyspace Syntax: string Default: \"mongooseim\" Example: keyspace = \"big_mongooseim_database\" To use plain text authentication (using cqerl_auth_plain_handler module): outgoing_pools.cassandra.*.connection.auth.plain.username Syntax: string Example: username = \"auser\" outgoing_pools.cassandra.*.connection.auth.plain.password Syntax: string Example: password = \"somesecretpassword\" Support for other authentication modules may be added in the future. Cassandra also supports all TLS-specific options described in the TLS section. Elasticsearch options Currently only one pool tagged default can be used. outgoing_pools.elastic.default.connection.host Syntax: string Default: \"localhost\" Example: host = \"otherhost\" outgoing_pools.elastic.default.connection.port Syntax: positive integer Default: 9200 Example: port = 9211 MongooseIM uses inaka/tirerl library to communicate with ElasticSearch. This library uses worker_pool in a bit different way than MongooseIM does, so the following options are not configurable: call_timeout (infinity) worker selection strategy ( available_worker or what's set as default_strategy of worker_pool application) The only pool-related variable you can tweak is thus the number of workers. Run the following function in the MongooseIM shell to verify that the connection has been established: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 1 > mongoose_elasticsearch : health (). { ok ,#{ << \"active_primary_shards\" >> => 15 , << \"active_shards\" >> => 15 , << \"active_shards_percent_as_number\" >> => 50 . 0 , << \"cluster_name\" >> => << \"docker-cluster\" >> , << \"delayed_unassigned_shards\" >> => 0 , << \"initializing_shards\" >> => 0 , << \"number_of_data_nodes\" >> => 1 , << \"number_of_in_flight_fetch\" >> => 0 , << \"number_of_nodes\" >> => 1 , << \"number_of_pending_tasks\" >> => 0 , << \"relocating_shards\" >> => 0 , << \"status\" >> => << \"yellow\" >> , << \"task_max_waiting_in_queue_millis\" >> => 0 , << \"timed_out\" >> => false , << \"unassigned_shards\" >> => 15 }} Note that the output might differ based on your ElasticSearch cluster configuration. RabbitMQ options The Tag parameter must be set to event_pusher in order to be able to use the pool for mod_event_pusher_rabbit . Any other Tag can be used for other purposes. outgoing_pools.rabbit.*.connection.amqp_host Syntax: string Default: \"localhost\" Example: amqp_host = \"anotherhost\" outgoing_pools.rabbit.*.connection.amqp_port Syntax: integer Default: 5672 Example: amqp_port = 4561 outgoing_pools.rabbit.*.connection.amqp_username Syntax: string Default: \"guest\" Example: amqp_username = \"corpop\" outgoing_pools.rabbit.*.connection.amqp_password Syntax: string Default: \"guest\" Example: amqp_password = \"guest\" outgoing_pools.rabbit.*.connection.confirms_enabled Syntax: boolean Default: false Example: confirms_enabled = false Enables/disables one-to-one publishers confirms. outgoing_pools.rabbit.*.connection.max_worker_queue_len Syntax: non-negative integer or \"infinity\" Default: 1000 Example: max_worker_queue_len = \"infinity\" Sets a limit of messages in a worker's mailbox above which the worker starts dropping the messages. If a worker message queue length reaches the limit, messages from the head of the queue are dropped until the queue length is again below the limit. Use infinity to disable. LDAP options outgoing_pools.ldap.*.connection.servers Syntax: an array of strings Default: [\"localhost\"] Example: servers = [\"ldap_one\", \"ldap_two\"] outgoing_pools.ldap.*.connection.port Syntax: integer Default: 389 (or 636 if encryption is enabled) Example: port = 800 outgoing_pools.ldap.*.connection.rootdn Syntax: string Default: empty string Example: rootdn = \"cn=admin,dc=example,dc=com\" Leaving out this option makes it an anonymous connection, which most likely is what you want. outgoing_pools.ldap.*.connection.password Syntax: string Default: empty string Example: password = \"topsecret\" outgoing_pools.ldap.*.connection.connect_interval Syntax: integer Default: 10000 Example: connect_interval = 20000 Reconnect interval after a failed connection. outgoing_pools.ldap.*.connection.encrypt Syntax: string, one of: \"none\" or \"tls\" Default: \"none\" Example: encrypt = \"tls\" LDAP also supports all TLS-specific options described in the TLS section (provided encrypt is set to tls ). TLS options TLS options for a given pool type/tag pair are defined in a subsection starting with [outgoing_pools.[pool_type].[pool_tag].connection.tls] . outgoing_pools.*.*.connection.tls.required Syntax: boolean Default: false Example: tls.required = true This option is Postgresql-specific, doesn't apply in other cases. outgoing_pools.*.*.connection.tls.verify_peer Syntax: boolean Default: false Example: tls.verify_peer = true Enforces verification of a client certificate. Requires a valid cacertfile . outgoing_pools.*.*.connection.tls.certfile Syntax: string, path in the file system Default: not set Example: tls.certfile = \"server.pem\" Path to the X509 PEM file with a certificate and a private key (not protected by a password). If the certificate is signed by an intermediate CA, you should specify here the whole CA chain by concatenating all public keys together and appending the private key after that. outgoing_pools.*.*.connection.tls.cacertfile Syntax: string, path in the file system Default: not set Example: tls.cacertfile = \"ca.pem\" Path to the X509 PEM file with a CA chain that will be used to verify clients. It won't have any effect if verify_peer is not enabled. outgoing_pools.*.*.connection.tls.dhfile Syntax: string, path in the file system Default: not set Example: tls.dhfile = \"dh.pem\" Path to the Diffie-Hellman parameter file. outgoing_pools.*.*.connection.tls.keyfile Syntax: string, path in the file system Default: not set Example: tls.keyfile = \"key.pem\" Path to the X509 PEM file with the private key. outgoing_pools.*.*.connection.tls.password Syntax: string Default: not set Example: tls.password = \"secret\" Password to the X509 PEM file with the private key. outgoing_pools.*.*.connection.tls.ciphers Syntax: string with the OpenSSL cipher suite specification Default: not set, all supported cipher suites are accepted Example: tls.ciphers = \"ECDHE-RSA-AES256-GCM-SHA384:ECDHE-ECDSA-AES256-GCM-SHA384\" Cipher suites to use. Please refer to the OpenSSL documentation for the cipher string format. For allowed values, see the Erlang/OTP SSL documentation . outgoing_pools.*.*.connection.tls.versions Syntax: list of strings Default: not set, all supported versions are accepted Example: tls.versions = [\"tlsv1.2\", \"tlsv1.3\"] Cipher suites to use. For allowed values, see the Erlang/OTP SSL documentation outgoing_pools.*.*.connection.tls.server_name_indication Syntax: boolean Default: true Example: tls.server_name_indication = false Enables SNI extension to TLS protocol.","title":"Options: Outgoing connections"},{"location":"advanced-configuration/outgoing-connections/#general-pool-options","text":"","title":"General pool options"},{"location":"advanced-configuration/outgoing-connections/#outgoing_poolsscope","text":"Syntax: string, one of: \"global\" , \"host\" , \"single_host\" Default: \"global\" Example: scope = \"host\"","title":"outgoing_pools.*.*.scope"},{"location":"advanced-configuration/outgoing-connections/#outgoing_poolshost","text":"Syntax: string Default: no default; required if \"single_host\" scope is specified Example: host = \"anotherhost.com\" scope can be set to: * global - meaning that the pool will started once no matter how many XMPP hosts are served by MongooseIM * host - the pool will be started for each XMPP host served by MongooseIM * single_host - the pool will be started for the selected host only (you must provide a host name).","title":"outgoing_pools.*.*.host"},{"location":"advanced-configuration/outgoing-connections/#worker-pool-options","text":"All pools are managed by the inaka/worker_pool library. Available options are:","title":"Worker pool options"},{"location":"advanced-configuration/outgoing-connections/#outgoing_poolsstrategy","text":"Syntax: string, one of: \"best_worker\" , \"random_worker\" , \"next_worker\" , \"available_worker\" , \"next_available_worker\" Default: \"best_worker\" Example: strategy = \"available_worker\" Defines worker seletion strategy. Consult worker_pool documentation for details.","title":"outgoing_pools.*.*.strategy"},{"location":"advanced-configuration/outgoing-connections/#outgoing_poolsworkers","text":"Syntax: positive integer Default: 100 Example: workers = 10 Number of workers to be started by the pool.","title":"outgoing_pools.*.*.workers"},{"location":"advanced-configuration/outgoing-connections/#outgoing_poolscall_timeout","text":"Syntax: positive integer Default: 5000 Example: call_timeout = 5000 Number of milliseconds after which a call to the pool will time out.","title":"outgoing_pools.*.*.call_timeout"},{"location":"advanced-configuration/outgoing-connections/#connection-options","text":"Options specific to a pool connection are defined in a subsection starting with [outgoing_pools.*.*.connection] . For example: 1 2 3 4 5 6 [outgoing_pools.rdbms.default] scope = \"global\" workers = 5 [outgoing_pools.rdbms.default.connection] ...","title":"Connection options"},{"location":"advanced-configuration/outgoing-connections/#rdbms-options","text":"","title":"RDBMS options"},{"location":"advanced-configuration/outgoing-connections/#outgoing_poolsrdbmsconnectiondriver","text":"Syntax: string, one of \"pgsql\" , \"mysql\" or \"odbc\" (a supported driver) Example: driver = \"psgql\" Selects driver for RDBMS connection. The choice of driver impacts the set of available options.","title":"outgoing_pools.rdbms.*.connection.driver"},{"location":"advanced-configuration/outgoing-connections/#outgoing_poolsrdbmsconnectioncall_timeout","text":"Syntax: positive integer Default: 60000 (msec) Example: call_timeout = 60000 RDBMS pool sets its own default value of this option.","title":"outgoing_pools.rdbms.*.connection.call_timeout"},{"location":"advanced-configuration/outgoing-connections/#odbc-options","text":"","title":"ODBC options"},{"location":"advanced-configuration/outgoing-connections/#outgoing_poolsrdbmsconnectionsettings","text":"Syntax: string Default: no default; required if the \"odbc\" driver is specified Example: settings = \"DSN=mydb\" ODBC - specific string defining connection parameters.","title":"outgoing_pools.rdbms.*.connection.settings"},{"location":"advanced-configuration/outgoing-connections/#odbc-ssl-connection-setup","text":"If you've configured MongooseIM to use an ODBC driver, then the SSL options, along other connection options, should be present in the ~/.odbc.ini file. To enable SSL connection the sslmode option needs to be set to verify-full . Additionally, you can provide the path to the CA certificate using the sslrootcert option.","title":"ODBC SSL connection setup"},{"location":"advanced-configuration/outgoing-connections/#example-odbcini-configuration","text":"1 2 3 4 5 6 7 [mydb] Driver = ... ServerName = ... Port = ... ... sslmode = verify-full sslrootcert = /path/to/ca/cert","title":"Example ~/.odbc.ini configuration"},{"location":"advanced-configuration/outgoing-connections/#other-rdbms-backends","text":"","title":"Other RDBMS backends"},{"location":"advanced-configuration/outgoing-connections/#outgoing_poolsrdbmsconnectionhost","text":"Syntax: string Example: host = \"localhost\"","title":"outgoing_pools.rdbms.*.connection.host"},{"location":"advanced-configuration/outgoing-connections/#outgoing_poolsrdbmsconnectiondatabase","text":"Syntax: string Example: database = \"mim-db\"","title":"outgoing_pools.rdbms.*.connection.database"},{"location":"advanced-configuration/outgoing-connections/#outgoing_poolsrdbmsconnectionusername","text":"Syntax: string Example: username = \"mim-user\"","title":"outgoing_pools.rdbms.*.connection.username"},{"location":"advanced-configuration/outgoing-connections/#outgoing_poolsrdbmsconnectionpassword","text":"Syntax: string Example: password = \"mim-password\"","title":"outgoing_pools.rdbms.*.connection.password"},{"location":"advanced-configuration/outgoing-connections/#outgoing_poolsrdbmsconnectionkeepalive_interval","text":"Syntax: positive integer Default: undefined (keep-alive not activated) Example: keepalive_interval = 30 When enabled, MongooseIM will send SELECT 1 query through every DB connection at given interval to keep them open. This option should be used to ensure that database connections are restarted after they became broken (e.g. due to a database restart or a load balancer dropping connections). Currently, not every network-related error returned from a database driver to a regular query will imply a connection restart.","title":"outgoing_pools.rdbms.*.connection.keepalive_interval"},{"location":"advanced-configuration/outgoing-connections/#http-options","text":"","title":"HTTP options"},{"location":"advanced-configuration/outgoing-connections/#outgoing_poolshttpconnectionhost","text":"Syntax: \"http[s]://string[:integer]\" Example: host = \"https://server.com:879\"","title":"outgoing_pools.http.*.connection.host"},{"location":"advanced-configuration/outgoing-connections/#outgoing_poolshttpconnectionpath_prefix","text":"Syntax: string Default: \"/\" Example: path_prefix = \"/api/auth/\" Initial part of path which will be common to all calls. Prefix will be automatically prepended to path specified by a call to the pool.","title":"outgoing_pools.http.*.connection.path_prefix"},{"location":"advanced-configuration/outgoing-connections/#outgoing_poolshttpconnectionrequest_timeout","text":"Syntax: positive integer Default: 2000 (milliseconds) Example: request_timeout = 5000 Number of milliseconds after which http call to the server will time out. It should be lower than call_timeout set at the pool level. HTTP also supports all TLS-specific options described in the TLS section.","title":"outgoing_pools.http.*.connection.request_timeout"},{"location":"advanced-configuration/outgoing-connections/#redis-specific-options","text":"Redis can be used as a session manager backend. Global distribution (implemented in mod_global_distrib ) requires Redis pool. There are two important limitations: for a session backend, the Tag parameter has to be equal to default redis backend is not compatible with available_worker strategy.","title":"Redis-specific options"},{"location":"advanced-configuration/outgoing-connections/#outgoing_poolsredisconnectionhost","text":"Syntax: string Default: \"127.0.0.1\" Example: host = \"redis.local\"","title":"outgoing_pools.redis.*.connection.host"},{"location":"advanced-configuration/outgoing-connections/#outgoing_poolsredisconnectionport","text":"Syntax: integer, between 0 and 65535, non-inclusive Default: 6379 Example: port = 9876","title":"outgoing_pools.redis.*.connection.port"},{"location":"advanced-configuration/outgoing-connections/#outgoing_poolsredisconnectiondatabase","text":"Syntax: non-negative integer Default: 0 Example: database = 2 Logical database index (zero-based).","title":"outgoing_pools.redis.*.connection.database"},{"location":"advanced-configuration/outgoing-connections/#outgoing_poolsredisconnectionpassword","text":"Syntax: string Default: \"\" Example: password = \"topsecret\"","title":"outgoing_pools.redis.*.connection.password"},{"location":"advanced-configuration/outgoing-connections/#riak-options","text":"Currently only one Riak connection pool can exist for each supported XMPP host (the default pool). WARNING: riak backend is not compatible with available_worker strategy.","title":"Riak options"},{"location":"advanced-configuration/outgoing-connections/#outgoing_poolsriakconnectionaddress","text":"Syntax: string Example: address = \"127.0.0.1\"","title":"outgoing_pools.riak.*.connection.address"},{"location":"advanced-configuration/outgoing-connections/#outgoing_poolsriakconnectionport","text":"Syntax: integer Example: port = 8087","title":"outgoing_pools.riak.*.connection.port"},{"location":"advanced-configuration/outgoing-connections/#outgoing_poolsriakconnectioncredentials","text":"Syntax: {user = \"username\", password = \"pass\"} Default: none Example: credentials = {user = \"myuser\", password = \"tisismepasswd\"} This is optional - setting this option forces connection over TLS Riak also supports all TLS-specific options described in the TLS section.","title":"outgoing_pools.riak.*.connection.credentials"},{"location":"advanced-configuration/outgoing-connections/#cassandra-options","text":"","title":"Cassandra options"},{"location":"advanced-configuration/outgoing-connections/#outgoing_poolscassandraconnectionservers","text":"Syntax: a TOML array of tables containing keys \"ip_adddress\" and \"port\" Default: [{ip_address = \"localhost\", port = 9042}] Example: servers = [{ip_address = \"host_one\", port = 9042}, {ip_address = \"host_two\", port = 9042}]","title":"outgoing_pools.cassandra.*.connection.servers"},{"location":"advanced-configuration/outgoing-connections/#outgoing_poolscassandraconnectionkeyspace","text":"Syntax: string Default: \"mongooseim\" Example: keyspace = \"big_mongooseim_database\" To use plain text authentication (using cqerl_auth_plain_handler module):","title":"outgoing_pools.cassandra.*.connection.keyspace"},{"location":"advanced-configuration/outgoing-connections/#outgoing_poolscassandraconnectionauthplainusername","text":"Syntax: string Example: username = \"auser\"","title":"outgoing_pools.cassandra.*.connection.auth.plain.username"},{"location":"advanced-configuration/outgoing-connections/#outgoing_poolscassandraconnectionauthplainpassword","text":"Syntax: string Example: password = \"somesecretpassword\" Support for other authentication modules may be added in the future. Cassandra also supports all TLS-specific options described in the TLS section.","title":"outgoing_pools.cassandra.*.connection.auth.plain.password"},{"location":"advanced-configuration/outgoing-connections/#elasticsearch-options","text":"Currently only one pool tagged default can be used.","title":"Elasticsearch options"},{"location":"advanced-configuration/outgoing-connections/#outgoing_poolselasticdefaultconnectionhost","text":"Syntax: string Default: \"localhost\" Example: host = \"otherhost\"","title":"outgoing_pools.elastic.default.connection.host"},{"location":"advanced-configuration/outgoing-connections/#outgoing_poolselasticdefaultconnectionport","text":"Syntax: positive integer Default: 9200 Example: port = 9211 MongooseIM uses inaka/tirerl library to communicate with ElasticSearch. This library uses worker_pool in a bit different way than MongooseIM does, so the following options are not configurable: call_timeout (infinity) worker selection strategy ( available_worker or what's set as default_strategy of worker_pool application) The only pool-related variable you can tweak is thus the number of workers. Run the following function in the MongooseIM shell to verify that the connection has been established: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 1 > mongoose_elasticsearch : health (). { ok ,#{ << \"active_primary_shards\" >> => 15 , << \"active_shards\" >> => 15 , << \"active_shards_percent_as_number\" >> => 50 . 0 , << \"cluster_name\" >> => << \"docker-cluster\" >> , << \"delayed_unassigned_shards\" >> => 0 , << \"initializing_shards\" >> => 0 , << \"number_of_data_nodes\" >> => 1 , << \"number_of_in_flight_fetch\" >> => 0 , << \"number_of_nodes\" >> => 1 , << \"number_of_pending_tasks\" >> => 0 , << \"relocating_shards\" >> => 0 , << \"status\" >> => << \"yellow\" >> , << \"task_max_waiting_in_queue_millis\" >> => 0 , << \"timed_out\" >> => false , << \"unassigned_shards\" >> => 15 }} Note that the output might differ based on your ElasticSearch cluster configuration.","title":"outgoing_pools.elastic.default.connection.port"},{"location":"advanced-configuration/outgoing-connections/#rabbitmq-options","text":"The Tag parameter must be set to event_pusher in order to be able to use the pool for mod_event_pusher_rabbit . Any other Tag can be used for other purposes.","title":"RabbitMQ options"},{"location":"advanced-configuration/outgoing-connections/#outgoing_poolsrabbitconnectionamqp_host","text":"Syntax: string Default: \"localhost\" Example: amqp_host = \"anotherhost\"","title":"outgoing_pools.rabbit.*.connection.amqp_host"},{"location":"advanced-configuration/outgoing-connections/#outgoing_poolsrabbitconnectionamqp_port","text":"Syntax: integer Default: 5672 Example: amqp_port = 4561","title":"outgoing_pools.rabbit.*.connection.amqp_port"},{"location":"advanced-configuration/outgoing-connections/#outgoing_poolsrabbitconnectionamqp_username","text":"Syntax: string Default: \"guest\" Example: amqp_username = \"corpop\"","title":"outgoing_pools.rabbit.*.connection.amqp_username"},{"location":"advanced-configuration/outgoing-connections/#outgoing_poolsrabbitconnectionamqp_password","text":"Syntax: string Default: \"guest\" Example: amqp_password = \"guest\"","title":"outgoing_pools.rabbit.*.connection.amqp_password"},{"location":"advanced-configuration/outgoing-connections/#outgoing_poolsrabbitconnectionconfirms_enabled","text":"Syntax: boolean Default: false Example: confirms_enabled = false Enables/disables one-to-one publishers confirms.","title":"outgoing_pools.rabbit.*.connection.confirms_enabled"},{"location":"advanced-configuration/outgoing-connections/#outgoing_poolsrabbitconnectionmax_worker_queue_len","text":"Syntax: non-negative integer or \"infinity\" Default: 1000 Example: max_worker_queue_len = \"infinity\" Sets a limit of messages in a worker's mailbox above which the worker starts dropping the messages. If a worker message queue length reaches the limit, messages from the head of the queue are dropped until the queue length is again below the limit. Use infinity to disable.","title":"outgoing_pools.rabbit.*.connection.max_worker_queue_len"},{"location":"advanced-configuration/outgoing-connections/#ldap-options","text":"","title":"LDAP options"},{"location":"advanced-configuration/outgoing-connections/#outgoing_poolsldapconnectionservers","text":"Syntax: an array of strings Default: [\"localhost\"] Example: servers = [\"ldap_one\", \"ldap_two\"]","title":"outgoing_pools.ldap.*.connection.servers"},{"location":"advanced-configuration/outgoing-connections/#outgoing_poolsldapconnectionport","text":"Syntax: integer Default: 389 (or 636 if encryption is enabled) Example: port = 800","title":"outgoing_pools.ldap.*.connection.port"},{"location":"advanced-configuration/outgoing-connections/#outgoing_poolsldapconnectionrootdn","text":"Syntax: string Default: empty string Example: rootdn = \"cn=admin,dc=example,dc=com\" Leaving out this option makes it an anonymous connection, which most likely is what you want.","title":"outgoing_pools.ldap.*.connection.rootdn"},{"location":"advanced-configuration/outgoing-connections/#outgoing_poolsldapconnectionpassword","text":"Syntax: string Default: empty string Example: password = \"topsecret\"","title":"outgoing_pools.ldap.*.connection.password"},{"location":"advanced-configuration/outgoing-connections/#outgoing_poolsldapconnectionconnect_interval","text":"Syntax: integer Default: 10000 Example: connect_interval = 20000 Reconnect interval after a failed connection.","title":"outgoing_pools.ldap.*.connection.connect_interval"},{"location":"advanced-configuration/outgoing-connections/#outgoing_poolsldapconnectionencrypt","text":"Syntax: string, one of: \"none\" or \"tls\" Default: \"none\" Example: encrypt = \"tls\" LDAP also supports all TLS-specific options described in the TLS section (provided encrypt is set to tls ).","title":"outgoing_pools.ldap.*.connection.encrypt"},{"location":"advanced-configuration/outgoing-connections/#tls-options","text":"TLS options for a given pool type/tag pair are defined in a subsection starting with [outgoing_pools.[pool_type].[pool_tag].connection.tls] .","title":"TLS options"},{"location":"advanced-configuration/outgoing-connections/#outgoing_poolsconnectiontlsrequired","text":"Syntax: boolean Default: false Example: tls.required = true This option is Postgresql-specific, doesn't apply in other cases.","title":"outgoing_pools.*.*.connection.tls.required"},{"location":"advanced-configuration/outgoing-connections/#outgoing_poolsconnectiontlsverify_peer","text":"Syntax: boolean Default: false Example: tls.verify_peer = true Enforces verification of a client certificate. Requires a valid cacertfile .","title":"outgoing_pools.*.*.connection.tls.verify_peer"},{"location":"advanced-configuration/outgoing-connections/#outgoing_poolsconnectiontlscertfile","text":"Syntax: string, path in the file system Default: not set Example: tls.certfile = \"server.pem\" Path to the X509 PEM file with a certificate and a private key (not protected by a password). If the certificate is signed by an intermediate CA, you should specify here the whole CA chain by concatenating all public keys together and appending the private key after that.","title":"outgoing_pools.*.*.connection.tls.certfile"},{"location":"advanced-configuration/outgoing-connections/#outgoing_poolsconnectiontlscacertfile","text":"Syntax: string, path in the file system Default: not set Example: tls.cacertfile = \"ca.pem\" Path to the X509 PEM file with a CA chain that will be used to verify clients. It won't have any effect if verify_peer is not enabled.","title":"outgoing_pools.*.*.connection.tls.cacertfile"},{"location":"advanced-configuration/outgoing-connections/#outgoing_poolsconnectiontlsdhfile","text":"Syntax: string, path in the file system Default: not set Example: tls.dhfile = \"dh.pem\" Path to the Diffie-Hellman parameter file.","title":"outgoing_pools.*.*.connection.tls.dhfile"},{"location":"advanced-configuration/outgoing-connections/#outgoing_poolsconnectiontlskeyfile","text":"Syntax: string, path in the file system Default: not set Example: tls.keyfile = \"key.pem\" Path to the X509 PEM file with the private key.","title":"outgoing_pools.*.*.connection.tls.keyfile"},{"location":"advanced-configuration/outgoing-connections/#outgoing_poolsconnectiontlspassword","text":"Syntax: string Default: not set Example: tls.password = \"secret\" Password to the X509 PEM file with the private key.","title":"outgoing_pools.*.*.connection.tls.password"},{"location":"advanced-configuration/outgoing-connections/#outgoing_poolsconnectiontlsciphers","text":"Syntax: string with the OpenSSL cipher suite specification Default: not set, all supported cipher suites are accepted Example: tls.ciphers = \"ECDHE-RSA-AES256-GCM-SHA384:ECDHE-ECDSA-AES256-GCM-SHA384\" Cipher suites to use. Please refer to the OpenSSL documentation for the cipher string format. For allowed values, see the Erlang/OTP SSL documentation .","title":"outgoing_pools.*.*.connection.tls.ciphers"},{"location":"advanced-configuration/outgoing-connections/#outgoing_poolsconnectiontlsversions","text":"Syntax: list of strings Default: not set, all supported versions are accepted Example: tls.versions = [\"tlsv1.2\", \"tlsv1.3\"] Cipher suites to use. For allowed values, see the Erlang/OTP SSL documentation","title":"outgoing_pools.*.*.connection.tls.versions"},{"location":"advanced-configuration/outgoing-connections/#outgoing_poolsconnectiontlsserver_name_indication","text":"Syntax: boolean Default: true Example: tls.server_name_indication = false Enables SNI extension to TLS protocol.","title":"outgoing_pools.*.*.connection.tls.server_name_indication"},{"location":"advanced-configuration/release-options/","text":"When building a MongooseIM release from source code, the initial configuration files are generated with options taken from the vars-toml.config file found in the [MongooseIM root]/rel/ directory. You can change the values in this file to affect the resulting vm.args and mongooseim.toml files. The file contains erlang tuples terminated with period ('.'). For users not familiar with Erlang syntax, here is a quick cheat sheet: Each config option (key and value) is a tuple. Tuples are (Erlangers, forgive us the simplification) other Erlang terms separated with commas and enclosed in curly brackets ({}). Tuples (at least the top-level ones) in vars.config are always 2-element. The first element of each tuple is the name (Erlang atom). The second element is a quoted string. Any quotes ( \" ) inside the string should be escaped with a backslash ( \\ ). There are two types of options: parameters and blocks: a parameter is inserted into the value of an already defined option. Parameters are mandatory - a valid value has to be provided. a block can be an empty string, one line or multiple lines, defining zero, one or more options. Blocks are optional - the default is an empty string. vm.args options These options are inserted into the rel/files/vm.args template. node_name Type: parameter Option: value of -sname in vm.args Syntax: Erlang node name: name@host Example: {node_name, \"mongooseim@localhost\"}. highload_vm_args Type: block Option: arguments in vm.args : +K , +A , +P , -env ERL_MAX_PORTS Syntax: command-line arguments Example: {highload_vm_args, \"+P 10000000 -env ERL_MAX_PORTS 250000\"}. TOML Options These options are inserted into the rel/files/mongooseim.toml template. hosts Type: parameter Option: general.hosts Syntax: comma-separated list of strings Example: {hosts, \"\\\"localhost\\\", \\\"domain2\\\"\"}. host_config Type: block Option: host_config Syntax: TOML block, one or more [[host_config]] sections. Example: 1 2 3 4 5 6 7 {host_config, \" [[host_config]] host = \\\"anonymous.localhost\\\" [host_config.auth] methods = [\\\"anonymous\\\"] \"}. auth_ldap Type: block Option: auth.ldap Syntax: TOML block, the [auth.ldap] subsection Example: 1 2 3 4 5 {auth_ldap, \" [auth.ldap] base = \\\"ou=Users,dc=esl,dc=com\\\" filter = \\\"(objectClass=inetOrgPerson)\\\" \"}. all_metrics_are_global Type: parameter Option: general.all_metrics_are_global Syntax: boolean Example: {all_metrics_are_global, \"false\"}. s2s_addr Type: block Option: auth.s2s.address Syntax: TOML key-value pair with the address option Example: 1 2 3 4 5 6 {s2s_addr, \" address = [ {host = \\\"my.xmpp.org\\\", ip_address = \\\"192.0.100.1\\\"}, {host = \\\"your.xmpp.org\\\", ip_address = \\\"192.0.1.100\\\", port = 5271} ] \"}. s2s_default_policy Type: parameter Option: s2s.default_policy Syntax: string Example: {s2s_default_policy, \"\\\"deny\\\"\"}. outgoing_s2s_port Type: parameter Option: s2s.outgoing.port Syntax: integer Example: {outgoing_s2s_port, \"5269\"}. c2s_port Type: parameter Option: listen.c2s.port Syntax: integer Example: {c2s_port, \"5222\"}. s2s_port Type: parameter Option: listen.s2s.port Syntax: integer Example: {s2s_port, \"5269\"}. cowboy_port Type: parameter Option: listen.http.port Syntax: integer Example: {http_port, \"5280\"}. mod_last Type: block Option: modules.mod_last Syntax: TOML section: [modules.mod_last] Example: {mod_last, \"[modules.mod_last]\"}. mod_offline Type: block Option: modules.mod_offline Syntax: TOML section: [modules.mod_offline] Example: 1 2 3 4 {mod_offline, \" [modules.mod_offline] access_max_user_messages = \\\"max_user_offline_messages\\\" \"}. mod_privacy Type: block Option: modules.mod_privacy Syntax: TOML section: [modules.mod_privacy] Example: {mod_privacy, \"[modules.mod_privacy]\"}. mod_private Type: block Option: modules.mod_private Syntax: TOML section: [modules.mod_private] Example: {mod_private, \"[modules.mod_private]\"}. mod_roster Type: block Option: modules.mod_roster Syntax: TOML section: [modules.mod_roster] Example: {mod_roster, \"[modules.mod_roster]\"}. mod_vcard Type: block Option: modules.mod_vcard Syntax: TOML section: [modules.mod_vcard] Example: 1 2 3 4 {mod_vcard, \" [modules.mod_vcard] host = \\\"vjud.@HOST@\\\" \"}. sm_backend Type: parameter Option: general.sm_backend Syntax: string Example: {sm_backend, \"\\\"redis\\\"\"}. tls_config Type: block Option: listen.c2s.tls.* Syntax: TOML key-value pairs Example: 1 2 3 4 {tls_config, \" tls.certfile = \\\"priv/ssl/fake_server.pem\\\" tls.mode = \\\"starttls\\\" \"}. auth_method Type: parameter Option: auth.methods Syntax: comma-separated list of strings Example: {auth_method, \"\\\"internal\\\"\"}. zlib Type: parameter Option: listen.c2s.zlib Syntax: positive integer Example: {zlib, \"10_000\"}.","title":"Release options"},{"location":"advanced-configuration/release-options/#vmargs-options","text":"These options are inserted into the rel/files/vm.args template.","title":"vm.args options"},{"location":"advanced-configuration/release-options/#node_name","text":"Type: parameter Option: value of -sname in vm.args Syntax: Erlang node name: name@host Example: {node_name, \"mongooseim@localhost\"}.","title":"node_name"},{"location":"advanced-configuration/release-options/#highload_vm_args","text":"Type: block Option: arguments in vm.args : +K , +A , +P , -env ERL_MAX_PORTS Syntax: command-line arguments Example: {highload_vm_args, \"+P 10000000 -env ERL_MAX_PORTS 250000\"}.","title":"highload_vm_args"},{"location":"advanced-configuration/release-options/#toml-options","text":"These options are inserted into the rel/files/mongooseim.toml template.","title":"TOML Options"},{"location":"advanced-configuration/release-options/#hosts","text":"Type: parameter Option: general.hosts Syntax: comma-separated list of strings Example: {hosts, \"\\\"localhost\\\", \\\"domain2\\\"\"}.","title":"hosts"},{"location":"advanced-configuration/release-options/#host_config","text":"Type: block Option: host_config Syntax: TOML block, one or more [[host_config]] sections. Example: 1 2 3 4 5 6 7 {host_config, \" [[host_config]] host = \\\"anonymous.localhost\\\" [host_config.auth] methods = [\\\"anonymous\\\"] \"}.","title":"host_config"},{"location":"advanced-configuration/release-options/#auth_ldap","text":"Type: block Option: auth.ldap Syntax: TOML block, the [auth.ldap] subsection Example: 1 2 3 4 5 {auth_ldap, \" [auth.ldap] base = \\\"ou=Users,dc=esl,dc=com\\\" filter = \\\"(objectClass=inetOrgPerson)\\\" \"}.","title":"auth_ldap"},{"location":"advanced-configuration/release-options/#all_metrics_are_global","text":"Type: parameter Option: general.all_metrics_are_global Syntax: boolean Example: {all_metrics_are_global, \"false\"}.","title":"all_metrics_are_global"},{"location":"advanced-configuration/release-options/#s2s_addr","text":"Type: block Option: auth.s2s.address Syntax: TOML key-value pair with the address option Example: 1 2 3 4 5 6 {s2s_addr, \" address = [ {host = \\\"my.xmpp.org\\\", ip_address = \\\"192.0.100.1\\\"}, {host = \\\"your.xmpp.org\\\", ip_address = \\\"192.0.1.100\\\", port = 5271} ] \"}.","title":"s2s_addr"},{"location":"advanced-configuration/release-options/#s2s_default_policy","text":"Type: parameter Option: s2s.default_policy Syntax: string Example: {s2s_default_policy, \"\\\"deny\\\"\"}.","title":"s2s_default_policy"},{"location":"advanced-configuration/release-options/#outgoing_s2s_port","text":"Type: parameter Option: s2s.outgoing.port Syntax: integer Example: {outgoing_s2s_port, \"5269\"}.","title":"outgoing_s2s_port"},{"location":"advanced-configuration/release-options/#c2s_port","text":"Type: parameter Option: listen.c2s.port Syntax: integer Example: {c2s_port, \"5222\"}.","title":"c2s_port"},{"location":"advanced-configuration/release-options/#s2s_port","text":"Type: parameter Option: listen.s2s.port Syntax: integer Example: {s2s_port, \"5269\"}.","title":"s2s_port"},{"location":"advanced-configuration/release-options/#cowboy_port","text":"Type: parameter Option: listen.http.port Syntax: integer Example: {http_port, \"5280\"}.","title":"cowboy_port"},{"location":"advanced-configuration/release-options/#mod_last","text":"Type: block Option: modules.mod_last Syntax: TOML section: [modules.mod_last] Example: {mod_last, \"[modules.mod_last]\"}.","title":"mod_last"},{"location":"advanced-configuration/release-options/#mod_offline","text":"Type: block Option: modules.mod_offline Syntax: TOML section: [modules.mod_offline] Example: 1 2 3 4 {mod_offline, \" [modules.mod_offline] access_max_user_messages = \\\"max_user_offline_messages\\\" \"}.","title":"mod_offline"},{"location":"advanced-configuration/release-options/#mod_privacy","text":"Type: block Option: modules.mod_privacy Syntax: TOML section: [modules.mod_privacy] Example: {mod_privacy, \"[modules.mod_privacy]\"}.","title":"mod_privacy"},{"location":"advanced-configuration/release-options/#mod_private","text":"Type: block Option: modules.mod_private Syntax: TOML section: [modules.mod_private] Example: {mod_private, \"[modules.mod_private]\"}.","title":"mod_private"},{"location":"advanced-configuration/release-options/#mod_roster","text":"Type: block Option: modules.mod_roster Syntax: TOML section: [modules.mod_roster] Example: {mod_roster, \"[modules.mod_roster]\"}.","title":"mod_roster"},{"location":"advanced-configuration/release-options/#mod_vcard","text":"Type: block Option: modules.mod_vcard Syntax: TOML section: [modules.mod_vcard] Example: 1 2 3 4 {mod_vcard, \" [modules.mod_vcard] host = \\\"vjud.@HOST@\\\" \"}.","title":"mod_vcard"},{"location":"advanced-configuration/release-options/#sm_backend","text":"Type: parameter Option: general.sm_backend Syntax: string Example: {sm_backend, \"\\\"redis\\\"\"}.","title":"sm_backend"},{"location":"advanced-configuration/release-options/#tls_config","text":"Type: block Option: listen.c2s.tls.* Syntax: TOML key-value pairs Example: 1 2 3 4 {tls_config, \" tls.certfile = \\\"priv/ssl/fake_server.pem\\\" tls.mode = \\\"starttls\\\" \"}.","title":"tls_config"},{"location":"advanced-configuration/release-options/#auth_method","text":"Type: parameter Option: auth.methods Syntax: comma-separated list of strings Example: {auth_method, \"\\\"internal\\\"\"}.","title":"auth_method"},{"location":"advanced-configuration/release-options/#zlib","text":"Type: parameter Option: listen.c2s.zlib Syntax: positive integer Example: {zlib, \"10_000\"}.","title":"zlib"},{"location":"advanced-configuration/s2s/","text":"The s2s section contains options configuring the server-to-server connections used to communicate with other federated XMPP servers. General options These options affect both incoming and outgoing S2S connections. s2s.default_policy Scope: local Syntax: string, \"allow\" or \"deny\" Default: \"allow\" Example: default_policy = \"deny\" Default policy for opening new S2S connections to/from remote servers. s2s.host_policy Scope: local Syntax: array of TOML tables with the following mandatory content: host - string, host name policy - string, \"allow\" or \"deny\" Default: \"allow\" Example: 1 2 3 4 host_policy = [ { host = \"good.xmpp.org\" , policy = \"allow\" }, { host = \"bad.xmpp.org\" , policy = \"deny\" } ] Policy for opening new connections to/from specific remote servers. s2s.use_starttls Scope: local Syntax: string, one of \"false\" , \"optional\" , \"required\" , \"required_trusted\" Default: \"false\" Example: use_starttls = \"required\" Allows to configure StartTLS for incoming and outgoing S2S connections: false - StartTLS is disabled, optional - StartTLS is supported, required - StartTLS is supported and enforced, required_trusted - StartTLS is supported and enforced with certificate verification. s2s.certfile Scope: local Syntax: string, path in the file system Default: not set Example: certfile = \"cert.pem\" Path to the X509 PEM file with a certificate and a private key inside (not protected by any password). Required if use_starttls is not false . s2s.domain_certfile Scope: local Syntax: array of TOML tables with the following mandatory content: domain - string, XMPP domain name certfile - string, path in the file system Default: not set Example: 1 2 3 4 domain_certfile = [ { domain = \"localhost1.com\" , certfile = \"cert1.pem\" }, { domain = \"localhost2.com\" , certfile = \"cert2.pem\" } ] This option overrides the configured certificate file for specific local XMPP domains. Notes: This option applies to S2S and C2S connections. Each domain needs to be included in the list of hosts configured in the general section. s2s.shared Scope: local Syntax: string Default: 10 strong random bytes, hex-encoded Example: shared = \"82gc8b23ct7824\" S2S shared secret used in the Server Dialback extension. Outgoing connections The options listed below affect only the outgoing S2S connections. s2s.address Scope: local Syntax: array of TOML tables with the following content: host - string, mandatory, host name ip_address - string, mandatory, IP address port - integer, optional, port number Default: \"allow\" Example: 1 2 3 4 address = [ { host = \"my.xmpp.org\" , ip_address = \"192.0.100.1\" }, { host = \"your.xmpp.org\" , ip_address = \"192.0.1.100\" , port = 5271 } ] This option defines IP addresses and port numbers for specific non-local XMPP domains, allowing to override the DNS lookup for outgoing S2S connections. s2s.ciphers Scope: local Syntax: string Default: \"TLSv1.2:TLSv1.3\" Example: ciphers = \"TLSv1.2\" Defines a list of accepted SSL ciphers for outgoing S2S connections. Please refer to the OpenSSL documentation for the cipher string format. s2s.max_retry_delay Scope: local Syntax: positive integer Default: 300 Example: max_retry_delay = 300 Specifies the maximum time in seconds that MongooseIM will wait until the next attempt to connect to a remote XMPP server. The delays between consecutive attempts will be doubled until this limit is reached. s2s.outgoing.port Scope: local Syntax: integer, port number Default: 5269 Example: outgoing.port = 5270 Defines the port to be used for outgoing S2S connections. s2s.outgoing.ip_versions Scope: local Syntax: array of integers (IP versions): 4 or 6 Default: [4, 6] Example: outgoing.ip_versions = [6] Specifies the order of IP address families to try when establishing an outgoing S2S connection. s2s.outgoing.connection_timeout Scope: local Syntax: positive integer or the string \"infinity\" Default: 10_000 Example: outgoing.connection_timeout = 5000 Timeout (in seconds) for establishing an outgoing S2S connection. s2s.dns.timeout Scope: local Syntax: positive integer Default: 10 Example: dns.timeout = 30 Timeout (in seconds) for DNS lookups when opening an outgoing S2S connection. s2s.dns.retries Scope: local Syntax: positive integer Default: 2 Example: dns.retries = 1 Number of DNS lookup attempts when opening an outgoing S2S connection.","title":"Options: S2S"},{"location":"advanced-configuration/s2s/#general-options","text":"These options affect both incoming and outgoing S2S connections.","title":"General options"},{"location":"advanced-configuration/s2s/#s2sdefault_policy","text":"Scope: local Syntax: string, \"allow\" or \"deny\" Default: \"allow\" Example: default_policy = \"deny\" Default policy for opening new S2S connections to/from remote servers.","title":"s2s.default_policy"},{"location":"advanced-configuration/s2s/#s2shost_policy","text":"Scope: local Syntax: array of TOML tables with the following mandatory content: host - string, host name policy - string, \"allow\" or \"deny\" Default: \"allow\" Example: 1 2 3 4 host_policy = [ { host = \"good.xmpp.org\" , policy = \"allow\" }, { host = \"bad.xmpp.org\" , policy = \"deny\" } ] Policy for opening new connections to/from specific remote servers.","title":"s2s.host_policy"},{"location":"advanced-configuration/s2s/#s2suse_starttls","text":"Scope: local Syntax: string, one of \"false\" , \"optional\" , \"required\" , \"required_trusted\" Default: \"false\" Example: use_starttls = \"required\" Allows to configure StartTLS for incoming and outgoing S2S connections: false - StartTLS is disabled, optional - StartTLS is supported, required - StartTLS is supported and enforced, required_trusted - StartTLS is supported and enforced with certificate verification.","title":"s2s.use_starttls"},{"location":"advanced-configuration/s2s/#s2scertfile","text":"Scope: local Syntax: string, path in the file system Default: not set Example: certfile = \"cert.pem\" Path to the X509 PEM file with a certificate and a private key inside (not protected by any password). Required if use_starttls is not false .","title":"s2s.certfile"},{"location":"advanced-configuration/s2s/#s2sdomain_certfile","text":"Scope: local Syntax: array of TOML tables with the following mandatory content: domain - string, XMPP domain name certfile - string, path in the file system Default: not set Example: 1 2 3 4 domain_certfile = [ { domain = \"localhost1.com\" , certfile = \"cert1.pem\" }, { domain = \"localhost2.com\" , certfile = \"cert2.pem\" } ] This option overrides the configured certificate file for specific local XMPP domains. Notes: This option applies to S2S and C2S connections. Each domain needs to be included in the list of hosts configured in the general section.","title":"s2s.domain_certfile"},{"location":"advanced-configuration/s2s/#s2sshared","text":"Scope: local Syntax: string Default: 10 strong random bytes, hex-encoded Example: shared = \"82gc8b23ct7824\" S2S shared secret used in the Server Dialback extension.","title":"s2s.shared"},{"location":"advanced-configuration/s2s/#outgoing-connections","text":"The options listed below affect only the outgoing S2S connections.","title":"Outgoing connections"},{"location":"advanced-configuration/s2s/#s2saddress","text":"Scope: local Syntax: array of TOML tables with the following content: host - string, mandatory, host name ip_address - string, mandatory, IP address port - integer, optional, port number Default: \"allow\" Example: 1 2 3 4 address = [ { host = \"my.xmpp.org\" , ip_address = \"192.0.100.1\" }, { host = \"your.xmpp.org\" , ip_address = \"192.0.1.100\" , port = 5271 } ] This option defines IP addresses and port numbers for specific non-local XMPP domains, allowing to override the DNS lookup for outgoing S2S connections.","title":"s2s.address"},{"location":"advanced-configuration/s2s/#s2sciphers","text":"Scope: local Syntax: string Default: \"TLSv1.2:TLSv1.3\" Example: ciphers = \"TLSv1.2\" Defines a list of accepted SSL ciphers for outgoing S2S connections. Please refer to the OpenSSL documentation for the cipher string format.","title":"s2s.ciphers"},{"location":"advanced-configuration/s2s/#s2smax_retry_delay","text":"Scope: local Syntax: positive integer Default: 300 Example: max_retry_delay = 300 Specifies the maximum time in seconds that MongooseIM will wait until the next attempt to connect to a remote XMPP server. The delays between consecutive attempts will be doubled until this limit is reached.","title":"s2s.max_retry_delay"},{"location":"advanced-configuration/s2s/#s2soutgoingport","text":"Scope: local Syntax: integer, port number Default: 5269 Example: outgoing.port = 5270 Defines the port to be used for outgoing S2S connections.","title":"s2s.outgoing.port"},{"location":"advanced-configuration/s2s/#s2soutgoingip_versions","text":"Scope: local Syntax: array of integers (IP versions): 4 or 6 Default: [4, 6] Example: outgoing.ip_versions = [6] Specifies the order of IP address families to try when establishing an outgoing S2S connection.","title":"s2s.outgoing.ip_versions"},{"location":"advanced-configuration/s2s/#s2soutgoingconnection_timeout","text":"Scope: local Syntax: positive integer or the string \"infinity\" Default: 10_000 Example: outgoing.connection_timeout = 5000 Timeout (in seconds) for establishing an outgoing S2S connection.","title":"s2s.outgoing.connection_timeout"},{"location":"advanced-configuration/s2s/#s2sdnstimeout","text":"Scope: local Syntax: positive integer Default: 10 Example: dns.timeout = 30 Timeout (in seconds) for DNS lookups when opening an outgoing S2S connection.","title":"s2s.dns.timeout"},{"location":"advanced-configuration/s2s/#s2sdnsretries","text":"Scope: local Syntax: positive integer Default: 2 Example: dns.retries = 1 Number of DNS lookup attempts when opening an outgoing S2S connection.","title":"s2s.dns.retries"},{"location":"advanced-configuration/shaper/","text":"The shaper section specifies traffic shapers used to limit the incoming XMPP traffic, providing a safety valve to protect the server. It can be used to prevent DoS attacks or to calm down too noisy clients. Scope: global Syntax: each shaper is specified in a subsection starting with [shaper.name] where name is used to uniquely identify the shaper. Default: no default - each shaper needs to be specified explicitly. Example: the normal shaper is used for the C2S connections. 1 2 [shaper.normal] max_rate = 1000 Traffic shaper options shaper.maxrate Syntax: positive integer Default: no default, this option is mandatory Example: maxrate = 1000 Defines the maximum accepted rate. For the shapers used by XMPP listeners this is the number of bytes per second, but there are shapers that use different units, e.g. MAM shapers . Examples The following examples show the typical shaper definitions. C2S Shaper This is the typical definition of an XMPP shaper, which accepts the maximum data rate of 1 kbps. When the rate is exceeded, the receiver pauses before processing the next packet. 1 2 [shaper.normal] max_rate = 1000 To make use of it, the corresponding rule should be defined in the access section. Finally, the C2S listener has to be configured to use the defined shaper - see the C2S Example . S2S Shaper For S2S connections we need to increase the limit as they receive the accumulated traffic from multiple users - e.g. to 50 kbps: 1 2 [shaper.fast] max_rate = 50 _000 To make use of it, the corresponding rule should be defined in the access section. Finally, the C2S listener has to be configured to use the defined shaper - see the S2S Example . MAM Shapers These shapers limit the number of MAM operations per second (rather than bytes per second). 1 2 3 4 5 [shaper.mam_shaper] max_rate = 1 [shaper.mam_global_shaper] max_rate = 1000 To make use of them, the corresponding rules should be defined in the access section.","title":"Options: Shaper"},{"location":"advanced-configuration/shaper/#traffic-shaper-options","text":"","title":"Traffic shaper options"},{"location":"advanced-configuration/shaper/#shapermaxrate","text":"Syntax: positive integer Default: no default, this option is mandatory Example: maxrate = 1000 Defines the maximum accepted rate. For the shapers used by XMPP listeners this is the number of bytes per second, but there are shapers that use different units, e.g. MAM shapers .","title":"shaper.maxrate"},{"location":"advanced-configuration/shaper/#examples","text":"The following examples show the typical shaper definitions.","title":"Examples"},{"location":"advanced-configuration/shaper/#c2s-shaper","text":"This is the typical definition of an XMPP shaper, which accepts the maximum data rate of 1 kbps. When the rate is exceeded, the receiver pauses before processing the next packet. 1 2 [shaper.normal] max_rate = 1000 To make use of it, the corresponding rule should be defined in the access section. Finally, the C2S listener has to be configured to use the defined shaper - see the C2S Example .","title":"C2S Shaper"},{"location":"advanced-configuration/shaper/#s2s-shaper","text":"For S2S connections we need to increase the limit as they receive the accumulated traffic from multiple users - e.g. to 50 kbps: 1 2 [shaper.fast] max_rate = 50 _000 To make use of it, the corresponding rule should be defined in the access section. Finally, the C2S listener has to be configured to use the defined shaper - see the S2S Example .","title":"S2S Shaper"},{"location":"advanced-configuration/shaper/#mam-shapers","text":"These shapers limit the number of MAM operations per second (rather than bytes per second). 1 2 3 4 5 [shaper.mam_shaper] max_rate = 1 [shaper.mam_global_shaper] max_rate = 1000 To make use of them, the corresponding rules should be defined in the access section.","title":"MAM Shapers"},{"location":"authentication-methods/anonymous/","text":"Overview This authentication method allows the users to connect anonymously. Configuration options auth.anonymous.allow_multiple_connections Syntax: boolean Default: false Example: allow_multiple_connections = true When set to true, allows multiple connections from the same JID using the anonymous authentication method. auth.anonymous.protocol Syntax: string, one of \"sasl_anon\" , \"login_anon\" , \"both\" Default: sasl_anon Example: protocol = \"both\" Specifies the SASL mechanisms supported by the anonymous authentication method: sasl_anon - support only the the ANONYMOUS mechanism, login_anon - support the non-anonymous mechanisms ( PLAIN , DIGEST-MD5 , SCRAM-* ), both - support both types of mechanisms. Example 1 2 3 4 5 6 [auth] methods = [\"anonymous\"] [auth.anonymous] allow_multiple_connections = true protocol = \"both\"","title":"Anonymous"},{"location":"authentication-methods/anonymous/#overview","text":"This authentication method allows the users to connect anonymously.","title":"Overview"},{"location":"authentication-methods/anonymous/#configuration-options","text":"","title":"Configuration options"},{"location":"authentication-methods/anonymous/#authanonymousallow_multiple_connections","text":"Syntax: boolean Default: false Example: allow_multiple_connections = true When set to true, allows multiple connections from the same JID using the anonymous authentication method.","title":"auth.anonymous.allow_multiple_connections"},{"location":"authentication-methods/anonymous/#authanonymousprotocol","text":"Syntax: string, one of \"sasl_anon\" , \"login_anon\" , \"both\" Default: sasl_anon Example: protocol = \"both\" Specifies the SASL mechanisms supported by the anonymous authentication method: sasl_anon - support only the the ANONYMOUS mechanism, login_anon - support the non-anonymous mechanisms ( PLAIN , DIGEST-MD5 , SCRAM-* ), both - support both types of mechanisms.","title":"auth.anonymous.protocol"},{"location":"authentication-methods/anonymous/#example","text":"1 2 3 4 5 6 [auth] methods = [\"anonymous\"] [auth.anonymous] allow_multiple_connections = true protocol = \"both\"","title":"Example"},{"location":"authentication-methods/dummy/","text":"Overview The purpose of this method is to make it possible to authenticate a user without the need for real authentication. In other words, using this module allows to connect any user to the server without providing any password, certificate, etc. This kind of authorization sometimes really comes in handy, especially during development and testing. The backend just accepts every authentication attempt and introduces a random delay (50-500ms) to an authorization response. The delay works like 1 timer : sleep ( Base + rand : uniform ( Variance )), where Base is base_time and Variance is variance , as configured below. Configuration auth.dummy.base_time Scope: local Syntax: integer Default: 50 Example: base_time = 5 auth.dummy.variance Scope: local Syntax: integer Default: 450 Example: variance = 10 Example 1 2 3 4 [auth] methods = [\"dummy\"] dummy . base = 5 dummy . variance = 10","title":"Dummy"},{"location":"authentication-methods/dummy/#overview","text":"The purpose of this method is to make it possible to authenticate a user without the need for real authentication. In other words, using this module allows to connect any user to the server without providing any password, certificate, etc. This kind of authorization sometimes really comes in handy, especially during development and testing. The backend just accepts every authentication attempt and introduces a random delay (50-500ms) to an authorization response. The delay works like 1 timer : sleep ( Base + rand : uniform ( Variance )), where Base is base_time and Variance is variance , as configured below.","title":"Overview"},{"location":"authentication-methods/dummy/#configuration","text":"","title":"Configuration"},{"location":"authentication-methods/dummy/#authdummybase_time","text":"Scope: local Syntax: integer Default: 50 Example: base_time = 5","title":"auth.dummy.base_time"},{"location":"authentication-methods/dummy/#authdummyvariance","text":"Scope: local Syntax: integer Default: 450 Example: variance = 10","title":"auth.dummy.variance"},{"location":"authentication-methods/dummy/#example","text":"1 2 3 4 [auth] methods = [\"dummy\"] dummy . base = 5 dummy . variance = 10","title":"Example"},{"location":"authentication-methods/external/","text":"Overview This authentication method delegates the authentication to an external script. It uses the SASL PLAIN mechanism. Script API specification All \"commands\" sent from Erlang VM to the script are prefixed with a 2-byte unsigned integer (command length), MSB first. The script is expected to return responses in the same format. Currently only 2 response packets are supported: 0x0000 = false (for failure). 0x0001 = true (for success). The following list describes packets that the script should support. auth:<username>:<domain>:<password> - Check password. setpass:<username>:<domain>:<password> - Set password. tryregister:<username>:<domain>:<password> - Register a user. removeuser:<username>:<domain> - Remove a user. isuser:<username>:<domain> - Check if a user exists. Configuration options auth.external.program Syntax: string Default: no default, this option is mandatory for the external authentication method Example: program = \"/usr/bin/auth-script.sh\" Path to the external authentication program. auth.external.instances Syntax: positive integer Default: 1 Example: instances = 2 Specifies the number of workers serving external authentication requests. Example 1 2 3 4 5 6 [auth] methods = [\"external\"] [auth.external] program = \"/home/user/authenticator\" instances = 5","title":"External"},{"location":"authentication-methods/external/#overview","text":"This authentication method delegates the authentication to an external script. It uses the SASL PLAIN mechanism.","title":"Overview"},{"location":"authentication-methods/external/#script-api-specification","text":"All \"commands\" sent from Erlang VM to the script are prefixed with a 2-byte unsigned integer (command length), MSB first. The script is expected to return responses in the same format. Currently only 2 response packets are supported: 0x0000 = false (for failure). 0x0001 = true (for success). The following list describes packets that the script should support. auth:<username>:<domain>:<password> - Check password. setpass:<username>:<domain>:<password> - Set password. tryregister:<username>:<domain>:<password> - Register a user. removeuser:<username>:<domain> - Remove a user. isuser:<username>:<domain> - Check if a user exists.","title":"Script API specification"},{"location":"authentication-methods/external/#configuration-options","text":"","title":"Configuration options"},{"location":"authentication-methods/external/#authexternalprogram","text":"Syntax: string Default: no default, this option is mandatory for the external authentication method Example: program = \"/usr/bin/auth-script.sh\" Path to the external authentication program.","title":"auth.external.program"},{"location":"authentication-methods/external/#authexternalinstances","text":"Syntax: positive integer Default: 1 Example: instances = 2 Specifies the number of workers serving external authentication requests.","title":"auth.external.instances"},{"location":"authentication-methods/external/#example","text":"1 2 3 4 5 6 [auth] methods = [\"external\"] [auth.external] program = \"/home/user/authenticator\" instances = 5","title":"Example"},{"location":"authentication-methods/http/","text":"Overview The purpose of this method is to connect to an external REST API and delegate the authentication operations to it. The component must implement the API described below . This method can be especially useful when the user database is shared with other services. It fits perfectly when the client application uses a custom authentication token and MongooseIM has to validate it externally. Configuration options The auth method uses an outgoing HTTP connection pool called auth , which has to be defined in the outgoing_pools section. For additional configuration, the following options can be provided in the auth section: auth.http.basic_auth Syntax: string Default: not set Example: basic_auth = \"admin:secret\" Optional HTTP Basic Authentication in format \"username:password\" - used to authenticate MongooseIM in the HTTP service. Example Authentication: 1 2 3 4 5 [auth] methods = [\"http\"] [auth.http] basic_auth = \"mongooseim:DzviNQw3qyGJDrJDu+ClyA\" Outgoing pools: 1 2 [outgoing_pools.http.auth] connection . host = \"https://auth-service:8000\" SCRAM support The http method can use the SASL SCRAM-* mechanisms. When SCRAM is enabled, the passwords sent to the auth service are serialised and the same serialised format is expected when fetching a password from the component. It is transparent when MongooseIM is responsible for all DB operations such as password setting, account creation etc. The service CAN perform the (de)serialization of SCRAM-encoded passwords. You can find more details on the SCRAM serialization page. Authentication service API URL format All GET requests include the following URL-encoded query string: ?user=<username>&server=<domain>&pass=<password> . All POST requests have the following URL-encoded string in the request body: user=<username>&server=<domain>&pass=<password> . If a certain method does not need a password, the value of pass is undefined , so it shouldn't be used. Return codes For the best integration, the return code range should not exceed the list below: 500 - internal server error 409 - conflict 404 - not found 403 - not allowed 401 - not authorised 400 - other error, should be sent in response body 204 - success, no return data 201 - created 200 - success, return value in response body Whenever the specification says \"anything else\", service should use one of the codes from the list above. Some requests consider multiple return codes a \"success\". It is up to the server-side developer to pick one of the codes. HTTP header Content-Length IMPORTANT: The authentication server MUST include a Content-Length HTTP header in the response. A body can be missing in the first data chunk read from a socket, leading to strange authentication errors. Method register Description: Creates a user account. HTTP method: POST Type: mandatory when mod_register is enabled Return values: 201 - success 409 - user already exists anything else - will be treated as failure Method check_password Description: Must respond if the password is valid for the user. HTTP method: GET Type: mandatory when SCRAM is not used Return values: 200, true or false in the body anything else - will be treated as false Method get_password Description: Must return the user's password in plaintext or in the SCRAM serialised form. HTTP method: GET Type: mandatory when SCRAM or DIGEST SASL mechanism is used Return values: 200, password in the body anything else - get_password will fail Method get_certs Description: Must return all the valid certificates of a user in the PEM format . HTTP method: GET Type: mandatory when EXTERNAL SASL mechanism is used Return values: 200, all the user's certificates listed one after another (as in a PEM file) anything else - get_certs will fail Method user_exists Description: Must return the information whether the user exists in DB. HTTP method: GET Type: mandatory Return values: 200, true or false in body anything else - will be treated as false Method set_password Description: Must set user's password in the internal database to a provided value. The value should not be transformed (except for URL-decoding) before writing into the DB. HTTP method: POST Type: mandatory when mod_register is enabled Return values: 200 or 201 or 204 - success anything else - will be treated as false Method remove_user Description: Removes a user account. HTTP method: POST Type: mandatory when mod_register is enabled Return values: 200 or 201 or 204 - success 404 - user does not exist 403 - not allowed for some reason 40X - will be treated as bad request Authentication service API recipes Below you can find some examples of the auth service APIs and MongooseIM-side configuration along with use cases. System using a common, custom auth token An Auth token is provided as a password. Service implements: check_password , user_exists MongooseIM config: password.format : plain , mod_register disabled Client side: Must NOT use the DIGEST-MD5 mechanism; use PLAIN instead Central database of plaintext passwords Service implements: check_password , get_password , user_exists MongooseIM config: password.format : plain , mod_register disabled Client side: May use any available SASL mechanism Central database able to process SCRAM Service implements: get_password , user_exists MongooseIM config: password.format : scram , mod_register disabled Client side: May use any available SASL mechanism Godlike MongooseIM Service implements: all methods MongooseIM config: password.format : scram (recommended) or plain , mod_register enabled Client side: May use any available SASL mechanism","title":"HTTP"},{"location":"authentication-methods/http/#overview","text":"The purpose of this method is to connect to an external REST API and delegate the authentication operations to it. The component must implement the API described below . This method can be especially useful when the user database is shared with other services. It fits perfectly when the client application uses a custom authentication token and MongooseIM has to validate it externally.","title":"Overview"},{"location":"authentication-methods/http/#configuration-options","text":"The auth method uses an outgoing HTTP connection pool called auth , which has to be defined in the outgoing_pools section. For additional configuration, the following options can be provided in the auth section:","title":"Configuration options"},{"location":"authentication-methods/http/#authhttpbasic_auth","text":"Syntax: string Default: not set Example: basic_auth = \"admin:secret\" Optional HTTP Basic Authentication in format \"username:password\" - used to authenticate MongooseIM in the HTTP service.","title":"auth.http.basic_auth"},{"location":"authentication-methods/http/#example","text":"Authentication: 1 2 3 4 5 [auth] methods = [\"http\"] [auth.http] basic_auth = \"mongooseim:DzviNQw3qyGJDrJDu+ClyA\" Outgoing pools: 1 2 [outgoing_pools.http.auth] connection . host = \"https://auth-service:8000\"","title":"Example"},{"location":"authentication-methods/http/#scram-support","text":"The http method can use the SASL SCRAM-* mechanisms. When SCRAM is enabled, the passwords sent to the auth service are serialised and the same serialised format is expected when fetching a password from the component. It is transparent when MongooseIM is responsible for all DB operations such as password setting, account creation etc. The service CAN perform the (de)serialization of SCRAM-encoded passwords. You can find more details on the SCRAM serialization page.","title":"SCRAM support"},{"location":"authentication-methods/http/#authentication-service-api","text":"","title":"Authentication service API"},{"location":"authentication-methods/http/#url-format","text":"All GET requests include the following URL-encoded query string: ?user=<username>&server=<domain>&pass=<password> . All POST requests have the following URL-encoded string in the request body: user=<username>&server=<domain>&pass=<password> . If a certain method does not need a password, the value of pass is undefined , so it shouldn't be used.","title":"URL format"},{"location":"authentication-methods/http/#return-codes","text":"For the best integration, the return code range should not exceed the list below: 500 - internal server error 409 - conflict 404 - not found 403 - not allowed 401 - not authorised 400 - other error, should be sent in response body 204 - success, no return data 201 - created 200 - success, return value in response body Whenever the specification says \"anything else\", service should use one of the codes from the list above. Some requests consider multiple return codes a \"success\". It is up to the server-side developer to pick one of the codes.","title":"Return codes"},{"location":"authentication-methods/http/#http-header-content-length","text":"IMPORTANT: The authentication server MUST include a Content-Length HTTP header in the response. A body can be missing in the first data chunk read from a socket, leading to strange authentication errors.","title":"HTTP header Content-Length"},{"location":"authentication-methods/http/#method-register","text":"Description: Creates a user account. HTTP method: POST Type: mandatory when mod_register is enabled Return values: 201 - success 409 - user already exists anything else - will be treated as failure","title":"Method register"},{"location":"authentication-methods/http/#method-check_password","text":"Description: Must respond if the password is valid for the user. HTTP method: GET Type: mandatory when SCRAM is not used Return values: 200, true or false in the body anything else - will be treated as false","title":"Method check_password"},{"location":"authentication-methods/http/#method-get_password","text":"Description: Must return the user's password in plaintext or in the SCRAM serialised form. HTTP method: GET Type: mandatory when SCRAM or DIGEST SASL mechanism is used Return values: 200, password in the body anything else - get_password will fail","title":"Method get_password"},{"location":"authentication-methods/http/#method-get_certs","text":"Description: Must return all the valid certificates of a user in the PEM format . HTTP method: GET Type: mandatory when EXTERNAL SASL mechanism is used Return values: 200, all the user's certificates listed one after another (as in a PEM file) anything else - get_certs will fail","title":"Method get_certs"},{"location":"authentication-methods/http/#method-user_exists","text":"Description: Must return the information whether the user exists in DB. HTTP method: GET Type: mandatory Return values: 200, true or false in body anything else - will be treated as false","title":"Method user_exists"},{"location":"authentication-methods/http/#method-set_password","text":"Description: Must set user's password in the internal database to a provided value. The value should not be transformed (except for URL-decoding) before writing into the DB. HTTP method: POST Type: mandatory when mod_register is enabled Return values: 200 or 201 or 204 - success anything else - will be treated as false","title":"Method set_password"},{"location":"authentication-methods/http/#method-remove_user","text":"Description: Removes a user account. HTTP method: POST Type: mandatory when mod_register is enabled Return values: 200 or 201 or 204 - success 404 - user does not exist 403 - not allowed for some reason 40X - will be treated as bad request","title":"Method remove_user"},{"location":"authentication-methods/http/#authentication-service-api-recipes","text":"Below you can find some examples of the auth service APIs and MongooseIM-side configuration along with use cases.","title":"Authentication service API recipes"},{"location":"authentication-methods/http/#system-using-a-common-custom-auth-token","text":"An Auth token is provided as a password. Service implements: check_password , user_exists MongooseIM config: password.format : plain , mod_register disabled Client side: Must NOT use the DIGEST-MD5 mechanism; use PLAIN instead","title":"System using a common, custom auth token"},{"location":"authentication-methods/http/#central-database-of-plaintext-passwords","text":"Service implements: check_password , get_password , user_exists MongooseIM config: password.format : plain , mod_register disabled Client side: May use any available SASL mechanism","title":"Central database of plaintext passwords"},{"location":"authentication-methods/http/#central-database-able-to-process-scram","text":"Service implements: get_password , user_exists MongooseIM config: password.format : scram , mod_register disabled Client side: May use any available SASL mechanism","title":"Central database able to process SCRAM"},{"location":"authentication-methods/http/#godlike-mongooseim","text":"Service implements: all methods MongooseIM config: password.format : scram (recommended) or plain , mod_register enabled Client side: May use any available SASL mechanism","title":"Godlike MongooseIM"},{"location":"authentication-methods/jwt/","text":"Overview This authentication method can verify JSON Web Tokens provided by the clients. A wide range of signature algorithms is supported, including those using public key cryptography. The module checks the signature and validity of the following parameters: exp - an expired token is rejected, iat - a token must be issued in the past, nbf - a token might not be valid yet . It requires the SASL PLAIN mechanism listed in sasl_mechanisms . Configuration options auth.jwt.secret Syntax: TOML table with exactly one of the possible items listed below: file - string, path to the file with the JWT secret, env - string, environment variable name with the JWT secret, value - string, the JWT secret value. Default: no default, this option is mandatory Example: secret.env = \"JWT_SECRET\" This is the JWT secret used for the authentication. You can store it in a file, as an environment variable or specify it directly. auth.jwt.algorithm Syntax: string, one of: \"HS256\" , \"RS256\" , \"ES256\" , \"HS386\" , \"RS386\" , \"ES386\" , \"HS512\" , \"RS512\" , \"ES512\" Default: no default, this option is mandatory Example: algorithm = \"HS512\" Name of the algorithm used to sign the JWT. auth.jwt.username_key Syntax: string Default: no default, this option is mandatory Example: username_key = \"user_name\" Name of the JWT key that contains the user name to verify. Example 1 2 3 4 5 6 7 [auth] methods = [\"jwt\"] [auth.jwt] secret . value = \"top-secret123\" algorithm = \"HS256\" username_key = \"user\"","title":"JWT"},{"location":"authentication-methods/jwt/#overview","text":"This authentication method can verify JSON Web Tokens provided by the clients. A wide range of signature algorithms is supported, including those using public key cryptography. The module checks the signature and validity of the following parameters: exp - an expired token is rejected, iat - a token must be issued in the past, nbf - a token might not be valid yet . It requires the SASL PLAIN mechanism listed in sasl_mechanisms .","title":"Overview"},{"location":"authentication-methods/jwt/#configuration-options","text":"","title":"Configuration options"},{"location":"authentication-methods/jwt/#authjwtsecret","text":"Syntax: TOML table with exactly one of the possible items listed below: file - string, path to the file with the JWT secret, env - string, environment variable name with the JWT secret, value - string, the JWT secret value. Default: no default, this option is mandatory Example: secret.env = \"JWT_SECRET\" This is the JWT secret used for the authentication. You can store it in a file, as an environment variable or specify it directly.","title":"auth.jwt.secret"},{"location":"authentication-methods/jwt/#authjwtalgorithm","text":"Syntax: string, one of: \"HS256\" , \"RS256\" , \"ES256\" , \"HS386\" , \"RS386\" , \"ES386\" , \"HS512\" , \"RS512\" , \"ES512\" Default: no default, this option is mandatory Example: algorithm = \"HS512\" Name of the algorithm used to sign the JWT.","title":"auth.jwt.algorithm"},{"location":"authentication-methods/jwt/#authjwtusername_key","text":"Syntax: string Default: no default, this option is mandatory Example: username_key = \"user_name\" Name of the JWT key that contains the user name to verify.","title":"auth.jwt.username_key"},{"location":"authentication-methods/jwt/#example","text":"1 2 3 4 5 6 7 [auth] methods = [\"jwt\"] [auth.jwt] secret . value = \"top-secret123\" algorithm = \"HS256\" username_key = \"user\"","title":"Example"},{"location":"authentication-methods/ldap/","text":"Overview This authentication method provides a read-only abstraction over an LDAP directory. The following SASL mechanisms are supported: SASL EXTERNAL User credentials are verified by performing an LDAP search with the user name provided by the client. This can be used to verify that the user is allowed to log in after the provided certificate has been verified. This method requires one connection pool with the default tag (unless you change it with the pool_tag option). You need to provide the root DN and password unless your LDAP password allows anonymous searches. Example: 1 2 3 4 5 [outgoing_pools.ldap.default] workers = 5 connection . servers = [\"ldap-server.example.com\"] connection . rootdn = \"cn=admin,dc=example,dc=com\" connection . password = \"ldap-admin-password\" For more details see outgoing connections . SASL PLAIN User credentials are verified by performing an LDAP search followed by a bind with the user name and password provided by the client. To use SASL PLAIN, you need to configure two connection pools: one with the default tag (unless you change it with the pool_tag option) for the search operations (like for SASL EXTERNAL), one with the bind tag (unless you change it with the bind_pool_tag option) for the bind operations - for this one it is not necessary to provide the root DN and password as the bind operations will be performed with users' credentials. This pool has to be used exclusively for the bind operations as the authentication state of the connection changes with each request. Example: 1 2 3 4 5 6 7 8 [outgoing_pools.ldap.default] workers = 5 connection . servers = [\"ldap-server.example.com\"] connection . rootdn = \"cn=admin,dc=example,dc=com\" connection . password = \"ldap-admin-password\" [outgoing_pools.ldap.bind] connection . servers = [\"ldap-server.example.com\"] For more details see outgoing connections . Configuration options auth.ldap.pool_tag Syntax: string Default: \"default\" Example: pool_tag = \"my_pool\" Specifies the tag for the primary outgoing connection pool for LDAP authentication. auth.ldap.bind_pool_tag Syntax: string Default: \"bind\" Example: bind_pool_tag = \"my_bind_pool\" Specifies the tag for the secondary outgoing connection pool for LDAP authentication, used for operations requiring the bind operations, such as checking passwords. auth.ldap.base Syntax: string Default: no default, this option is mandatory Example: base = \"ou=Users,dc=example,dc=com\" LDAP base directory which stores user accounts. auth.ldap.uids Syntax: array of TOML tables with the following content: attr - string, mandatory, name of the attribute format - pattern, default: \"%u\" , requires attr Default: [{attr = \"my_uid\"}] Example: uids = [{attr = \"my_uid\", format = \"%u@example.org\"}, {attr = \"another_uid\"}] List of LDAP attributes that contain the user name (user's part of the JID), used to search for user accounts. They are used as alternatives - it is enough if one of them contains the name. By default the whole value of the attribute is expected to be the user name. If this is not the case, use the format option. It must contain one and only one pattern variable %u which will be replaced by the user name. auth.ldap.filter Syntax: string Default: not set Example: filter = \"(&(objectClass=shadowAccount)(memberOf=Jabber Users))\" An additional LDAP filter used to narrow down the search for user accounts. Do not forget to close the brackets and do not use superfluous whitespaces as this expression is processed before sending to LDAP - the match for user name (see ldap.uids ) is added automatically. auth.ldap.dn_filter Syntax: TOML table with the following content: filter - string (LDAP filter), mandatory attributes - array of strings (attribute names) Default: not set Example: dn_filter = {filter = \"(&(name=%s)(owner=%D)(user=%u@%d))\", attributes = [\"sn\"]} This filter is applied to the results returned by the main filter. It performs an additional LDAP lookup to provide the complete result. This is useful when you are unable to define all filter rules in ldap.filter . You can define %u , %d , %s and %D pattern variables in the filter: %u is replaced by the user\u2019s part of a JID, %d is replaced by the corresponding domain (virtual host), %s variables are consecutively replaced by values of the attributes listen as attributes %D is replaced by the Distinguished Name. Since this filter makes additional LDAP lookups, use it only as the last resort; try to define all filter rules in ldap.filter if possible. auth.ldap.local_filter Syntax: TOML table with the following content: operation - string, mandatory, \"equal\" or \"notequal\" attribute - string, mandatory, LDAP attribute values - array of strings (attribute values) Default: not set Example: local_filter = {operation = \"equal\", attribute = \"accountStatus\", values = [\"enabled\"]} If you can\u2019t use the ldap.filter due to performance reasons (the LDAP server has many users registered), you can use this local filter. The local filter checks an attribute in MongooseIM, not in LDAP, so this limits the load on the LDAP directory. The example above shows a filter which matches accounts with the \"enabled\" status. Another example is shown below - it matches any account that is neither \"disabled\" nor \"blacklisted\". It also shows the usage of TOML dotted keys, which is recommended when the inline table grows too big. 1 2 3 local_filter . operation = \"notequal\" local_filter . attribute = \"accountStatus\" local_filter . values = [\"disabled\", \"blacklisted\"] auth.ldap.deref Syntax: string, one of: \"never\" , \"always\" , \"finding\" , \"searching\" Default: \"never\" Example: deref = \"always\" Specifies whether or not to dereference aliases: finding means to dereference only when finding the base and searching - only when performing the LDAP search. See the documentation on LDAP search operation for more information. Example 1 2 3 4 5 6 [auth] methods = [\"ldap\"] [auth.ldap] base = \"ou=Users,dc=example,dc=com\" filter = \"(objectClass=inetOrgPerson)\"","title":"LDAP"},{"location":"authentication-methods/ldap/#overview","text":"This authentication method provides a read-only abstraction over an LDAP directory. The following SASL mechanisms are supported:","title":"Overview"},{"location":"authentication-methods/ldap/#sasl-external","text":"User credentials are verified by performing an LDAP search with the user name provided by the client. This can be used to verify that the user is allowed to log in after the provided certificate has been verified. This method requires one connection pool with the default tag (unless you change it with the pool_tag option). You need to provide the root DN and password unless your LDAP password allows anonymous searches. Example: 1 2 3 4 5 [outgoing_pools.ldap.default] workers = 5 connection . servers = [\"ldap-server.example.com\"] connection . rootdn = \"cn=admin,dc=example,dc=com\" connection . password = \"ldap-admin-password\" For more details see outgoing connections .","title":"SASL EXTERNAL"},{"location":"authentication-methods/ldap/#sasl-plain","text":"User credentials are verified by performing an LDAP search followed by a bind with the user name and password provided by the client. To use SASL PLAIN, you need to configure two connection pools: one with the default tag (unless you change it with the pool_tag option) for the search operations (like for SASL EXTERNAL), one with the bind tag (unless you change it with the bind_pool_tag option) for the bind operations - for this one it is not necessary to provide the root DN and password as the bind operations will be performed with users' credentials. This pool has to be used exclusively for the bind operations as the authentication state of the connection changes with each request. Example: 1 2 3 4 5 6 7 8 [outgoing_pools.ldap.default] workers = 5 connection . servers = [\"ldap-server.example.com\"] connection . rootdn = \"cn=admin,dc=example,dc=com\" connection . password = \"ldap-admin-password\" [outgoing_pools.ldap.bind] connection . servers = [\"ldap-server.example.com\"] For more details see outgoing connections .","title":"SASL PLAIN"},{"location":"authentication-methods/ldap/#configuration-options","text":"","title":"Configuration options"},{"location":"authentication-methods/ldap/#authldappool_tag","text":"Syntax: string Default: \"default\" Example: pool_tag = \"my_pool\" Specifies the tag for the primary outgoing connection pool for LDAP authentication.","title":"auth.ldap.pool_tag"},{"location":"authentication-methods/ldap/#authldapbind_pool_tag","text":"Syntax: string Default: \"bind\" Example: bind_pool_tag = \"my_bind_pool\" Specifies the tag for the secondary outgoing connection pool for LDAP authentication, used for operations requiring the bind operations, such as checking passwords.","title":"auth.ldap.bind_pool_tag"},{"location":"authentication-methods/ldap/#authldapbase","text":"Syntax: string Default: no default, this option is mandatory Example: base = \"ou=Users,dc=example,dc=com\" LDAP base directory which stores user accounts.","title":"auth.ldap.base"},{"location":"authentication-methods/ldap/#authldapuids","text":"Syntax: array of TOML tables with the following content: attr - string, mandatory, name of the attribute format - pattern, default: \"%u\" , requires attr Default: [{attr = \"my_uid\"}] Example: uids = [{attr = \"my_uid\", format = \"%u@example.org\"}, {attr = \"another_uid\"}] List of LDAP attributes that contain the user name (user's part of the JID), used to search for user accounts. They are used as alternatives - it is enough if one of them contains the name. By default the whole value of the attribute is expected to be the user name. If this is not the case, use the format option. It must contain one and only one pattern variable %u which will be replaced by the user name.","title":"auth.ldap.uids"},{"location":"authentication-methods/ldap/#authldapfilter","text":"Syntax: string Default: not set Example: filter = \"(&(objectClass=shadowAccount)(memberOf=Jabber Users))\" An additional LDAP filter used to narrow down the search for user accounts. Do not forget to close the brackets and do not use superfluous whitespaces as this expression is processed before sending to LDAP - the match for user name (see ldap.uids ) is added automatically.","title":"auth.ldap.filter"},{"location":"authentication-methods/ldap/#authldapdn_filter","text":"Syntax: TOML table with the following content: filter - string (LDAP filter), mandatory attributes - array of strings (attribute names) Default: not set Example: dn_filter = {filter = \"(&(name=%s)(owner=%D)(user=%u@%d))\", attributes = [\"sn\"]} This filter is applied to the results returned by the main filter. It performs an additional LDAP lookup to provide the complete result. This is useful when you are unable to define all filter rules in ldap.filter . You can define %u , %d , %s and %D pattern variables in the filter: %u is replaced by the user\u2019s part of a JID, %d is replaced by the corresponding domain (virtual host), %s variables are consecutively replaced by values of the attributes listen as attributes %D is replaced by the Distinguished Name. Since this filter makes additional LDAP lookups, use it only as the last resort; try to define all filter rules in ldap.filter if possible.","title":"auth.ldap.dn_filter"},{"location":"authentication-methods/ldap/#authldaplocal_filter","text":"Syntax: TOML table with the following content: operation - string, mandatory, \"equal\" or \"notequal\" attribute - string, mandatory, LDAP attribute values - array of strings (attribute values) Default: not set Example: local_filter = {operation = \"equal\", attribute = \"accountStatus\", values = [\"enabled\"]} If you can\u2019t use the ldap.filter due to performance reasons (the LDAP server has many users registered), you can use this local filter. The local filter checks an attribute in MongooseIM, not in LDAP, so this limits the load on the LDAP directory. The example above shows a filter which matches accounts with the \"enabled\" status. Another example is shown below - it matches any account that is neither \"disabled\" nor \"blacklisted\". It also shows the usage of TOML dotted keys, which is recommended when the inline table grows too big. 1 2 3 local_filter . operation = \"notequal\" local_filter . attribute = \"accountStatus\" local_filter . values = [\"disabled\", \"blacklisted\"]","title":"auth.ldap.local_filter"},{"location":"authentication-methods/ldap/#authldapderef","text":"Syntax: string, one of: \"never\" , \"always\" , \"finding\" , \"searching\" Default: \"never\" Example: deref = \"always\" Specifies whether or not to dereference aliases: finding means to dereference only when finding the base and searching - only when performing the LDAP search. See the documentation on LDAP search operation for more information.","title":"auth.ldap.deref"},{"location":"authentication-methods/ldap/#example","text":"1 2 3 4 5 6 [auth] methods = [\"ldap\"] [auth.ldap] base = \"ou=Users,dc=example,dc=com\" filter = \"(objectClass=inetOrgPerson)\"","title":"Example"},{"location":"authentication-methods/pki/","text":"Overview This is a simple authentication method, meant to be used with the SASL EXTERNAL mechanism. It simply accepts all usernames as long as they are validated by the SASL logic. WARNING Some of its callbacks return hardcoded values, as it's impossible for this backend to properly acquire certain pieces of information. These include: Function Hardcoded value Explanation does_user_exist true PKI reponds with true to modules checking if user's interlocutor actually exists so e.g. messages to nonexistent users will always be stored by mod_mam . This is not necessarily a security threat but something to be aware of. dirty_get_registered_users , get_vh_registered_users , get_vh_registered_users_number [] Any metrics or statistics (e.g. available via mongooseimctl ) related to accounts list or numbers, won't display proper values, as this backend cannot possibly \"know\" how many users there are. Configuration options None.","title":"PKI"},{"location":"authentication-methods/pki/#overview","text":"This is a simple authentication method, meant to be used with the SASL EXTERNAL mechanism. It simply accepts all usernames as long as they are validated by the SASL logic.","title":"Overview"},{"location":"authentication-methods/pki/#warning","text":"Some of its callbacks return hardcoded values, as it's impossible for this backend to properly acquire certain pieces of information. These include: Function Hardcoded value Explanation does_user_exist true PKI reponds with true to modules checking if user's interlocutor actually exists so e.g. messages to nonexistent users will always be stored by mod_mam . This is not necessarily a security threat but something to be aware of. dirty_get_registered_users , get_vh_registered_users , get_vh_registered_users_number [] Any metrics or statistics (e.g. available via mongooseimctl ) related to accounts list or numbers, won't display proper values, as this backend cannot possibly \"know\" how many users there are.","title":"WARNING"},{"location":"authentication-methods/pki/#configuration-options","text":"None.","title":"Configuration options"},{"location":"authentication-methods/rdbms/","text":"Overview This authentication method stores user accounts in a relational database, e.g. MySQL or PostgreSQL. Configuration The rdbms method uses an outgoing connection pool of type rdbms with the default tag - it has to be defined in the outgoing_pools section. auth.rdbms.users_number_estimate Scope: local Syntax: boolean Default: false Example: users_number_estimate = true By default querying MongooseIM for the number of registered users uses the SELECT COUNT query, which might be slow. Enabling this option makes MongooseIM use an alternative query that might be not as accurate, but is always fast. Note: this option is effective only for MySQL and PostgreSQL. Example Authentication: 1 2 3 4 5 [auth] methods = [\"rdbms\"] [auth.rdbms] users_number_estimate = true Outgoing pools: 1 2 3 4 5 6 [outgoing_pools.rdbms.default.connection] driver = \"pgsql\" host = \"localhost\" database = \"mongooseim\" username = \"mongooseim\" password = \"mongooseim_secret\"","title":"RDBMS"},{"location":"authentication-methods/rdbms/#overview","text":"This authentication method stores user accounts in a relational database, e.g. MySQL or PostgreSQL.","title":"Overview"},{"location":"authentication-methods/rdbms/#configuration","text":"The rdbms method uses an outgoing connection pool of type rdbms with the default tag - it has to be defined in the outgoing_pools section.","title":"Configuration"},{"location":"authentication-methods/rdbms/#authrdbmsusers_number_estimate","text":"Scope: local Syntax: boolean Default: false Example: users_number_estimate = true By default querying MongooseIM for the number of registered users uses the SELECT COUNT query, which might be slow. Enabling this option makes MongooseIM use an alternative query that might be not as accurate, but is always fast. Note: this option is effective only for MySQL and PostgreSQL.","title":"auth.rdbms.users_number_estimate"},{"location":"authentication-methods/rdbms/#example","text":"Authentication: 1 2 3 4 5 [auth] methods = [\"rdbms\"] [auth.rdbms] users_number_estimate = true Outgoing pools: 1 2 3 4 5 6 [outgoing_pools.rdbms.default.connection] driver = \"pgsql\" host = \"localhost\" database = \"mongooseim\" username = \"mongooseim\" password = \"mongooseim_secret\"","title":"Example"},{"location":"authentication-methods/riak/","text":"Overview This authentication method stores user accounts in Riak. Configuration options The riak method uses an outgoing connection pool of type riak with the default tag - it has to be defined in the outgoing_pools section. There is one additional option: auth.riak.bucket_type Syntax: string Default: \"users\" Example: bucket_type = \"user_bucket\" Bucket type for storing users in Riak. Example Authentication: 1 2 3 4 5 [auth] methods = [\"riak\"] [auth.riak] bucket_type = \"user\" Outgoing pools: 1 2 3 [outgoing_pools.riak.default] connection . address = \"127.0.0.1\" connection . port = 8087","title":"Riak"},{"location":"authentication-methods/riak/#overview","text":"This authentication method stores user accounts in Riak.","title":"Overview"},{"location":"authentication-methods/riak/#configuration-options","text":"The riak method uses an outgoing connection pool of type riak with the default tag - it has to be defined in the outgoing_pools section. There is one additional option:","title":"Configuration options"},{"location":"authentication-methods/riak/#authriakbucket_type","text":"Syntax: string Default: \"users\" Example: bucket_type = \"user_bucket\" Bucket type for storing users in Riak.","title":"auth.riak.bucket_type"},{"location":"authentication-methods/riak/#example","text":"Authentication: 1 2 3 4 5 [auth] methods = [\"riak\"] [auth.riak] bucket_type = \"user\" Outgoing pools: 1 2 3 [outgoing_pools.riak.default] connection . address = \"127.0.0.1\" connection . port = 8087","title":"Example"},{"location":"developers-guide/Basic-iq-handler/","text":"Basic IQ Handler XMPP stands for Extensible Messaging and Presence Protocol. One way the protocol can be extended is by defining new types of queries, or IQs , that XMPP entities should be able to handle. It's usual that a XEP defining some XMPP extension contains some new type of IQ. IQs can also be used to implement custom features - required in a particular problem domain - but not defined by any official XEP. This tutorial will show you how to add and test a simple module with an IQ handler to MongooseIM. gen_iq_handler module provides functionality for registering IQ handlers for specific namespaces. Clone & build See How-to-build for details on building MongooseIM from source code. Create a module & add a basic IQ handler Go to src/ and create a basic module implementing the gen_mod behaviour. In start/2 register the IQ handler with a specified namespace, type (IQ processing policy), and function which will handle the incoming IQ stanza. In stop/1 remove the registered handler. Implement the function for handler: If the incoming IQ stanza is of type get or set it will be returned with the type set to result . If the server doesn't recognise the hostname, the returning stanza will be of type error . See Server Rules for Processing XML Stanzas for more detailed information on the topic. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 - module ( mod_iq_example ). - behaviour ( gen_mod ). - include ( \"mongoose.hrl\" ). - include ( \"jlib.hrl\" ). %% gen_mod callbacks - export ([ start / 2 , stop / 1 ]). %% IQ handlers - export ([ process_iq / 4 ]). start ( Host , _ Opts ) -> gen_iq_handler : add_iq_handler ( ejabberd_sm , Host , << \"erlang-solutions.com:example\" >> , ? MODULE , process_iq , no_queue ). stop ( Host ) -> gen_iq_handler : remove_iq_handler ( ejabberd_sm , Host , << \"erlang-solutions.com:example\" >> ). process_iq (_ From , _ To , Acc , IQ ) -> IQRes = IQ #iq { type = result }, ? LOG_INFO (#{ what => example_handler , acc => Acc , iq_result => IQRes }), { Acc , IQRes }. Test your handler Go to big_tests/tests and create a test suite for your handler. Implement the test case for success and failure. We will register two users, which are predefined in $REPO/big_tests/test.config : 1 2 3 4 5 6 7 8 9 { alice , [ { username , << \"alicE\" >> }, { server , << \"localhost\" >> }, { password , << \"matygrysa\" >> }]}, { alice_bis , [ { username , << \"alicE\" >> }, { server , << \"localhost.bis\" >> }, { host , << \"localhost\" >> }, { password , << \"matygrysa\" >> }]}, Our IQ handler will be enabled only for one domain, localhost . After sending an IQ stanza to alice we should get a result, but as our IQ handler is not enabled for localhost.bis domain, we should get an error. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 - module ( mod_iq_example_SUITE ). - export ([ all / 0 , groups / 0 , suite / 0 , init_per_suite / 1 , end_per_suite / 1 , init_per_group / 2 , end_per_group / 2 , init_per_testcase / 2 , end_per_testcase / 2 ]). %% Tests - export ([ should_return_result / 1 , should_return_error / 1 ]). - include_lib ( \"exml/include/exml.hrl\" ). - define ( EXAMPLE_NS , << \"erlang-solutions.com:example\" >> ). - define ( USERS , [ alice , alice_bis ]). - import ( distributed_helper , [ mim / 0 , require_rpc_nodes / 1 , rpc / 4 ]). %%-------------------------------------------------------------------- %% Suite configuration %%-------------------------------------------------------------------- all () -> [{ group , mod_iq_example }]. groups () -> G = [{ mod_iq_example , [], [ should_return_result , should_return_error ]}], ct_helper : repeat_all_until_all_ok ( G ). suite () -> require_rpc_nodes ([ mim ]) ++ escalus : suite (). %%-------------------------------------------------------------------- %% Init & teardown %%-------------------------------------------------------------------- init_per_suite ( Config ) -> Domain = ct : get_config ({ hosts , mim , domain }), dynamic_modules : start ( Domain , mod_iq_example , [ no_opts ]), escalus : init_per_suite ( Config ). end_per_suite ( Config ) -> Domain = ct : get_config ({ hosts , mim , domain }), dynamic_modules : stop ( Domain , mod_iq_example ), escalus : end_per_suite ( Config ). init_per_group (_, Config ) -> escalus : create_users ( Config , ? USERS ). end_per_group (_, Config ) -> escalus : delete_users ( Config , ? USERS ). init_per_testcase ( CaseName , Config ) -> escalus : init_per_testcase ( CaseName , Config ). end_per_testcase ( CaseName , Config ) -> escalus : end_per_testcase ( CaseName , Config ). %%-------------------------------------------------------------------- %% Tests %%-------------------------------------------------------------------- should_return_result ( Config ) -> %% given escalus : story ( Config , [{ alice , 1 }], fun ( Alice ) -> %% when sending a request Req = escalus_stanza : iq_get ( ? EXAMPLE_NS , [ #xmlel { name = << \"example\" >> }]), ct : pal ( \"req: ~p \" , [ Req ]), escalus : send ( Alice , Req ), %% then we should get a result Res = escalus : wait_for_stanza ( Alice ), ct : pal ( \"res: ~p \" , [ Res ]), escalus : assert ( is_iq , [ << \"result\" >> , ? EXAMPLE_NS ], Res ) end ). should_return_error ( Config ) -> %% given escalus : story ( Config , [{ alice_bis , 1 }], fun ( Alice ) -> %% when sending a request with unregistered server Req = escalus_stanza : iq_get ( ? EXAMPLE_NS , [ #xmlel { name = << \"example\" >> }]), ct : pal ( \"req: ~p \" , [ Req ]), escalus : send ( Alice , Req ), %% then we should get an error Res = escalus : wait_for_stanza ( Alice ), ct : pal ( \"res: ~p \" , [ Res ]), escalus : assert ( is_iq , [ << \"error\" >> , ? EXAMPLE_NS ], Res ), escalus : assert ( is_error , [ << \"cancel\" >> , << \"service-unavailable\" >> ], Res ) end ). Run it Compile & generate releases for testing purposes according to How-to-build . Go to $REPO/_build/mim1/rel/mongooseim and start one MongooseIM node. 1 bin/mongooseim live Open up a new terminal window, go to $REPO and use the test runner . Run single suite with the already started mim1 node. 1 2 source tools/test-runner-complete.sh test-runner.sh --rerun-big-tests -- mod_iq_example","title":"Basic IQ Handler"},{"location":"developers-guide/Basic-iq-handler/#basic-iq-handler","text":"XMPP stands for Extensible Messaging and Presence Protocol. One way the protocol can be extended is by defining new types of queries, or IQs , that XMPP entities should be able to handle. It's usual that a XEP defining some XMPP extension contains some new type of IQ. IQs can also be used to implement custom features - required in a particular problem domain - but not defined by any official XEP. This tutorial will show you how to add and test a simple module with an IQ handler to MongooseIM. gen_iq_handler module provides functionality for registering IQ handlers for specific namespaces.","title":"Basic IQ Handler"},{"location":"developers-guide/Basic-iq-handler/#clone-build","text":"See How-to-build for details on building MongooseIM from source code.","title":"Clone &amp; build"},{"location":"developers-guide/Basic-iq-handler/#create-a-module-add-a-basic-iq-handler","text":"Go to src/ and create a basic module implementing the gen_mod behaviour. In start/2 register the IQ handler with a specified namespace, type (IQ processing policy), and function which will handle the incoming IQ stanza. In stop/1 remove the registered handler. Implement the function for handler: If the incoming IQ stanza is of type get or set it will be returned with the type set to result . If the server doesn't recognise the hostname, the returning stanza will be of type error . See Server Rules for Processing XML Stanzas for more detailed information on the topic. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 - module ( mod_iq_example ). - behaviour ( gen_mod ). - include ( \"mongoose.hrl\" ). - include ( \"jlib.hrl\" ). %% gen_mod callbacks - export ([ start / 2 , stop / 1 ]). %% IQ handlers - export ([ process_iq / 4 ]). start ( Host , _ Opts ) -> gen_iq_handler : add_iq_handler ( ejabberd_sm , Host , << \"erlang-solutions.com:example\" >> , ? MODULE , process_iq , no_queue ). stop ( Host ) -> gen_iq_handler : remove_iq_handler ( ejabberd_sm , Host , << \"erlang-solutions.com:example\" >> ). process_iq (_ From , _ To , Acc , IQ ) -> IQRes = IQ #iq { type = result }, ? LOG_INFO (#{ what => example_handler , acc => Acc , iq_result => IQRes }), { Acc , IQRes }.","title":"Create a module &amp; add a basic IQ handler"},{"location":"developers-guide/Basic-iq-handler/#test-your-handler","text":"Go to big_tests/tests and create a test suite for your handler. Implement the test case for success and failure. We will register two users, which are predefined in $REPO/big_tests/test.config : 1 2 3 4 5 6 7 8 9 { alice , [ { username , << \"alicE\" >> }, { server , << \"localhost\" >> }, { password , << \"matygrysa\" >> }]}, { alice_bis , [ { username , << \"alicE\" >> }, { server , << \"localhost.bis\" >> }, { host , << \"localhost\" >> }, { password , << \"matygrysa\" >> }]}, Our IQ handler will be enabled only for one domain, localhost . After sending an IQ stanza to alice we should get a result, but as our IQ handler is not enabled for localhost.bis domain, we should get an error. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 - module ( mod_iq_example_SUITE ). - export ([ all / 0 , groups / 0 , suite / 0 , init_per_suite / 1 , end_per_suite / 1 , init_per_group / 2 , end_per_group / 2 , init_per_testcase / 2 , end_per_testcase / 2 ]). %% Tests - export ([ should_return_result / 1 , should_return_error / 1 ]). - include_lib ( \"exml/include/exml.hrl\" ). - define ( EXAMPLE_NS , << \"erlang-solutions.com:example\" >> ). - define ( USERS , [ alice , alice_bis ]). - import ( distributed_helper , [ mim / 0 , require_rpc_nodes / 1 , rpc / 4 ]). %%-------------------------------------------------------------------- %% Suite configuration %%-------------------------------------------------------------------- all () -> [{ group , mod_iq_example }]. groups () -> G = [{ mod_iq_example , [], [ should_return_result , should_return_error ]}], ct_helper : repeat_all_until_all_ok ( G ). suite () -> require_rpc_nodes ([ mim ]) ++ escalus : suite (). %%-------------------------------------------------------------------- %% Init & teardown %%-------------------------------------------------------------------- init_per_suite ( Config ) -> Domain = ct : get_config ({ hosts , mim , domain }), dynamic_modules : start ( Domain , mod_iq_example , [ no_opts ]), escalus : init_per_suite ( Config ). end_per_suite ( Config ) -> Domain = ct : get_config ({ hosts , mim , domain }), dynamic_modules : stop ( Domain , mod_iq_example ), escalus : end_per_suite ( Config ). init_per_group (_, Config ) -> escalus : create_users ( Config , ? USERS ). end_per_group (_, Config ) -> escalus : delete_users ( Config , ? USERS ). init_per_testcase ( CaseName , Config ) -> escalus : init_per_testcase ( CaseName , Config ). end_per_testcase ( CaseName , Config ) -> escalus : end_per_testcase ( CaseName , Config ). %%-------------------------------------------------------------------- %% Tests %%-------------------------------------------------------------------- should_return_result ( Config ) -> %% given escalus : story ( Config , [{ alice , 1 }], fun ( Alice ) -> %% when sending a request Req = escalus_stanza : iq_get ( ? EXAMPLE_NS , [ #xmlel { name = << \"example\" >> }]), ct : pal ( \"req: ~p \" , [ Req ]), escalus : send ( Alice , Req ), %% then we should get a result Res = escalus : wait_for_stanza ( Alice ), ct : pal ( \"res: ~p \" , [ Res ]), escalus : assert ( is_iq , [ << \"result\" >> , ? EXAMPLE_NS ], Res ) end ). should_return_error ( Config ) -> %% given escalus : story ( Config , [{ alice_bis , 1 }], fun ( Alice ) -> %% when sending a request with unregistered server Req = escalus_stanza : iq_get ( ? EXAMPLE_NS , [ #xmlel { name = << \"example\" >> }]), ct : pal ( \"req: ~p \" , [ Req ]), escalus : send ( Alice , Req ), %% then we should get an error Res = escalus : wait_for_stanza ( Alice ), ct : pal ( \"res: ~p \" , [ Res ]), escalus : assert ( is_iq , [ << \"error\" >> , ? EXAMPLE_NS ], Res ), escalus : assert ( is_error , [ << \"cancel\" >> , << \"service-unavailable\" >> ], Res ) end ).","title":"Test your handler"},{"location":"developers-guide/Basic-iq-handler/#run-it","text":"Compile & generate releases for testing purposes according to How-to-build . Go to $REPO/_build/mim1/rel/mongooseim and start one MongooseIM node. 1 bin/mongooseim live Open up a new terminal window, go to $REPO and use the test runner . Run single suite with the already started mim1 node. 1 2 source tools/test-runner-complete.sh test-runner.sh --rerun-big-tests -- mod_iq_example","title":"Run it"},{"location":"developers-guide/Hooks-and-handlers/","text":"Hooks, handlers and accumulators The hooks and handlers mechanism is one of the core architectural features of MongooseIM. It allows for loose coupling between components of the system by calling only those which are available and configured to be used at runtime. It can be thought of as a simple eventing mechanism notifying about certain things happening in the server. That results in an extensible system with pluggable extra functionality. To focus our attention, we'll analyze mod_offline which is responsible for storing messages for delivery to users unavailable at the time of sending. mod_offline is an implementation of XEP-0203: Delayed Delivery . Running a hook Basic usage ejabberd_sm (ejabberd/MongooseIM session manager) is the module discovering whether the recipient of a message is available or not. That's where storing the message for later delivery takes place. It is possible, but not recommended, to save a message in an offline storage by calling mod_offline directly: 1 mod_offline : store_packet ( From , To , Packet ) Note that in this example ejabberd_sm is coupled with mod_offline . I.e. if mod_offline was not available, the code would simply crash; if it was misconfigured or turned off, the behaviour would be undefined. To avoid that coupling and also to enable other ( possibly yet to be written ) code to carry out some action at this particular moment, ejabberd_sm would instead call: 1 2 3 4 Acc1 = ejabberd_hooks : run_fold ( offline_message_hook , LServer , Acc , [ From , To , Packet ]) The extra level of indirection introduced by this call gives the flexibility to determine at runtime what code actually gets run at this point. offline_message_hook is just the name of the hook (in other words of the event that is being signalled); From , To and Packet are the arguments passed to the handler just as they would in case of the function being called directly; LServer is the XMPP domain for which this hook is signalled . Notice: For the clarity of the explanation of the hooks mechanism, the provided code snippets are not exactly taken from the current code. The reasons for it will be described later . Getting results from handlers Hook handlers are called by \"folding\". This means that each handler on a list is passed a set of arguments and an initial value that it then modifies, returns and hands over to the next handler in line. A simple example would look like this: 1 2 3 4 5 ListOfSomething = ejabberd_hooks : run_fold ( a_certain_hook , StateData #state.server , [], [ StateData #state.user , StateData #state.server ]) The initial value of the accumulator being passed through the sequence of handlers (in this case an empty list [] ) is inserted between the XMPP domain StateData#state.server and handler arguments. In between the XMPP domain ( StateData#state.server ) and handler arguments is the initial value of the accumulator being passed through the sequence of handlers is inserted - in this case an empty list ( [] ). Sidenote: Folds If you haven't encountered the term fold before, think of it as reduce (like Array.reduce ) in Ruby-speak, roughly equivalent to the Reduce step in MapReduce, sometimes called accumulate , aggregate or compress . See Wikipedia for more. Using accumulators MongooseIM uses a dedicated data structure to accumulate data related to stanza processing (see \"Accumulators\" ). It is instantiated with an incoming stanza, passed along throughout the processing chain, supplied to and returned from certain hook calls, and terminated when stanza is leaving MongooseIM. If a Mongoose accumulator is passed to a hook, handlers should store their return values in one of 3 ways: If it is a one-off value which doesn't need to be passed on along with the accumulator (can be overwritten any time), use mongoose_acc:set(hook, result, Value, Acc) . If the value is to be passed on to be reused within the current processing context, use mongoose_acc:set(Namespace, Key, Value, Acc) . If the value should be passed on to the recipient's session, pubsub node etc. use mongoose_acc:set_permanent(Namespace, Key, Value, Acc) . A real life example, then, with regard to mod_offline is the resend_offline_messages_hook run in ejabberd_c2s : 1 2 3 4 5 Acc1 = ejabberd_hooks : run_fold ( resend_offline_messages_hook , StateData #state.server , Acc , [ StateData #state.user , StateData #state.server ]), Rs = mongoose_acc : get ( offline , messages , Acc1 , []), Sidenote: something deprecated In the past you may have found some calls to ejabberd_hooks:run/3 in the MongooseIM source code. Under the hood it called the same handlers with ok as the initial accumulator. This is deprecated, and some day will be removed. Error handling in hooks Hooks are meant to decouple modules; in other words, the caller signals that some event took place or that it intends to use a certain feature or a set of features, but how and if those features are implemented is beyond its interest. For that reason hooks don't use the \"let it crash\" approach. Instead it is rather like \"fire-and-forget\", more similar in principle to the Pid ! signal way. In practical terms: if a handler throws an error the hook machine logs a message and proceeds to the next handler with an unmodified accumulator. If there are no handlers registered for a given hook, the run_fold call simply has no effect. Sidenote: Code yet to be written Let's imagine, that when building a minimum viable product we settle on using mod_offline for delayed delivery of messages to unavailable clients. However, while the product evolves (or the relevant client software catches up) we might drop mod_offline in favour of a more sophisticated solution like Message Archive Management which would require a different action to be taken at the same point. Thanks to loose coupling and ejabberd_hooks it's possible to turn off mod_offline and turn on mod_mam without changing a single line of code in ejabberd_sm . The only required change is to the configuration (apart from deploying the new module) which can even be performed at runtime - without restarting the server. Sidenote: Multiple Domains A MongooseIM cluster may serve more than one domain at the same time. E.g. it is quite common that services like Multi User Chat or Publish-Subscribe are available as subdomains of the main XMPP domain served by an installation. Registering hook handlers In order to store a packet when ejabberd_sm runs offline_message_hook the relevant module must register a handler for this hook. To attain the runtime configurability the module should register the handlers when it's loaded and unregister them when it's unloaded. That's usually done in, respectively, start/2 and stop/1 functions. Here is the relevant snippet from mod_offline:start/2 : 1 2 ejabberd_hooks : add ( offline_message_hook , Host , ? MODULE , store_packet , 50 ) It is clearly visible that the handler is added to the offline_message_hook . Host corresponds to the LServer used in the aforementioned call to the ejabberd_hooks:run_fold , i.e. it's the XMPP domain for which the handler is to be executed. The handler itself is specified as a module-function pair; the arity of the function is not specified at the registration nor verified when calling the handler. This may change in the future, but for now we recommend calling the hooks through the mongoose_hooks module and checking the arity there when writing a handler. If the handler expects an incorrect number of arguments it will simply crash. Multiple handlers may be registered for the same hook. The last argument, 50, is the sequence number of this handler in the handler chain. The higher the number, the later in the sequence the handler will be executed. It's reasonable to keep this number small (e.g. in the range 0-100), though there's no real limit other than the size of the integer type in the Erlang VM. Unregistering handlers Pluggability also requires the components to be unpluggable at will. For that purpose there's the option to unregister a hook handler. It's done in mod_offline:stop/1 in a similar fashion to: 1 2 ejabberd_hooks : delete ( offline_message_hook , Host , ? MODULE , store_packet , 50 ) The arguments are exactly the same as passed to ejabberd_hooks:add/5 . Sidenote: Metrics Every time a hook is run, a corresponding metric of the same name in the same host is incremented by one. There are some exceptions though as some metrics were implemented before the generic hook metrics. List of hooks not updating generic metrics can be found in the mongoose_metrics:filter_hook/1 function. Such skipped hooks update metrics defined in the mongoose_metrics_hooks module. Writing handlers The signature of a handler has to follow three rules: Correct arity (the number of args passed to run_fold in mongoose_hooks + 1). The first arg is a mutable accumulator (may be mongoose_acc in particular). Returns an accumulator of the same type as the input one. Let's look at this example, from MongooseIM codebase: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 process_iq_get ( Acc , #jid { lserver = FromS } = From , To , #iq {} = IQ , _ ActiveList ) -> MUCHost = gen_mod : get_module_opt_subhost ( FromS , ? MODULE , default_host ()), case { mod_muc_light_codec_backend : decode ( From , To , IQ ), gen_mod : get_module_opt_by_subhost ( MUCHost , ? MODULE , blocking , ? DEFAULT_BLOCKING )} of {{ ok , { get , #blocking {} = Blocking }}, true } -> Items = mod_muc_light_db_backend : get_blocking ( jid : to_lus ( From ), MUCHost ), mod_muc_light_codec_backend : encode ( { get , Blocking #blocking { items = Items }}, From , jid : to_lus ( To ), fun (_, _, Packet ) -> put ( encode_res , Packet ) end ), #xmlel { children = ResponseChildren } = erase ( encode_res ), Result = { result , ResponseChildren }, { stop , mongoose_acc : set ( hook , result , Result , Acc )}; {{ ok , { get , #blocking {}}}, false } -> Result = { error , ? ERR_BAD_REQUEST }, { stop , mongoose_acc : set ( hook , result , Result , Acc )}; _ -> Result = { error , ? ERR_BAD_REQUEST }, mongoose_acc : set ( hook , result , Result , Acc ) end . As seen in this example, a handler receives an accumulator, puts some value into it and returns it for further processing. There's also one important feature to note: in some cases our handler returns a tuple {stop, Acc} . This skips calling the latter actions in the handler sequence, while the call to run_fold returns the Acc. If a handler returns just an atom stop , then all later actions are skipped and run_fold returns stopped . Watch out! Different handlers may be registered for the same hook - the priority mechanism orders their execution. If a handler returns stop but runs early in the handler chain, it may prevent some other handler from running at all! That might or might not be intentional. It may be especially surprising in case of handlers from different modules registered for the same hook. Always ensure what handlers are registered for a given hook ( grep is your friend) and that you understand their interdependencies. Hooks list and how to extract it The following command should give you a list of all the hooks available in MongooseIM: 1 2 3 4 5 6 7 8 $ find src/ -name '*.erl' -print | xargs ./tools/find-hooks.awk \\ > | sort | uniq adhoc_local_commands adhoc_local_items ... ... ... webadmin_user_parse_query Refer to grep / ack to find where they're used. Here are the contents of find-hooks.awk : 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 #!/usr/bin/env awk -f BEGIN { RS = \")\" ORS = \"\" FS = \"[ (,]\" } $ 0 ~ /ejabberd_hooks:run/ { found = - 1 for ( i = 1 ; i < NF ; i ++ ) { if ( $ i ~ /ejabberd_hooks:run/ ) { found = i } } if ( found != - 1 && $ ( found + 1 ) != \"\" && $ ( found + 1 ) ~ /^[a-z]/ ) print $ ( found + 1 ) \"\\n\" } Creating your own hooks There's no special function or any setup necessary to create a new hook. The only thing that needs to be done is calling ejabberd_hooks:run_fold/4 with the name of the new hook and relevant arguments. However, if you want static code analysis, you should put the new hook inside mongoose_hooks with a correct type specification. We've added this module to provide some security and type checking in places where the hooks are run. This is the way all hooks are called in MongooseIM (see the examples in the hooks description ). Of course, as long as no module registers handlers for a hook, running a run_fold won't have any effects. Similar is the case when a module registers handlers for some hook, but that hook is never run in the code. That won't have an effect either. The following is a self-contained example of a module which both runs and registers a few handlers for a completely new hook. The handlers are run sequentially using disparate priorities and passing over an accumulator value. One of the handlers stops the handler execution chain prematurely by returning {stop, NewVal} . It's also possible to try out what happens when the same hook is run with different XMPP domains by passing an argument to run_custom_hook/1 - we'll see that the handlers are registered for a particular domain only. At the end, you can see a printout of an accumulator with some debugging info. To cut the long story short: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 - module ( mod_hook_example ). - author ( \"bartek\" ). - behaviour ( gen_mod ). - include ( \"mongoose.hrl\" ). %% API - export ([ run_custom_hook / 1 ]). %% gen_mod callbacks - export ([ start / 2 , stop / 1 ]). %% Hook handlers - export ([ first_handler / 2 , stopping_handler / 2 , never_run_handler / 2 ]). start ( Host , _ Opts ) -> ejabberd_hooks : add ( custom_new_hook , Host , ? MODULE , first_handler , 25 ), ejabberd_hooks : add ( custom_new_hook , Host , ? MODULE , stopping_handler , 50 ), ejabberd_hooks : add ( custom_new_hook , Host , ? MODULE , never_run_handler , 75 ). stop ( Host ) -> ejabberd_hooks : delete ( custom_new_hook , Host , ? MODULE , first_handler , 25 ), ejabberd_hooks : delete ( custom_new_hook , Host , ? MODULE , stopping_handler , 50 ), ejabberd_hooks : delete ( custom_new_hook , Host , ? MODULE , never_run_handler , 75 ). run_custom_hook ( Host ) -> Acc = mongoose_acc : new (#{ location => ? LOCATION , lserver => Host , element => undefined }), Acc1 = mongoose_acc : set ( example , value , 5 , Acc ), ResultAcc = ejabberd_hooks : run_fold ( custom_new_hook , Host , Acc1 , [ 2 ]), ResultValue = mongoose_acc : get ( example , value , ResultAcc ), ? LOG_INFO (#{ what => hook_finished , result => ResultValue , result_acc => ResultAcc }). first_handler ( Acc , Number ) -> V0 = mongoose_acc : get ( example , value , Acc ), Result = V0 + Number , ? LOG_INFO (#{ what => first_handler , value => V0 , argument => Number , result => Result }), mongoose_acc : set ( example , value , Result , Acc ). stopping_handler ( Acc , Number ) -> V0 = mongoose_acc : get ( example , value , Acc ), Result = V0 + Number , ? LOG_INFO (#{ what => stopping_handler , value => V0 , argument => Number , result => Result }), { stop , mongoose_acc : set ( example , value , Result , Acc )}. never_run_handler ( Acc , Number ) -> ? LOG_INFO (#{ what => never_run_handler , text => << \"This hook won't run as it's registered with a priority bigger \" \"than that of stopping_handler/2 is. \" \"This text should never get printed.\" >> }), Acc * Number . The module is intended to be used from the shell for educational purposes: 1 2 3 4 5 6 7 8 9 10 11 12 13 ( mongooseim @ localhost ) 1 > gen_mod : is_loaded ( << \"localhost\" >> , mod_hook_example ). false ( mongooseim @ localhost ) 2 > gen_mod : start_module ( << \"localhost\" >> , mod_hook_example , [ no_opts ]). { ok , ok } ( mongooseim @ localhost ) 3 > gen_mod : is_loaded ( << \"localhost\" >> , mod_hook_example ). true ( mongooseim @ localhost ) 4 > mongoose_logs : set_module_loglevel ( mod_hook_example , info ). ok ( mongooseim @ localhost ) 5 > mod_hook_example : run_custom_hook ( << \"localhost\" >> ). when = 2020 - 12 - 02 T10 : 29 : 14 . 875981 + 00 : 00 level = error what = first_handler pid =< 0 . 2321 . 0 > at = mod_hook_example : first_handler / 2 : 40 value = 5 result = 7 argument = 2 when = 2020 - 12 - 02 T10 : 29 : 14 . 876248 + 00 : 00 level = error what = stopping_handler pid =< 0 . 2321 . 0 > at = mod_hook_example : stopping_handler / 2 : 46 value = 7 result = 9 argument = 2 ok when = 2020 - 12 - 02 T10 : 29 : 14 . 876453 + 00 : 00 level = error what = hook_finished pid =< 0 . 2321 . 0 > at = mod_hook_example : run_custom_hook / 1 : 35 result_acc_ { example , value } = 9 result_acc_timestamp = 1606904954871246 result_acc_stanza = undefined result_acc_ref = # Ref < 0 . 186499973 . 2771648514 . 42380 > result_acc_origin_stanza = undefined result_acc_origin_pid =< 0 . 2321 . 0 > result_acc_origin_location_mfa = { mod_hook_example , run_custom_hook , 1 } result_acc_origin_location_line = 31 result_acc_origin_location_file =/ Users / mikhailuvarov / erlang / esl / MongooseIM / src / mod_hook_example . erl result_acc_non_strippable = result_acc_mongoose_acc = true result_acc_lserver = localhost result = 9","title":"Hooks and Handlers"},{"location":"developers-guide/Hooks-and-handlers/#hooks-handlers-and-accumulators","text":"The hooks and handlers mechanism is one of the core architectural features of MongooseIM. It allows for loose coupling between components of the system by calling only those which are available and configured to be used at runtime. It can be thought of as a simple eventing mechanism notifying about certain things happening in the server. That results in an extensible system with pluggable extra functionality. To focus our attention, we'll analyze mod_offline which is responsible for storing messages for delivery to users unavailable at the time of sending. mod_offline is an implementation of XEP-0203: Delayed Delivery .","title":"Hooks, handlers and accumulators"},{"location":"developers-guide/Hooks-and-handlers/#running-a-hook","text":"","title":"Running a hook"},{"location":"developers-guide/Hooks-and-handlers/#basic-usage","text":"ejabberd_sm (ejabberd/MongooseIM session manager) is the module discovering whether the recipient of a message is available or not. That's where storing the message for later delivery takes place. It is possible, but not recommended, to save a message in an offline storage by calling mod_offline directly: 1 mod_offline : store_packet ( From , To , Packet ) Note that in this example ejabberd_sm is coupled with mod_offline . I.e. if mod_offline was not available, the code would simply crash; if it was misconfigured or turned off, the behaviour would be undefined. To avoid that coupling and also to enable other ( possibly yet to be written ) code to carry out some action at this particular moment, ejabberd_sm would instead call: 1 2 3 4 Acc1 = ejabberd_hooks : run_fold ( offline_message_hook , LServer , Acc , [ From , To , Packet ]) The extra level of indirection introduced by this call gives the flexibility to determine at runtime what code actually gets run at this point. offline_message_hook is just the name of the hook (in other words of the event that is being signalled); From , To and Packet are the arguments passed to the handler just as they would in case of the function being called directly; LServer is the XMPP domain for which this hook is signalled . Notice: For the clarity of the explanation of the hooks mechanism, the provided code snippets are not exactly taken from the current code. The reasons for it will be described later .","title":"Basic usage"},{"location":"developers-guide/Hooks-and-handlers/#getting-results-from-handlers","text":"Hook handlers are called by \"folding\". This means that each handler on a list is passed a set of arguments and an initial value that it then modifies, returns and hands over to the next handler in line. A simple example would look like this: 1 2 3 4 5 ListOfSomething = ejabberd_hooks : run_fold ( a_certain_hook , StateData #state.server , [], [ StateData #state.user , StateData #state.server ]) The initial value of the accumulator being passed through the sequence of handlers (in this case an empty list [] ) is inserted between the XMPP domain StateData#state.server and handler arguments. In between the XMPP domain ( StateData#state.server ) and handler arguments is the initial value of the accumulator being passed through the sequence of handlers is inserted - in this case an empty list ( [] ).","title":"Getting results from handlers"},{"location":"developers-guide/Hooks-and-handlers/#sidenote-folds","text":"If you haven't encountered the term fold before, think of it as reduce (like Array.reduce ) in Ruby-speak, roughly equivalent to the Reduce step in MapReduce, sometimes called accumulate , aggregate or compress . See Wikipedia for more.","title":"Sidenote: Folds"},{"location":"developers-guide/Hooks-and-handlers/#using-accumulators","text":"MongooseIM uses a dedicated data structure to accumulate data related to stanza processing (see \"Accumulators\" ). It is instantiated with an incoming stanza, passed along throughout the processing chain, supplied to and returned from certain hook calls, and terminated when stanza is leaving MongooseIM. If a Mongoose accumulator is passed to a hook, handlers should store their return values in one of 3 ways: If it is a one-off value which doesn't need to be passed on along with the accumulator (can be overwritten any time), use mongoose_acc:set(hook, result, Value, Acc) . If the value is to be passed on to be reused within the current processing context, use mongoose_acc:set(Namespace, Key, Value, Acc) . If the value should be passed on to the recipient's session, pubsub node etc. use mongoose_acc:set_permanent(Namespace, Key, Value, Acc) . A real life example, then, with regard to mod_offline is the resend_offline_messages_hook run in ejabberd_c2s : 1 2 3 4 5 Acc1 = ejabberd_hooks : run_fold ( resend_offline_messages_hook , StateData #state.server , Acc , [ StateData #state.user , StateData #state.server ]), Rs = mongoose_acc : get ( offline , messages , Acc1 , []),","title":"Using accumulators"},{"location":"developers-guide/Hooks-and-handlers/#sidenote-something-deprecated","text":"In the past you may have found some calls to ejabberd_hooks:run/3 in the MongooseIM source code. Under the hood it called the same handlers with ok as the initial accumulator. This is deprecated, and some day will be removed.","title":"Sidenote: something deprecated"},{"location":"developers-guide/Hooks-and-handlers/#error-handling-in-hooks","text":"Hooks are meant to decouple modules; in other words, the caller signals that some event took place or that it intends to use a certain feature or a set of features, but how and if those features are implemented is beyond its interest. For that reason hooks don't use the \"let it crash\" approach. Instead it is rather like \"fire-and-forget\", more similar in principle to the Pid ! signal way. In practical terms: if a handler throws an error the hook machine logs a message and proceeds to the next handler with an unmodified accumulator. If there are no handlers registered for a given hook, the run_fold call simply has no effect.","title":"Error handling in hooks"},{"location":"developers-guide/Hooks-and-handlers/#sidenote-code-yet-to-be-written","text":"Let's imagine, that when building a minimum viable product we settle on using mod_offline for delayed delivery of messages to unavailable clients. However, while the product evolves (or the relevant client software catches up) we might drop mod_offline in favour of a more sophisticated solution like Message Archive Management which would require a different action to be taken at the same point. Thanks to loose coupling and ejabberd_hooks it's possible to turn off mod_offline and turn on mod_mam without changing a single line of code in ejabberd_sm . The only required change is to the configuration (apart from deploying the new module) which can even be performed at runtime - without restarting the server.","title":"Sidenote: Code yet to be written"},{"location":"developers-guide/Hooks-and-handlers/#sidenote-multiple-domains","text":"A MongooseIM cluster may serve more than one domain at the same time. E.g. it is quite common that services like Multi User Chat or Publish-Subscribe are available as subdomains of the main XMPP domain served by an installation.","title":"Sidenote: Multiple Domains"},{"location":"developers-guide/Hooks-and-handlers/#registering-hook-handlers","text":"In order to store a packet when ejabberd_sm runs offline_message_hook the relevant module must register a handler for this hook. To attain the runtime configurability the module should register the handlers when it's loaded and unregister them when it's unloaded. That's usually done in, respectively, start/2 and stop/1 functions. Here is the relevant snippet from mod_offline:start/2 : 1 2 ejabberd_hooks : add ( offline_message_hook , Host , ? MODULE , store_packet , 50 ) It is clearly visible that the handler is added to the offline_message_hook . Host corresponds to the LServer used in the aforementioned call to the ejabberd_hooks:run_fold , i.e. it's the XMPP domain for which the handler is to be executed. The handler itself is specified as a module-function pair; the arity of the function is not specified at the registration nor verified when calling the handler. This may change in the future, but for now we recommend calling the hooks through the mongoose_hooks module and checking the arity there when writing a handler. If the handler expects an incorrect number of arguments it will simply crash. Multiple handlers may be registered for the same hook. The last argument, 50, is the sequence number of this handler in the handler chain. The higher the number, the later in the sequence the handler will be executed. It's reasonable to keep this number small (e.g. in the range 0-100), though there's no real limit other than the size of the integer type in the Erlang VM.","title":"Registering hook handlers"},{"location":"developers-guide/Hooks-and-handlers/#unregistering-handlers","text":"Pluggability also requires the components to be unpluggable at will. For that purpose there's the option to unregister a hook handler. It's done in mod_offline:stop/1 in a similar fashion to: 1 2 ejabberd_hooks : delete ( offline_message_hook , Host , ? MODULE , store_packet , 50 ) The arguments are exactly the same as passed to ejabberd_hooks:add/5 .","title":"Unregistering handlers"},{"location":"developers-guide/Hooks-and-handlers/#sidenote-metrics","text":"Every time a hook is run, a corresponding metric of the same name in the same host is incremented by one. There are some exceptions though as some metrics were implemented before the generic hook metrics. List of hooks not updating generic metrics can be found in the mongoose_metrics:filter_hook/1 function. Such skipped hooks update metrics defined in the mongoose_metrics_hooks module.","title":"Sidenote: Metrics"},{"location":"developers-guide/Hooks-and-handlers/#writing-handlers","text":"The signature of a handler has to follow three rules: Correct arity (the number of args passed to run_fold in mongoose_hooks + 1). The first arg is a mutable accumulator (may be mongoose_acc in particular). Returns an accumulator of the same type as the input one. Let's look at this example, from MongooseIM codebase: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 process_iq_get ( Acc , #jid { lserver = FromS } = From , To , #iq {} = IQ , _ ActiveList ) -> MUCHost = gen_mod : get_module_opt_subhost ( FromS , ? MODULE , default_host ()), case { mod_muc_light_codec_backend : decode ( From , To , IQ ), gen_mod : get_module_opt_by_subhost ( MUCHost , ? MODULE , blocking , ? DEFAULT_BLOCKING )} of {{ ok , { get , #blocking {} = Blocking }}, true } -> Items = mod_muc_light_db_backend : get_blocking ( jid : to_lus ( From ), MUCHost ), mod_muc_light_codec_backend : encode ( { get , Blocking #blocking { items = Items }}, From , jid : to_lus ( To ), fun (_, _, Packet ) -> put ( encode_res , Packet ) end ), #xmlel { children = ResponseChildren } = erase ( encode_res ), Result = { result , ResponseChildren }, { stop , mongoose_acc : set ( hook , result , Result , Acc )}; {{ ok , { get , #blocking {}}}, false } -> Result = { error , ? ERR_BAD_REQUEST }, { stop , mongoose_acc : set ( hook , result , Result , Acc )}; _ -> Result = { error , ? ERR_BAD_REQUEST }, mongoose_acc : set ( hook , result , Result , Acc ) end . As seen in this example, a handler receives an accumulator, puts some value into it and returns it for further processing. There's also one important feature to note: in some cases our handler returns a tuple {stop, Acc} . This skips calling the latter actions in the handler sequence, while the call to run_fold returns the Acc. If a handler returns just an atom stop , then all later actions are skipped and run_fold returns stopped . Watch out! Different handlers may be registered for the same hook - the priority mechanism orders their execution. If a handler returns stop but runs early in the handler chain, it may prevent some other handler from running at all! That might or might not be intentional. It may be especially surprising in case of handlers from different modules registered for the same hook. Always ensure what handlers are registered for a given hook ( grep is your friend) and that you understand their interdependencies.","title":"Writing handlers"},{"location":"developers-guide/Hooks-and-handlers/#hooks-list-and-how-to-extract-it","text":"The following command should give you a list of all the hooks available in MongooseIM: 1 2 3 4 5 6 7 8 $ find src/ -name '*.erl' -print | xargs ./tools/find-hooks.awk \\ > | sort | uniq adhoc_local_commands adhoc_local_items ... ... ... webadmin_user_parse_query Refer to grep / ack to find where they're used. Here are the contents of find-hooks.awk : 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 #!/usr/bin/env awk -f BEGIN { RS = \")\" ORS = \"\" FS = \"[ (,]\" } $ 0 ~ /ejabberd_hooks:run/ { found = - 1 for ( i = 1 ; i < NF ; i ++ ) { if ( $ i ~ /ejabberd_hooks:run/ ) { found = i } } if ( found != - 1 && $ ( found + 1 ) != \"\" && $ ( found + 1 ) ~ /^[a-z]/ ) print $ ( found + 1 ) \"\\n\" }","title":"Hooks list and how to extract it"},{"location":"developers-guide/Hooks-and-handlers/#creating-your-own-hooks","text":"There's no special function or any setup necessary to create a new hook. The only thing that needs to be done is calling ejabberd_hooks:run_fold/4 with the name of the new hook and relevant arguments. However, if you want static code analysis, you should put the new hook inside mongoose_hooks with a correct type specification. We've added this module to provide some security and type checking in places where the hooks are run. This is the way all hooks are called in MongooseIM (see the examples in the hooks description ). Of course, as long as no module registers handlers for a hook, running a run_fold won't have any effects. Similar is the case when a module registers handlers for some hook, but that hook is never run in the code. That won't have an effect either. The following is a self-contained example of a module which both runs and registers a few handlers for a completely new hook. The handlers are run sequentially using disparate priorities and passing over an accumulator value. One of the handlers stops the handler execution chain prematurely by returning {stop, NewVal} . It's also possible to try out what happens when the same hook is run with different XMPP domains by passing an argument to run_custom_hook/1 - we'll see that the handlers are registered for a particular domain only. At the end, you can see a printout of an accumulator with some debugging info. To cut the long story short: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 - module ( mod_hook_example ). - author ( \"bartek\" ). - behaviour ( gen_mod ). - include ( \"mongoose.hrl\" ). %% API - export ([ run_custom_hook / 1 ]). %% gen_mod callbacks - export ([ start / 2 , stop / 1 ]). %% Hook handlers - export ([ first_handler / 2 , stopping_handler / 2 , never_run_handler / 2 ]). start ( Host , _ Opts ) -> ejabberd_hooks : add ( custom_new_hook , Host , ? MODULE , first_handler , 25 ), ejabberd_hooks : add ( custom_new_hook , Host , ? MODULE , stopping_handler , 50 ), ejabberd_hooks : add ( custom_new_hook , Host , ? MODULE , never_run_handler , 75 ). stop ( Host ) -> ejabberd_hooks : delete ( custom_new_hook , Host , ? MODULE , first_handler , 25 ), ejabberd_hooks : delete ( custom_new_hook , Host , ? MODULE , stopping_handler , 50 ), ejabberd_hooks : delete ( custom_new_hook , Host , ? MODULE , never_run_handler , 75 ). run_custom_hook ( Host ) -> Acc = mongoose_acc : new (#{ location => ? LOCATION , lserver => Host , element => undefined }), Acc1 = mongoose_acc : set ( example , value , 5 , Acc ), ResultAcc = ejabberd_hooks : run_fold ( custom_new_hook , Host , Acc1 , [ 2 ]), ResultValue = mongoose_acc : get ( example , value , ResultAcc ), ? LOG_INFO (#{ what => hook_finished , result => ResultValue , result_acc => ResultAcc }). first_handler ( Acc , Number ) -> V0 = mongoose_acc : get ( example , value , Acc ), Result = V0 + Number , ? LOG_INFO (#{ what => first_handler , value => V0 , argument => Number , result => Result }), mongoose_acc : set ( example , value , Result , Acc ). stopping_handler ( Acc , Number ) -> V0 = mongoose_acc : get ( example , value , Acc ), Result = V0 + Number , ? LOG_INFO (#{ what => stopping_handler , value => V0 , argument => Number , result => Result }), { stop , mongoose_acc : set ( example , value , Result , Acc )}. never_run_handler ( Acc , Number ) -> ? LOG_INFO (#{ what => never_run_handler , text => << \"This hook won't run as it's registered with a priority bigger \" \"than that of stopping_handler/2 is. \" \"This text should never get printed.\" >> }), Acc * Number . The module is intended to be used from the shell for educational purposes: 1 2 3 4 5 6 7 8 9 10 11 12 13 ( mongooseim @ localhost ) 1 > gen_mod : is_loaded ( << \"localhost\" >> , mod_hook_example ). false ( mongooseim @ localhost ) 2 > gen_mod : start_module ( << \"localhost\" >> , mod_hook_example , [ no_opts ]). { ok , ok } ( mongooseim @ localhost ) 3 > gen_mod : is_loaded ( << \"localhost\" >> , mod_hook_example ). true ( mongooseim @ localhost ) 4 > mongoose_logs : set_module_loglevel ( mod_hook_example , info ). ok ( mongooseim @ localhost ) 5 > mod_hook_example : run_custom_hook ( << \"localhost\" >> ). when = 2020 - 12 - 02 T10 : 29 : 14 . 875981 + 00 : 00 level = error what = first_handler pid =< 0 . 2321 . 0 > at = mod_hook_example : first_handler / 2 : 40 value = 5 result = 7 argument = 2 when = 2020 - 12 - 02 T10 : 29 : 14 . 876248 + 00 : 00 level = error what = stopping_handler pid =< 0 . 2321 . 0 > at = mod_hook_example : stopping_handler / 2 : 46 value = 7 result = 9 argument = 2 ok when = 2020 - 12 - 02 T10 : 29 : 14 . 876453 + 00 : 00 level = error what = hook_finished pid =< 0 . 2321 . 0 > at = mod_hook_example : run_custom_hook / 1 : 35 result_acc_ { example , value } = 9 result_acc_timestamp = 1606904954871246 result_acc_stanza = undefined result_acc_ref = # Ref < 0 . 186499973 . 2771648514 . 42380 > result_acc_origin_stanza = undefined result_acc_origin_pid =< 0 . 2321 . 0 > result_acc_origin_location_mfa = { mod_hook_example , run_custom_hook , 1 } result_acc_origin_location_line = 31 result_acc_origin_location_file =/ Users / mikhailuvarov / erlang / esl / MongooseIM / src / mod_hook_example . erl result_acc_non_strippable = result_acc_mongoose_acc = true result_acc_lserver = localhost result = 9","title":"Creating your own hooks"},{"location":"developers-guide/OpenSSL-and-FIPS/","text":"OpenSSL FIPS Support for OpenSSL FIPS was added to MongooseIM in version 1.7.0. Incompatibilities Currently known incompatible features are: SASL auth mechanism DIGEST-MD5: due to a forbidden MD5 hash function in FIPS mode. Requirements Build Erlang/OTP with FIPS support Make sure the option --enable-fips is specified for configure command. If you want to use a different OpenSSL than the default one, specify the option --with-ssl=PATH_TO_YOUR_OPENSSL as well. Here's an example of a command for building Erlang/OTP with kerl: 1 KERL_CONFIGURE_OPTIONS = \"--enable-fips\" ./kerl build 21 .3 21 .3-fips Building MongooseIM with a custom OpenSSL If you want to use a custom OpenSSL, please export the CFLAGS and LDFLAGS env vars pointing to a FIPS compliant OpenSSL before running ./rebar3 compile or make rel . 1 2 3 4 5 OPENSSL_LIB = ~/openssl/lib #put your path here OPENSSL_INC = ~/openssl/inc #put your path here export LDFLAGS = \"-Wl,-rpath= $OPENSSL_LIB -L $OPENSSL_LIB \" export CFLAGS = \"-I $OPENSSL_INC \" How to enable/disable FIPS mode Find etc/app.config in the release directory. FIPS mode is an option of the crypto application. In order to enable/disable it, add the following section to app.config : 1 { crypto , [{ fips_mode , Value }]}, where Value is either true or false . How to check if the FIPS mode is enabled Log message When MongooseIM starts, it prints the following log message if FIPS mode is enabled 1 2015-02-25 14:30:54.501 [warning] <0.242.0>@mongoose_fips:do_notify:37 FIPS mode enabled Run-time check Run the following function in the MongooseIM console: 1 mongoose_fips : status (). The function returns: not_enabled - fips_mode is not set to true in etc/app.config enabled - fips_mode is set to true in etc/app.config not_supported - erlang compiled without fips support Cipher suites difference A test using a cipher_suites_test.sh script (available in the tools directory) can be performed on MongooseIM with FIPS mode enabled and disabled. We've used OpenSSL 1.0.1j-fips . Here are all the cipher suites available when the FIPS mode is enabled (the list may vary for different openssl versions): ECDHE-RSA-AES256-SHA DHE-RSA-AES256-SHA AES256-SHA ECDHE-RSA-DES-CBC3-SHA EDH-RSA-DES-CBC3-SHA DES-CBC3-SHA ECDHE-RSA-AES128-SHA DHE-RSA-AES128-SHA AES128-SHA Here are all the cipher suites available when the FIPS mode is disabled (the list may vary for different openssl versions): ECDHE-RSA-AES256-SHA DHE-RSA-AES256-SHA DHE-RSA-CAMELLIA256-SHA AES256-SHA CAMELLIA256-SHA ECDHE-RSA-DES-CBC3-SHA EDH-RSA-DES-CBC3-SHA DES-CBC3-SHA ECDHE-RSA-AES128-SHA DHE-RSA-AES128-SHA DHE-RSA-SEED-SHA DHE-RSA-CAMELLIA128-SHA AES128-SHA SEED-SHA CAMELLIA128-SHA ECDHE-RSA-RC4-SHA RC4-SHA RC4-MD5","title":"FIPS mode"},{"location":"developers-guide/OpenSSL-and-FIPS/#openssl-fips","text":"Support for OpenSSL FIPS was added to MongooseIM in version 1.7.0.","title":"OpenSSL FIPS"},{"location":"developers-guide/OpenSSL-and-FIPS/#incompatibilities","text":"Currently known incompatible features are: SASL auth mechanism DIGEST-MD5: due to a forbidden MD5 hash function in FIPS mode.","title":"Incompatibilities"},{"location":"developers-guide/OpenSSL-and-FIPS/#requirements","text":"","title":"Requirements"},{"location":"developers-guide/OpenSSL-and-FIPS/#build-erlangotp-with-fips-support","text":"Make sure the option --enable-fips is specified for configure command. If you want to use a different OpenSSL than the default one, specify the option --with-ssl=PATH_TO_YOUR_OPENSSL as well. Here's an example of a command for building Erlang/OTP with kerl: 1 KERL_CONFIGURE_OPTIONS = \"--enable-fips\" ./kerl build 21 .3 21 .3-fips","title":"Build Erlang/OTP with FIPS support"},{"location":"developers-guide/OpenSSL-and-FIPS/#building-mongooseim-with-a-custom-openssl","text":"If you want to use a custom OpenSSL, please export the CFLAGS and LDFLAGS env vars pointing to a FIPS compliant OpenSSL before running ./rebar3 compile or make rel . 1 2 3 4 5 OPENSSL_LIB = ~/openssl/lib #put your path here OPENSSL_INC = ~/openssl/inc #put your path here export LDFLAGS = \"-Wl,-rpath= $OPENSSL_LIB -L $OPENSSL_LIB \" export CFLAGS = \"-I $OPENSSL_INC \"","title":"Building MongooseIM with a custom OpenSSL"},{"location":"developers-guide/OpenSSL-and-FIPS/#how-to-enabledisable-fips-mode","text":"Find etc/app.config in the release directory. FIPS mode is an option of the crypto application. In order to enable/disable it, add the following section to app.config : 1 { crypto , [{ fips_mode , Value }]}, where Value is either true or false .","title":"How to enable/disable FIPS mode"},{"location":"developers-guide/OpenSSL-and-FIPS/#how-to-check-if-the-fips-mode-is-enabled","text":"","title":"How to check if the FIPS mode is enabled"},{"location":"developers-guide/OpenSSL-and-FIPS/#log-message","text":"When MongooseIM starts, it prints the following log message if FIPS mode is enabled 1 2015-02-25 14:30:54.501 [warning] <0.242.0>@mongoose_fips:do_notify:37 FIPS mode enabled","title":"Log message"},{"location":"developers-guide/OpenSSL-and-FIPS/#run-time-check","text":"Run the following function in the MongooseIM console: 1 mongoose_fips : status (). The function returns: not_enabled - fips_mode is not set to true in etc/app.config enabled - fips_mode is set to true in etc/app.config not_supported - erlang compiled without fips support","title":"Run-time check"},{"location":"developers-guide/OpenSSL-and-FIPS/#cipher-suites-difference","text":"A test using a cipher_suites_test.sh script (available in the tools directory) can be performed on MongooseIM with FIPS mode enabled and disabled. We've used OpenSSL 1.0.1j-fips . Here are all the cipher suites available when the FIPS mode is enabled (the list may vary for different openssl versions): ECDHE-RSA-AES256-SHA DHE-RSA-AES256-SHA AES256-SHA ECDHE-RSA-DES-CBC3-SHA EDH-RSA-DES-CBC3-SHA DES-CBC3-SHA ECDHE-RSA-AES128-SHA DHE-RSA-AES128-SHA AES128-SHA Here are all the cipher suites available when the FIPS mode is disabled (the list may vary for different openssl versions): ECDHE-RSA-AES256-SHA DHE-RSA-AES256-SHA DHE-RSA-CAMELLIA256-SHA AES256-SHA CAMELLIA256-SHA ECDHE-RSA-DES-CBC3-SHA EDH-RSA-DES-CBC3-SHA DES-CBC3-SHA ECDHE-RSA-AES128-SHA DHE-RSA-AES128-SHA DHE-RSA-SEED-SHA DHE-RSA-CAMELLIA128-SHA AES128-SHA SEED-SHA CAMELLIA128-SHA ECDHE-RSA-RC4-SHA RC4-SHA RC4-MD5","title":"Cipher suites difference"},{"location":"developers-guide/SCRAM-serialization/","text":"Overview This document describes the SCRAM serialization format used by MongooseIM. Developers can use this information to create advanced endpoints for ejabberd_auth_http or enable other software to read (i.e. share) the user authentication data. Format description ==MULTI_SCRAM==,<iteration count>,===SHA1===<salt>|<stored key>|<server key>,==SHA224==<salt>|<stored key>|<server key>,==SHA256==<salt>|<stored key>|<server key>,==SHA384==<salt>|<stored key>|<server key>,==SHA512=<salt>|<stored key>|<server key> <iteration count> - Iteration Count formatted as a human-readable integer <salt> - Base64-encoded Salt <stored key> - Base64-encoded Stored Key <server key> - Base64-encoded Server Key The SCRAM format can vary depending on the SHA algorithms that are used for SCRAM. Salt and iteration count is common for different SHA types. Stored Key and Server Key are specific to a given SHA and are following a SHA prefix that is indicating which SHA they belong to. In order to learn more about the meaning of the Stored Key, Server Key, Salt and Iteration Count, please check the SCRAM specification . Example Password: padthai Erlang map: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 #{ iteration_count => 4096 , sha => #{ salt => << \"QClQsw/sfPEnwj4AEp6E1w==\" >> , server_key => << \"EJvxXWM42tO7BgW21lNZyBc1dD0=\" >> , stored_key => << \"ys1104hRhqMoRputBY5sLHKXoSw=\" >> }, sha224 => #{ salt => << \"dk0ImXFVPoUfqD5FveV7YA==\" >> , server_key => << \"EvE2EkZcUb3k4CooeOcVFy95P32t+NDX0xbQUA==\" >> , stored_key => << \"G0ibQ/YYuCtoun4I+1IF2zJ7Q8x2T23ETnq5Gg==\" >> }, sha256 => #{ salt => << \"M7BYKSo04XbzBr4C7b056g==\" >> , server_key => << \"XhtGFf6NDWsnVSCO4xkzPD3qc046fPL0pATZi7RmaWo=\" >> , stored_key => << \"A779MC05nSGQln5no0hKTGHFSaQ7oguKBZgORW3s+es=\" >> }, sha384 => #{ salt => << \"Ryu0fA29gbwgqFOBk5Mczw==\" >> , server_key => << \"kR+LMI/E0QBG3oF405/MTAT6NAlCOfPrFOaWH3WBVGM0Viu9Brk6kGwVwXjSP8v0\" >> , stored_key => << \"k3QwC0Lb1y1/V/31byC5KML5t3mH4JTPjFyeAz7lV2l4SPfzi3JHvLEdoNB5K/VY\" >> }, sha512 => #{ salt => << \"SLNuVNcWiNBmnYZNIdj+zg==\" >> , server_key => << \"jUUDbuQ9ae4UnAWS6RV6W4yifX3La3ESjfZjGol+TBROIb/ihR8UawPHrSHkp4yyDJXtRhR9RlHCHy4bcCm1Yg==\" >> , stored_key => << \"3ey3gzSsmbxcLnoc1VKCR/739uKX6uuPCyAzn6x8o87ibcjOdUaU8qhL5X4MUI9UPTt667GagNpVTmAWTFNsjA==\" >> }} Serialized password: 1 2 3 4 5 6 ==MULTI_SCRAM==,4096, ===SHA1===QClQsw/sfPEnwj4AEp6E1w==|ys1104hRhqMoRputBY5sLHKXoSw=|EJvxXWM42tO7BgW21lNZyBc1dD0=, ==SHA224==dk0ImXFVPoUfqD5FveV7YA==|G0ibQ/YYuCtoun4I+1IF2zJ7Q8x2T23ETnq5Gg==|EvE2EkZcUb3k4CooeOcVFy95P32t+NDX0xbQUA==, ==SHA256==M7BYKSo04XbzBr4C7b056g==|A779MC05nSGQln5no0hKTGHFSaQ7oguKBZgORW3s+es=|XhtGFf6NDWsnVSCO4xkzPD3qc046fPL0pATZi7RmaWo=, ==SHA384==Ryu0fA29gbwgqFOBk5Mczw==|k3QwC0Lb1y1/V/31byC5KML5t3mH4JTPjFyeAz7lV2l4SPfzi3JHvLEdoNB5K/VY|kR+LMI/E0QBG3oF405/MTAT6NAlCOfPrFOaWH3WBVGM0Viu9Brk6kGwVwXjSP8v0, ==SHA512==SLNuVNcWiNBmnYZNIdj+zg==|3ey3gzSsmbxcLnoc1VKCR/739uKX6uuPCyAzn6x8o87ibcjOdUaU8qhL5X4MUI9UPTt667GagNpVTmAWTFNsjA==|jUUDbuQ9ae4UnAWS6RV6W4yifX3La3ESjfZjGol+TBROIb/ihR8UawPHrSHkp4yyDJXtRhR9RlHCHy4bcCm1Yg== Legacy format description MongooseIM installations older or equal to 3.6.2 were supporting only SHA-1 as a hashing algorithm for SCRAM. The SCRAM format that was used can be seen below. ==SCRAM==,<stored key>,<server key>,<salt>,<iteration count> <stored key> - Base64-encoded Stored Key <server key> - Base64-encoded Server Key <salt> - Base64-encoded Salt <iteration count> - Iteration Count formatted as a human-readable integer In order to learn more about the meaning of the Stored Key, Server Key, Salt and Iteration Count, please check the SCRAM specification . Example Password: misio Erlang record: #scram{ storedkey = <<\"tmi5IE+9pceRV/jkPLFHEaVY33c=\">>, serverkey = <<\"MiWNa8T3dniVDwmh77ufJ41fpAQ=\">>, salt = <<\"inKXODlSY5y5SCsLxibi0w==\">>, iterationcount = 4096 } Serialized password: ==SCRAM==,tmi5IE+9pceRV/jkPLFHEaVY33c=,MiWNa8T3dniVDwmh77ufJ41fpAQ=,inKXODlSY5y5SCsLxibi0w==,4096","title":"SCRAM serialization format"},{"location":"developers-guide/SCRAM-serialization/#overview","text":"This document describes the SCRAM serialization format used by MongooseIM. Developers can use this information to create advanced endpoints for ejabberd_auth_http or enable other software to read (i.e. share) the user authentication data.","title":"Overview"},{"location":"developers-guide/SCRAM-serialization/#format-description","text":"==MULTI_SCRAM==,<iteration count>,===SHA1===<salt>|<stored key>|<server key>,==SHA224==<salt>|<stored key>|<server key>,==SHA256==<salt>|<stored key>|<server key>,==SHA384==<salt>|<stored key>|<server key>,==SHA512=<salt>|<stored key>|<server key> <iteration count> - Iteration Count formatted as a human-readable integer <salt> - Base64-encoded Salt <stored key> - Base64-encoded Stored Key <server key> - Base64-encoded Server Key The SCRAM format can vary depending on the SHA algorithms that are used for SCRAM. Salt and iteration count is common for different SHA types. Stored Key and Server Key are specific to a given SHA and are following a SHA prefix that is indicating which SHA they belong to. In order to learn more about the meaning of the Stored Key, Server Key, Salt and Iteration Count, please check the SCRAM specification .","title":"Format description"},{"location":"developers-guide/SCRAM-serialization/#example","text":"Password: padthai Erlang map: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 #{ iteration_count => 4096 , sha => #{ salt => << \"QClQsw/sfPEnwj4AEp6E1w==\" >> , server_key => << \"EJvxXWM42tO7BgW21lNZyBc1dD0=\" >> , stored_key => << \"ys1104hRhqMoRputBY5sLHKXoSw=\" >> }, sha224 => #{ salt => << \"dk0ImXFVPoUfqD5FveV7YA==\" >> , server_key => << \"EvE2EkZcUb3k4CooeOcVFy95P32t+NDX0xbQUA==\" >> , stored_key => << \"G0ibQ/YYuCtoun4I+1IF2zJ7Q8x2T23ETnq5Gg==\" >> }, sha256 => #{ salt => << \"M7BYKSo04XbzBr4C7b056g==\" >> , server_key => << \"XhtGFf6NDWsnVSCO4xkzPD3qc046fPL0pATZi7RmaWo=\" >> , stored_key => << \"A779MC05nSGQln5no0hKTGHFSaQ7oguKBZgORW3s+es=\" >> }, sha384 => #{ salt => << \"Ryu0fA29gbwgqFOBk5Mczw==\" >> , server_key => << \"kR+LMI/E0QBG3oF405/MTAT6NAlCOfPrFOaWH3WBVGM0Viu9Brk6kGwVwXjSP8v0\" >> , stored_key => << \"k3QwC0Lb1y1/V/31byC5KML5t3mH4JTPjFyeAz7lV2l4SPfzi3JHvLEdoNB5K/VY\" >> }, sha512 => #{ salt => << \"SLNuVNcWiNBmnYZNIdj+zg==\" >> , server_key => << \"jUUDbuQ9ae4UnAWS6RV6W4yifX3La3ESjfZjGol+TBROIb/ihR8UawPHrSHkp4yyDJXtRhR9RlHCHy4bcCm1Yg==\" >> , stored_key => << \"3ey3gzSsmbxcLnoc1VKCR/739uKX6uuPCyAzn6x8o87ibcjOdUaU8qhL5X4MUI9UPTt667GagNpVTmAWTFNsjA==\" >> }} Serialized password: 1 2 3 4 5 6 ==MULTI_SCRAM==,4096, ===SHA1===QClQsw/sfPEnwj4AEp6E1w==|ys1104hRhqMoRputBY5sLHKXoSw=|EJvxXWM42tO7BgW21lNZyBc1dD0=, ==SHA224==dk0ImXFVPoUfqD5FveV7YA==|G0ibQ/YYuCtoun4I+1IF2zJ7Q8x2T23ETnq5Gg==|EvE2EkZcUb3k4CooeOcVFy95P32t+NDX0xbQUA==, ==SHA256==M7BYKSo04XbzBr4C7b056g==|A779MC05nSGQln5no0hKTGHFSaQ7oguKBZgORW3s+es=|XhtGFf6NDWsnVSCO4xkzPD3qc046fPL0pATZi7RmaWo=, ==SHA384==Ryu0fA29gbwgqFOBk5Mczw==|k3QwC0Lb1y1/V/31byC5KML5t3mH4JTPjFyeAz7lV2l4SPfzi3JHvLEdoNB5K/VY|kR+LMI/E0QBG3oF405/MTAT6NAlCOfPrFOaWH3WBVGM0Viu9Brk6kGwVwXjSP8v0, ==SHA512==SLNuVNcWiNBmnYZNIdj+zg==|3ey3gzSsmbxcLnoc1VKCR/739uKX6uuPCyAzn6x8o87ibcjOdUaU8qhL5X4MUI9UPTt667GagNpVTmAWTFNsjA==|jUUDbuQ9ae4UnAWS6RV6W4yifX3La3ESjfZjGol+TBROIb/ihR8UawPHrSHkp4yyDJXtRhR9RlHCHy4bcCm1Yg==","title":"Example"},{"location":"developers-guide/SCRAM-serialization/#legacy-format-description","text":"MongooseIM installations older or equal to 3.6.2 were supporting only SHA-1 as a hashing algorithm for SCRAM. The SCRAM format that was used can be seen below. ==SCRAM==,<stored key>,<server key>,<salt>,<iteration count> <stored key> - Base64-encoded Stored Key <server key> - Base64-encoded Server Key <salt> - Base64-encoded Salt <iteration count> - Iteration Count formatted as a human-readable integer In order to learn more about the meaning of the Stored Key, Server Key, Salt and Iteration Count, please check the SCRAM specification .","title":"Legacy format description"},{"location":"developers-guide/SCRAM-serialization/#example_1","text":"Password: misio Erlang record: #scram{ storedkey = <<\"tmi5IE+9pceRV/jkPLFHEaVY33c=\">>, serverkey = <<\"MiWNa8T3dniVDwmh77ufJ41fpAQ=\">>, salt = <<\"inKXODlSY5y5SCsLxibi0w==\">>, iterationcount = 4096 } Serialized password: ==SCRAM==,tmi5IE+9pceRV/jkPLFHEaVY33c=,MiWNa8T3dniVDwmh77ufJ41fpAQ=,inKXODlSY5y5SCsLxibi0w==,4096","title":"Example"},{"location":"developers-guide/Stanza-routing/","text":"Route of a message through the system Let's examine the flow of a message sent from user A to user B, both of whom are served by the same domain. Note that hooks are called at various stages of routing - they perform many tasks, in fact, many MongooseIM functionalities are implemented through hooks & handlers. For a general introduction to hooks, see Hooks and Handlers ; to get a closer look at a core few, see the hooks description . 1. Receiving the stanza User A's ejabberd_receiver receives the stanza and passes it to ejabberd_c2s . 2. Call to user_send_packet Upon some minimal validation of the stanza, a hook user_send_packet is called. This is handled by a couple of modules which subscribe to this hook. Those modules do various complementary tasks, like storing the message in an archive, sending carbon copies, etc. 3. Privacy lists and ejabberd_router:route/3 The stanza is checked against any privacy lists in use and, in the case of being allowed, it will be routed by ejabberd_router:route/3 . This also takes into account \"blocking commands\", which are part of the privacy system. 4. Chain of routing Further on, the behaviour is configurable: ejabberd_router:route/3 passes the stanza through a chain of routing modules and applies Mod:filter/3 and Mod:route/3 from each of them. Each of those modules has to implement xmpp_router behaviour. There are a few actions available to the module: it can drop or route the stanza, it can pass the stanza on unchanged or modify it and pass the result on. A set of routing modules can be set in configuration as routing_modules . The default behaviour is the following: mongoose_router_global : runs a global filter_packet hook mongoose_router_external_local : checks if there is an external component registered for the destination domain on the current node, possibly routes the stanza to it mongoose_router_external : checks if there is an external component registered for the destination domain on any node in the cluster, possibly routes the stanza to it mongoose_router_localdomain : checks if there is a local route registered for the destination domain (i.e. there is an entry in mnesia route table), possibly routes the stanza to it ejabberd_s2s : tries to find or establish a connection to another server and send the stanza there 5. Look up external_component and route An external component and a local route are obtained by looking up external_component and route mnesia tables, respectively. The items stored in the tables provide funs to call and MFs to apply: 1 2 3 4 5 6 ( ejabberd @ localhost ) 2 > ets : tab2list ( route ). [{ route , << \"vjud.localhost\" >> , { apply_fun , # Fun < ejabberd_router . 2 . 123745223 > }}, { route , << \"muc.localhost\" >> , { apply_fun , # Fun < mod_muc . 2 . 63726579 > }}, { route , << \"localhost\" >> ,{ apply , ejabberd_local , route }}] Here we see that for a domain \"localhost\" ejabberd_local:route() is called. Routing the stanza there means calling mongoose_local_delivery:do_route/5 , which calls filter_local_packet hook and, if passed, runs the fun or applies the handler. In most cases, the handler is ejabberd_local:route/3 . 6. ejabberd_local to ejabberd_sm ejabberd_local routes the stanza to ejabberd_sm given it has at least a bare JID as the recipient. 7. ejabberd_sm ejabberd_sm determines the available resources of User B, takes into account their priorities and whether the message is addressed to a particular resource or a bare JID. It appropriately replicates (or not) the message and sends it to the recipient's ejabberd_c2s process(es). In case no resources are available for delivery (hence no ejabberd_c2s processes to pass the message to), offline_message_hook is run. 8. ejabberd_c2s ejabberd_c2s verifies the stanza against relevant privacy lists and sends it to the socket. user_receive_packet hook is run to notify the rest of the system about the stanza delivery to User B.","title":"Stanza routing"},{"location":"developers-guide/Stanza-routing/#route-of-a-message-through-the-system","text":"Let's examine the flow of a message sent from user A to user B, both of whom are served by the same domain. Note that hooks are called at various stages of routing - they perform many tasks, in fact, many MongooseIM functionalities are implemented through hooks & handlers. For a general introduction to hooks, see Hooks and Handlers ; to get a closer look at a core few, see the hooks description .","title":"Route of a message through the system"},{"location":"developers-guide/Stanza-routing/#1-receiving-the-stanza","text":"User A's ejabberd_receiver receives the stanza and passes it to ejabberd_c2s .","title":"1. Receiving the stanza"},{"location":"developers-guide/Stanza-routing/#2-call-to-user_send_packet","text":"Upon some minimal validation of the stanza, a hook user_send_packet is called. This is handled by a couple of modules which subscribe to this hook. Those modules do various complementary tasks, like storing the message in an archive, sending carbon copies, etc.","title":"2. Call to user_send_packet"},{"location":"developers-guide/Stanza-routing/#3-privacy-lists-and-ejabberd_routerroute3","text":"The stanza is checked against any privacy lists in use and, in the case of being allowed, it will be routed by ejabberd_router:route/3 . This also takes into account \"blocking commands\", which are part of the privacy system.","title":"3. Privacy lists and ejabberd_router:route/3"},{"location":"developers-guide/Stanza-routing/#4-chain-of-routing","text":"Further on, the behaviour is configurable: ejabberd_router:route/3 passes the stanza through a chain of routing modules and applies Mod:filter/3 and Mod:route/3 from each of them. Each of those modules has to implement xmpp_router behaviour. There are a few actions available to the module: it can drop or route the stanza, it can pass the stanza on unchanged or modify it and pass the result on. A set of routing modules can be set in configuration as routing_modules . The default behaviour is the following: mongoose_router_global : runs a global filter_packet hook mongoose_router_external_local : checks if there is an external component registered for the destination domain on the current node, possibly routes the stanza to it mongoose_router_external : checks if there is an external component registered for the destination domain on any node in the cluster, possibly routes the stanza to it mongoose_router_localdomain : checks if there is a local route registered for the destination domain (i.e. there is an entry in mnesia route table), possibly routes the stanza to it ejabberd_s2s : tries to find or establish a connection to another server and send the stanza there","title":"4. Chain of routing"},{"location":"developers-guide/Stanza-routing/#5-look-up-external_component-and-route","text":"An external component and a local route are obtained by looking up external_component and route mnesia tables, respectively. The items stored in the tables provide funs to call and MFs to apply: 1 2 3 4 5 6 ( ejabberd @ localhost ) 2 > ets : tab2list ( route ). [{ route , << \"vjud.localhost\" >> , { apply_fun , # Fun < ejabberd_router . 2 . 123745223 > }}, { route , << \"muc.localhost\" >> , { apply_fun , # Fun < mod_muc . 2 . 63726579 > }}, { route , << \"localhost\" >> ,{ apply , ejabberd_local , route }}] Here we see that for a domain \"localhost\" ejabberd_local:route() is called. Routing the stanza there means calling mongoose_local_delivery:do_route/5 , which calls filter_local_packet hook and, if passed, runs the fun or applies the handler. In most cases, the handler is ejabberd_local:route/3 .","title":"5. Look up external_component and route"},{"location":"developers-guide/Stanza-routing/#6-ejabberd_local-to-ejabberd_sm","text":"ejabberd_local routes the stanza to ejabberd_sm given it has at least a bare JID as the recipient.","title":"6. ejabberd_local to ejabberd_sm"},{"location":"developers-guide/Stanza-routing/#7-ejabberd_sm","text":"ejabberd_sm determines the available resources of User B, takes into account their priorities and whether the message is addressed to a particular resource or a bare JID. It appropriately replicates (or not) the message and sends it to the recipient's ejabberd_c2s process(es). In case no resources are available for delivery (hence no ejabberd_c2s processes to pass the message to), offline_message_hook is run.","title":"7. ejabberd_sm"},{"location":"developers-guide/Stanza-routing/#8-ejabberd_c2s","text":"ejabberd_c2s verifies the stanza against relevant privacy lists and sends it to the socket. user_receive_packet hook is run to notify the rest of the system about the stanza delivery to User B.","title":"8. ejabberd_c2s"},{"location":"developers-guide/Testing-MongooseIM/","text":"Test runner The test runner script is used to compile MongooseIM and run tests. Requirements Docker Docker must be installed on the local system, and the user executing the tests must have privileges to start new containers (usually achieved by adding the user to the docker group). FreeTDS for MSSQL connectivity MongooseIM requires FreeTDS in order to connect to MSSQL container. Please install the driver: 1 2 3 4 5 6 7 8 # Ubuntu $ sudo apt install freetds-dev tdsodbc # CentOS $ sudo yum install freetds # macOS $ brew install freetds In case you are using an operating system different from Ubuntu or MacOS or have a custom FreeTDS installation, you may have to modify the tools/travis-setup-db.sh script to use the proper paths. Find a configuration block starting with [mongoose-mssql] and change the Driver and Setup . For example, for CentOS change them to /usr/lib64/libtdsodbc.so.0 and /usr/lib64/libtdsS.so respectively. How to print the instructions The help command prints a list of supported options. 1 ./tools/test-runner.sh --help Test runner examples Usage example: 1 ./tools/test-runner.sh --db redis --preset internal_mnesia The command runs both big (feature) and small (unit) tests. To view more examples, run: 1 ./tools/test-runner.sh --examples Test runner completion Test runner supports shell TAB completion. To enable completion in bash or zsh, run: 1 source tools/test-runner-complete.sh To view completion examples, run: 1 ./tools/test-runner.sh --examples-complete Viewing test reports To view test execution results, run: 1 2 ./tools/test-runner.sh --show-big-reports ./tools/test-runner.sh --show-small-reports Rerun big tests Very often we want to restart a specific suite when some test failed. For example, some test has failed in mam_SUITE . The command was used to execute tests: 1 ./tools/test-runner.sh --skip-small-tests --db pgqsl --preset pgsql_mnesia --skip-stop-nodes --skip-stop-nodes is optional here, because if any big test fails, then nodes would be still running. We can just execute the same command, but it would rebuild nodes and start them. The command can be used instead: 1 ./tools/test-runner.sh --rerun-big-tests -- mam --rerun-big-tests expands into --skip-small-tests --skip-setup-db --dev-nodes --test-hosts --skip-cover --skip-preset . And mam is used to run mam_SUITE suite only. Debugging big tests database This command opens MySQL shell interface: 1 ./tools/open-test-database-shell.sh mysql This command opens PgSQL shell interface: 1 ./tools/open-test-database-shell.sh pgsql This command opens MSSQL shell interface : 1 ./tools/open-test-database-shell.sh mssql You can use this command to execute SQL queries directly. It's useful when designing new SQL queries. Unit tests (a.k.a. \"small tests\") These test suites are aimed at testing various modules and libraries standalone, without launching a MongooseIM instance. They are very useful for developing/debugging libraries. The test suites are located in test/ directory. To run all of them, use ./rebar3 ct ; to run just a selected suite, use ./rebar3 ct --suite test/my_selected_SUITE . Rebar recompiles all the code automatically, there is no need for a separate compilation step. If all the tests pass, you will get no output and summary log will be available in ct.log . If any of the tests fail the summary log is printed to stdout. Detailed test results in a nice HTML format are saved in 1 _build/test/logs/ct_run.[something][datetime]/ Unit test running example using test runner: 1 2 3 4 5 6 7 8 # Run all small tests, show progress ./tools/test-runner.sh --skip-big-tests --verbose # Run sha_SUITE without cover ./tools/test-runner.sh --skip-big-tests --skip-cover -- sha # Run the 'general' group in config_parser_SUITE, show progress ./tools/test-runner.sh --skip-big-tests --verbose -- config_parser:general End-to-end tests (a.k.a. \"big tests\") Using test runner Most important options are preset and database: 1 2 3 4 5 6 7 # Runs privacy_SUITE and private_SUITE with PostgreSQL ./tools/test-runner.sh --skip-small-tests --db pgsql --preset pgsql_mnesia -- privacy private # Runs rdbms_SUITE with MSSQL # Initialises a single MongooseIM node (works for some tests only) # Disables cover ./tools/test-runner.sh --skip-small-tests --db mssql --preset odbc_mssql_mnesia --test-hosts mim --dev-nodes mim1 --skip-cover -- rdbms TL;DR You can also run the tests \"by hand\", instead of using the test runner. In shell #1: 1 2 3 cd $MONGOOSEIM ./rebar3 compile make devrel In shell #2: 1 2 cd $MONGOOSEIM /_build/mim1/rel/mongooseim ./bin/mongooseimctl live In shell #3: 1 2 cd $MONGOOSEIM /_build/mim2/rel/mongooseim ./bin/mongooseimctl live In shell #4: 1 2 cd $MONGOOSEIM /_build/mim3/rel/mongooseim ./bin/mongooseimctl live In shell #5: 1 2 cd $MONGOOSEIM /_build/fed1/rel/mongooseim ./bin/mongooseimctl live In shell #6: 1 2 cd $MONGOOSEIM /_build/reg1/rel/mongooseim ./bin/mongooseimctl live Back to shell #1: 1 2 cd big_tests/ make quicktest Wait for the tests to finish and celebrate (or wallow in despair and grief)! One-liner alternative for tmux users: 1 2 3 4 5 6 7 8 9 10 11 12 13 ./rebar3 compile make devrel tmux new-window -n mim1 '_build/mim1/rel/mongooseim/bin/mongooseimctl live' tmux new-window -n mim2 '_build/mim2/rel/mongooseim/bin/mongooseimctl live' tmux new-window -n mim3 '_build/mim3/rel/mongooseim/bin/mongooseimctl live' tmux new-window -n fed1 '_build/fed1/rel/mongooseim/bin/mongooseimctl live' tmux new-window -n reg1 '_build/fed1/rel/mongooseim/bin/mongooseimctl live' _build/mim1/rel/mongooseim/bin/mongooseimctl started _build/mim2/rel/mongooseim/bin/mongooseimctl started _build/mim3/rel/mongooseim/bin/mongooseimctl started _build/fed1/rel/mongooseim/bin/mongooseimctl started _build/reg1/rel/mongooseim/bin/mongooseimctl started make -C big_tests quicktest Start a new tmux and paste the commands. Step-by-step breakdown make devrel builds four server nodes, preconfigured for a wide range of features covered by end-to-end tests. $MONGOOSEIM/_build/mim1/rel , for most test SUITEs $MONGOOSEIM/_build/mim*/rel , in order to test cluster-related commands;; $MONGOOSEIM/_build/fed1/rel , in order to test XMPP federation (server to server communication, S2S). $MONGOOSEIM/_build/reg1/rel , in order to test global distribution feature. In general, running a server in the interactive mode (i.e. mongooseimctl live ) is not required to test it, but it's convenient as any warnings and errors can be spotted in real time. It's also easy to inspect the server state or trace execution (e.g. using dbg ) in case of anything going wrong in some of the tests. To run the server in the background instead of the interactive mode, use mongooseimctl start && mongooseimctl started . The quicktest configuration is a relatively comprehensive one, giving good overview of what does and what doesn't work in the system, without repeating tests. Why would we want to ever repeat the tests? In order to test different backends of the same parts of the system. E.g. a message archive might store messages in MySQL/PostgreSQL or Riak KV - the glue code between the XMPP logic module and database is different in each case, therefore repeating the same tests with different databases is necessary to guarantee a truthful code coverage measurement. Testing a feature in development / TDD The whole suite takes a significant amount of time to complete. When you develop a new feature, the speed of iterating is crucial to maintain the flow (who doesn't like the feeling?!) and not lose focus. In $MONGOOSEIM/big_tests/ we have: 1 2 3 4 5 6 7 8 $ tree big_tests/ -L 1 -F big_tests/ \u251c\u2500\u2500 Makefile \u251c\u2500\u2500 README.md \u251c\u2500\u2500 default.spec \u251c\u2500\u2500 test.config \u251c\u2500\u2500 tests/ \u2514\u2500\u2500 ... tests/ is where the test suites reside. *.config files are the suite configuration files - they contain predefined XMPP client specifications, server addresses and XMPP domains to use, and options required by test support libraries (i.e. Escalus ). *.spec files are the test specifications - they define the configuration file to use, the suites, test groups or individual test cases to run or skip, and some less important things. default.spec is the default when running make quicktest , but it can be overridden with a TESTSPEC variable: 1 2 3 # make sure we're in $MONGOOSEIM/big_tests/ cd $MONGOOSEIM /big_tests/ make quicktest TESTSPEC = my-feature.spec To speed up the development cycle, developers usually create a .spec file for each feature (or each project, if you're cloning away) and only enable the suites / test groups they are working on. The allows testing only the parts of the system that are actually being changed. It's worth running default.spec once in a while to check for regressions. Consult the default.spec file to see how to run only selected tests/groups/cases. If you're sure that none of the test dependencies have changed, and you only edited the test suites and/or MongooseIM code, it's possible to speed up the tests by skipping the Rebar dependency and compilation checks by providing PREPARE= (i.e. an empty value): 1 make quicktest PREPARE = Consult the big_tests/Makefile to see how it works. Applying code changes When working on a feature or a bug fix you often modify the code and check if it works as expected. In order to change the code on dev nodes that are already generated ( mim* and fed* ) recompile the code for a specific node. For example, to update the code on mim1 node all you have to do is: 1 ./rebar3 as mim1 compile A similar command applies to other nodes, the important thing being rebar3's profile. When the above command finishes, the code can be reloaded on the server by either reloading changed module(s) in the node's shell, e.g. l(mongoose_riak) , or restarting the node. Reading test reports When finished, the test engine writes detailed html reports into a directory: 1 big_tests/ct_report/ct_run.[gobbledygook][datetime]/ Each run is saved into a new directory. This snippet: 1 2 3 4 5 #!/bin/bash lst = $( ls -rt ct_report | grep ct_run | tail -n 1 ) rm ct_report/lastrun ln -s $lst ct_report/lastrun can be of some help. Checking coverage If you want to check how much of the code is covered by tests, run: 1 make cover_quicktest Note: You need all the mim nodes (mim1, mim2 and mim3) up and running, even if you only run some of the tests. If any of the nodes is down, the test will crash. This command will recompile and reload the code on dev nodes with coverage enabled and run test suites as defined in the spec. Coverage statistics will be available in big_tests/ct_report/cover.html and coverage subdirectory. Advanced topics There are many more options available. One of them is sequentially testing a number of preset configurations - we do it every day on CircleCI, testing MongooseIM with various OTP versions and database backends. Altogether, we have eight preset configuration. If you want to dig deeper, consult .circleci/config.yml , .github/workflows/ci.yml and tools/travis-test.sh , everything we do is there. Gathering test reports from tests If you test your MongooseIM fork on Travis or other CI provider, you might want to access test reports (which also include node logs and crash dumps) that are created by the test runner. Uploading reports to S3 Our script uses AWS CLI to upload test results to an S3 bucket. Simply set relevant environment variables in your repository settings (at least AWS_ACCESS_KEY_ID and AWS_SECRET_ACCESS_KEY have to be set), and enjoy test reports landing straight into your bucket ( AWS_BUCKET variable should store the bucket's name). Uploading reports to Google Drive To store test results in Google Drive you need to create a new project and obtain service account credentials . You must also add Google Drive API to your project - to do this, navigate to APIs & Services in your project console and find & add Google Drive API in the Library tab. Once downloaded, encode the credentials file with base64 (e.g. cat serviceCreds.json | base64 ) and use the result as GDRIVE_SERVICE_ACCOUNT_CREDENTIALS environment variable in your repository settings. Saving reports on your personal account The uploaded files will belong to the project that you created, i.e. will not be immediately visible from your personal Google Drive UI. To be able to upload files to your personal account, you can share the reports' directory with the project account. First, note the ID of the project's user that you created to gain the service account credentials (e.g. test-123@fair-smile-123456.iam.gserviceaccount.com ). You can see this on the Service Accounts tab of the project console . Now, create a directory on your Google Drive that will serve as the test root directory. Go into the directory's sharing options and paste in the project's user ID, granting it write access. Click to expand the advanced sharing options and note the ID of the shared directory that's displayed in the share link (e.g. if the link is https://drive.google.com/drive/folders/1234567890abcdef?usp=sharing , the directory's ID is 1234567890abcdef ). Finally, set GDRIVE_PARENT_DIR environment variable of your build to the directory ID that you noted in the previous step. Load testing Alongside CI, we do also CLT (Continuous Load Testing). We have our own load testing infrastructure, called Tide, which is triggered after every successful test run, and gives us a feedback on changes to MongooseIM performance. Test results are publicly available on the Hello Tide! page.","title":"Testing MongooseIM"},{"location":"developers-guide/Testing-MongooseIM/#test-runner","text":"The test runner script is used to compile MongooseIM and run tests.","title":"Test runner"},{"location":"developers-guide/Testing-MongooseIM/#requirements","text":"","title":"Requirements"},{"location":"developers-guide/Testing-MongooseIM/#docker","text":"Docker must be installed on the local system, and the user executing the tests must have privileges to start new containers (usually achieved by adding the user to the docker group).","title":"Docker"},{"location":"developers-guide/Testing-MongooseIM/#freetds-for-mssql-connectivity","text":"MongooseIM requires FreeTDS in order to connect to MSSQL container. Please install the driver: 1 2 3 4 5 6 7 8 # Ubuntu $ sudo apt install freetds-dev tdsodbc # CentOS $ sudo yum install freetds # macOS $ brew install freetds In case you are using an operating system different from Ubuntu or MacOS or have a custom FreeTDS installation, you may have to modify the tools/travis-setup-db.sh script to use the proper paths. Find a configuration block starting with [mongoose-mssql] and change the Driver and Setup . For example, for CentOS change them to /usr/lib64/libtdsodbc.so.0 and /usr/lib64/libtdsS.so respectively.","title":"FreeTDS for MSSQL connectivity"},{"location":"developers-guide/Testing-MongooseIM/#how-to-print-the-instructions","text":"The help command prints a list of supported options. 1 ./tools/test-runner.sh --help","title":"How to print the instructions"},{"location":"developers-guide/Testing-MongooseIM/#test-runner-examples","text":"Usage example: 1 ./tools/test-runner.sh --db redis --preset internal_mnesia The command runs both big (feature) and small (unit) tests. To view more examples, run: 1 ./tools/test-runner.sh --examples","title":"Test runner examples"},{"location":"developers-guide/Testing-MongooseIM/#test-runner-completion","text":"Test runner supports shell TAB completion. To enable completion in bash or zsh, run: 1 source tools/test-runner-complete.sh To view completion examples, run: 1 ./tools/test-runner.sh --examples-complete","title":"Test runner completion"},{"location":"developers-guide/Testing-MongooseIM/#viewing-test-reports","text":"To view test execution results, run: 1 2 ./tools/test-runner.sh --show-big-reports ./tools/test-runner.sh --show-small-reports","title":"Viewing test reports"},{"location":"developers-guide/Testing-MongooseIM/#rerun-big-tests","text":"Very often we want to restart a specific suite when some test failed. For example, some test has failed in mam_SUITE . The command was used to execute tests: 1 ./tools/test-runner.sh --skip-small-tests --db pgqsl --preset pgsql_mnesia --skip-stop-nodes --skip-stop-nodes is optional here, because if any big test fails, then nodes would be still running. We can just execute the same command, but it would rebuild nodes and start them. The command can be used instead: 1 ./tools/test-runner.sh --rerun-big-tests -- mam --rerun-big-tests expands into --skip-small-tests --skip-setup-db --dev-nodes --test-hosts --skip-cover --skip-preset . And mam is used to run mam_SUITE suite only.","title":"Rerun big tests"},{"location":"developers-guide/Testing-MongooseIM/#debugging-big-tests-database","text":"This command opens MySQL shell interface: 1 ./tools/open-test-database-shell.sh mysql This command opens PgSQL shell interface: 1 ./tools/open-test-database-shell.sh pgsql This command opens MSSQL shell interface : 1 ./tools/open-test-database-shell.sh mssql You can use this command to execute SQL queries directly. It's useful when designing new SQL queries.","title":"Debugging big tests database"},{"location":"developers-guide/Testing-MongooseIM/#unit-tests-aka-small-tests","text":"These test suites are aimed at testing various modules and libraries standalone, without launching a MongooseIM instance. They are very useful for developing/debugging libraries. The test suites are located in test/ directory. To run all of them, use ./rebar3 ct ; to run just a selected suite, use ./rebar3 ct --suite test/my_selected_SUITE . Rebar recompiles all the code automatically, there is no need for a separate compilation step. If all the tests pass, you will get no output and summary log will be available in ct.log . If any of the tests fail the summary log is printed to stdout. Detailed test results in a nice HTML format are saved in 1 _build/test/logs/ct_run.[something][datetime]/ Unit test running example using test runner: 1 2 3 4 5 6 7 8 # Run all small tests, show progress ./tools/test-runner.sh --skip-big-tests --verbose # Run sha_SUITE without cover ./tools/test-runner.sh --skip-big-tests --skip-cover -- sha # Run the 'general' group in config_parser_SUITE, show progress ./tools/test-runner.sh --skip-big-tests --verbose -- config_parser:general","title":"Unit tests (a.k.a. \"small tests\")"},{"location":"developers-guide/Testing-MongooseIM/#end-to-end-tests-aka-big-tests","text":"","title":"End-to-end tests (a.k.a. \"big tests\")"},{"location":"developers-guide/Testing-MongooseIM/#using-test-runner","text":"Most important options are preset and database: 1 2 3 4 5 6 7 # Runs privacy_SUITE and private_SUITE with PostgreSQL ./tools/test-runner.sh --skip-small-tests --db pgsql --preset pgsql_mnesia -- privacy private # Runs rdbms_SUITE with MSSQL # Initialises a single MongooseIM node (works for some tests only) # Disables cover ./tools/test-runner.sh --skip-small-tests --db mssql --preset odbc_mssql_mnesia --test-hosts mim --dev-nodes mim1 --skip-cover -- rdbms","title":"Using test runner"},{"location":"developers-guide/Testing-MongooseIM/#tldr","text":"You can also run the tests \"by hand\", instead of using the test runner. In shell #1: 1 2 3 cd $MONGOOSEIM ./rebar3 compile make devrel In shell #2: 1 2 cd $MONGOOSEIM /_build/mim1/rel/mongooseim ./bin/mongooseimctl live In shell #3: 1 2 cd $MONGOOSEIM /_build/mim2/rel/mongooseim ./bin/mongooseimctl live In shell #4: 1 2 cd $MONGOOSEIM /_build/mim3/rel/mongooseim ./bin/mongooseimctl live In shell #5: 1 2 cd $MONGOOSEIM /_build/fed1/rel/mongooseim ./bin/mongooseimctl live In shell #6: 1 2 cd $MONGOOSEIM /_build/reg1/rel/mongooseim ./bin/mongooseimctl live Back to shell #1: 1 2 cd big_tests/ make quicktest Wait for the tests to finish and celebrate (or wallow in despair and grief)! One-liner alternative for tmux users: 1 2 3 4 5 6 7 8 9 10 11 12 13 ./rebar3 compile make devrel tmux new-window -n mim1 '_build/mim1/rel/mongooseim/bin/mongooseimctl live' tmux new-window -n mim2 '_build/mim2/rel/mongooseim/bin/mongooseimctl live' tmux new-window -n mim3 '_build/mim3/rel/mongooseim/bin/mongooseimctl live' tmux new-window -n fed1 '_build/fed1/rel/mongooseim/bin/mongooseimctl live' tmux new-window -n reg1 '_build/fed1/rel/mongooseim/bin/mongooseimctl live' _build/mim1/rel/mongooseim/bin/mongooseimctl started _build/mim2/rel/mongooseim/bin/mongooseimctl started _build/mim3/rel/mongooseim/bin/mongooseimctl started _build/fed1/rel/mongooseim/bin/mongooseimctl started _build/reg1/rel/mongooseim/bin/mongooseimctl started make -C big_tests quicktest Start a new tmux and paste the commands.","title":"TL;DR"},{"location":"developers-guide/Testing-MongooseIM/#step-by-step-breakdown","text":"make devrel builds four server nodes, preconfigured for a wide range of features covered by end-to-end tests. $MONGOOSEIM/_build/mim1/rel , for most test SUITEs $MONGOOSEIM/_build/mim*/rel , in order to test cluster-related commands;; $MONGOOSEIM/_build/fed1/rel , in order to test XMPP federation (server to server communication, S2S). $MONGOOSEIM/_build/reg1/rel , in order to test global distribution feature. In general, running a server in the interactive mode (i.e. mongooseimctl live ) is not required to test it, but it's convenient as any warnings and errors can be spotted in real time. It's also easy to inspect the server state or trace execution (e.g. using dbg ) in case of anything going wrong in some of the tests. To run the server in the background instead of the interactive mode, use mongooseimctl start && mongooseimctl started . The quicktest configuration is a relatively comprehensive one, giving good overview of what does and what doesn't work in the system, without repeating tests. Why would we want to ever repeat the tests? In order to test different backends of the same parts of the system. E.g. a message archive might store messages in MySQL/PostgreSQL or Riak KV - the glue code between the XMPP logic module and database is different in each case, therefore repeating the same tests with different databases is necessary to guarantee a truthful code coverage measurement.","title":"Step-by-step breakdown"},{"location":"developers-guide/Testing-MongooseIM/#testing-a-feature-in-development-tdd","text":"The whole suite takes a significant amount of time to complete. When you develop a new feature, the speed of iterating is crucial to maintain the flow (who doesn't like the feeling?!) and not lose focus. In $MONGOOSEIM/big_tests/ we have: 1 2 3 4 5 6 7 8 $ tree big_tests/ -L 1 -F big_tests/ \u251c\u2500\u2500 Makefile \u251c\u2500\u2500 README.md \u251c\u2500\u2500 default.spec \u251c\u2500\u2500 test.config \u251c\u2500\u2500 tests/ \u2514\u2500\u2500 ... tests/ is where the test suites reside. *.config files are the suite configuration files - they contain predefined XMPP client specifications, server addresses and XMPP domains to use, and options required by test support libraries (i.e. Escalus ). *.spec files are the test specifications - they define the configuration file to use, the suites, test groups or individual test cases to run or skip, and some less important things. default.spec is the default when running make quicktest , but it can be overridden with a TESTSPEC variable: 1 2 3 # make sure we're in $MONGOOSEIM/big_tests/ cd $MONGOOSEIM /big_tests/ make quicktest TESTSPEC = my-feature.spec To speed up the development cycle, developers usually create a .spec file for each feature (or each project, if you're cloning away) and only enable the suites / test groups they are working on. The allows testing only the parts of the system that are actually being changed. It's worth running default.spec once in a while to check for regressions. Consult the default.spec file to see how to run only selected tests/groups/cases. If you're sure that none of the test dependencies have changed, and you only edited the test suites and/or MongooseIM code, it's possible to speed up the tests by skipping the Rebar dependency and compilation checks by providing PREPARE= (i.e. an empty value): 1 make quicktest PREPARE = Consult the big_tests/Makefile to see how it works.","title":"Testing a feature in development / TDD"},{"location":"developers-guide/Testing-MongooseIM/#applying-code-changes","text":"When working on a feature or a bug fix you often modify the code and check if it works as expected. In order to change the code on dev nodes that are already generated ( mim* and fed* ) recompile the code for a specific node. For example, to update the code on mim1 node all you have to do is: 1 ./rebar3 as mim1 compile A similar command applies to other nodes, the important thing being rebar3's profile. When the above command finishes, the code can be reloaded on the server by either reloading changed module(s) in the node's shell, e.g. l(mongoose_riak) , or restarting the node.","title":"Applying code changes"},{"location":"developers-guide/Testing-MongooseIM/#reading-test-reports","text":"When finished, the test engine writes detailed html reports into a directory: 1 big_tests/ct_report/ct_run.[gobbledygook][datetime]/ Each run is saved into a new directory. This snippet: 1 2 3 4 5 #!/bin/bash lst = $( ls -rt ct_report | grep ct_run | tail -n 1 ) rm ct_report/lastrun ln -s $lst ct_report/lastrun can be of some help.","title":"Reading test reports"},{"location":"developers-guide/Testing-MongooseIM/#checking-coverage","text":"If you want to check how much of the code is covered by tests, run: 1 make cover_quicktest Note: You need all the mim nodes (mim1, mim2 and mim3) up and running, even if you only run some of the tests. If any of the nodes is down, the test will crash. This command will recompile and reload the code on dev nodes with coverage enabled and run test suites as defined in the spec. Coverage statistics will be available in big_tests/ct_report/cover.html and coverage subdirectory.","title":"Checking coverage"},{"location":"developers-guide/Testing-MongooseIM/#advanced-topics","text":"There are many more options available. One of them is sequentially testing a number of preset configurations - we do it every day on CircleCI, testing MongooseIM with various OTP versions and database backends. Altogether, we have eight preset configuration. If you want to dig deeper, consult .circleci/config.yml , .github/workflows/ci.yml and tools/travis-test.sh , everything we do is there.","title":"Advanced topics"},{"location":"developers-guide/Testing-MongooseIM/#gathering-test-reports-from-tests","text":"If you test your MongooseIM fork on Travis or other CI provider, you might want to access test reports (which also include node logs and crash dumps) that are created by the test runner.","title":"Gathering test reports from tests"},{"location":"developers-guide/Testing-MongooseIM/#uploading-reports-to-s3","text":"Our script uses AWS CLI to upload test results to an S3 bucket. Simply set relevant environment variables in your repository settings (at least AWS_ACCESS_KEY_ID and AWS_SECRET_ACCESS_KEY have to be set), and enjoy test reports landing straight into your bucket ( AWS_BUCKET variable should store the bucket's name).","title":"Uploading reports to S3"},{"location":"developers-guide/Testing-MongooseIM/#uploading-reports-to-google-drive","text":"To store test results in Google Drive you need to create a new project and obtain service account credentials . You must also add Google Drive API to your project - to do this, navigate to APIs & Services in your project console and find & add Google Drive API in the Library tab. Once downloaded, encode the credentials file with base64 (e.g. cat serviceCreds.json | base64 ) and use the result as GDRIVE_SERVICE_ACCOUNT_CREDENTIALS environment variable in your repository settings.","title":"Uploading reports to Google Drive"},{"location":"developers-guide/Testing-MongooseIM/#saving-reports-on-your-personal-account","text":"The uploaded files will belong to the project that you created, i.e. will not be immediately visible from your personal Google Drive UI. To be able to upload files to your personal account, you can share the reports' directory with the project account. First, note the ID of the project's user that you created to gain the service account credentials (e.g. test-123@fair-smile-123456.iam.gserviceaccount.com ). You can see this on the Service Accounts tab of the project console . Now, create a directory on your Google Drive that will serve as the test root directory. Go into the directory's sharing options and paste in the project's user ID, granting it write access. Click to expand the advanced sharing options and note the ID of the shared directory that's displayed in the share link (e.g. if the link is https://drive.google.com/drive/folders/1234567890abcdef?usp=sharing , the directory's ID is 1234567890abcdef ). Finally, set GDRIVE_PARENT_DIR environment variable of your build to the directory ID that you noted in the previous step.","title":"Saving reports on your personal account"},{"location":"developers-guide/Testing-MongooseIM/#load-testing","text":"Alongside CI, we do also CLT (Continuous Load Testing). We have our own load testing infrastructure, called Tide, which is triggered after every successful test run, and gives us a feedback on changes to MongooseIM performance. Test results are publicly available on the Hello Tide! page.","title":"Load testing"},{"location":"developers-guide/accumulators/","text":"Accumulators XMPP stanza processing starts in the ejabberd_c2s module, which receives the stanza from a socket, or in ejabberd_s2s_in which receives stanzas from federated XMPP clusters. The stanza is processed and eventually it and/or other messages are sent out, either to the original sender, to another c2s process within the same MongooseIM installation, or to another XMPP server. At the beginning of the main processing chain an accumulator is created containing following set of keys: ref - A unique reference of the acc, useful for tracing. timestamp - An Erlang timestamp retrieved from os:timestamp() . origin_pid - A PID of the process that created the accumulator. origin_location - {Module, Function Line} - A place in the code where the accumulator was created. origin_stanza - Original stanza that triggered the processing (in a binary). lserver - Nameprepped domain of the processing context. stanza - A map with information about the stanza being routed. May be missing in some processing chains (when they are not triggered by a stanza)! element - exml:element() with the current stanza being routed. from_jid , to_jid - jid:jid() with the sender and the recipient. name - A name of the top-level element in element . type - A value of type attribute of the top-level element. If the attribute is missing, this field contains undefined . ref - A reference of routed stanza. It is then passed through all the stages until it reaches the end of its life. Throughout the process it is the very same accumulator; it is therefore possible to store a value in it on one stage of the processing and retrieve the same value later on. The main assumption is that whatever MongooseIM does, it is always triggered by a stanza entering the system, with some exceptions, such as a couple of mongooseimctl operations, which create stanza-less accumulators. The stanza should always be packed into an accumulator and passed on, so that internally every action is performed the same way. There are three main benefits from this approach: Performance - if we need to do something involving inspecting a stanza or more complicated operations (e.g. privacy check) we don't need to do it multiple times on various stages of processing - instead we can do it once and store the result in an accumulator. Debugging - it is now very easy to produce an exact track record of a stanza. Simplified implementation of modules which inherently involve multi-stage processing (e.g. mod_amp ). API mongoose_acc module exports t() type which is the accumulator type. new(new_acc_params()) A constructor for accumulators. new_acc_params() is a map with following supported keys: location - Should be a {Module, Function, Line} tuple (may be constructed with ?LOCATION macro from mongoose.hrl ). Its format is not enforced by the acc logic but Dialyzer will most probably complain about any other type. lserver - Nameprepped domain of a the processing context. element (optional) - If present, it will be used as a source for the stanza map. from_jid , to_jid (optional) - Values used to override from and to attributes of the element , respectively. If element is provided, the sender and recipient JIDs are extracted, either from the element itself, or from to_jid and from_jid parameters. The call will fail with an exception if it's not possible. While allowed, stanza-less accumulators usage should be avoided. Getters for predefined fields ref(t()) timestamp(t()) lserver(t()) element(t()) stanza_name(t()) - Returns name value from stanza map. stanza_type(t()) - Returns type value from stanza map. stanza_ref(t()) - Returns ref value from stanza map. This is not the same as ref(t()) ! update_stanza(stanza_params(), t()) Replaces the whole stanza field in accumulator with params provided in stanza_params() , which is a map of 3 fields: element , from_jid , to_jid . The same rules apply as in the case of constructor ( new/1 ) but this time element field is mandatory . Access to namespaced fields It is possible to store and retrieve any data in the accumulator, that is related to the processing. There is no scope protection, so every module may access all namespaces and keys inside them. set(Namespace :: any(), Key :: any(), Value :: any(), t()) set_permanent(Namespace :: any(), Key :: any(), Value :: any(), t()) - Upserts a field, which won't be removed during strip operation. append(Namespace :: any(), Key :: any(), Value :: any(), t()) - In order to use this function, a Namespace:Key field must not exist or must be a list. Value is appended to the end of this list. If Value is a list, then a OldValue ++ Value operation is performed. In other cases OldValue ++ [Value] is used. get(Namespace :: any(), Key :: any(), t()) - Returns a value of a specified field. Will crash if the NS:Key is not found. get(Namespace :: any(), Key :: any(), Default :: any(), t()) - Returns a value of a specified field or Default if NS:Key is not found. delete(Namespace :: any(), Key :: any(), t()) - Removes a specified field, no matter if it is permanent or not. Stripping Accumulator is used mostly to cache values for reuse within a c2s process; when it goes out to somewhere else, it is stripped of all unnecessary attributes except for: ref timestamp origin_pid origin_location origin_stanza non_strippable - A set of permanent NS:Key pairs. If you want it to carry some additional values along with it, please use a dedicated api for setting \"permanent\" fields: 1 Acc2 = mongoose_acc : set_permanent ( myns , myprop , 123 , Acc1 ), Permanent fields may be retrieved with ordinary get/3,4 functions. The rationale behind stripping an accumulator is that some values stored in it are context-dependend. For example, at the beginning lserver refers to the host of the sender C2S. When an accumulator goes to the c2s of the recipient, the lserver attribute may change. There are also many cached values which are not valid anymore when user changes (e.g. privacy checks). In order to strip an accumulator, please use strip(strip_params(), t()) , where strip_params() is a map of: lserver - New host context. Obviously, may be equal to the old value. element , from_jid , to_jid - The same rules apply as in update_stanza/2 . Main principles of an accumulator processing An accumulator is created when a stanza enters the server. An XML stanza is never passed around as a pure exml:element() . An accumulator is stripped when it is passed to a different context (e.g. another c2s process). If a process produces more stanzas to be routed, they must reuse original acc but with stanza replaced with update_stanza/2 . Hooks Many of the MongooseIM functionalities are implemented in submodules which attach their handlers to hooks (this is covered in detail in \"Hooks and handlers\" . When it comes to the accumulators, the following rules apply: If a hook is related to stanza processing and is executed with run_fold , a Mongoose accumulator should be provided. A hook handler may modify an accumulator in every permitted way (i.e. shouldn't directly modify acc fields, bypassing mongoose_acc API) and should return the execution result in the hook:result field. This is not enforced but should be followed by convention. Avoid passing superfluous arguments to handlers - e.g. an LServer in hook args is redundant since it is already present in the accumulator. Do not use run - it is still present in API but executes run_fold with ok as an initial accumulator anyway. Handlers have been rewritten so that they accept an acc as the first arg. Note that run is deprecated now and at some point will be removed. Most handlers have already been modified so that they accept an instance of mongoose_acc:t() as the first argument and return value by storing it inside it. How the accumulator is used within a module is up to the implementors of the module. IQs and accumulators mongoose_iq module exposes a dedicated API for accessing IQ-related accumulator fields. These are: info(Acc) - Returns a #iq{} record produced from a stanza stored in the accumulator. May be invalid or not_iq if the stanza is not a valid IQ. xmlns(Acc) - Returns XMLNS of the first subelement inside an IQ. In most cases it is a namespace of <query/> subelement. May be undefined . command(Acc) - Returns the name of a first subelement inside an IQ. May be undefined . These functions ensure that cached information matches the accumulator's stanza, so all of them return a tuple with a possibly updated acc as a second element. Sample usage, actual and potential Privacy check Stanzas are often checked against privacy lists. According to the current mongoose_privacy:privacy_check_packet implementation, the result is stored in an accumulator so if a check has to be repeated it is just one map read. Tracing origin_stanza field is fully immutable for the lifespan of a single accumulator, so it's easier to correlate one of the stanzas sent by a client with some \"unexpected\" stanza routed from a completely different part of a server. There are many places in the server, where an accumulator may be created, so origin_location makes it much easier to find out what event has triggered the processing. Performance measurement Given that each accumulator has a timestamp denoting its creation time, it is now very easy to implement a metric showing the stanza processing time, or even multiple metrics splitting it into stages.","title":"Accumulators"},{"location":"developers-guide/accumulators/#accumulators","text":"XMPP stanza processing starts in the ejabberd_c2s module, which receives the stanza from a socket, or in ejabberd_s2s_in which receives stanzas from federated XMPP clusters. The stanza is processed and eventually it and/or other messages are sent out, either to the original sender, to another c2s process within the same MongooseIM installation, or to another XMPP server. At the beginning of the main processing chain an accumulator is created containing following set of keys: ref - A unique reference of the acc, useful for tracing. timestamp - An Erlang timestamp retrieved from os:timestamp() . origin_pid - A PID of the process that created the accumulator. origin_location - {Module, Function Line} - A place in the code where the accumulator was created. origin_stanza - Original stanza that triggered the processing (in a binary). lserver - Nameprepped domain of the processing context. stanza - A map with information about the stanza being routed. May be missing in some processing chains (when they are not triggered by a stanza)! element - exml:element() with the current stanza being routed. from_jid , to_jid - jid:jid() with the sender and the recipient. name - A name of the top-level element in element . type - A value of type attribute of the top-level element. If the attribute is missing, this field contains undefined . ref - A reference of routed stanza. It is then passed through all the stages until it reaches the end of its life. Throughout the process it is the very same accumulator; it is therefore possible to store a value in it on one stage of the processing and retrieve the same value later on. The main assumption is that whatever MongooseIM does, it is always triggered by a stanza entering the system, with some exceptions, such as a couple of mongooseimctl operations, which create stanza-less accumulators. The stanza should always be packed into an accumulator and passed on, so that internally every action is performed the same way. There are three main benefits from this approach: Performance - if we need to do something involving inspecting a stanza or more complicated operations (e.g. privacy check) we don't need to do it multiple times on various stages of processing - instead we can do it once and store the result in an accumulator. Debugging - it is now very easy to produce an exact track record of a stanza. Simplified implementation of modules which inherently involve multi-stage processing (e.g. mod_amp ).","title":"Accumulators"},{"location":"developers-guide/accumulators/#api","text":"mongoose_acc module exports t() type which is the accumulator type.","title":"API"},{"location":"developers-guide/accumulators/#newnew_acc_params","text":"A constructor for accumulators. new_acc_params() is a map with following supported keys: location - Should be a {Module, Function, Line} tuple (may be constructed with ?LOCATION macro from mongoose.hrl ). Its format is not enforced by the acc logic but Dialyzer will most probably complain about any other type. lserver - Nameprepped domain of a the processing context. element (optional) - If present, it will be used as a source for the stanza map. from_jid , to_jid (optional) - Values used to override from and to attributes of the element , respectively. If element is provided, the sender and recipient JIDs are extracted, either from the element itself, or from to_jid and from_jid parameters. The call will fail with an exception if it's not possible. While allowed, stanza-less accumulators usage should be avoided.","title":"new(new_acc_params())"},{"location":"developers-guide/accumulators/#getters-for-predefined-fields","text":"ref(t()) timestamp(t()) lserver(t()) element(t()) stanza_name(t()) - Returns name value from stanza map. stanza_type(t()) - Returns type value from stanza map. stanza_ref(t()) - Returns ref value from stanza map. This is not the same as ref(t()) !","title":"Getters for predefined fields"},{"location":"developers-guide/accumulators/#update_stanzastanza_params-t","text":"Replaces the whole stanza field in accumulator with params provided in stanza_params() , which is a map of 3 fields: element , from_jid , to_jid . The same rules apply as in the case of constructor ( new/1 ) but this time element field is mandatory .","title":"update_stanza(stanza_params(), t())"},{"location":"developers-guide/accumulators/#access-to-namespaced-fields","text":"It is possible to store and retrieve any data in the accumulator, that is related to the processing. There is no scope protection, so every module may access all namespaces and keys inside them. set(Namespace :: any(), Key :: any(), Value :: any(), t()) set_permanent(Namespace :: any(), Key :: any(), Value :: any(), t()) - Upserts a field, which won't be removed during strip operation. append(Namespace :: any(), Key :: any(), Value :: any(), t()) - In order to use this function, a Namespace:Key field must not exist or must be a list. Value is appended to the end of this list. If Value is a list, then a OldValue ++ Value operation is performed. In other cases OldValue ++ [Value] is used. get(Namespace :: any(), Key :: any(), t()) - Returns a value of a specified field. Will crash if the NS:Key is not found. get(Namespace :: any(), Key :: any(), Default :: any(), t()) - Returns a value of a specified field or Default if NS:Key is not found. delete(Namespace :: any(), Key :: any(), t()) - Removes a specified field, no matter if it is permanent or not.","title":"Access to namespaced fields"},{"location":"developers-guide/accumulators/#stripping","text":"Accumulator is used mostly to cache values for reuse within a c2s process; when it goes out to somewhere else, it is stripped of all unnecessary attributes except for: ref timestamp origin_pid origin_location origin_stanza non_strippable - A set of permanent NS:Key pairs. If you want it to carry some additional values along with it, please use a dedicated api for setting \"permanent\" fields: 1 Acc2 = mongoose_acc : set_permanent ( myns , myprop , 123 , Acc1 ), Permanent fields may be retrieved with ordinary get/3,4 functions. The rationale behind stripping an accumulator is that some values stored in it are context-dependend. For example, at the beginning lserver refers to the host of the sender C2S. When an accumulator goes to the c2s of the recipient, the lserver attribute may change. There are also many cached values which are not valid anymore when user changes (e.g. privacy checks). In order to strip an accumulator, please use strip(strip_params(), t()) , where strip_params() is a map of: lserver - New host context. Obviously, may be equal to the old value. element , from_jid , to_jid - The same rules apply as in update_stanza/2 .","title":"Stripping"},{"location":"developers-guide/accumulators/#main-principles-of-an-accumulator-processing","text":"An accumulator is created when a stanza enters the server. An XML stanza is never passed around as a pure exml:element() . An accumulator is stripped when it is passed to a different context (e.g. another c2s process). If a process produces more stanzas to be routed, they must reuse original acc but with stanza replaced with update_stanza/2 .","title":"Main principles of an accumulator processing"},{"location":"developers-guide/accumulators/#hooks","text":"Many of the MongooseIM functionalities are implemented in submodules which attach their handlers to hooks (this is covered in detail in \"Hooks and handlers\" . When it comes to the accumulators, the following rules apply: If a hook is related to stanza processing and is executed with run_fold , a Mongoose accumulator should be provided. A hook handler may modify an accumulator in every permitted way (i.e. shouldn't directly modify acc fields, bypassing mongoose_acc API) and should return the execution result in the hook:result field. This is not enforced but should be followed by convention. Avoid passing superfluous arguments to handlers - e.g. an LServer in hook args is redundant since it is already present in the accumulator. Do not use run - it is still present in API but executes run_fold with ok as an initial accumulator anyway. Handlers have been rewritten so that they accept an acc as the first arg. Note that run is deprecated now and at some point will be removed. Most handlers have already been modified so that they accept an instance of mongoose_acc:t() as the first argument and return value by storing it inside it. How the accumulator is used within a module is up to the implementors of the module.","title":"Hooks"},{"location":"developers-guide/accumulators/#iqs-and-accumulators","text":"mongoose_iq module exposes a dedicated API for accessing IQ-related accumulator fields. These are: info(Acc) - Returns a #iq{} record produced from a stanza stored in the accumulator. May be invalid or not_iq if the stanza is not a valid IQ. xmlns(Acc) - Returns XMLNS of the first subelement inside an IQ. In most cases it is a namespace of <query/> subelement. May be undefined . command(Acc) - Returns the name of a first subelement inside an IQ. May be undefined . These functions ensure that cached information matches the accumulator's stanza, so all of them return a tuple with a possibly updated acc as a second element.","title":"IQs and accumulators"},{"location":"developers-guide/accumulators/#sample-usage-actual-and-potential","text":"","title":"Sample usage, actual and potential"},{"location":"developers-guide/accumulators/#privacy-check","text":"Stanzas are often checked against privacy lists. According to the current mongoose_privacy:privacy_check_packet implementation, the result is stored in an accumulator so if a check has to be repeated it is just one map read.","title":"Privacy check"},{"location":"developers-guide/accumulators/#tracing","text":"origin_stanza field is fully immutable for the lifespan of a single accumulator, so it's easier to correlate one of the stanzas sent by a client with some \"unexpected\" stanza routed from a completely different part of a server. There are many places in the server, where an accumulator may be created, so origin_location makes it much easier to find out what event has triggered the processing.","title":"Tracing"},{"location":"developers-guide/accumulators/#performance-measurement","text":"Given that each accumulator has a timestamp denoting its creation time, it is now very easy to implement a metric showing the stanza processing time, or even multiple metrics splitting it into stages.","title":"Performance measurement"},{"location":"developers-guide/domain_management/","text":"MongooseIM core component Implemented by mongoose_domain_core module. It must be based on gen_server & ETS table w. public read access. This module is local for the node, it must not implement any sync across the nodes in a cluster. This component will be responsible for dynamic routing, it will always be started by MIM even if there is no support of dynamic domain names configured. It must provide the following interfaces: Init - should accept the list of initial domain/host_type pairs provided in config file and the list of host_types that can be used for dynamic insertion. Any of these lists can be empty, initial list of domain/host_type pairs can have some unique host_types not mentioned in the host_types list. The component must be initialised by the main MIM supervisor. Implemented in mongoose_domain_api:init() . Insert - adding new domain/host_type pair. This function must be idempotent , it must return success on attempt to insert the existing data, but it must fail if ETS already has the domain name associated with another host type. Implemented in mongoose_domain_api:insert_domain(Domain, HostType) . Remove - This function must be idempotent. this function deletes existing domain/host_type pairs. It must be impossible to delete domain/host_type pairs specified on init of the component. Implemented in mongoose_domain_api:delete_domain(Domain) . Get host type by domain. Implemented in mongoose_domain_api:get_host_type(Domain). . Get all domains configured for the host_type. Implemented in mongoose_domain_api:get_domains_by_host_type(HostType). . Get the list of the host_types provided during initialisation. Implemented in mongoose_domain_api:get_all_static(). . mongoose_domain_core implementation: Has mongoose_domain_core table. Default (initial) domains are static . Disabled or deleted domains are not in mongoose_domain_core . Static domains are non-mutable. Static domains are not replicated. Static domains has priority above DB domains. MongooseIM service Implements the service behaviour. Implemented by service_domain_db module. This service must provide an interface for dynamic management of domain names. It must have persistent storage (RDBMS) where it stores information about domain names. This service must ensure synchronization of dynamically managed domain names across different nodes in the cluster. The minimal set of information associated with domain name is this: Host type Status (enabled/disabled) This service must provide the following interfaces: Init - on init all the \u201cenabled\u201d domain names from the persistent storage must be added to the core MIM component described above. Add domain name (w/ host type) - This function must be idempotent. Added domain is always \u201cenabled\u201d by default it must be added in the core MIM component described in the previous section. If it\u2019s successfully enabled than Information about the domain name must be added into persistent storage and distributed across all the nodes in the cluster. Disabling/Enabling domain name - This function must be idempotent. the status of the existing domain must be changed. If domain name is enabled, then it must be added in the core MIM component. On disabling domain name must be deleted from the core MIM component. Change of the status must be distributed across all the nodes in the cluster. Remove the domain name - This function must be idempotent. Domain name must be deleted from the core MIM component (if required) and from the DB. This action must be distributed across all the nodes in the cluster. In case of any issues (domain name is already configured with another host_type or host_type is not supported), they must be logged as errors. The database schema contains two tables: domain_settings - one record per domain. Maps domain name to host_type and enabled status. domain_events - the log of changes. The only reason it exists is that we can track updates in the domain_settings and get apply updates across different nodes. The old events are eventually deleted from the table. Removal is triggered by all nodes of MongooseIM, that have the service configured. service_domain_db module does two tasks: Initially downloads domains from domain_settings table, using sorting by id. Waits for check_for_updates message and updates core component, depending on records in the domain_events table. We use id field to sort records when paginating. Domain removal You are not allowed to delete domains with unknown host-type. Configure host-type first to delete such domains. Service options event_cleaning_interval The number of seconds between cleaning attempts of the domain_events table. Syntax: positive integer Default: 1800 (30 minutes) Example: event_cleaning_interval = 1800 event_max_age The number of seconds after an event must be deleted from the domain_events table. Syntax: positive integer Default: 7200 (2 hours) Example: event_max_age = 7200 REST API Provides API for adding/removing and enabling/disabling domains over HTTP. Implemented by mongoose_domain_handler module. Configuration example: 1 2 3 4 5 6 7 8 9 [[listen.http]] ip_address = \"127.0.0.1\" port = 8088 transport . num_acceptors = 10 transport . max_connections = 1024 [[listen.http.handlers.mongoose_domain_handler]] host = \"localhost\" path = \"/api\" Add domain 1 2 3 curl -v -X PUT \"http://localhost:8088/api/domains/example.db\" \\ -H 'content-type: application/json' \\ -d '{\"host_type\": \"type1\"}' Result codes: 204 - inserted. 409 - domain already exists with a different host type. 403 - DB service disabled. 403 - unknown host type. 500 - other errors. Example of the result body with a failure reason: 1 {\"what\":\"unknown host type\"} Check the src/domain/mongoose_domain_handler.erl file for the exact values of the what field if needed. Delete domain You must provide the domain's host type inside the body: 1 2 3 curl -v -X DELETE \"http://localhost:8088/api/domains/example.db\" \\ -H 'content-type: application/json' \\ -d '{\"host_type\": \"type1\"}' Result codes: 204 - the domain is removed or not found. 403 - the domain is static. 403 - the DB service is disabled. 403 - the host type is wrong (does not match the host type in the database). 403 - the host type is unknown. 500 - other errors. Enable/disable domain Provide {\"enabled\": true} as a body to enable a domain. Provide {\"enabled\": false} as a body to disable a domain. 1 2 3 curl -v -X PATCH \"http://localhost:8088/api/domains/example.db\" \\ -H 'content-type: application/json' \\ -d '{\"enabled\": true}' Result codes: 204 - updated. 404 - domain not found; 403 - domain is static; 403 - service disabled. Command Line Interface Implemented by service_admin_extra_domain module. Configuration example: 1 2 3 [services.service_admin_extra] submods = [ \"node\" , \"accounts\" , \"sessions\" , \"vcard\" , \"gdpr\" , \"upload\" , \"roster\" , \"last\" , \"private\" , \"stanza\" , \"stats\" , \"domain\" ] Add domain: 1 ./mongooseimctl insert_domain domain host_type Delete domain: 1 ./mongooseimctl delete_domain domain host_type Disable domain: 1 ./mongooseimctl disable_domain domain Enable domain: 1 ./mongooseimctl enable_domain domain","title":"Domain management"},{"location":"developers-guide/domain_management/#mongooseim-core-component","text":"Implemented by mongoose_domain_core module. It must be based on gen_server & ETS table w. public read access. This module is local for the node, it must not implement any sync across the nodes in a cluster. This component will be responsible for dynamic routing, it will always be started by MIM even if there is no support of dynamic domain names configured. It must provide the following interfaces: Init - should accept the list of initial domain/host_type pairs provided in config file and the list of host_types that can be used for dynamic insertion. Any of these lists can be empty, initial list of domain/host_type pairs can have some unique host_types not mentioned in the host_types list. The component must be initialised by the main MIM supervisor. Implemented in mongoose_domain_api:init() . Insert - adding new domain/host_type pair. This function must be idempotent , it must return success on attempt to insert the existing data, but it must fail if ETS already has the domain name associated with another host type. Implemented in mongoose_domain_api:insert_domain(Domain, HostType) . Remove - This function must be idempotent. this function deletes existing domain/host_type pairs. It must be impossible to delete domain/host_type pairs specified on init of the component. Implemented in mongoose_domain_api:delete_domain(Domain) . Get host type by domain. Implemented in mongoose_domain_api:get_host_type(Domain). . Get all domains configured for the host_type. Implemented in mongoose_domain_api:get_domains_by_host_type(HostType). . Get the list of the host_types provided during initialisation. Implemented in mongoose_domain_api:get_all_static(). . mongoose_domain_core implementation: Has mongoose_domain_core table. Default (initial) domains are static . Disabled or deleted domains are not in mongoose_domain_core . Static domains are non-mutable. Static domains are not replicated. Static domains has priority above DB domains.","title":"MongooseIM core component"},{"location":"developers-guide/domain_management/#mongooseim-service","text":"Implements the service behaviour. Implemented by service_domain_db module. This service must provide an interface for dynamic management of domain names. It must have persistent storage (RDBMS) where it stores information about domain names. This service must ensure synchronization of dynamically managed domain names across different nodes in the cluster. The minimal set of information associated with domain name is this: Host type Status (enabled/disabled) This service must provide the following interfaces: Init - on init all the \u201cenabled\u201d domain names from the persistent storage must be added to the core MIM component described above. Add domain name (w/ host type) - This function must be idempotent. Added domain is always \u201cenabled\u201d by default it must be added in the core MIM component described in the previous section. If it\u2019s successfully enabled than Information about the domain name must be added into persistent storage and distributed across all the nodes in the cluster. Disabling/Enabling domain name - This function must be idempotent. the status of the existing domain must be changed. If domain name is enabled, then it must be added in the core MIM component. On disabling domain name must be deleted from the core MIM component. Change of the status must be distributed across all the nodes in the cluster. Remove the domain name - This function must be idempotent. Domain name must be deleted from the core MIM component (if required) and from the DB. This action must be distributed across all the nodes in the cluster. In case of any issues (domain name is already configured with another host_type or host_type is not supported), they must be logged as errors. The database schema contains two tables: domain_settings - one record per domain. Maps domain name to host_type and enabled status. domain_events - the log of changes. The only reason it exists is that we can track updates in the domain_settings and get apply updates across different nodes. The old events are eventually deleted from the table. Removal is triggered by all nodes of MongooseIM, that have the service configured. service_domain_db module does two tasks: Initially downloads domains from domain_settings table, using sorting by id. Waits for check_for_updates message and updates core component, depending on records in the domain_events table. We use id field to sort records when paginating.","title":"MongooseIM service"},{"location":"developers-guide/domain_management/#domain-removal","text":"You are not allowed to delete domains with unknown host-type. Configure host-type first to delete such domains.","title":"Domain removal"},{"location":"developers-guide/domain_management/#service-options","text":"","title":"Service options"},{"location":"developers-guide/domain_management/#event_cleaning_interval","text":"The number of seconds between cleaning attempts of the domain_events table. Syntax: positive integer Default: 1800 (30 minutes) Example: event_cleaning_interval = 1800","title":"event_cleaning_interval"},{"location":"developers-guide/domain_management/#event_max_age","text":"The number of seconds after an event must be deleted from the domain_events table. Syntax: positive integer Default: 7200 (2 hours) Example: event_max_age = 7200","title":"event_max_age"},{"location":"developers-guide/domain_management/#rest-api","text":"Provides API for adding/removing and enabling/disabling domains over HTTP. Implemented by mongoose_domain_handler module. Configuration example: 1 2 3 4 5 6 7 8 9 [[listen.http]] ip_address = \"127.0.0.1\" port = 8088 transport . num_acceptors = 10 transport . max_connections = 1024 [[listen.http.handlers.mongoose_domain_handler]] host = \"localhost\" path = \"/api\"","title":"REST API"},{"location":"developers-guide/domain_management/#add-domain","text":"1 2 3 curl -v -X PUT \"http://localhost:8088/api/domains/example.db\" \\ -H 'content-type: application/json' \\ -d '{\"host_type\": \"type1\"}' Result codes: 204 - inserted. 409 - domain already exists with a different host type. 403 - DB service disabled. 403 - unknown host type. 500 - other errors. Example of the result body with a failure reason: 1 {\"what\":\"unknown host type\"} Check the src/domain/mongoose_domain_handler.erl file for the exact values of the what field if needed.","title":"Add domain"},{"location":"developers-guide/domain_management/#delete-domain","text":"You must provide the domain's host type inside the body: 1 2 3 curl -v -X DELETE \"http://localhost:8088/api/domains/example.db\" \\ -H 'content-type: application/json' \\ -d '{\"host_type\": \"type1\"}' Result codes: 204 - the domain is removed or not found. 403 - the domain is static. 403 - the DB service is disabled. 403 - the host type is wrong (does not match the host type in the database). 403 - the host type is unknown. 500 - other errors.","title":"Delete domain"},{"location":"developers-guide/domain_management/#enabledisable-domain","text":"Provide {\"enabled\": true} as a body to enable a domain. Provide {\"enabled\": false} as a body to disable a domain. 1 2 3 curl -v -X PATCH \"http://localhost:8088/api/domains/example.db\" \\ -H 'content-type: application/json' \\ -d '{\"enabled\": true}' Result codes: 204 - updated. 404 - domain not found; 403 - domain is static; 403 - service disabled.","title":"Enable/disable domain"},{"location":"developers-guide/domain_management/#command-line-interface","text":"Implemented by service_admin_extra_domain module. Configuration example: 1 2 3 [services.service_admin_extra] submods = [ \"node\" , \"accounts\" , \"sessions\" , \"vcard\" , \"gdpr\" , \"upload\" , \"roster\" , \"last\" , \"private\" , \"stanza\" , \"stats\" , \"domain\" ] Add domain: 1 ./mongooseimctl insert_domain domain host_type Delete domain: 1 ./mongooseimctl delete_domain domain host_type Disable domain: 1 ./mongooseimctl disable_domain domain Enable domain: 1 ./mongooseimctl enable_domain domain","title":"Command Line Interface"},{"location":"developers-guide/hooks_description/","text":"Selected hooks description This is a brief documentation for a few selected hooks. Though hooks & handlers differ in what they are there to do, it is not necessary to describe them all, because the mechanism is general. The following is meant to give you the idea of how the hooks work, what they are used for and the various purposes they can serve. user_send_packet 1 2 3 mongoose_hooks : user_send_packet ( LServer , Acc , FromJID , ToJID , El ) This hook is run in ejabberd_c2s after the user sends a packet. Some rudimentary verification of the stanza is done once it is received from the socket: if present, the from attribute of the stanza is checked against the identity of the user whose session the process in question serves; if the identity does not match the contents of the attribute, an error is returned, the recipient JID ( to attribute) format is verified. The hook is not run for stanzas which do not pass these basic validity checks. Neither are such stanzas further processed by the server. The hook is not run for stanzas in the jabber:iq:privacy or urn:xmpp:blocking namespaces. This hook won't be called for stanzas arriving from a user served by a federated server (i.e. on a server-to-server connection handled by ejabberd_s2s ) intended for a user served by the relevant ejabberd instance. It is handled by the following modules: mod_caps - detects and caches capability information sent with certain messages for later use mod_carboncopy - if the packet being sent is a message, it forwards it to all the user's resources which have carbon copying enabled mod_event_pusher - if configured, sends selected messages to an external service mod_mam - stores outgoing messages in an archive mod_ping - upon reception of every message from the client, this module (re)starts a timer; if nothing more is received from the client within 60 seconds, it sends an IQ ping, to which the client should reply - which starts another timer. user_receive_packet 1 2 3 Acc2 = mongoose_hooks : user_receive_packet ( StateData #state.server , Acc , StateData #state.jid , From , To , FixedEl ), The hook is run just before a packet received by the server is sent to the user. Prior to sending, the packet is verified against any relevant privacy lists (the mechanism is described in XEP-0016: Privacy Lists ). The privacy list mechanism itself is not mandatory and requires mod_privacy to be configured; otherwise all stanzas are allowed to pass. This hook won't run for stanzas which are destined to users of a different XMPP domain served by a federated server, connection to which is handled by ejabberd_s2s . It is handled by the following modules: mod_caps - detects and caches capability information sent with certain messages for later use mod_carboncopy - if the received packet is a message, it forwards it to all the user's resources which have carbon copying enabled filter_packet 1 mongoose_hooks : filter_packet ({ OrigFrom , OrigTo , OrigAcc , OrigPacket }) Which in turn executes this line of code: 1 ejabberd_hooks : run_fold ( filter_packet , { From , To , Acc , Packet }, []). This hook is run by mongoose_router_global when the packet is being routed by ejaberd_router:route/3 . It is in fact the first call made within the routing procedure. If a function hooked in to filter_packet returns drop , the packet is not processed. The ejaberd_router:route/3 fun is the most general function used to route stanzas across the entire cluster and its calls are scattered all over ejabberd code. ejabberd_c2s calls it after it receives a packet from ejabberd_receiver (i.e. the socket) and multiple modules use it for sending replies and errors. As seen in the example, the handlers take no arguments. The accumulator is the packet which may or may not be filtered out (in case the handler chain returns drop ) or modified. Note that this hook is run with ejabberd_hooks:run_fold/3 , not the usual and already mentioned ejabberd_hooks:run_fold/4 . The ternary variant doesn't take the XMPP domain argument and hence it's not possible to register per-domain handlers for this hook. Keep that in mind when registering the handlers and appropriately use ejabberd_hooks:add/4 instead of ejabberd_hooks:add/5 . offline_message_hook 1 mongoose_hooks : offline_message_hook ( LServer , Acc , From , To , Packet ) ejabberd_sm runs this hook once it determines that a routed stanza is a message and while it ordinarily could be delivered, no resource (i.e. device or desktop client application) of its recipient is available online for delivery. The hook is first handled by mod_offline , which should store that message in a persistent way until the recipient comes online and the message can be successfully delivered. The handler in mod_offline stores the message and returns stop , which terminates the call and no more hook handlers are called. If the mod_offline handler fails to store the message, we should notify the user that the message could not be stored. To this end, there is another handler registered, but with a greater sequence number, so that it is called after mod_offline . If mod_offline fails, ejabberd_sm:bounce_offline_message is called and the user gets their notification. remove_user 1 mongoose_hooks : remove_user ( LServer , Acc , LUser ) remove_user is run by ejabberd_auth - the authentication module - when a request is made to remove the user from the database of the server. This one is rather complex, since removing a user requires many cleanup operations: mod_last removes last activity information ( XEP-0012: Last Activity ); mod_mam removes the user's message archive; mod_muc_light quits multi-user chat rooms; mod_offline deletes the user's offline messages; mod_privacy removes the user's privacy lists; mod_private removes the user's private xml data storage; mod_pubsub unsubscribes from publish/subsribe channels; and mod_roster removes the user's roster from database. node_cleanup 1 ejabberd_hooks : run ( node_cleanup , [ Node ]) node_cleanup is run by a mongooseim_cleaner process which subscribes to nodedown messages. Currently the hook is run inside a global transaction (via global:trans/4 ). The job of this hook is to remove all processes registered in Mnesia. MongooseIM uses Mnesia to store processes through which messages are then routed - like user sessions or server-to-server communication channels - or various handlers, e.g. IQ request handlers. Those must obviously be removed when a node goes down, and to do this the modules ejabberd_local , ejabberd_s2s , ejabberd_sm and mod_bosh register their handlers with this hook. Number of retries for this transaction is set to 1 which means that in some situations the hook may be run on more than one node in the cluster, especially when there is little garbage to clean after the dead node. Setting retries to 0 is not good decision as it was observed that in some setups it may abort the transaction on all nodes. session_opening_allowed_for_user 1 2 allow == mongoose_hooks : session_opening_allowed_for_user ( Server , allow , JID ). This hook is run after authenticating when user sends the IQ opening a session. Handler function are expected to return: allow if a given JID is allowed to open a new sessions (the default) deny if the JID is not allowed but other handlers should be run {stop, deny} if the JID is not allowed but other handlers should not be run In the default implementation the hook is not used, built-in user control methods are supported elsewhere. This is the perfect place to plug in custom security control. Other hooks adhoc_local_items adhoc_sm_items amp_check_condition amp_check_packet amp_determine_strategy amp_error_action_triggered amp_notify_action_triggered amp_verify_support anonymous_purge_hook auth_failed c2s_broadcast_recipients c2s_filter_packet c2s_preprocessing_hook c2s_presence_in c2s_stream_features c2s_unauthenticated_iq c2s_update_presence can_access_identity can_access_room caps_add caps_recognised caps_update check_bl_c2s disco_info disco_local_features disco_local_identity disco_local_items disco_sm_features disco_sm_identity disco_sm_items ejabberd_ctl_process empty failed_to_store_message filter_local_packet filter_packet filter_room_packet find_s2s_bridge forbidden_session_hook forget_room get_key host_config_update inbox_unread_count invitation_sent is_muc_room_owner join_room leave_room local_send_to_resource_hook mam_archive_id mam_archive_message mam_archive_size mam_drop_iq mam_drop_message mam_drop_messages mam_flush_messages mam_get_behaviour mam_get_prefs mam_lookup_messages mam_muc_archive_id mam_muc_archive_message mam_muc_archive_size mam_muc_drop_iq mam_muc_drop_message mam_muc_flush_messages mam_muc_get_behaviour mam_muc_get_prefs mam_muc_lookup_messages mam_muc_remove_archive mam_muc_set_prefs mam_remove_archive mam_set_prefs mod_global_distrib_known_recipient mod_global_distrib_unknown_recipient offline_groupchat_message_hook offline_message_hook packet_to_component presence_probe_hook privacy_check_packet privacy_get_user_list privacy_iq_get privacy_iq_set privacy_updated_list pubsub_create_node pubsub_delete_node pubsub_publish_item push_notifications register_command register_subhost register_user remove_user resend_offline_messages_hook rest_user_send_packet room_packet roster_get roster_get_jid_info roster_get_subscription_lists roster_get_versioning_feature roster_groups roster_in_subscription roster_out_subscription roster_process_item roster_push roster_set s2s_allow_host s2s_connect_hook s2s_receive_packet s2s_send_packet s2s_stream_features session_cleanup session_opening_allowed_for_user set_presence_hook set_vcard sm_broadcast sm_filter_offline_message sm_register_connection_hook sm_remove_connection_hook unregister_command unregister_subhost unset_presence_hook update_inbox_for_muc user_available_hook user_ping_timeout user_ping_response user_receive_packet user_send_packet user_sent_keep_alive vcard_set xmpp_bounce_message xmpp_send_element xmpp_stanza_dropped","title":"Hooks description"},{"location":"developers-guide/hooks_description/#selected-hooks-description","text":"This is a brief documentation for a few selected hooks. Though hooks & handlers differ in what they are there to do, it is not necessary to describe them all, because the mechanism is general. The following is meant to give you the idea of how the hooks work, what they are used for and the various purposes they can serve.","title":"Selected hooks description"},{"location":"developers-guide/hooks_description/#user_send_packet","text":"1 2 3 mongoose_hooks : user_send_packet ( LServer , Acc , FromJID , ToJID , El ) This hook is run in ejabberd_c2s after the user sends a packet. Some rudimentary verification of the stanza is done once it is received from the socket: if present, the from attribute of the stanza is checked against the identity of the user whose session the process in question serves; if the identity does not match the contents of the attribute, an error is returned, the recipient JID ( to attribute) format is verified. The hook is not run for stanzas which do not pass these basic validity checks. Neither are such stanzas further processed by the server. The hook is not run for stanzas in the jabber:iq:privacy or urn:xmpp:blocking namespaces. This hook won't be called for stanzas arriving from a user served by a federated server (i.e. on a server-to-server connection handled by ejabberd_s2s ) intended for a user served by the relevant ejabberd instance. It is handled by the following modules: mod_caps - detects and caches capability information sent with certain messages for later use mod_carboncopy - if the packet being sent is a message, it forwards it to all the user's resources which have carbon copying enabled mod_event_pusher - if configured, sends selected messages to an external service mod_mam - stores outgoing messages in an archive mod_ping - upon reception of every message from the client, this module (re)starts a timer; if nothing more is received from the client within 60 seconds, it sends an IQ ping, to which the client should reply - which starts another timer.","title":"user_send_packet"},{"location":"developers-guide/hooks_description/#user_receive_packet","text":"1 2 3 Acc2 = mongoose_hooks : user_receive_packet ( StateData #state.server , Acc , StateData #state.jid , From , To , FixedEl ), The hook is run just before a packet received by the server is sent to the user. Prior to sending, the packet is verified against any relevant privacy lists (the mechanism is described in XEP-0016: Privacy Lists ). The privacy list mechanism itself is not mandatory and requires mod_privacy to be configured; otherwise all stanzas are allowed to pass. This hook won't run for stanzas which are destined to users of a different XMPP domain served by a federated server, connection to which is handled by ejabberd_s2s . It is handled by the following modules: mod_caps - detects and caches capability information sent with certain messages for later use mod_carboncopy - if the received packet is a message, it forwards it to all the user's resources which have carbon copying enabled","title":"user_receive_packet"},{"location":"developers-guide/hooks_description/#filter_packet","text":"1 mongoose_hooks : filter_packet ({ OrigFrom , OrigTo , OrigAcc , OrigPacket }) Which in turn executes this line of code: 1 ejabberd_hooks : run_fold ( filter_packet , { From , To , Acc , Packet }, []). This hook is run by mongoose_router_global when the packet is being routed by ejaberd_router:route/3 . It is in fact the first call made within the routing procedure. If a function hooked in to filter_packet returns drop , the packet is not processed. The ejaberd_router:route/3 fun is the most general function used to route stanzas across the entire cluster and its calls are scattered all over ejabberd code. ejabberd_c2s calls it after it receives a packet from ejabberd_receiver (i.e. the socket) and multiple modules use it for sending replies and errors. As seen in the example, the handlers take no arguments. The accumulator is the packet which may or may not be filtered out (in case the handler chain returns drop ) or modified. Note that this hook is run with ejabberd_hooks:run_fold/3 , not the usual and already mentioned ejabberd_hooks:run_fold/4 . The ternary variant doesn't take the XMPP domain argument and hence it's not possible to register per-domain handlers for this hook. Keep that in mind when registering the handlers and appropriately use ejabberd_hooks:add/4 instead of ejabberd_hooks:add/5 .","title":"filter_packet"},{"location":"developers-guide/hooks_description/#offline_message_hook","text":"1 mongoose_hooks : offline_message_hook ( LServer , Acc , From , To , Packet ) ejabberd_sm runs this hook once it determines that a routed stanza is a message and while it ordinarily could be delivered, no resource (i.e. device or desktop client application) of its recipient is available online for delivery. The hook is first handled by mod_offline , which should store that message in a persistent way until the recipient comes online and the message can be successfully delivered. The handler in mod_offline stores the message and returns stop , which terminates the call and no more hook handlers are called. If the mod_offline handler fails to store the message, we should notify the user that the message could not be stored. To this end, there is another handler registered, but with a greater sequence number, so that it is called after mod_offline . If mod_offline fails, ejabberd_sm:bounce_offline_message is called and the user gets their notification.","title":"offline_message_hook"},{"location":"developers-guide/hooks_description/#remove_user","text":"1 mongoose_hooks : remove_user ( LServer , Acc , LUser ) remove_user is run by ejabberd_auth - the authentication module - when a request is made to remove the user from the database of the server. This one is rather complex, since removing a user requires many cleanup operations: mod_last removes last activity information ( XEP-0012: Last Activity ); mod_mam removes the user's message archive; mod_muc_light quits multi-user chat rooms; mod_offline deletes the user's offline messages; mod_privacy removes the user's privacy lists; mod_private removes the user's private xml data storage; mod_pubsub unsubscribes from publish/subsribe channels; and mod_roster removes the user's roster from database.","title":"remove_user"},{"location":"developers-guide/hooks_description/#node_cleanup","text":"1 ejabberd_hooks : run ( node_cleanup , [ Node ]) node_cleanup is run by a mongooseim_cleaner process which subscribes to nodedown messages. Currently the hook is run inside a global transaction (via global:trans/4 ). The job of this hook is to remove all processes registered in Mnesia. MongooseIM uses Mnesia to store processes through which messages are then routed - like user sessions or server-to-server communication channels - or various handlers, e.g. IQ request handlers. Those must obviously be removed when a node goes down, and to do this the modules ejabberd_local , ejabberd_s2s , ejabberd_sm and mod_bosh register their handlers with this hook. Number of retries for this transaction is set to 1 which means that in some situations the hook may be run on more than one node in the cluster, especially when there is little garbage to clean after the dead node. Setting retries to 0 is not good decision as it was observed that in some setups it may abort the transaction on all nodes.","title":"node_cleanup"},{"location":"developers-guide/hooks_description/#session_opening_allowed_for_user","text":"1 2 allow == mongoose_hooks : session_opening_allowed_for_user ( Server , allow , JID ). This hook is run after authenticating when user sends the IQ opening a session. Handler function are expected to return: allow if a given JID is allowed to open a new sessions (the default) deny if the JID is not allowed but other handlers should be run {stop, deny} if the JID is not allowed but other handlers should not be run In the default implementation the hook is not used, built-in user control methods are supported elsewhere. This is the perfect place to plug in custom security control.","title":"session_opening_allowed_for_user"},{"location":"developers-guide/hooks_description/#other-hooks","text":"adhoc_local_items adhoc_sm_items amp_check_condition amp_check_packet amp_determine_strategy amp_error_action_triggered amp_notify_action_triggered amp_verify_support anonymous_purge_hook auth_failed c2s_broadcast_recipients c2s_filter_packet c2s_preprocessing_hook c2s_presence_in c2s_stream_features c2s_unauthenticated_iq c2s_update_presence can_access_identity can_access_room caps_add caps_recognised caps_update check_bl_c2s disco_info disco_local_features disco_local_identity disco_local_items disco_sm_features disco_sm_identity disco_sm_items ejabberd_ctl_process empty failed_to_store_message filter_local_packet filter_packet filter_room_packet find_s2s_bridge forbidden_session_hook forget_room get_key host_config_update inbox_unread_count invitation_sent is_muc_room_owner join_room leave_room local_send_to_resource_hook mam_archive_id mam_archive_message mam_archive_size mam_drop_iq mam_drop_message mam_drop_messages mam_flush_messages mam_get_behaviour mam_get_prefs mam_lookup_messages mam_muc_archive_id mam_muc_archive_message mam_muc_archive_size mam_muc_drop_iq mam_muc_drop_message mam_muc_flush_messages mam_muc_get_behaviour mam_muc_get_prefs mam_muc_lookup_messages mam_muc_remove_archive mam_muc_set_prefs mam_remove_archive mam_set_prefs mod_global_distrib_known_recipient mod_global_distrib_unknown_recipient offline_groupchat_message_hook offline_message_hook packet_to_component presence_probe_hook privacy_check_packet privacy_get_user_list privacy_iq_get privacy_iq_set privacy_updated_list pubsub_create_node pubsub_delete_node pubsub_publish_item push_notifications register_command register_subhost register_user remove_user resend_offline_messages_hook rest_user_send_packet room_packet roster_get roster_get_jid_info roster_get_subscription_lists roster_get_versioning_feature roster_groups roster_in_subscription roster_out_subscription roster_process_item roster_push roster_set s2s_allow_host s2s_connect_hook s2s_receive_packet s2s_send_packet s2s_stream_features session_cleanup session_opening_allowed_for_user set_presence_hook set_vcard sm_broadcast sm_filter_offline_message sm_register_connection_hook sm_remove_connection_hook unregister_command unregister_subhost unset_presence_hook update_inbox_for_muc user_available_hook user_ping_timeout user_ping_response user_receive_packet user_send_packet user_sent_keep_alive vcard_set xmpp_bounce_message xmpp_send_element xmpp_stanza_dropped","title":"Other hooks"},{"location":"developers-guide/logging/","text":"Logging To use logger in your module, include 1 - include ( \"mongoose_logger.hrl\" ). or 1 - include ( \"mongoose.hrl\" ). Logging macros There are several macros for the most common logging levels: 1 2 3 4 5 6 ? LOG_DEBUG (#{ what => debug_event , info => Arg }), ? LOG_INFO (#{ what => info_event , info => Arg }), ? LOG_NOTICE (#{ what => notice_event , info => Arg }), ? LOG_WARNING (#{ what => warning_event , info => Arg }), ? LOG_ERROR (#{ what => error_event , info => Arg }), ? LOG_CRITICAL (#{ what => critical_event , info => Arg }), Use them in correspondence with the appropriate log level. Please be mindful of what is logged and which log level is used for it. Logging levels A system operator can choose the global log level by setting loglevel in mongooseim.toml . Possible values are the standard syslog severity levels, plus all or none: \"all\" , \"debug\" , \"info\" , \"notice\" , \"warning\" , \"error\" , \"critical\" , \"alert\" , \"emergency\" , and \"none\" . 1 2 [general] loglevel = \"notice\" If a user sets the log level to all , then they would see all messages in logs. Levels warning and error are the most commonly used for production systems. Logging format We use structured logging as inspired by Ferd's post . We also use a modified logfmt format as one of the possible default logger formatters. This format is Splunk and ELK friendly. Check the list of fields for fields documentation. what => something_interesting field is required. 1 2 3 4 5 6 7 8 9 10 ? LOG_ERROR (#{ what => check_password_failed , reason => Error , user => LUser }) try ... catch Class : Reason : StackTrace -> ? LOG_ERROR (#{ what => check_password_failed , class => Class , reason => Reason , stacktrace => StackTrace }), erlang : raise ( Class , Reason , StackTrace ) end Field user => <<\"alice\">> is often used too. A common way to name an error event is what => function_name_failed . For example, what => remove_user_failed . Use the advice critically, it would not work well for any function. Counterexample: 1 2 3 handle_info ( Info , State ) -> ? LOG_WARNING (#{ what => unexpected_message , msg => Info }), { noreply , State }. Filtering logs by module Setting loglevel to debug can lead to a flood of messages in logs. To set a different loglevel for just one module, call: 1 2 mongoose_logs : set_global_loglevel ( error ). mongoose_logs : set_module_loglevel ( mod_mam , debug ). This code sets the loglevel to error for all log messages, except for those generated by mod_mam . All messages from mod_mam would be logged.","title":"Logging"},{"location":"developers-guide/logging/#logging","text":"To use logger in your module, include 1 - include ( \"mongoose_logger.hrl\" ). or 1 - include ( \"mongoose.hrl\" ).","title":"Logging"},{"location":"developers-guide/logging/#logging-macros","text":"There are several macros for the most common logging levels: 1 2 3 4 5 6 ? LOG_DEBUG (#{ what => debug_event , info => Arg }), ? LOG_INFO (#{ what => info_event , info => Arg }), ? LOG_NOTICE (#{ what => notice_event , info => Arg }), ? LOG_WARNING (#{ what => warning_event , info => Arg }), ? LOG_ERROR (#{ what => error_event , info => Arg }), ? LOG_CRITICAL (#{ what => critical_event , info => Arg }), Use them in correspondence with the appropriate log level. Please be mindful of what is logged and which log level is used for it.","title":"Logging macros"},{"location":"developers-guide/logging/#logging-levels","text":"A system operator can choose the global log level by setting loglevel in mongooseim.toml . Possible values are the standard syslog severity levels, plus all or none: \"all\" , \"debug\" , \"info\" , \"notice\" , \"warning\" , \"error\" , \"critical\" , \"alert\" , \"emergency\" , and \"none\" . 1 2 [general] loglevel = \"notice\" If a user sets the log level to all , then they would see all messages in logs. Levels warning and error are the most commonly used for production systems.","title":"Logging levels"},{"location":"developers-guide/logging/#logging-format","text":"We use structured logging as inspired by Ferd's post . We also use a modified logfmt format as one of the possible default logger formatters. This format is Splunk and ELK friendly. Check the list of fields for fields documentation. what => something_interesting field is required. 1 2 3 4 5 6 7 8 9 10 ? LOG_ERROR (#{ what => check_password_failed , reason => Error , user => LUser }) try ... catch Class : Reason : StackTrace -> ? LOG_ERROR (#{ what => check_password_failed , class => Class , reason => Reason , stacktrace => StackTrace }), erlang : raise ( Class , Reason , StackTrace ) end Field user => <<\"alice\">> is often used too. A common way to name an error event is what => function_name_failed . For example, what => remove_user_failed . Use the advice critically, it would not work well for any function. Counterexample: 1 2 3 handle_info ( Info , State ) -> ? LOG_WARNING (#{ what => unexpected_message , msg => Info }), { noreply , State }.","title":"Logging format"},{"location":"developers-guide/logging/#filtering-logs-by-module","text":"Setting loglevel to debug can lead to a flood of messages in logs. To set a different loglevel for just one module, call: 1 2 mongoose_logs : set_global_loglevel ( error ). mongoose_logs : set_module_loglevel ( mod_mam , debug ). This code sets the loglevel to error for all log messages, except for those generated by mod_mam . All messages from mod_mam would be logged.","title":"Filtering logs by module"},{"location":"developers-guide/mod_amp_developers_guide/","text":"The Developer's Guide to mod_amp This is a quick, introductory guide for developers wishing to extend mod_amp or plug into the message processing system. Source Files, Headers and Tests include/amp.hrl This header file contains the amp XML namespace and the types used by mod_amp: amp_rule() and amp_strategy() are the top-level points of interest. src/mod_amp.erl This module is responsible for plugging in all the other components. It's main driving function is filter_packet . After determining that a given message contains amp rules, the module proceeds by determining its strategy for the message and comparing it against the rules. The server may return an error at multiple points in its work-flow. This is signaled by calling the function send_error_and_drop/3 or send_errors_and_drop/2 . src/amp.erl This module is responsible for parsing rules from incoming elements and serializing server responses in the proper format. binaries_to_rule/3 can return either a proper amp_rule() , or an amp_invalid_rule() , which does not contain sensible values, but can be used by the server to create an appropriate error message. test/amp_SUITE.erl Tests for the API functions exported by amp.erl src/amp_strategy.erl This module is where the server-side hook for determining a default action for a given message is performed. Calls to ejabberd_sm are made here. src/amp_resolver.erl This module models the resolution of amp rules, given a certain strategy. Also, the function verify_rule_support is hard-coded here to return an unsupported- type error for unsupported rule actions and values. test/amp_resolver_SUITE.erl These tests verify that the amp_resolver:check_condition/4 hook works as intended, i.e: that the rules which would be triggered given a particular server-side strategy actually do get triggered, and that all others get rejected. test/amp_gen.erl This module contains PropEr generators for server-side strategies, as well as valid and invalid amp rules. Used in both test suites. Hooks for Other Modules If your module would like to have some say in the amp decision making process, please refer to the hooks: amp_determine_strategy and amp_check_condition . Remember that the hook for check_condition is a fold on a boolean(), and should behave like a variadic or . I.e: once a rule is deemed to apply, other hooks SHOULD NOT revert this value to false. Cf. this code from amp_resolver : 1 2 3 4 5 6 7 - spec check_condition ( any (), amp_strategy (), amp_condition (), amp_value ()) -> boolean (). check_condition ( HookAcc , Strategy , Condition , Value ) -> case HookAcc of true -> true ; %% SOME OTHER HOOK HAS DECIDED THAT THIS RULE APPLIES %% _ -> resolve ( Strategy , Condition , Value ) %% PERFORM LOCAL CHECK %% end . Ideas for Further Development Easy Implement the 'alert' and 'drop' action types. Implement support for the 'stored' value for 'deliver' Medium Implement the security policy described in the third bullet point of XEP-0079, Section 9 (Security Considerations). This will require that amp_resolver:verify_support also take the {From, To, Packet} :: hook_data() parameter and check that From is permitted to know about To 's presence. If they are not, then the server should treat this as a not-acceptable amp request. Make support for various actions, conditions and values configurable. This will require implementing an intelligent mechanism for matching the user-supplied rules with what's configured server-side. Currently, server-side support is hard-coded in several places: Disco announcements are in mod_amp:amp_features/0 Rule support is in amp_resolver:verify_rule_support/1 Every other function that deals with rules can handle unsupported rules, but ignores their meaning and decides that these rules don't apply. Hard Implement support for the 'expire-at' condition.","title":"mod_amp development"},{"location":"developers-guide/mod_amp_developers_guide/#the-developers-guide-to-mod_amp","text":"This is a quick, introductory guide for developers wishing to extend mod_amp or plug into the message processing system.","title":"The Developer's Guide to mod_amp"},{"location":"developers-guide/mod_amp_developers_guide/#source-files-headers-and-tests","text":"include/amp.hrl This header file contains the amp XML namespace and the types used by mod_amp: amp_rule() and amp_strategy() are the top-level points of interest. src/mod_amp.erl This module is responsible for plugging in all the other components. It's main driving function is filter_packet . After determining that a given message contains amp rules, the module proceeds by determining its strategy for the message and comparing it against the rules. The server may return an error at multiple points in its work-flow. This is signaled by calling the function send_error_and_drop/3 or send_errors_and_drop/2 . src/amp.erl This module is responsible for parsing rules from incoming elements and serializing server responses in the proper format. binaries_to_rule/3 can return either a proper amp_rule() , or an amp_invalid_rule() , which does not contain sensible values, but can be used by the server to create an appropriate error message. test/amp_SUITE.erl Tests for the API functions exported by amp.erl src/amp_strategy.erl This module is where the server-side hook for determining a default action for a given message is performed. Calls to ejabberd_sm are made here. src/amp_resolver.erl This module models the resolution of amp rules, given a certain strategy. Also, the function verify_rule_support is hard-coded here to return an unsupported- type error for unsupported rule actions and values. test/amp_resolver_SUITE.erl These tests verify that the amp_resolver:check_condition/4 hook works as intended, i.e: that the rules which would be triggered given a particular server-side strategy actually do get triggered, and that all others get rejected. test/amp_gen.erl This module contains PropEr generators for server-side strategies, as well as valid and invalid amp rules. Used in both test suites.","title":"Source Files, Headers and Tests"},{"location":"developers-guide/mod_amp_developers_guide/#hooks-for-other-modules","text":"If your module would like to have some say in the amp decision making process, please refer to the hooks: amp_determine_strategy and amp_check_condition . Remember that the hook for check_condition is a fold on a boolean(), and should behave like a variadic or . I.e: once a rule is deemed to apply, other hooks SHOULD NOT revert this value to false. Cf. this code from amp_resolver : 1 2 3 4 5 6 7 - spec check_condition ( any (), amp_strategy (), amp_condition (), amp_value ()) -> boolean (). check_condition ( HookAcc , Strategy , Condition , Value ) -> case HookAcc of true -> true ; %% SOME OTHER HOOK HAS DECIDED THAT THIS RULE APPLIES %% _ -> resolve ( Strategy , Condition , Value ) %% PERFORM LOCAL CHECK %% end .","title":"Hooks for Other Modules"},{"location":"developers-guide/mod_amp_developers_guide/#ideas-for-further-development","text":"","title":"Ideas for Further Development"},{"location":"developers-guide/mod_amp_developers_guide/#easy","text":"Implement the 'alert' and 'drop' action types. Implement support for the 'stored' value for 'deliver'","title":"Easy"},{"location":"developers-guide/mod_amp_developers_guide/#medium","text":"Implement the security policy described in the third bullet point of XEP-0079, Section 9 (Security Considerations). This will require that amp_resolver:verify_support also take the {From, To, Packet} :: hook_data() parameter and check that From is permitted to know about To 's presence. If they are not, then the server should treat this as a not-acceptable amp request. Make support for various actions, conditions and values configurable. This will require implementing an intelligent mechanism for matching the user-supplied rules with what's configured server-side. Currently, server-side support is hard-coded in several places: Disco announcements are in mod_amp:amp_features/0 Rule support is in amp_resolver:verify_rule_support/1 Every other function that deals with rules can handle unsupported rules, but ignores their meaning and decides that these rules don't apply.","title":"Medium"},{"location":"developers-guide/mod_amp_developers_guide/#hard","text":"Implement support for the 'expire-at' condition.","title":"Hard"},{"location":"developers-guide/mod_muc_light_developers_guide/","text":"The Developer's Guide to mod_muc_light This is an in-depth guide on mod_muc_light design decisions and implementation. Source, header and test suite files All source files can be found in src/muc_light/ . mod_muc_light.erl Main module. It implements the gen_mod behaviour. It subscribes to some essential hooks and exports several functions, mostly callbacks. It handles integration with mod_disco , mod_privacy and mod_roster . All operations that take place outside the room (including the room creation) are implemented here. Last but not least - this module prevents service-unavailable errors being sent when an offline user receives a groupchat message. mod_muc_light_codec.erl A behaviour implemented by modules that translate the MUC Light internal data format to stanzas for clients and vice versa. Besides specifying callbacks, it implements generic error encoder function. mod_muc_light_codec_legacy.erl An implementation of XEP-0045 compatibility mode. Note, that while some parts of the legacy mode are implemented directly in mod_muc_light.erl , the stanza translation takes place here. It does not utilise the full potential of the MUC Light extension but allows using the standard MUC implementation in XMPP client libraries for prototyping or the transition phase. Not recommended for production systems (less efficient than modern codec and requires more round-trips). mod_muc_light_codec_modern.erl An implementation of a modern MUC Light protocol, described in the XEP. Supports all MUC Light features. mod_muc_light_commands.erl MUC Light-related commands. They are registered in the mongoose_commands module, so they are available via the REST API. mod_muc_light_db.erl A behaviour implemented by database backends for the MUC Light extension. mod_muc_light_db_mnesia.erl A Mnesia backend for this extension. Uses transactions for room metadata updates (configuration and affiliation list) and dirty reads whenever possible. mod_muc_light_db_rdbms.erl An SQL backend for mod_muc_light . create_room , destroy_room , remove_user , set_config , modify_aff_users execute at least one query in a single transaction. room_exists , get_user_rooms , get_user_rooms_count , get_config , get_blocking , set_blocking , get_aff_users execute only one query per function call. get_info executes 3 SELECT queries, not protected by a transaction. mod_muc_light_db_rdbms_sql.erl SQL queries for mod_muc_light_db_rdbms.erl . mod_muc_light_room.erl This module handles everything that occurs inside the room: access checks, metadata changes, message broadcasting etc. mod_muc_light_utils.erl Utilities shared by other MUC Light modules. It includes the room configuration processing and the affiliation logic. The header file can be found in include/ . mod_muc_light.hrl It contains definitions of MUC Light namespaces, default configuration options and several common data types and records. There are 2 test suites and one helper module in big_tests/tests . muc_light_SUITE.erl Main test suite, checks all the most important functionalities of the MUC Light extension. muc_light_legacy_SUITE.erl muc_light_SUITE.erl equivalent that uses XEP-0045 compatibility mode. muc_helper.erl Provides handy iterators over room participants. Used in MUC Light suites but in the future could be used in muc_SUITE as well. Hooks handled by this extension offline_groupchat_message_hook handled by mod_muc_light:prevent_service_unavailable/3 Prevents the default behaviour of sending service-unavailable error to the room when a groupchat message is sent to an offline occupant. remove_user handled by mod_muc_light:remove_user/2 Triggers DB cleanup of all data related to the removed user. Includes a broadcast of a notification about user removal from occupied rooms. disco_local_items handled by mod_muc_light:get_muc_service/5 Adds a MUC service item to the Disco result. Uses either a MUC Light or a classic MUC namespace when the legacy mode is enabled. roster_get handled by mod_muc_light:add_rooms_to_roster/2 Injects room items to the user's roster. privacy_iq_get , privacy_iq_set handled by mod_muc_light:process_iq_get/5 and mod_muc_light:process_iq_set/4 respectively These callbacks handle blocking settings when legacy mode is enabled. is_muc_room_owner , can_access_room , can_access_identity used by mod_muc_light:is_room_owner/3 , mod_muc_light:can_access_room/3 and mod_muc_light:can_access_identity/3 respectively Callbacks that provide essential data for the mod_mam_muc extension. Hooks executed by this extension filter_room_packet by codecs Allows mod_mam_muc to archive groupchat messages. forget_room by mod_muc_light_db_mnesia and mod_muc_light_room It is a part of mod_mam_muc integration as well. A hook used for MAM cleanup upon room destruction. Advantages and drawbacks (compared to classic MUC) The new MUC implementation brings quite a few benefits to the table: It is fully distributed - Does not have SPOF, concurrent senders do not block each other, especially in large rooms. Message broadcasting is being done in sender c2s context. It does not use presences - Much less traffic and stable membership information, especially on mobile networks. It provides built-in blocking support - Instead of blocking traffic like Privacy Lists do, it handles blocklists internally, preventing the blocker from being added to or by blocked entities. Less round-trips - A room can be created and configured with an initial list of occupants with a single request. Versioning - Reduces traffic and allows clients to reliably and quickly detect that the room state has changed. Isolation - Processing errors are contained in a sender context, not affecting other room occupants. Fully customisable room configuration - Your users can store any meta room information you allow. Drawbacks are: Requires DB transactions to ensure Room state consistency. Fetches the occupant list from DB for every message that is broadcasted. Due to concurrent message broadcast, it is possible for occupants to receive messages in a different order (given the messages are broadcasted at the exactly same time). With stream resumption disabled or when resumption times out, user may miss a message in a following scenario: Message A archived Message B archived Message B delivered to the user User loses connection Resumption timeout User queries MAM for all messages after B and misses A Ideas for Further Development Easy Add more tests for negative cases Medium Add optional per-room processes to avoid the need of DB transactions and ensure message ordering (maybe \"hard\"?). Riak backend Redis backend Hard Room metadata cache (maybe \"medium\"?).","title":"mod_muc_light developers doc"},{"location":"developers-guide/mod_muc_light_developers_guide/#the-developers-guide-to-mod_muc_light","text":"This is an in-depth guide on mod_muc_light design decisions and implementation.","title":"The Developer's Guide to mod_muc_light"},{"location":"developers-guide/mod_muc_light_developers_guide/#source-header-and-test-suite-files","text":"All source files can be found in src/muc_light/ . mod_muc_light.erl Main module. It implements the gen_mod behaviour. It subscribes to some essential hooks and exports several functions, mostly callbacks. It handles integration with mod_disco , mod_privacy and mod_roster . All operations that take place outside the room (including the room creation) are implemented here. Last but not least - this module prevents service-unavailable errors being sent when an offline user receives a groupchat message. mod_muc_light_codec.erl A behaviour implemented by modules that translate the MUC Light internal data format to stanzas for clients and vice versa. Besides specifying callbacks, it implements generic error encoder function. mod_muc_light_codec_legacy.erl An implementation of XEP-0045 compatibility mode. Note, that while some parts of the legacy mode are implemented directly in mod_muc_light.erl , the stanza translation takes place here. It does not utilise the full potential of the MUC Light extension but allows using the standard MUC implementation in XMPP client libraries for prototyping or the transition phase. Not recommended for production systems (less efficient than modern codec and requires more round-trips). mod_muc_light_codec_modern.erl An implementation of a modern MUC Light protocol, described in the XEP. Supports all MUC Light features. mod_muc_light_commands.erl MUC Light-related commands. They are registered in the mongoose_commands module, so they are available via the REST API. mod_muc_light_db.erl A behaviour implemented by database backends for the MUC Light extension. mod_muc_light_db_mnesia.erl A Mnesia backend for this extension. Uses transactions for room metadata updates (configuration and affiliation list) and dirty reads whenever possible. mod_muc_light_db_rdbms.erl An SQL backend for mod_muc_light . create_room , destroy_room , remove_user , set_config , modify_aff_users execute at least one query in a single transaction. room_exists , get_user_rooms , get_user_rooms_count , get_config , get_blocking , set_blocking , get_aff_users execute only one query per function call. get_info executes 3 SELECT queries, not protected by a transaction. mod_muc_light_db_rdbms_sql.erl SQL queries for mod_muc_light_db_rdbms.erl . mod_muc_light_room.erl This module handles everything that occurs inside the room: access checks, metadata changes, message broadcasting etc. mod_muc_light_utils.erl Utilities shared by other MUC Light modules. It includes the room configuration processing and the affiliation logic. The header file can be found in include/ . mod_muc_light.hrl It contains definitions of MUC Light namespaces, default configuration options and several common data types and records. There are 2 test suites and one helper module in big_tests/tests . muc_light_SUITE.erl Main test suite, checks all the most important functionalities of the MUC Light extension. muc_light_legacy_SUITE.erl muc_light_SUITE.erl equivalent that uses XEP-0045 compatibility mode. muc_helper.erl Provides handy iterators over room participants. Used in MUC Light suites but in the future could be used in muc_SUITE as well.","title":"Source, header and test suite files"},{"location":"developers-guide/mod_muc_light_developers_guide/#hooks-handled-by-this-extension","text":"offline_groupchat_message_hook handled by mod_muc_light:prevent_service_unavailable/3 Prevents the default behaviour of sending service-unavailable error to the room when a groupchat message is sent to an offline occupant. remove_user handled by mod_muc_light:remove_user/2 Triggers DB cleanup of all data related to the removed user. Includes a broadcast of a notification about user removal from occupied rooms. disco_local_items handled by mod_muc_light:get_muc_service/5 Adds a MUC service item to the Disco result. Uses either a MUC Light or a classic MUC namespace when the legacy mode is enabled. roster_get handled by mod_muc_light:add_rooms_to_roster/2 Injects room items to the user's roster. privacy_iq_get , privacy_iq_set handled by mod_muc_light:process_iq_get/5 and mod_muc_light:process_iq_set/4 respectively These callbacks handle blocking settings when legacy mode is enabled. is_muc_room_owner , can_access_room , can_access_identity used by mod_muc_light:is_room_owner/3 , mod_muc_light:can_access_room/3 and mod_muc_light:can_access_identity/3 respectively Callbacks that provide essential data for the mod_mam_muc extension.","title":"Hooks handled by this extension"},{"location":"developers-guide/mod_muc_light_developers_guide/#hooks-executed-by-this-extension","text":"filter_room_packet by codecs Allows mod_mam_muc to archive groupchat messages. forget_room by mod_muc_light_db_mnesia and mod_muc_light_room It is a part of mod_mam_muc integration as well. A hook used for MAM cleanup upon room destruction.","title":"Hooks executed by this extension"},{"location":"developers-guide/mod_muc_light_developers_guide/#advantages-and-drawbacks-compared-to-classic-muc","text":"The new MUC implementation brings quite a few benefits to the table: It is fully distributed - Does not have SPOF, concurrent senders do not block each other, especially in large rooms. Message broadcasting is being done in sender c2s context. It does not use presences - Much less traffic and stable membership information, especially on mobile networks. It provides built-in blocking support - Instead of blocking traffic like Privacy Lists do, it handles blocklists internally, preventing the blocker from being added to or by blocked entities. Less round-trips - A room can be created and configured with an initial list of occupants with a single request. Versioning - Reduces traffic and allows clients to reliably and quickly detect that the room state has changed. Isolation - Processing errors are contained in a sender context, not affecting other room occupants. Fully customisable room configuration - Your users can store any meta room information you allow. Drawbacks are: Requires DB transactions to ensure Room state consistency. Fetches the occupant list from DB for every message that is broadcasted. Due to concurrent message broadcast, it is possible for occupants to receive messages in a different order (given the messages are broadcasted at the exactly same time). With stream resumption disabled or when resumption times out, user may miss a message in a following scenario: Message A archived Message B archived Message B delivered to the user User loses connection Resumption timeout User queries MAM for all messages after B and misses A","title":"Advantages and drawbacks (compared to classic MUC)"},{"location":"developers-guide/mod_muc_light_developers_guide/#ideas-for-further-development","text":"","title":"Ideas for Further Development"},{"location":"developers-guide/mod_muc_light_developers_guide/#easy","text":"Add more tests for negative cases","title":"Easy"},{"location":"developers-guide/mod_muc_light_developers_guide/#medium","text":"Add optional per-room processes to avoid the need of DB transactions and ensure message ordering (maybe \"hard\"?). Riak backend Redis backend","title":"Medium"},{"location":"developers-guide/mod_muc_light_developers_guide/#hard","text":"Room metadata cache (maybe \"medium\"?).","title":"Hard"},{"location":"developers-guide/mongoose_wpool/","text":"mongoose_wpool All the outgoing pools configured by the outgoing_pools option are hidden behind the mongoose_wpool API. Every pool is described by a tuple {Type, Host, Tag, PoolOptions, ConnectionOptions} (see outgoing pools for details about each element of the tuple). Supervision tree mongoose_wpool_sup supervisor for every type of the pool. Under it there can be many children of: mongoose_wpool_type_sup is started on-demand when a pool of given type is started. Many pools of the same type are supervised by the supervisor. Its children are: mongoose_wpool_mgr all the pools of the same type are managed by a manager. It's responsible for starting, stopping and restarting the pool. Restarting happens when the main worker_pool process for the pool is stopped unintentionally. This usually happens when there was too many restarts of worker processes. many worker_pool supervisors holding a specific pool are on the same level as the manager. The mongoose_wpool_mgr manages the pool by setting monitor for every started pool. Implementing new pool type To add a new pool type, create a mongoose_wpool_NEW_TYPE module implementing the mongoose_wpool behaviour. This means that for a new type xyz we need to create a mongoose_wpool_xyz module. Then we can use the xyz type to start the pool via outgoing_pools option or directly via the mongoose_wpool API.","title":"mongoose_wpool"},{"location":"developers-guide/mongoose_wpool/#mongoose_wpool","text":"All the outgoing pools configured by the outgoing_pools option are hidden behind the mongoose_wpool API. Every pool is described by a tuple {Type, Host, Tag, PoolOptions, ConnectionOptions} (see outgoing pools for details about each element of the tuple).","title":"mongoose_wpool"},{"location":"developers-guide/mongoose_wpool/#supervision-tree","text":"mongoose_wpool_sup supervisor for every type of the pool. Under it there can be many children of: mongoose_wpool_type_sup is started on-demand when a pool of given type is started. Many pools of the same type are supervised by the supervisor. Its children are: mongoose_wpool_mgr all the pools of the same type are managed by a manager. It's responsible for starting, stopping and restarting the pool. Restarting happens when the main worker_pool process for the pool is stopped unintentionally. This usually happens when there was too many restarts of worker processes. many worker_pool supervisors holding a specific pool are on the same level as the manager. The mongoose_wpool_mgr manages the pool by setting monitor for every started pool.","title":"Supervision tree"},{"location":"developers-guide/mongoose_wpool/#implementing-new-pool-type","text":"To add a new pool type, create a mongoose_wpool_NEW_TYPE module implementing the mongoose_wpool behaviour. This means that for a new type xyz we need to create a mongoose_wpool_xyz module. Then we can use the xyz type to start the pool via outgoing_pools option or directly via the mongoose_wpool API.","title":"Implementing new pool type"},{"location":"developers-guide/xep_tool/","text":"XEP-tool usage The XEP-tool is the answer for developers who wonder how to maintain an actual list of supported XEPs. It's a fast and easy way to automatically produce documentation from raw, beam files. This is a quick guide on how to enjoy the usage of the XEP-tool. Sign your module file first The architecture of MongooseIM determines that almost every XEP or feature implementation resides in its own file. It is not strictly enforced but usually the file is named with a mod_ prefix. For example mod_privacy file implements XEP-0016: Privacy Lists . Mandatory xep and version In order to let the XEP-tool know about your module, we add a special attribute xep at the beginning of the mod_privacy module: 1 - xep ([{ xep , 16 }, { version , \"1.6\" }]). Now we know that this module implements to XEP-0016: Privacy Lists with version 1.6. It gives the tool enough information to generate a URL to the XEP homepage. There are also some variations of the xep attribute like: You ought to remember to specify xep and version attributes every time. You can also put several xep attributes in one module. For example mod_mam_muc implements attributes of XEP-0313: Message Archive Management and also XEP-0045: Multi-User Chat . Just list them one after another: 1 2 - xep ([{ xep , 45 }, { version , \"1.25\" }]). - xep ([{ xep , 313 }, { version , \"0.5.1\" }]). Specific URL 1 - xep ([{ xep , 16 }, { version , \"1.6\" }, { url , \"http://xmpp.org/extensions/xep-0016.html\" }]). Comment 1 - xep ([{ xep , 16 }, { version , \"1.6\" }, { comment , \"Example comment: Partial Implemented\" }]). And the XEP-tool will do the work! Compile and run You've just finished marking your modules. The only thing left is to make compile MongooseIM in order to generate the .beam files. To run the XEP tool, you must issue an additional subcommand. There are two choices: markdown : to produce a markdown list of supported XEPs. This option also needs an output file as an argument. list : to print out supported XEPs to the console. For example, to run our XEP-tool with a markdown command, type: 1 make xeplist Or do it manually: 1 $MONGOOSEIM_ROOT /tools/xep_tool/xep_tool.escript markdown <PATH_TO_EBIN> <OPTIONAL_OUTPUT_FILE> In our case, from MongooseIM root directory: 1 ./tools/xep_tool/xep_tool.escript markdown ebin list.md The Markdown list with unique XEP names and URLs is saved to file list.md You can copy-paste the content of this file to your main README file. Generated file example XEP-0012: Last Activity XEP-0016: Privacy Lists XEP-0018: Invisible Presence XEP-0022: Message Events XEP-0023: Message Expiration XEP-0030: Service Discovery XEP-0045: Multi-User Chat XEP-0049: Private XML Storage XEP-0050: Ad-Hoc Commands XEP-0054: vcard-temp XEP-0055: Jabber Search XEP-0059: Result Set Management XEP-0068: Field Standardization for Data Forms XEP-0077: In-Band Registration XEP-0078: Non-SASL Authentication XEP-0079: Advanced Message Processing XEP-0082: XMPP Date and Time Profiles XEP-0083: Nested Roster Groups XEP-0085: Chat State Notifications XEP-0086: Error Condition Mappings XEP-0093: Roster Item Exchange XEP-0114: Jabber Component Protocol XEP-0124: Bidirectional-streams Over Synchronous HTTP (BOSH) XEP-0126: Invisibility XEP-0138: Stream Compression XEP-0157: Contact Addresses for XMPP Services XEP-0160: Best Practices for Handling Offline Messages XEP-0170: Recommended Order of Stream Feature Negotiation XEP-0175: Best Practices for Use of SASL ANONYMOUS XEP-0198: Stream Management XEP-0199: XMPP Ping XEP-0202: Entity Time XEP-0206: XMPP Over BOSH XEP-0212: XMPP Basic Server 2008 XEP-0237: Roster Versioning XEP-0279: Server IP Check XEP-0280: Message Carbons XEP-0313: Message Archive Management","title":"xep-tool usage"},{"location":"developers-guide/xep_tool/#xep-tool-usage","text":"The XEP-tool is the answer for developers who wonder how to maintain an actual list of supported XEPs. It's a fast and easy way to automatically produce documentation from raw, beam files. This is a quick guide on how to enjoy the usage of the XEP-tool.","title":"XEP-tool usage"},{"location":"developers-guide/xep_tool/#sign-your-module-file-first","text":"The architecture of MongooseIM determines that almost every XEP or feature implementation resides in its own file. It is not strictly enforced but usually the file is named with a mod_ prefix. For example mod_privacy file implements XEP-0016: Privacy Lists .","title":"Sign your module file first"},{"location":"developers-guide/xep_tool/#mandatory-xep-and-version","text":"In order to let the XEP-tool know about your module, we add a special attribute xep at the beginning of the mod_privacy module: 1 - xep ([{ xep , 16 }, { version , \"1.6\" }]). Now we know that this module implements to XEP-0016: Privacy Lists with version 1.6. It gives the tool enough information to generate a URL to the XEP homepage. There are also some variations of the xep attribute like: You ought to remember to specify xep and version attributes every time. You can also put several xep attributes in one module. For example mod_mam_muc implements attributes of XEP-0313: Message Archive Management and also XEP-0045: Multi-User Chat . Just list them one after another: 1 2 - xep ([{ xep , 45 }, { version , \"1.25\" }]). - xep ([{ xep , 313 }, { version , \"0.5.1\" }]).","title":"Mandatory xep and version"},{"location":"developers-guide/xep_tool/#specific-url","text":"1 - xep ([{ xep , 16 }, { version , \"1.6\" }, { url , \"http://xmpp.org/extensions/xep-0016.html\" }]).","title":"Specific URL"},{"location":"developers-guide/xep_tool/#comment","text":"1 - xep ([{ xep , 16 }, { version , \"1.6\" }, { comment , \"Example comment: Partial Implemented\" }]). And the XEP-tool will do the work!","title":"Comment"},{"location":"developers-guide/xep_tool/#compile-and-run","text":"You've just finished marking your modules. The only thing left is to make compile MongooseIM in order to generate the .beam files. To run the XEP tool, you must issue an additional subcommand. There are two choices: markdown : to produce a markdown list of supported XEPs. This option also needs an output file as an argument. list : to print out supported XEPs to the console. For example, to run our XEP-tool with a markdown command, type: 1 make xeplist Or do it manually: 1 $MONGOOSEIM_ROOT /tools/xep_tool/xep_tool.escript markdown <PATH_TO_EBIN> <OPTIONAL_OUTPUT_FILE> In our case, from MongooseIM root directory: 1 ./tools/xep_tool/xep_tool.escript markdown ebin list.md The Markdown list with unique XEP names and URLs is saved to file list.md You can copy-paste the content of this file to your main README file.","title":"Compile and run"},{"location":"developers-guide/xep_tool/#generated-file-example","text":"XEP-0012: Last Activity XEP-0016: Privacy Lists XEP-0018: Invisible Presence XEP-0022: Message Events XEP-0023: Message Expiration XEP-0030: Service Discovery XEP-0045: Multi-User Chat XEP-0049: Private XML Storage XEP-0050: Ad-Hoc Commands XEP-0054: vcard-temp XEP-0055: Jabber Search XEP-0059: Result Set Management XEP-0068: Field Standardization for Data Forms XEP-0077: In-Band Registration XEP-0078: Non-SASL Authentication XEP-0079: Advanced Message Processing XEP-0082: XMPP Date and Time Profiles XEP-0083: Nested Roster Groups XEP-0085: Chat State Notifications XEP-0086: Error Condition Mappings XEP-0093: Roster Item Exchange XEP-0114: Jabber Component Protocol XEP-0124: Bidirectional-streams Over Synchronous HTTP (BOSH) XEP-0126: Invisibility XEP-0138: Stream Compression XEP-0157: Contact Addresses for XMPP Services XEP-0160: Best Practices for Handling Offline Messages XEP-0170: Recommended Order of Stream Feature Negotiation XEP-0175: Best Practices for Use of SASL ANONYMOUS XEP-0198: Stream Management XEP-0199: XMPP Ping XEP-0202: Entity Time XEP-0206: XMPP Over BOSH XEP-0212: XMPP Basic Server 2008 XEP-0237: Roster Versioning XEP-0279: Server IP Check XEP-0280: Message Carbons XEP-0313: Message Archive Management","title":"Generated file example"},{"location":"migrations/3.1.1_3.2.0/","text":"odbc renamed to rdbms in module names and options For MongooseIM users: simply replace all instances of odbc in your config files with rdbms . E.g. {auth_method, odbc}. would now be {auth_method, rdbms}. . It's also important to note that all metrics that previously contained odbc in their names have also been renamed to contain rdbms instead. Please note that odbc_server has been completely replaced with new outgoing_pools (see one of the next sections of this document) config element. For developers calling MongooseIM modules: most modules, functions and atoms had odbc in their names replaced with rdbms . The only exceptions to this rule were names actually pertaining to the ODBC driver, e.g. mongoose_rdbms_odbc . ejabberd.cfg renamed to mongooseim.cfg Rename the existing config file of MongooseIM from ejabberd.cfg to mongooseim.cfg . Pools configuration Configuring pools to external services has changed, please see Outgoing Connection doc for more details. NOTE: Keep in mind that outgoing_pools is a list of pools, it may turn out that you will have more than one entry in the list when more than a single outgoing pool is needed. Example - Old format 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 { elasticsearch_server , [{ host , \"elastic.host.com\" }, { port , 9042 }]}. { riak_server , [{ pool_size , 20 }, { address , \"127.0.0.1\" }, { port , 8087 }, { riak_pb_socket_opts , []}]}. { http_connections , [{ conn1 , [{ server , \"http://server:8080\" }, { pool_size , 50 }]} ]}. { cassandra_servers , [ { default , 100 , [ { servers , [ { \"cassandra_server1.example.com\" , 9042 }, { \"cassandra_server2.example.com\" , 9042 }, { \"cassandra_server3.example.com\" , 9042 }, { \"cassandra_server4.example.com\" , 9042 } ] }, { keyspace , \"big_mongooseim\" } ] } ] }. Example - New format This section provides direct \"translation\" of configuration from \"Old format\" section. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 { outgoing_pools , [ { elastic , global , default , [], [{ host , \"elastic.host.com\" }, { port , 9042 }]}, { riak , global , default , [{ workers , 20 }], [{ address , \"127.0.0.1\" }, { port , 8087 }]}, { http , global , conn1 , [{ workers , 50 }], [{ server , \"http://server:8080\" }]}, { cassandra , global , default , [{ workers , 100 }], [ { servers , [ { \"cassandra_server1.example.com\" , 9042 }, { \"cassandra_server2.example.com\" , 9042 }, { \"cassandra_server3.example.com\" , 9042 }, { \"cassandra_server4.example.com\" , 9042 } ]}, { keyspace , \"big_mongooseim\" } ]} ]}. RDBMS configuration migration RDBMS pools are no longer configured by a {pool, odbc, _} tuple, instead using the generic outgoing pools mechanism. The connection configuration is now passed via server option of the pool insted of being configured via a top-level {odbc_server, _} tuple. Similarly, the number of workers is no longer configured by odbc_pool_size , and the default pool no longer set by odbc_pool . A top-level odbc_keepalive_interval is now also specified as an option for a specific pool. For example: 1 2 3 4 5 { odbc_pool_size , 10 }. { pool , odbc , default }. { odbc_server_type , mssql }. { odbc_server , \"DSN=mongoose-mssql;UID=sa;PWD=mongooseim_secret+ESL123\" }. { odbc_keepalive_interval , 10 }. will now become: 1 2 3 4 5 { rdbms_server_type , mssql }. { outgoing_pools , [ { rdbms , global , default , [{ workers , 10 }], [{ server , \"DSN=mongoose-mssql;UID=sa;PWD=mongooseim_secret+ESL123\" }, { keepalive_interval , 10 }]} ]}. Note that odbc_server_type was only renamed to rdbms_server_type and still remains a top-level configuration value. sm_backend If you had the sm_backend set to redis like below: 1 { sm_backend , { redis , [{ pool_size , 3 }, { worker_config , [{ host , \"localhost\" }, { port , 6379 }]}]}}. The pool needs to be defined inside outgoing_pools like this: 1 2 3 4 5 { outgoing_pools , [ { redis , global , default , [{ workers , 3 }], [{ host , \"localhost\" }, { port , 6379 }]} ]}. and the sm_backend configuration needs to changed to just: 1 { sm_backend , { redis , []}}. mod_global_distrib If you had mod_global_distrib configured in the following way: 1 2 3 4 5 6 7 { mod_global_distrib , [ (...) { redis , [ { pool_size , 24 }, { server , \"172.16.0.3\" } ]} ]} The redis pool needs to be defined inside outgoing_pools : 1 2 3 { outgoing_pools , [ { redis , global , global_distrib , [{ workers , 24 }], [{ host , \"172.16.0.3\" }]} ]}.","title":"3.1.1 to 3.2.0"},{"location":"migrations/3.1.1_3.2.0/#odbc-renamed-to-rdbms-in-module-names-and-options","text":"For MongooseIM users: simply replace all instances of odbc in your config files with rdbms . E.g. {auth_method, odbc}. would now be {auth_method, rdbms}. . It's also important to note that all metrics that previously contained odbc in their names have also been renamed to contain rdbms instead. Please note that odbc_server has been completely replaced with new outgoing_pools (see one of the next sections of this document) config element. For developers calling MongooseIM modules: most modules, functions and atoms had odbc in their names replaced with rdbms . The only exceptions to this rule were names actually pertaining to the ODBC driver, e.g. mongoose_rdbms_odbc .","title":"odbc renamed to rdbms in module names and options"},{"location":"migrations/3.1.1_3.2.0/#ejabberdcfg-renamed-to-mongooseimcfg","text":"Rename the existing config file of MongooseIM from ejabberd.cfg to mongooseim.cfg .","title":"ejabberd.cfg renamed to mongooseim.cfg"},{"location":"migrations/3.1.1_3.2.0/#pools-configuration","text":"Configuring pools to external services has changed, please see Outgoing Connection doc for more details. NOTE: Keep in mind that outgoing_pools is a list of pools, it may turn out that you will have more than one entry in the list when more than a single outgoing pool is needed.","title":"Pools configuration"},{"location":"migrations/3.1.1_3.2.0/#example-old-format","text":"1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 { elasticsearch_server , [{ host , \"elastic.host.com\" }, { port , 9042 }]}. { riak_server , [{ pool_size , 20 }, { address , \"127.0.0.1\" }, { port , 8087 }, { riak_pb_socket_opts , []}]}. { http_connections , [{ conn1 , [{ server , \"http://server:8080\" }, { pool_size , 50 }]} ]}. { cassandra_servers , [ { default , 100 , [ { servers , [ { \"cassandra_server1.example.com\" , 9042 }, { \"cassandra_server2.example.com\" , 9042 }, { \"cassandra_server3.example.com\" , 9042 }, { \"cassandra_server4.example.com\" , 9042 } ] }, { keyspace , \"big_mongooseim\" } ] } ] }.","title":"Example - Old format"},{"location":"migrations/3.1.1_3.2.0/#example-new-format","text":"This section provides direct \"translation\" of configuration from \"Old format\" section. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 { outgoing_pools , [ { elastic , global , default , [], [{ host , \"elastic.host.com\" }, { port , 9042 }]}, { riak , global , default , [{ workers , 20 }], [{ address , \"127.0.0.1\" }, { port , 8087 }]}, { http , global , conn1 , [{ workers , 50 }], [{ server , \"http://server:8080\" }]}, { cassandra , global , default , [{ workers , 100 }], [ { servers , [ { \"cassandra_server1.example.com\" , 9042 }, { \"cassandra_server2.example.com\" , 9042 }, { \"cassandra_server3.example.com\" , 9042 }, { \"cassandra_server4.example.com\" , 9042 } ]}, { keyspace , \"big_mongooseim\" } ]} ]}.","title":"Example - New format"},{"location":"migrations/3.1.1_3.2.0/#rdbms-configuration-migration","text":"RDBMS pools are no longer configured by a {pool, odbc, _} tuple, instead using the generic outgoing pools mechanism. The connection configuration is now passed via server option of the pool insted of being configured via a top-level {odbc_server, _} tuple. Similarly, the number of workers is no longer configured by odbc_pool_size , and the default pool no longer set by odbc_pool . A top-level odbc_keepalive_interval is now also specified as an option for a specific pool. For example: 1 2 3 4 5 { odbc_pool_size , 10 }. { pool , odbc , default }. { odbc_server_type , mssql }. { odbc_server , \"DSN=mongoose-mssql;UID=sa;PWD=mongooseim_secret+ESL123\" }. { odbc_keepalive_interval , 10 }. will now become: 1 2 3 4 5 { rdbms_server_type , mssql }. { outgoing_pools , [ { rdbms , global , default , [{ workers , 10 }], [{ server , \"DSN=mongoose-mssql;UID=sa;PWD=mongooseim_secret+ESL123\" }, { keepalive_interval , 10 }]} ]}. Note that odbc_server_type was only renamed to rdbms_server_type and still remains a top-level configuration value.","title":"RDBMS configuration migration"},{"location":"migrations/3.1.1_3.2.0/#sm_backend","text":"If you had the sm_backend set to redis like below: 1 { sm_backend , { redis , [{ pool_size , 3 }, { worker_config , [{ host , \"localhost\" }, { port , 6379 }]}]}}. The pool needs to be defined inside outgoing_pools like this: 1 2 3 4 5 { outgoing_pools , [ { redis , global , default , [{ workers , 3 }], [{ host , \"localhost\" }, { port , 6379 }]} ]}. and the sm_backend configuration needs to changed to just: 1 { sm_backend , { redis , []}}.","title":"sm_backend"},{"location":"migrations/3.1.1_3.2.0/#mod_global_distrib","text":"If you had mod_global_distrib configured in the following way: 1 2 3 4 5 6 7 { mod_global_distrib , [ (...) { redis , [ { pool_size , 24 }, { server , \"172.16.0.3\" } ]} ]} The redis pool needs to be defined inside outgoing_pools : 1 2 3 { outgoing_pools , [ { redis , global , global_distrib , [{ workers , 24 }], [{ host , \"172.16.0.3\" }]} ]}.","title":"mod_global_distrib"},{"location":"migrations/3.3.0_3.4.0/","text":"New field in Message Archive Management MUC entries: Sender ID As a part of ensuring GDPR compliance, it is essential to be able to efficiently query MAM MUC data via sender ID (to retrieve user's personal data). Originally, the sender JID could be found only as a part of an encoded XML message element, so finding all items sent by a certain user would be extremely inefficient (or rather: anti-efficient). MongooseIM 3.4.0 uses a modified schema for MAM MUC backends which enables a more efficient extraction. Below you may find migration instructions specific to your MAM backend. RDBMS Step 1 Please execute the following SQL statements on your MIM database: MySQL 1 2 ALTER TABLE mam_muc_message ADD COLUMN sender_id INT UNSIGNED ; CREATE INDEX i_mam_muc_message_sender_id USING BTREE ON mam_muc_message ( sender_id ); PostgreSQL 1 2 ALTER TABLE mam_muc_message ADD COLUMN sender_id INT ; CREATE INDEX i_mam_muc_message_sender_id ON mam_muc_message USING BTREE ( sender_id ); MSSQL 1 2 ALTER TABLE [ dbo ].[ mam_muc_message ] ADD sender_id bigint ; CREATE INDEX i_mam_muc_message_sender_id ON mam_muc_message ( sender_id ); Step 2 Now you have a schema that is compatible with MIM 3.4.0 but isn't GDPR-compliant yet because the new column has no meaningful data. Please pick your favourite scripting/programming language and populate the new column with the help of a dedicated script . You'll need to iterate over the whole mam_muc_message table with the following algorithm: Provide message column content to the script. The script returns sender's JID as username@server string. You need to split it to get a separate username and server. Select ID from mam_server_user by the username and server. If it doesn't exist, insert a new one ( id column is automatically incremented). Update the sender_id column in mam_muc_message with the retrieved ID. Cassandra Step 1 Please execute the following CQL statements on your MIM database: 1 2 3 4 USE mongooseim ; ALTER TABLE mam_muc_message ADD from_jid varchar ; CREATE INDEX ON mam_muc_message ( from_jid ); DESC mam_muc_message ; Step 2 Now you have a schema that is compatible with MIM 3.4.0 but isn't GDPR-compliant yet because the new column has no meaningful data. Please pick your favourite scripting/programming language and populate the new column with the help of a dedicated script . You'll need to iterate over the whole mam_muc_message table with the following algorithm: Extract the whole mam_muc_message table. Please make sure to use the paging feature of your Cassandra client, as the MAM tables tend to be very large. 1 SELECT * FROM mam_muc_message ; To make data extraction faster, MongooseIM stores 2 copies of the message in the table: 1 2 3 4 5 6 cqlsh:mongooseim> SELECT * FROM mam_muc_message WHERE id = 399582233150625537 ALLOW FILTERING; room_jid | with_nick | id | from_jid | message | nick_name -------------------------------+-----------+--------------------+----------+--------------------------------+----------- room-ad1d999b9e@muc.localhost | | 399582233150625537 | null | 0x8350000001...998de2fa8426837 | Sid room-ad1d999b9e@muc.localhost | Sid | 399582233150625537 | null | 0x8350000001...998de2fa8426837 | Sid The copy with an empty with_nick column must be updated. Extract the sender's JID from the message column in the same way as described in the RDBMS migration section. By default cassandra backend uses the eterm format. Update the from_jid column with the value of the extracted sender's JID : 1 2 3 4 5 6 7 cqlsh:mongooseim> UPDATE mam_muc_message SET from_jid = 'username@server' WHERE id = 399582233150625537 AND with_nick = '' AND room_jid = 'room-ad1d999b9e@muc.localhost'; cqlsh:mongooseim> SELECT * FROM mam_muc_message WHERE id = 399582233150625537 ALLOW FILTERING; room_jid | with_nick | id | from_jid | message | nick_name -------------------------------+-----------+--------------------+-----------------+--------------------------------+----------- room-ad1d999b9e@muc.localhost | | 399582233150625537 | username@server | 0x8350000001...998de2fa8426837 | Sid room-ad1d999b9e@muc.localhost | Sid | 399582233150625537 | null | 0x8350000001...998de2fa8426837 | Sid Riak Changes to Riak schema are backward compatible with the current MongooseIM release. This means that skipping the migration will cause only some of the new features (namely GDPR data retrival) to not work correctly. Step 1 Please update the Riak schema: 1 2 3 4 5 6 # Set the RIAK_HOST to your Riak HTTP endpoint # Set the RIAK_MAM_SCHEMA_PATH to point to new schema path, which # by default is: RIAK_MAM_SCHEMA_PATH=tools/mam_search_schema.xml curl -v -XPUT $RIAK_HOST /search/schema/mam \\ -H 'Content-Type:application/xml' \\ --data-binary @ ${ RIAK_MAM_SCHEMA_PATH } After that we need to either reload all Riak nodes (restart them) or manually reload the schema on live nodes. Reloading the schema on live nodes requires access to Erlang Shell of one of the Riak nodes (any of them). The instruction on how to get to Riak's Erlang shell is beyond this guide, but if you manage to get to it, just call: 1 yz_index : reload ( << \"mam\" >> ). Step 2 After the schema is posted and reloaded, all \"new\" objects will be indexed properly as long they contain 2 new fields: msg_owner_jid and mam_type . The new MongooseIM code will insert both of them for all new MAM entires, but for all existing ones need to have the fields added. In order to do that, we need to create a migration script (just pick your favourite scripting/programming language) that will do the following for each object in each bucket of type mam_yz (the object will be referred as obj ): Use this dedicated script to convert the obj.packet_register field value into a so called $SENDER_JID . If the script returns $SENDER_JID correctly: set obj.mam_type = 'muc' set obj.msg_owner_jid = $SENDER_JID If the script returns error code -2 set obj.mam_type = 'pm' based on obj_yz_rk formatted as $LOCAL_JID/$REMOTE_JID/$MSG_ID , set obj.msg_owner_jid = $LOCAL_JID Save the modified obj ElasticSearch Step 1 Please update the mapping for muc_messages : 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 PUT muc_messages/_mapping/muc { \"properties\": { \"mam_id\": { \"type\": \"long\" }, \"room\": { \"type\": \"keyword\" }, \"from_jid\" : { \"type\": \"keyword\" }, \"source_jid\": { \"type\": \"keyword\" }, \"message\": { \"type\": \"text\", \"index\": false }, \"body\": { \"type\": \"text\", \"analyzer\": \"english\" } } } Step 2 Now you have a schema that is compatible with MIM 3.4.0 but isn't GDPR-compliant yet because the new field has no meaningful data. Please pick your favourite scripting/programming language and populate the new column with the help of a dedicated script . You'll need to iterate over the all muc_messages documents with the following algorithm: Extract some documents (notice the size parameter) for conversion: 1 GET muc_messages/_search/?size=100&q=!_exists_:from_jid Extract the sender's JID from the message field in the same way as described in the RDBMS migration section. Elasticsearch backend uses exclusively the xml format. Update the from_jid column with the value of the extracted sender's JID : 1 2 3 4 5 6 POST localhost:9200/muc_messages/muc/%_id%/_update { \"doc\": { \"from_jid\" : \"%sender's jid%\" } } Repeat all the actions until the full conversion of the database is done.","title":"3.3.0 to 3.4.0"},{"location":"migrations/3.3.0_3.4.0/#new-field-in-message-archive-management-muc-entries-sender-id","text":"As a part of ensuring GDPR compliance, it is essential to be able to efficiently query MAM MUC data via sender ID (to retrieve user's personal data). Originally, the sender JID could be found only as a part of an encoded XML message element, so finding all items sent by a certain user would be extremely inefficient (or rather: anti-efficient). MongooseIM 3.4.0 uses a modified schema for MAM MUC backends which enables a more efficient extraction. Below you may find migration instructions specific to your MAM backend.","title":"New field in Message Archive Management MUC entries: Sender ID"},{"location":"migrations/3.3.0_3.4.0/#rdbms","text":"","title":"RDBMS"},{"location":"migrations/3.3.0_3.4.0/#step-1","text":"Please execute the following SQL statements on your MIM database: MySQL 1 2 ALTER TABLE mam_muc_message ADD COLUMN sender_id INT UNSIGNED ; CREATE INDEX i_mam_muc_message_sender_id USING BTREE ON mam_muc_message ( sender_id ); PostgreSQL 1 2 ALTER TABLE mam_muc_message ADD COLUMN sender_id INT ; CREATE INDEX i_mam_muc_message_sender_id ON mam_muc_message USING BTREE ( sender_id ); MSSQL 1 2 ALTER TABLE [ dbo ].[ mam_muc_message ] ADD sender_id bigint ; CREATE INDEX i_mam_muc_message_sender_id ON mam_muc_message ( sender_id );","title":"Step 1"},{"location":"migrations/3.3.0_3.4.0/#step-2","text":"Now you have a schema that is compatible with MIM 3.4.0 but isn't GDPR-compliant yet because the new column has no meaningful data. Please pick your favourite scripting/programming language and populate the new column with the help of a dedicated script . You'll need to iterate over the whole mam_muc_message table with the following algorithm: Provide message column content to the script. The script returns sender's JID as username@server string. You need to split it to get a separate username and server. Select ID from mam_server_user by the username and server. If it doesn't exist, insert a new one ( id column is automatically incremented). Update the sender_id column in mam_muc_message with the retrieved ID.","title":"Step 2"},{"location":"migrations/3.3.0_3.4.0/#cassandra","text":"","title":"Cassandra"},{"location":"migrations/3.3.0_3.4.0/#step-1_1","text":"Please execute the following CQL statements on your MIM database: 1 2 3 4 USE mongooseim ; ALTER TABLE mam_muc_message ADD from_jid varchar ; CREATE INDEX ON mam_muc_message ( from_jid ); DESC mam_muc_message ;","title":"Step 1"},{"location":"migrations/3.3.0_3.4.0/#step-2_1","text":"Now you have a schema that is compatible with MIM 3.4.0 but isn't GDPR-compliant yet because the new column has no meaningful data. Please pick your favourite scripting/programming language and populate the new column with the help of a dedicated script . You'll need to iterate over the whole mam_muc_message table with the following algorithm: Extract the whole mam_muc_message table. Please make sure to use the paging feature of your Cassandra client, as the MAM tables tend to be very large. 1 SELECT * FROM mam_muc_message ; To make data extraction faster, MongooseIM stores 2 copies of the message in the table: 1 2 3 4 5 6 cqlsh:mongooseim> SELECT * FROM mam_muc_message WHERE id = 399582233150625537 ALLOW FILTERING; room_jid | with_nick | id | from_jid | message | nick_name -------------------------------+-----------+--------------------+----------+--------------------------------+----------- room-ad1d999b9e@muc.localhost | | 399582233150625537 | null | 0x8350000001...998de2fa8426837 | Sid room-ad1d999b9e@muc.localhost | Sid | 399582233150625537 | null | 0x8350000001...998de2fa8426837 | Sid The copy with an empty with_nick column must be updated. Extract the sender's JID from the message column in the same way as described in the RDBMS migration section. By default cassandra backend uses the eterm format. Update the from_jid column with the value of the extracted sender's JID : 1 2 3 4 5 6 7 cqlsh:mongooseim> UPDATE mam_muc_message SET from_jid = 'username@server' WHERE id = 399582233150625537 AND with_nick = '' AND room_jid = 'room-ad1d999b9e@muc.localhost'; cqlsh:mongooseim> SELECT * FROM mam_muc_message WHERE id = 399582233150625537 ALLOW FILTERING; room_jid | with_nick | id | from_jid | message | nick_name -------------------------------+-----------+--------------------+-----------------+--------------------------------+----------- room-ad1d999b9e@muc.localhost | | 399582233150625537 | username@server | 0x8350000001...998de2fa8426837 | Sid room-ad1d999b9e@muc.localhost | Sid | 399582233150625537 | null | 0x8350000001...998de2fa8426837 | Sid","title":"Step 2"},{"location":"migrations/3.3.0_3.4.0/#riak","text":"Changes to Riak schema are backward compatible with the current MongooseIM release. This means that skipping the migration will cause only some of the new features (namely GDPR data retrival) to not work correctly.","title":"Riak"},{"location":"migrations/3.3.0_3.4.0/#step-1_2","text":"Please update the Riak schema: 1 2 3 4 5 6 # Set the RIAK_HOST to your Riak HTTP endpoint # Set the RIAK_MAM_SCHEMA_PATH to point to new schema path, which # by default is: RIAK_MAM_SCHEMA_PATH=tools/mam_search_schema.xml curl -v -XPUT $RIAK_HOST /search/schema/mam \\ -H 'Content-Type:application/xml' \\ --data-binary @ ${ RIAK_MAM_SCHEMA_PATH } After that we need to either reload all Riak nodes (restart them) or manually reload the schema on live nodes. Reloading the schema on live nodes requires access to Erlang Shell of one of the Riak nodes (any of them). The instruction on how to get to Riak's Erlang shell is beyond this guide, but if you manage to get to it, just call: 1 yz_index : reload ( << \"mam\" >> ).","title":"Step 1"},{"location":"migrations/3.3.0_3.4.0/#step-2_2","text":"After the schema is posted and reloaded, all \"new\" objects will be indexed properly as long they contain 2 new fields: msg_owner_jid and mam_type . The new MongooseIM code will insert both of them for all new MAM entires, but for all existing ones need to have the fields added. In order to do that, we need to create a migration script (just pick your favourite scripting/programming language) that will do the following for each object in each bucket of type mam_yz (the object will be referred as obj ): Use this dedicated script to convert the obj.packet_register field value into a so called $SENDER_JID . If the script returns $SENDER_JID correctly: set obj.mam_type = 'muc' set obj.msg_owner_jid = $SENDER_JID If the script returns error code -2 set obj.mam_type = 'pm' based on obj_yz_rk formatted as $LOCAL_JID/$REMOTE_JID/$MSG_ID , set obj.msg_owner_jid = $LOCAL_JID Save the modified obj","title":"Step 2"},{"location":"migrations/3.3.0_3.4.0/#elasticsearch","text":"","title":"ElasticSearch"},{"location":"migrations/3.3.0_3.4.0/#step-1_3","text":"Please update the mapping for muc_messages : 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 PUT muc_messages/_mapping/muc { \"properties\": { \"mam_id\": { \"type\": \"long\" }, \"room\": { \"type\": \"keyword\" }, \"from_jid\" : { \"type\": \"keyword\" }, \"source_jid\": { \"type\": \"keyword\" }, \"message\": { \"type\": \"text\", \"index\": false }, \"body\": { \"type\": \"text\", \"analyzer\": \"english\" } } }","title":"Step 1"},{"location":"migrations/3.3.0_3.4.0/#step-2_3","text":"Now you have a schema that is compatible with MIM 3.4.0 but isn't GDPR-compliant yet because the new field has no meaningful data. Please pick your favourite scripting/programming language and populate the new column with the help of a dedicated script . You'll need to iterate over the all muc_messages documents with the following algorithm: Extract some documents (notice the size parameter) for conversion: 1 GET muc_messages/_search/?size=100&q=!_exists_:from_jid Extract the sender's JID from the message field in the same way as described in the RDBMS migration section. Elasticsearch backend uses exclusively the xml format. Update the from_jid column with the value of the extracted sender's JID : 1 2 3 4 5 6 POST localhost:9200/muc_messages/muc/%_id%/_update { \"doc\": { \"from_jid\" : \"%sender's jid%\" } } Repeat all the actions until the full conversion of the database is done.","title":"Step 2"},{"location":"migrations/3.5.0_3.6.0/","text":"Push notifications In this version, push notifications work with MongoosePush 2.0.0 and its API v3 by default. Push notifications are send from the server's JID Since this version, MongooseIM sends the PubSub publish request to push notifications node from the server's JID. Previously the publish request was sent from the user's JID. If the push PubSub node was created with pubsub#access_mode set to whitelist and pubsub#publish_model set to publishers , now the server's JID needs to be added to the push node in order to send the push notifications successfully. It can be done by sending the following request from the push node's owner: 1 2 3 4 5 6 7 8 9 10 <iq to= 'pubsub.mypubsub' type= 'set' id= 'wy6Hibg=' from= 'alice@wonderland.com/resource' > <pubsub xmlns= 'http://jabber.org/protocol/pubsub#owner' > <affiliations node= 'punsub_node_for_my_private_iphone' > <affiliation jid= 'mychat.com' affiliation= 'publish-only' /> </affiliations> </pubsub> </iq> mod_push module is no longer available mod_push has been deprecated since MongooseIM 2.1.1 and it is no longer present in this release. Please use the push backend for mod_event_pusher , which is the direct equivalent of mod_push . Different MUC Light room schema definition We have introduced a change that enforces defining fields with default values. The previous setup led to problems with the RDBMS backend as separating MUC Light options for the schema from the default values was unintuitive. In a specific case when the default config was a subset of the schema and the client failed to provide these values when a room was created, MUC Light stored the incomplete config in the table. Then the missing config fields could not be supplied by the clients. If you've experienced this issue, a way to fix it is described in the Known issues page. The current method makes it impossible to make the same mistake, as it disallows field definition without any default value. What has changed? - for administrators It's no longer possible to declare a room config field only with its name. There is no default_config option anymore. Declaring a field name and type without an atom key is no longer supported. Example 1 Old config: 1 2 3 4 5 6 7 8 9 10 { config_schema , [ \"roomname\" , \"subject\" , \"background\" , \"notification_sound\" ]}, { default_config , [ { \"roomname\" , \"The room\" }, { \"subject\" , \"Chit-chat\" } ]} New config: 1 2 3 4 5 6 { config_schema , [ { \"roomname\" , \"The room\" }, { \"subject\" , \"Chit-chat\" }, { \"background\" , \"\" }, { \"notification_sound\" , \"\" } ]} Example 2 Old config: 1 2 3 4 5 6 7 8 9 10 { config_schema , [ \"roomname\" , { \"subject\" , binary }, { \"priority\" , priority , integer }, { \"owners-height\" , owners_height , float } ]}, { default_config , [ { \"roomname\" , \"The room\" }, { \"subject\" , \"Chit-chat\" }, { \"priority\" , 10 }]} New config: 1 2 3 4 5 6 { config_schema , [ { \"roomname\" , \"The room\" }, { \"subject\" , \"Chit-chat\" }, { \"priority\" , 10 , priority , integer }, { \"owners-height\" , 180 . 0 , owners_height , float } ]} What has changed? - for developers The room config schema is currently stored in a completely different data structure, so if you have any custom modules that use it, you'll need to adjust them. Additionally, all definitions and the room config API have been extracted from mod_muc_light.hrl and mod_muc_light_utils.erl into mod_muc_light_room_config.erl module. For more information, please check the specs for types and functions in the aforementioned file. What hasn't changed? The default room config is still the same, i.e. roomname (default: \"Untitled\" ) and subject (empty string). The room config representation in databases (both Mnesia and RDBMS) is the same; no need for migration. Offline storage In this version the offline storage entries contain one additional information for internal use. Riak and mnesia backends don't require any changes when upgrading to this version. In case of the RDBMS backends, a new column needs to be added. Below there are MySQL, PgSQL and MSSQL queries which can be used to add the new column. MySQL 1 ALTER TABLE offline_message ADD COLUMN permanent_fields mediumblob ; PostgreSQL 1 ALTER TABLE offline_message ADD COLUMN permanent_fields bytea ; MSSQL 1 ALTER TABLE [ dbo ].[ offline_message ] ADD permanent_fields varbinary ( max ); Persistent Cluster ID In this version, a new cluster ID has been created, to correctly identify the lifetime of a cluster, across restarts and nodes joining and leaving. This is used for example by System Metrics . This cluster ID is persisted in RDBMS, when an RDBMS database is available, but a new table is required: MySQL 1 CREATE TABLE mongoose_cluster_id ( k varchar ( 50 ) PRIMARY KEY , v text ); PostgreSQL 1 CREATE TABLE mongoose_cluster_id ( k varchar ( 50 ) PRIMARY KEY , v text ); MSSQL 1 CREATE TABLE mongoose_cluster_id ( k varchar ( 50 ) NOT NULL PRIMARY KEY , v text );","title":"3.5.0 to 3.6.0"},{"location":"migrations/3.5.0_3.6.0/#push-notifications","text":"In this version, push notifications work with MongoosePush 2.0.0 and its API v3 by default.","title":"Push notifications"},{"location":"migrations/3.5.0_3.6.0/#push-notifications-are-send-from-the-servers-jid","text":"Since this version, MongooseIM sends the PubSub publish request to push notifications node from the server's JID. Previously the publish request was sent from the user's JID. If the push PubSub node was created with pubsub#access_mode set to whitelist and pubsub#publish_model set to publishers , now the server's JID needs to be added to the push node in order to send the push notifications successfully. It can be done by sending the following request from the push node's owner: 1 2 3 4 5 6 7 8 9 10 <iq to= 'pubsub.mypubsub' type= 'set' id= 'wy6Hibg=' from= 'alice@wonderland.com/resource' > <pubsub xmlns= 'http://jabber.org/protocol/pubsub#owner' > <affiliations node= 'punsub_node_for_my_private_iphone' > <affiliation jid= 'mychat.com' affiliation= 'publish-only' /> </affiliations> </pubsub> </iq>","title":"Push notifications are send from the server's JID"},{"location":"migrations/3.5.0_3.6.0/#mod_push-module-is-no-longer-available","text":"mod_push has been deprecated since MongooseIM 2.1.1 and it is no longer present in this release. Please use the push backend for mod_event_pusher , which is the direct equivalent of mod_push .","title":"mod_push module is no longer available"},{"location":"migrations/3.5.0_3.6.0/#different-muc-light-room-schema-definition","text":"We have introduced a change that enforces defining fields with default values. The previous setup led to problems with the RDBMS backend as separating MUC Light options for the schema from the default values was unintuitive. In a specific case when the default config was a subset of the schema and the client failed to provide these values when a room was created, MUC Light stored the incomplete config in the table. Then the missing config fields could not be supplied by the clients. If you've experienced this issue, a way to fix it is described in the Known issues page. The current method makes it impossible to make the same mistake, as it disallows field definition without any default value.","title":"Different MUC Light room schema definition"},{"location":"migrations/3.5.0_3.6.0/#what-has-changed-for-administrators","text":"It's no longer possible to declare a room config field only with its name. There is no default_config option anymore. Declaring a field name and type without an atom key is no longer supported.","title":"What has changed? - for administrators"},{"location":"migrations/3.5.0_3.6.0/#example-1","text":"Old config: 1 2 3 4 5 6 7 8 9 10 { config_schema , [ \"roomname\" , \"subject\" , \"background\" , \"notification_sound\" ]}, { default_config , [ { \"roomname\" , \"The room\" }, { \"subject\" , \"Chit-chat\" } ]} New config: 1 2 3 4 5 6 { config_schema , [ { \"roomname\" , \"The room\" }, { \"subject\" , \"Chit-chat\" }, { \"background\" , \"\" }, { \"notification_sound\" , \"\" } ]}","title":"Example 1"},{"location":"migrations/3.5.0_3.6.0/#example-2","text":"Old config: 1 2 3 4 5 6 7 8 9 10 { config_schema , [ \"roomname\" , { \"subject\" , binary }, { \"priority\" , priority , integer }, { \"owners-height\" , owners_height , float } ]}, { default_config , [ { \"roomname\" , \"The room\" }, { \"subject\" , \"Chit-chat\" }, { \"priority\" , 10 }]} New config: 1 2 3 4 5 6 { config_schema , [ { \"roomname\" , \"The room\" }, { \"subject\" , \"Chit-chat\" }, { \"priority\" , 10 , priority , integer }, { \"owners-height\" , 180 . 0 , owners_height , float } ]}","title":"Example 2"},{"location":"migrations/3.5.0_3.6.0/#what-has-changed-for-developers","text":"The room config schema is currently stored in a completely different data structure, so if you have any custom modules that use it, you'll need to adjust them. Additionally, all definitions and the room config API have been extracted from mod_muc_light.hrl and mod_muc_light_utils.erl into mod_muc_light_room_config.erl module. For more information, please check the specs for types and functions in the aforementioned file.","title":"What has changed? - for developers"},{"location":"migrations/3.5.0_3.6.0/#what-hasnt-changed","text":"The default room config is still the same, i.e. roomname (default: \"Untitled\" ) and subject (empty string). The room config representation in databases (both Mnesia and RDBMS) is the same; no need for migration.","title":"What hasn't changed?"},{"location":"migrations/3.5.0_3.6.0/#offline-storage","text":"In this version the offline storage entries contain one additional information for internal use. Riak and mnesia backends don't require any changes when upgrading to this version. In case of the RDBMS backends, a new column needs to be added. Below there are MySQL, PgSQL and MSSQL queries which can be used to add the new column. MySQL 1 ALTER TABLE offline_message ADD COLUMN permanent_fields mediumblob ; PostgreSQL 1 ALTER TABLE offline_message ADD COLUMN permanent_fields bytea ; MSSQL 1 ALTER TABLE [ dbo ].[ offline_message ] ADD permanent_fields varbinary ( max );","title":"Offline storage"},{"location":"migrations/3.5.0_3.6.0/#persistent-cluster-id","text":"In this version, a new cluster ID has been created, to correctly identify the lifetime of a cluster, across restarts and nodes joining and leaving. This is used for example by System Metrics . This cluster ID is persisted in RDBMS, when an RDBMS database is available, but a new table is required: MySQL 1 CREATE TABLE mongoose_cluster_id ( k varchar ( 50 ) PRIMARY KEY , v text ); PostgreSQL 1 CREATE TABLE mongoose_cluster_id ( k varchar ( 50 ) PRIMARY KEY , v text ); MSSQL 1 CREATE TABLE mongoose_cluster_id ( k varchar ( 50 ) NOT NULL PRIMARY KEY , v text );","title":"Persistent Cluster ID"},{"location":"migrations/3.6.0_3.7.0/","text":"Extended SCRAM-SHA Support Since this version, SCRAM authentication mechanisms were extended to support additional hashing algorithms. So far only SHA-1 was available for hashing and now SHA-224, SHA-256, SHA-384 and SHA-512 are also supported. This includes the authentication mechanisms and the password format that is stored. Please note that enabling and using this functionality might require adjusting the server setup. SASL mechanisms The possible list of allowed SALS mechanisms was changed. We've added new and more secure methods that can be used during stream negotiation. Please note that if you were using the following in the configurations file {sasl_mechanisms, [cyrsasl_scram]} using cyrsasl_scram as sasl_mechanism is now incorrect. You can achieve the same result of allowing the usage of SHA-1 with SCRAM authentication mechanism with: {sasl_mechanisms, [cyrsasl_scram_sha1]} You can also specify a list of all supported SCRAM-SHA mechanisms with: {sasl_mechanisms, [cyrsasl_scram_sha1, cyrsasl_scram_sha224, cyrsasl_scram_sha256, cyrsasl_scram_sha384, cyrsasl_scram_sha512, cyrsasl_scram_sha1_plus, cyrsasl_scram_sha224_plus, cyrsasl_scram_sha256_plus, cyrsasl_scram_sha384_plus, cyrsasl_scram_sha512_plus]} Before setting up this configuration, please make sure that the client application is capable of authenticating with a selected set of authentication mechanisms. For more details please refer to the authentication section. SCRAM password format To complement the extensions of the authentication mechanisms, the SCRAM password format was also updated. Please note that SCRAM is now the default password format. While it is still possible to configure the password storage in plaintext format, we highly discourage doing so for security reasons. Changing the default of this option can lead to unexpected behaviours, so if after the upgrade you encounter issues with authenticating the users, please check the conifg file. If you are missing any of the following configuration lines: {password_format, scram} or {password_format, plain} it means that you were using the default plaintext format. Since the default of the password format has changed, your MongooseIM server thinks that the plaintext passwords are stored as SCRAM hashes. This can lead to users failing to authenticate. If you are still using the plaintext password format, please consider migrating your password storage to store scram hashes instead. Using the plaintext password format is still possible to support legacy installations and to ease the debuging while developing new features. Should you want to continue using the plaintext password format please add the following in the auth_opts : {password_format, plain} Legacy plaintext and SCRAM formats are still supported. Nonetheless, please note that if you were using SCRAM as a password format, this meant that SHA-1 was used as the hashing algorithm. This allowed authenticating with PLAINTEXT and SCRAM-SHA-1. In the new setup the user will still authenticate with those mechanisms given the possible slight syntax change explained above . However, mixing of the old password format with the new authentication mechanisms can lead to conflicting situations where: A user wants to authenticate with e.g. SCRAM-SHA-256. His old password format is only storing SHA-1 password hash. The authentication fails as it is not possible to derive SHA-256 hash from SHA-1. If you want to use the new password format with a full set of supported SHA hashes, a password change is required to calculate all the new SHA hashes. Otherwise, please make sure that you provide the right sasl_mechanism configuration, where the mechanism you authenticate with is compatible with the password format you store. For more details related to the new password format, please refer to authentication and SCRAM serialization sections. Message retraction If you are using MAM with RDBMS, please update your database schema with the following queries. This change is necessary as the support for XEP-0424: Message Retraction requires a new column for the origin_id attribute of MAM messages, which allows MAM to identify the messages to retract. Indexes for this column are required for efficient queries. Only the messages stored after this change can be retracted. MySQL 1 2 3 4 5 ALTER TABLE mam_message ADD COLUMN origin_id varchar ( 250 ) CHARACTER SET binary ; CREATE INDEX i_mam_message_username_jid_origin_id USING BTREE ON mam_message ( user_id , remote_bare_jid , origin_id ); ALTER TABLE mam_muc_message ADD COLUMN origin_id varchar ( 250 ) CHARACTER SET binary ; CREATE INDEX i_mam_muc_message_room_id_sender_id_origin_id USING BTREE ON mam_muc_message ( room_id , sender_id , origin_id ); PostgreSQL 1 2 3 4 5 ALTER TABLE mam_message ADD COLUMN origin_id varchar ; CREATE INDEX i_mam_message_username_jid_origin_id ON mam_message USING BTREE ( user_id , remote_bare_jid , origin_id ); ALTER TABLE mam_muc_message ADD COLUMN origin_id varchar ; CREATE INDEX i_mam_muc_message_room_id_sender_id_origin_id ON mam_muc_message USING BTREE ( room_id , sender_id , origin_id ); MSSQL Note: i_mam_message_username_jid_id was missing from the schema, this is now fixed. It is not required by message retraction, but this change is recommended. 1 2 3 4 5 6 ALTER TABLE mam_message ADD origin_id nvarchar ( 250 ) NULL ; CREATE INDEX i_mam_message_username_jid_id ON mam_message ( user_id , remote_bare_jid , id ); CREATE INDEX i_mam_message_username_jid_origin_id ON mam_message ( user_id , remote_bare_jid , origin_id ); ALTER TABLE mam_muc_message ADD origin_id nvarchar ( 250 ) NULL ; CREATE INDEX i_mam_muc_message_room_id_sender_id_origin_id ON mam_muc_message ( room_id , sender_id , origin_id ); RDBMS backend for Multi-User Chats (MUC) If you're planning to use the new RDBMS backend for MUC, note that the following tables need to be added to the schema: MySQL 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 CREATE TABLE muc_rooms ( id SERIAL , muc_host VARCHAR ( 250 ) NOT NULL , room_name VARCHAR ( 250 ) NOT NULL , options JSON NOT NULL , PRIMARY KEY ( muc_host , room_name ) ); CREATE TABLE muc_room_aff ( room_id BIGINT NOT NULL REFERENCES muc_rooms ( id ), luser VARCHAR ( 250 ) NOT NULL , lserver VARCHAR ( 250 ) NOT NULL , resource VARCHAR ( 250 ) NOT NULL , aff SMALLINT NOT NULL ); CREATE INDEX i_muc_room_aff_id ON muc_room_aff ( room_id ); CREATE TABLE muc_registered ( muc_host VARCHAR ( 250 ) NOT NULL , luser VARCHAR ( 250 ) NOT NULL , lserver VARCHAR ( 250 ) NOT NULL , nick VARCHAR ( 250 ) NOT NULL , PRIMARY KEY ( muc_host , luser , lserver ) ); PostgreSQL 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 CREATE TABLE muc_rooms ( id BIGSERIAL NOT NULL UNIQUE , muc_host VARCHAR ( 250 ) NOT NULL , room_name VARCHAR ( 250 ) NOT NULL , options JSON NOT NULL , PRIMARY KEY ( muc_host , room_name ) ); CREATE TABLE muc_room_aff ( room_id BIGINT NOT NULL REFERENCES muc_rooms ( id ), luser VARCHAR ( 250 ) NOT NULL , lserver VARCHAR ( 250 ) NOT NULL , resource VARCHAR ( 250 ) NOT NULL , aff SMALLINT NOT NULL ); CREATE INDEX i_muc_room_aff_id ON muc_room_aff ( room_id ); CREATE TABLE muc_registered ( muc_host VARCHAR ( 250 ) NOT NULL , luser VARCHAR ( 250 ) NOT NULL , lserver VARCHAR ( 250 ) NOT NULL , nick VARCHAR ( 250 ) NOT NULL , PRIMARY KEY ( muc_host , luser , lserver ) ); MSSQL 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 CREATE TABLE muc_rooms ( id BIGINT IDENTITY ( 1 , 1 ) NOT NULL UNIQUE , muc_host VARCHAR ( 250 ) NOT NULL , room_name VARCHAR ( 250 ) NOT NULL , options VARCHAR ( MAX ) NOT NULL , PRIMARY KEY ( muc_host , room_name ) ); CREATE TABLE muc_room_aff ( room_id BIGINT NOT NULL REFERENCES muc_rooms ( id ), luser VARCHAR ( 250 ) NOT NULL , lserver VARCHAR ( 250 ) NOT NULL , resource VARCHAR ( 250 ) NOT NULL , aff SMALLINT NOT NULL ); CREATE INDEX i_muc_room_aff_id ON muc_room_aff ( room_id ); CREATE TABLE muc_registered ( muc_host VARCHAR ( 250 ) NOT NULL , luser VARCHAR ( 250 ) NOT NULL , lserver VARCHAR ( 250 ) NOT NULL , nick VARCHAR ( 250 ) NOT NULL , PRIMARY KEY ( muc_host , luser , lserver ) );","title":"3.6.0 to 3.7.0"},{"location":"migrations/3.6.0_3.7.0/#extended-scram-sha-support","text":"Since this version, SCRAM authentication mechanisms were extended to support additional hashing algorithms. So far only SHA-1 was available for hashing and now SHA-224, SHA-256, SHA-384 and SHA-512 are also supported. This includes the authentication mechanisms and the password format that is stored. Please note that enabling and using this functionality might require adjusting the server setup.","title":"Extended SCRAM-SHA Support"},{"location":"migrations/3.6.0_3.7.0/#sasl-mechanisms","text":"The possible list of allowed SALS mechanisms was changed. We've added new and more secure methods that can be used during stream negotiation. Please note that if you were using the following in the configurations file {sasl_mechanisms, [cyrsasl_scram]} using cyrsasl_scram as sasl_mechanism is now incorrect. You can achieve the same result of allowing the usage of SHA-1 with SCRAM authentication mechanism with: {sasl_mechanisms, [cyrsasl_scram_sha1]} You can also specify a list of all supported SCRAM-SHA mechanisms with: {sasl_mechanisms, [cyrsasl_scram_sha1, cyrsasl_scram_sha224, cyrsasl_scram_sha256, cyrsasl_scram_sha384, cyrsasl_scram_sha512, cyrsasl_scram_sha1_plus, cyrsasl_scram_sha224_plus, cyrsasl_scram_sha256_plus, cyrsasl_scram_sha384_plus, cyrsasl_scram_sha512_plus]} Before setting up this configuration, please make sure that the client application is capable of authenticating with a selected set of authentication mechanisms. For more details please refer to the authentication section.","title":"SASL mechanisms"},{"location":"migrations/3.6.0_3.7.0/#scram-password-format","text":"To complement the extensions of the authentication mechanisms, the SCRAM password format was also updated. Please note that SCRAM is now the default password format. While it is still possible to configure the password storage in plaintext format, we highly discourage doing so for security reasons. Changing the default of this option can lead to unexpected behaviours, so if after the upgrade you encounter issues with authenticating the users, please check the conifg file. If you are missing any of the following configuration lines: {password_format, scram} or {password_format, plain} it means that you were using the default plaintext format. Since the default of the password format has changed, your MongooseIM server thinks that the plaintext passwords are stored as SCRAM hashes. This can lead to users failing to authenticate. If you are still using the plaintext password format, please consider migrating your password storage to store scram hashes instead. Using the plaintext password format is still possible to support legacy installations and to ease the debuging while developing new features. Should you want to continue using the plaintext password format please add the following in the auth_opts : {password_format, plain} Legacy plaintext and SCRAM formats are still supported. Nonetheless, please note that if you were using SCRAM as a password format, this meant that SHA-1 was used as the hashing algorithm. This allowed authenticating with PLAINTEXT and SCRAM-SHA-1. In the new setup the user will still authenticate with those mechanisms given the possible slight syntax change explained above . However, mixing of the old password format with the new authentication mechanisms can lead to conflicting situations where: A user wants to authenticate with e.g. SCRAM-SHA-256. His old password format is only storing SHA-1 password hash. The authentication fails as it is not possible to derive SHA-256 hash from SHA-1. If you want to use the new password format with a full set of supported SHA hashes, a password change is required to calculate all the new SHA hashes. Otherwise, please make sure that you provide the right sasl_mechanism configuration, where the mechanism you authenticate with is compatible with the password format you store. For more details related to the new password format, please refer to authentication and SCRAM serialization sections.","title":"SCRAM password format"},{"location":"migrations/3.6.0_3.7.0/#message-retraction","text":"If you are using MAM with RDBMS, please update your database schema with the following queries. This change is necessary as the support for XEP-0424: Message Retraction requires a new column for the origin_id attribute of MAM messages, which allows MAM to identify the messages to retract. Indexes for this column are required for efficient queries. Only the messages stored after this change can be retracted. MySQL 1 2 3 4 5 ALTER TABLE mam_message ADD COLUMN origin_id varchar ( 250 ) CHARACTER SET binary ; CREATE INDEX i_mam_message_username_jid_origin_id USING BTREE ON mam_message ( user_id , remote_bare_jid , origin_id ); ALTER TABLE mam_muc_message ADD COLUMN origin_id varchar ( 250 ) CHARACTER SET binary ; CREATE INDEX i_mam_muc_message_room_id_sender_id_origin_id USING BTREE ON mam_muc_message ( room_id , sender_id , origin_id ); PostgreSQL 1 2 3 4 5 ALTER TABLE mam_message ADD COLUMN origin_id varchar ; CREATE INDEX i_mam_message_username_jid_origin_id ON mam_message USING BTREE ( user_id , remote_bare_jid , origin_id ); ALTER TABLE mam_muc_message ADD COLUMN origin_id varchar ; CREATE INDEX i_mam_muc_message_room_id_sender_id_origin_id ON mam_muc_message USING BTREE ( room_id , sender_id , origin_id ); MSSQL Note: i_mam_message_username_jid_id was missing from the schema, this is now fixed. It is not required by message retraction, but this change is recommended. 1 2 3 4 5 6 ALTER TABLE mam_message ADD origin_id nvarchar ( 250 ) NULL ; CREATE INDEX i_mam_message_username_jid_id ON mam_message ( user_id , remote_bare_jid , id ); CREATE INDEX i_mam_message_username_jid_origin_id ON mam_message ( user_id , remote_bare_jid , origin_id ); ALTER TABLE mam_muc_message ADD origin_id nvarchar ( 250 ) NULL ; CREATE INDEX i_mam_muc_message_room_id_sender_id_origin_id ON mam_muc_message ( room_id , sender_id , origin_id );","title":"Message retraction"},{"location":"migrations/3.6.0_3.7.0/#rdbms-backend-for-multi-user-chats-muc","text":"If you're planning to use the new RDBMS backend for MUC, note that the following tables need to be added to the schema: MySQL 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 CREATE TABLE muc_rooms ( id SERIAL , muc_host VARCHAR ( 250 ) NOT NULL , room_name VARCHAR ( 250 ) NOT NULL , options JSON NOT NULL , PRIMARY KEY ( muc_host , room_name ) ); CREATE TABLE muc_room_aff ( room_id BIGINT NOT NULL REFERENCES muc_rooms ( id ), luser VARCHAR ( 250 ) NOT NULL , lserver VARCHAR ( 250 ) NOT NULL , resource VARCHAR ( 250 ) NOT NULL , aff SMALLINT NOT NULL ); CREATE INDEX i_muc_room_aff_id ON muc_room_aff ( room_id ); CREATE TABLE muc_registered ( muc_host VARCHAR ( 250 ) NOT NULL , luser VARCHAR ( 250 ) NOT NULL , lserver VARCHAR ( 250 ) NOT NULL , nick VARCHAR ( 250 ) NOT NULL , PRIMARY KEY ( muc_host , luser , lserver ) ); PostgreSQL 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 CREATE TABLE muc_rooms ( id BIGSERIAL NOT NULL UNIQUE , muc_host VARCHAR ( 250 ) NOT NULL , room_name VARCHAR ( 250 ) NOT NULL , options JSON NOT NULL , PRIMARY KEY ( muc_host , room_name ) ); CREATE TABLE muc_room_aff ( room_id BIGINT NOT NULL REFERENCES muc_rooms ( id ), luser VARCHAR ( 250 ) NOT NULL , lserver VARCHAR ( 250 ) NOT NULL , resource VARCHAR ( 250 ) NOT NULL , aff SMALLINT NOT NULL ); CREATE INDEX i_muc_room_aff_id ON muc_room_aff ( room_id ); CREATE TABLE muc_registered ( muc_host VARCHAR ( 250 ) NOT NULL , luser VARCHAR ( 250 ) NOT NULL , lserver VARCHAR ( 250 ) NOT NULL , nick VARCHAR ( 250 ) NOT NULL , PRIMARY KEY ( muc_host , luser , lserver ) ); MSSQL 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 CREATE TABLE muc_rooms ( id BIGINT IDENTITY ( 1 , 1 ) NOT NULL UNIQUE , muc_host VARCHAR ( 250 ) NOT NULL , room_name VARCHAR ( 250 ) NOT NULL , options VARCHAR ( MAX ) NOT NULL , PRIMARY KEY ( muc_host , room_name ) ); CREATE TABLE muc_room_aff ( room_id BIGINT NOT NULL REFERENCES muc_rooms ( id ), luser VARCHAR ( 250 ) NOT NULL , lserver VARCHAR ( 250 ) NOT NULL , resource VARCHAR ( 250 ) NOT NULL , aff SMALLINT NOT NULL ); CREATE INDEX i_muc_room_aff_id ON muc_room_aff ( room_id ); CREATE TABLE muc_registered ( muc_host VARCHAR ( 250 ) NOT NULL , luser VARCHAR ( 250 ) NOT NULL , lserver VARCHAR ( 250 ) NOT NULL , nick VARCHAR ( 250 ) NOT NULL , PRIMARY KEY ( muc_host , luser , lserver ) );","title":"RDBMS backend for Multi-User Chats (MUC)"},{"location":"migrations/3.7.0_4.0.0/","text":"TOML configuration file Note that a minor 4.0.1 version has been released with small but important changes to take into account if you're migrating to MongooseIM 4.0. There is a new TOML configuration file : mongooseim.toml . The legacy mongooseim.cfg file is still supported as an alternative, but deprecated. You are advised to rewrite your configuration file in the TOML format. Until then, you can still make MongooseIM use the old format by setting the MONGOOSEIM_CONFIG_FORMAT environment variable to cfg : MONGOOSEIM_CONFIG_FORMAT=cfg mongooseimctl start Changes in hooks If modified the code, e.g. by adding a custom extension module, you might want to update your handlers to the following hooks. You can find them in the mongoose_hooks module. We refactored the MAM (XEP-0313) implementation, replacing the long lists of arguments accepted by the mam_archive_message and mam_muc_archive_message hooks with a more readable key-value structure (a map). The argument list of the failed_to_store_message hook has been changed as a result of code refactoring. OTP Logger as the logging framework We've transitioned from lager to Logger as our logging framework. No internal changes were introduced, and the default handlers still implement the same behaviour, but the configuration is different, though still done in the same place. To know more, please refer to each framework's documentation. As an example, for our previous default lager configuration: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 { lager , [ %% Make logging more async %% If some very heavy loaded process want to log something, it's better to not block the process. { async_threshold , 2000 }, { async_threshold_window , 500 }, %% Kill sink if it has more than 10k messages { killer_hwm , 10000 }, { killer_reinstall_after , 5000 }, { log_root , \"log\" }, { crash_log , \"crash.log\" }, { handlers , [ { lager_console_backend , [{ level , info }]}, { lager_file_backend , [{ file , \"ejabberd.log\" }, { level , info }, { size , 2097152 }, { date , \"$D0\" }, { count , 5 }]} ]} ]} The equivalent Logger configuration is 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 { kernel , [ { logger_level , warning }, { logger , [ %% Console logger { handler , default , logger_std_h , #{}}, %% Disk logger for errors { handler , disk_log , logger_disk_log_h , #{ config => #{ file => \"log/mongooseim.log\" , type => wrap , max_no_files => 5 , max_no_bytes => 2097152 , sync_mode_qlen => 2000 , % If sync_mode_qlen is set to the same value as drop_mode_qlen, drop_mode_qlen => 2000 , % synchronous mode is disabled. That is, the handler always runs flush_qlen => 5000 , % in asynchronous mode, unless dropping or flushing is invoked. overload_kill_enable => true }, formatter => { logger_formatter , #{ depth => 12 , chars_limit => 4096 }} } } ]}]}","title":"3.7.0 to 4.0.0"},{"location":"migrations/3.7.0_4.0.0/#toml-configuration-file","text":"Note that a minor 4.0.1 version has been released with small but important changes to take into account if you're migrating to MongooseIM 4.0. There is a new TOML configuration file : mongooseim.toml . The legacy mongooseim.cfg file is still supported as an alternative, but deprecated. You are advised to rewrite your configuration file in the TOML format. Until then, you can still make MongooseIM use the old format by setting the MONGOOSEIM_CONFIG_FORMAT environment variable to cfg : MONGOOSEIM_CONFIG_FORMAT=cfg mongooseimctl start","title":"TOML configuration file"},{"location":"migrations/3.7.0_4.0.0/#changes-in-hooks","text":"If modified the code, e.g. by adding a custom extension module, you might want to update your handlers to the following hooks. You can find them in the mongoose_hooks module. We refactored the MAM (XEP-0313) implementation, replacing the long lists of arguments accepted by the mam_archive_message and mam_muc_archive_message hooks with a more readable key-value structure (a map). The argument list of the failed_to_store_message hook has been changed as a result of code refactoring.","title":"Changes in hooks"},{"location":"migrations/3.7.0_4.0.0/#otp-logger-as-the-logging-framework","text":"We've transitioned from lager to Logger as our logging framework. No internal changes were introduced, and the default handlers still implement the same behaviour, but the configuration is different, though still done in the same place. To know more, please refer to each framework's documentation. As an example, for our previous default lager configuration: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 { lager , [ %% Make logging more async %% If some very heavy loaded process want to log something, it's better to not block the process. { async_threshold , 2000 }, { async_threshold_window , 500 }, %% Kill sink if it has more than 10k messages { killer_hwm , 10000 }, { killer_reinstall_after , 5000 }, { log_root , \"log\" }, { crash_log , \"crash.log\" }, { handlers , [ { lager_console_backend , [{ level , info }]}, { lager_file_backend , [{ file , \"ejabberd.log\" }, { level , info }, { size , 2097152 }, { date , \"$D0\" }, { count , 5 }]} ]} ]} The equivalent Logger configuration is 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 { kernel , [ { logger_level , warning }, { logger , [ %% Console logger { handler , default , logger_std_h , #{}}, %% Disk logger for errors { handler , disk_log , logger_disk_log_h , #{ config => #{ file => \"log/mongooseim.log\" , type => wrap , max_no_files => 5 , max_no_bytes => 2097152 , sync_mode_qlen => 2000 , % If sync_mode_qlen is set to the same value as drop_mode_qlen, drop_mode_qlen => 2000 , % synchronous mode is disabled. That is, the handler always runs flush_qlen => 5000 , % in asynchronous mode, unless dropping or flushing is invoked. overload_kill_enable => true }, formatter => { logger_formatter , #{ depth => 12 , chars_limit => 4096 }} } } ]}]}","title":"OTP Logger as the logging framework"},{"location":"migrations/4.0.0_4.0.1/","text":"TOML configuration file After the latest MongooseIM 4.0.0 release that announced the new TOML configuration format, we've changed a few configuration formats: Removed the backend option for mod_bosh as \"mnesia\" was the only valid option. Removed the backend option for mod_inbox as \"rdbms\" was the only valid option. Deprecated mod_revproxy , it can now only be configured with the older, .cfg configuration file. Please refer to the older versions of the documentation to see how to do this. For mod_global_distrib : Replaced the bounce option with bounce.enabled for mod_global_distrib . It was a \"boolean with only false being a valid option\" which was very confusing. This was because when someone wanted to have bounce enabled it became a TOML table as opposed to a key. Now there is a switch in the bounce section for this behaviour which keeps the behaviour of having bounce enabled by default. Replaced the tls option with tls.enabled for mod_global_distrib for the same reason. The only issue here is as tls is disabled by default (it needs some options in the tls section to be set), the \"no section - disabled\" approach seems more natural. Just for the consistency, it's changed to be similar to the bounce section in this regard. mod_http_notification module is no longer available mod_http_notification has been deprecated since MongooseIM 2.1.1 and it is no longer available in this release. Please use the http backend for mod_event_pusher , which is the direct equivalent of mod_http_notification . Metrics mod_http_notification metric was updated and now is available as mod_event_pusher_http . For more details on how to configure mod_event_pusher with http backend, please see this section .","title":"4.0.0 to 4.0.1"},{"location":"migrations/4.0.0_4.0.1/#toml-configuration-file","text":"After the latest MongooseIM 4.0.0 release that announced the new TOML configuration format, we've changed a few configuration formats: Removed the backend option for mod_bosh as \"mnesia\" was the only valid option. Removed the backend option for mod_inbox as \"rdbms\" was the only valid option. Deprecated mod_revproxy , it can now only be configured with the older, .cfg configuration file. Please refer to the older versions of the documentation to see how to do this. For mod_global_distrib : Replaced the bounce option with bounce.enabled for mod_global_distrib . It was a \"boolean with only false being a valid option\" which was very confusing. This was because when someone wanted to have bounce enabled it became a TOML table as opposed to a key. Now there is a switch in the bounce section for this behaviour which keeps the behaviour of having bounce enabled by default. Replaced the tls option with tls.enabled for mod_global_distrib for the same reason. The only issue here is as tls is disabled by default (it needs some options in the tls section to be set), the \"no section - disabled\" approach seems more natural. Just for the consistency, it's changed to be similar to the bounce section in this regard.","title":"TOML configuration file"},{"location":"migrations/4.0.0_4.0.1/#mod_http_notification-module-is-no-longer-available","text":"mod_http_notification has been deprecated since MongooseIM 2.1.1 and it is no longer available in this release. Please use the http backend for mod_event_pusher , which is the direct equivalent of mod_http_notification .","title":"mod_http_notification module is no longer available"},{"location":"migrations/4.0.0_4.0.1/#metrics","text":"mod_http_notification metric was updated and now is available as mod_event_pusher_http . For more details on how to configure mod_event_pusher with http backend, please see this section .","title":"Metrics"},{"location":"migrations/4.0.1_4.1.0/","text":"HTTP File Upload HTTP File Upload specification older than 0.3.0 is no longer supported, i.e. the one namespaced with urn:xmpp:http:upload . Currently, only the urn:xmpp:http:upload:0 XMLNS is served. All major, modern client libraries and applications support the 0.3.0+ specification. If you experience any issues with making requests to the HTTP File Upload service, please update your client. Retirement of the old *.cfg format Since release 4.1.0, we are no longer supporting the *.cfg MongooseIM configuration format. Please use the TOML format instead. Minor changes in the TOML config format mod_bosh.max_pause instead of maxpause mod_disco.server_info.module : the field is optional, no longer required mod_global_distrib.connections.advertised_endpoints : default not set ( false is no longer accepted) mod_global_distrib.connections.tls.enabled : the flag was removed, TLS is enabled by providing the cacertfile and certfile options mod_http_upload.max_file_size : undefined is no longer allowed mod_mam_meta.user_prefs_store : false is no longer allowed mod_muc_light.config_schema : the usage of value and type fields was replaced with one of the following fields: string_value , integer_value or float_value mod_muc_log.css_file : the default value was changed from \"false\" to not set mod_stream_management : minor adjustments of buffer_max and ack_freq options, buffer and ack booleans were added listen.c2s.tls.ciphers , listen.http.tls.ciphers and outgoing_pools.*.*.connection.tls.ciphers : the ciphers should now be formatted as a specification string listen.http.handlers.mod_websockets.ping_rate : none is no longer allowed","title":"4.0.1 to 4.1.0"},{"location":"migrations/4.0.1_4.1.0/#http-file-upload","text":"HTTP File Upload specification older than 0.3.0 is no longer supported, i.e. the one namespaced with urn:xmpp:http:upload . Currently, only the urn:xmpp:http:upload:0 XMLNS is served. All major, modern client libraries and applications support the 0.3.0+ specification. If you experience any issues with making requests to the HTTP File Upload service, please update your client.","title":"HTTP File Upload"},{"location":"migrations/4.0.1_4.1.0/#retirement-of-the-old-cfg-format","text":"Since release 4.1.0, we are no longer supporting the *.cfg MongooseIM configuration format. Please use the TOML format instead.","title":"Retirement of the old *.cfg format"},{"location":"migrations/4.0.1_4.1.0/#minor-changes-in-the-toml-config-format","text":"mod_bosh.max_pause instead of maxpause mod_disco.server_info.module : the field is optional, no longer required mod_global_distrib.connections.advertised_endpoints : default not set ( false is no longer accepted) mod_global_distrib.connections.tls.enabled : the flag was removed, TLS is enabled by providing the cacertfile and certfile options mod_http_upload.max_file_size : undefined is no longer allowed mod_mam_meta.user_prefs_store : false is no longer allowed mod_muc_light.config_schema : the usage of value and type fields was replaced with one of the following fields: string_value , integer_value or float_value mod_muc_log.css_file : the default value was changed from \"false\" to not set mod_stream_management : minor adjustments of buffer_max and ack_freq options, buffer and ack booleans were added listen.c2s.tls.ciphers , listen.http.tls.ciphers and outgoing_pools.*.*.connection.tls.ciphers : the ciphers should now be formatted as a specification string listen.http.handlers.mod_websockets.ping_rate : none is no longer allowed","title":"Minor changes in the TOML config format"},{"location":"migrations/4.1.0_4.2.0/","text":"Minor changes in the TOML config format The pgsql_users_number_estimate option was moved to auth.rdbms.users_number_estimate . The new option supports PostgreSQL and MySQL. DB migrations New inbox features Inbox now implements new functionality (see inbox ), but this required adding new columns to the DB. If you're using inbox, please update the tables as follows: For Postgres or MySQL: 1 2 3 ALTER TABLE inbox ADD COLUMN archive BOOLEAN DEFAULT false , ADD COLUMN muted_until BIGINT DEFAULT 0 ; For MSSQL: 1 2 3 ALTER TABLE inbox ADD COLUMN archive TINYINT DEFAULT 0 , ADD COLUMN muted_until BIGINT DEFAULT 0 ; Archived groupchat messages in mod_mam The archive_groupchats option is now set to false by default, as documented. Before the change, the private message (PM) archive stored incoming groupchat messages as well, contrary to the documentation. After the upgrade you can manually remove those messages from the database. For example, when the MUC domain is muc.localhost and rdbms_message_format has the default value internal , one can remove such messages with the following query: 1 2 DELETE FROM mam_message WHERE direction = 'I' AND remote_bare_jid LIKE 'muc.localhost:%' ; This can be a heavy operation and it needs to be done with caution. Using mod_auth_token with MySQL and MS SQL The mod_auth_token module supports MySQL and MS SQL now. To use this functionality, you need to create the auth_token table with the query which you can find in priv/mysql.sql and priv/mssql2012.sql , respectively.","title":"4.1.0 to 4.2.0"},{"location":"migrations/4.1.0_4.2.0/#minor-changes-in-the-toml-config-format","text":"The pgsql_users_number_estimate option was moved to auth.rdbms.users_number_estimate . The new option supports PostgreSQL and MySQL.","title":"Minor changes in the TOML config format"},{"location":"migrations/4.1.0_4.2.0/#db-migrations","text":"","title":"DB migrations"},{"location":"migrations/4.1.0_4.2.0/#new-inbox-features","text":"Inbox now implements new functionality (see inbox ), but this required adding new columns to the DB. If you're using inbox, please update the tables as follows: For Postgres or MySQL: 1 2 3 ALTER TABLE inbox ADD COLUMN archive BOOLEAN DEFAULT false , ADD COLUMN muted_until BIGINT DEFAULT 0 ; For MSSQL: 1 2 3 ALTER TABLE inbox ADD COLUMN archive TINYINT DEFAULT 0 , ADD COLUMN muted_until BIGINT DEFAULT 0 ;","title":"New inbox features"},{"location":"migrations/4.1.0_4.2.0/#archived-groupchat-messages-in-mod_mam","text":"The archive_groupchats option is now set to false by default, as documented. Before the change, the private message (PM) archive stored incoming groupchat messages as well, contrary to the documentation. After the upgrade you can manually remove those messages from the database. For example, when the MUC domain is muc.localhost and rdbms_message_format has the default value internal , one can remove such messages with the following query: 1 2 DELETE FROM mam_message WHERE direction = 'I' AND remote_bare_jid LIKE 'muc.localhost:%' ; This can be a heavy operation and it needs to be done with caution.","title":"Archived groupchat messages in mod_mam"},{"location":"migrations/4.1.0_4.2.0/#using-mod_auth_token-with-mysql-and-ms-sql","text":"The mod_auth_token module supports MySQL and MS SQL now. To use this functionality, you need to create the auth_token table with the query which you can find in priv/mysql.sql and priv/mssql2012.sql , respectively.","title":"Using mod_auth_token with MySQL and MS SQL"},{"location":"migrations/4.2.0_4.3.0/","text":"DB migrations Inbox indexes Domain removal feature requires the order of fields to be changed: For Postgres: 1 2 3 4 5 6 7 8 9 10 11 12 13 -- Create a new index for the new primary key. CREATE UNIQUE INDEX i_inbox_sur ON inbox ( lserver , luser , remote_bare_jid ); -- Now enter a transaction block to replace the primary with the new one. BEGIN ; ALTER TABLE inbox DROP CONSTRAINT inbox_pkey ; ALTER TABLE inbox ADD CONSTRAINT inbox_pkey PRIMARY KEY USING INDEX i_inbox_sur ; COMMIT ; CREATE INDEX i_inbox_timestamp ON inbox USING BTREE ( lserver , luser , timestamp ); DROP INDEX i_inbox ; For MySQL: 1 2 3 4 5 6 7 BEGIN ; ALTER TABLE inbox DROP PRIMARY KEY ; ALTER TABLE inbox ADD PRIMARY KEY USING BTREE ( lserver , luser , remote_bare_jid ); COMMIT ; CREATE INDEX i_inbox_timestamp ON inbox ( lserver , luser , timestamp ); DROP INDEX i_inbox ON inbox ; For MSSQL: 1 2 3 4 5 6 7 8 9 10 11 12 CREATE INDEX i_inbox_su_ts ON inbox ( lserver , luser , timestamp ); GO DROP INDEX i_inbox_ts ON inbox ; GO ALTER TABLE inbox DROP CONSTRAINT PK_inbox ; GO ALTER TABLE inbox ADD CONSTRAINT PK_inbox PRIMARY KEY CLUSTERED ( lserver ASC , luser ASC , remote_bare_jid ASC ); GO MUC-light indexes Order of fields in i_muc_light_blocking has changed. For Postgres: 1 2 CREATE INDEX i_muc_light_blocking_su ON muc_light_blocking ( lserver , luser ); DROP INDEX i_muc_light_blocking ; For MySQL: 1 2 CREATE INDEX i_muc_light_blocking_su USING BTREE ON muc_light_blocking ( lserver , luser ); DROP INDEX i_muc_light_blocking ON muc_light_blocking ;; For MSSQL: 1 2 3 4 5 CREATE INDEX i_muc_light_blocking_su ON muc_light_blocking ( lserver , luser ); GO DROP INDEX i_muc_light_blocking ON muc_light_blocking ; GO Hook migrations filter_room_packet hook uses a map instead of a proplist for the event data information. room_send_packet hook has been removed. Use filter_room_packet instead. filter_room_packet is called for HostType (was for MucHost). forget_room is called for HostType (was for MucHost). forget_room takes an extra argument HostType. filter_room_packet takes an extra argument HostType. is_muc_room_owner is called for HostType (was for MucHost). is_muc_room_owner takes an extra argument HostType. muc_room_pid hook removed. load_permanent_rooms_at_startup option is ignored now. gen_mod:get_module_opt_by_subhost API removed. update_inbox_for_muc is called for HostType. get_mam_muc_gdpr_data is called for HostType. get_mam_pm_gdpr_data is called for HostType. get_personal_data handlers take an extra argument: HostType as the second parameter. get_mam_pm_gdpr_data and get_mam_muc_gdpr_data take HostType argument. Metrics REST API (obsolete) The API is still considered obsolete so if you are using it, please consider using WombatOAM or metrics reporters as described in Logging and monitoring . In each endpoint, host has been changed to host_type . This is because the metrics are now collected per host type rather than host.","title":"4.2.0 to 4.3.0"},{"location":"migrations/4.2.0_4.3.0/#db-migrations","text":"","title":"DB migrations"},{"location":"migrations/4.2.0_4.3.0/#inbox-indexes","text":"Domain removal feature requires the order of fields to be changed: For Postgres: 1 2 3 4 5 6 7 8 9 10 11 12 13 -- Create a new index for the new primary key. CREATE UNIQUE INDEX i_inbox_sur ON inbox ( lserver , luser , remote_bare_jid ); -- Now enter a transaction block to replace the primary with the new one. BEGIN ; ALTER TABLE inbox DROP CONSTRAINT inbox_pkey ; ALTER TABLE inbox ADD CONSTRAINT inbox_pkey PRIMARY KEY USING INDEX i_inbox_sur ; COMMIT ; CREATE INDEX i_inbox_timestamp ON inbox USING BTREE ( lserver , luser , timestamp ); DROP INDEX i_inbox ; For MySQL: 1 2 3 4 5 6 7 BEGIN ; ALTER TABLE inbox DROP PRIMARY KEY ; ALTER TABLE inbox ADD PRIMARY KEY USING BTREE ( lserver , luser , remote_bare_jid ); COMMIT ; CREATE INDEX i_inbox_timestamp ON inbox ( lserver , luser , timestamp ); DROP INDEX i_inbox ON inbox ; For MSSQL: 1 2 3 4 5 6 7 8 9 10 11 12 CREATE INDEX i_inbox_su_ts ON inbox ( lserver , luser , timestamp ); GO DROP INDEX i_inbox_ts ON inbox ; GO ALTER TABLE inbox DROP CONSTRAINT PK_inbox ; GO ALTER TABLE inbox ADD CONSTRAINT PK_inbox PRIMARY KEY CLUSTERED ( lserver ASC , luser ASC , remote_bare_jid ASC ); GO","title":"Inbox indexes"},{"location":"migrations/4.2.0_4.3.0/#muc-light-indexes","text":"Order of fields in i_muc_light_blocking has changed. For Postgres: 1 2 CREATE INDEX i_muc_light_blocking_su ON muc_light_blocking ( lserver , luser ); DROP INDEX i_muc_light_blocking ; For MySQL: 1 2 CREATE INDEX i_muc_light_blocking_su USING BTREE ON muc_light_blocking ( lserver , luser ); DROP INDEX i_muc_light_blocking ON muc_light_blocking ;; For MSSQL: 1 2 3 4 5 CREATE INDEX i_muc_light_blocking_su ON muc_light_blocking ( lserver , luser ); GO DROP INDEX i_muc_light_blocking ON muc_light_blocking ; GO","title":"MUC-light indexes"},{"location":"migrations/4.2.0_4.3.0/#hook-migrations","text":"filter_room_packet hook uses a map instead of a proplist for the event data information. room_send_packet hook has been removed. Use filter_room_packet instead. filter_room_packet is called for HostType (was for MucHost). forget_room is called for HostType (was for MucHost). forget_room takes an extra argument HostType. filter_room_packet takes an extra argument HostType. is_muc_room_owner is called for HostType (was for MucHost). is_muc_room_owner takes an extra argument HostType. muc_room_pid hook removed. load_permanent_rooms_at_startup option is ignored now. gen_mod:get_module_opt_by_subhost API removed. update_inbox_for_muc is called for HostType. get_mam_muc_gdpr_data is called for HostType. get_mam_pm_gdpr_data is called for HostType. get_personal_data handlers take an extra argument: HostType as the second parameter. get_mam_pm_gdpr_data and get_mam_muc_gdpr_data take HostType argument.","title":"Hook migrations"},{"location":"migrations/4.2.0_4.3.0/#metrics-rest-api-obsolete","text":"The API is still considered obsolete so if you are using it, please consider using WombatOAM or metrics reporters as described in Logging and monitoring . In each endpoint, host has been changed to host_type . This is because the metrics are now collected per host type rather than host.","title":"Metrics REST API (obsolete)"},{"location":"migrations/jid-from-mam-muc-script/","text":"The purpose of sender-jid-from-mam-message.escript This script may be used as a part of migration from MongooseIM 3.3.0 (or older). It is able to extract a JID of a groupchat message sender from an XML payload. This piece of information is essential for GDPR commands (retrieve data and remove user) to work properly, as without it the operations on MAM MUC data in DB would be extremely inefficient. Please consult \"3.3.0 to...\" migration guide for details. DB-specific sections describe where the payloads are stored and what you should do with the extracted JID. Requirements This script may be executed in every *nix environment which has OTP 19.0 (or newer) installed and escript executable is in PATH . It doesn't depend on any MongooseIM code or library, so it may be used as a standalone file. How to use? sender-jid-from-mam-message.escript (eterm | xml) The only parameter required by the script is the input format. You should use eterm if (in MongooseIM config file): You haven't set db_message_format option for MAM at all. db_message_format is set to mam_message_compressed_eterm or mam_message_eterm You should use the xml option if: db_message_format is set to mam_message_xml . Once started, the script will run in an infinite loop (until killed or interrupted), expecting a stream of inputs. For every provided payload, a JID will be returned immediately. All communication with the script is done via stdio . Input format For both eterm and xml mode, the script expects an input in a very similar format. The high-level overview is: 1 LENGTH\\nPAYLOAD LENGTH is the PAYLOAD length in bytes; if the data retrieved from a DBMS is a Unicode string, LENGTH is equal to the number of bytes used to encode this string PAYLOAD is a sequence of bytes; if a DBMS returns binary data encoded as hex, then it has to be decoded to raw bytes LENGTH and PAYLOAD are separated with a newline character (ASCII code 10 / 0x0a) Output format The script output format is very similar to the input: 1 LENGTH\\nJID LENGTH is the number of bytes in a JID JID is a sequence of bytes, which encodes a Unicode string LENGTH and PAYLOAD are separated with a newline character (ASCII code 10 / 0x0a) In case of an error (that is not a critical error, like I/O failure), script will print -N\\n (where N is an error code) and will continue to work. Technically it's -N for LENGTH , followed by a newline character and no PAYLOAD part (or 0-length PAYLOAD if you like). The following error codes are supported: * -1\\n - Unknown error. Something went wrong with the JID extraction (most likely malformed input). * -2\\n - Invalid message type. The message / stanza has been decoded successfully, but it's not a groupchat message. Examples tools/migration folder contains two files: sender-jid-from-mam-message.example.eterm and sender-jid-from-mam-message.example.xml . They are input samples for the script and may be used as a reference for the script usage. You can test them by running: tools/migration/sender-jid-from-mam-message.escript eterm < sender-jid-from-mam-message.example.eterm > out tools/migration/sender-jid-from-mam-message.escript xml < sender-jid-from-mam-message.example.xml > out In both cases the out file should have the following content: 1 2 37 g\u017ceg\u017c\u00f3\u0142ka@brz\u0119czyszczykiewicz.pl Debug If an environment variable DEBUG is set to 1 , the script will store error messages in a /tmp/script-debug file.","title":"MAM MUC migration helper"},{"location":"migrations/jid-from-mam-muc-script/#the-purpose-of-sender-jid-from-mam-messageescript","text":"This script may be used as a part of migration from MongooseIM 3.3.0 (or older). It is able to extract a JID of a groupchat message sender from an XML payload. This piece of information is essential for GDPR commands (retrieve data and remove user) to work properly, as without it the operations on MAM MUC data in DB would be extremely inefficient. Please consult \"3.3.0 to...\" migration guide for details. DB-specific sections describe where the payloads are stored and what you should do with the extracted JID.","title":"The purpose of sender-jid-from-mam-message.escript"},{"location":"migrations/jid-from-mam-muc-script/#requirements","text":"This script may be executed in every *nix environment which has OTP 19.0 (or newer) installed and escript executable is in PATH . It doesn't depend on any MongooseIM code or library, so it may be used as a standalone file.","title":"Requirements"},{"location":"migrations/jid-from-mam-muc-script/#how-to-use","text":"sender-jid-from-mam-message.escript (eterm | xml) The only parameter required by the script is the input format. You should use eterm if (in MongooseIM config file): You haven't set db_message_format option for MAM at all. db_message_format is set to mam_message_compressed_eterm or mam_message_eterm You should use the xml option if: db_message_format is set to mam_message_xml . Once started, the script will run in an infinite loop (until killed or interrupted), expecting a stream of inputs. For every provided payload, a JID will be returned immediately. All communication with the script is done via stdio .","title":"How to use?"},{"location":"migrations/jid-from-mam-muc-script/#input-format","text":"For both eterm and xml mode, the script expects an input in a very similar format. The high-level overview is: 1 LENGTH\\nPAYLOAD LENGTH is the PAYLOAD length in bytes; if the data retrieved from a DBMS is a Unicode string, LENGTH is equal to the number of bytes used to encode this string PAYLOAD is a sequence of bytes; if a DBMS returns binary data encoded as hex, then it has to be decoded to raw bytes LENGTH and PAYLOAD are separated with a newline character (ASCII code 10 / 0x0a)","title":"Input format"},{"location":"migrations/jid-from-mam-muc-script/#output-format","text":"The script output format is very similar to the input: 1 LENGTH\\nJID LENGTH is the number of bytes in a JID JID is a sequence of bytes, which encodes a Unicode string LENGTH and PAYLOAD are separated with a newline character (ASCII code 10 / 0x0a) In case of an error (that is not a critical error, like I/O failure), script will print -N\\n (where N is an error code) and will continue to work. Technically it's -N for LENGTH , followed by a newline character and no PAYLOAD part (or 0-length PAYLOAD if you like). The following error codes are supported: * -1\\n - Unknown error. Something went wrong with the JID extraction (most likely malformed input). * -2\\n - Invalid message type. The message / stanza has been decoded successfully, but it's not a groupchat message.","title":"Output format"},{"location":"migrations/jid-from-mam-muc-script/#examples","text":"tools/migration folder contains two files: sender-jid-from-mam-message.example.eterm and sender-jid-from-mam-message.example.xml . They are input samples for the script and may be used as a reference for the script usage. You can test them by running: tools/migration/sender-jid-from-mam-message.escript eterm < sender-jid-from-mam-message.example.eterm > out tools/migration/sender-jid-from-mam-message.escript xml < sender-jid-from-mam-message.example.xml > out In both cases the out file should have the following content: 1 2 37 g\u017ceg\u017c\u00f3\u0142ka@brz\u0119czyszczykiewicz.pl","title":"Examples"},{"location":"migrations/jid-from-mam-muc-script/#debug","text":"If an environment variable DEBUG is set to 1 , the script will store error messages in a /tmp/script-debug file.","title":"Debug"},{"location":"modules/mod_adhoc/","text":"Module Description This module implements XEP-0050: Ad-Hoc Commands . It allows XMPP entities to remotely execute various commands using forms. Options modules.mod_adhoc.iqdisc.type Syntax: string, one of \"one_queue\" , \"no_queue\" , \"queues\" , \"parallel\" Default: \"one_queue\" Strategy to handle incoming stanzas. For details, please refer to IQ processing policies . modules.mod_adhoc.report_commands_node Syntax: boolean Default: false Example: report_commands_node = true Determines whether the Ad-Hoc Commands should be announced upon Service Discovery. Example configuration 1 2 [modules.mod_adhoc] report_commands_node = true","title":"mod_adhoc"},{"location":"modules/mod_adhoc/#module-description","text":"This module implements XEP-0050: Ad-Hoc Commands . It allows XMPP entities to remotely execute various commands using forms.","title":"Module Description"},{"location":"modules/mod_adhoc/#options","text":"","title":"Options"},{"location":"modules/mod_adhoc/#modulesmod_adhociqdisctype","text":"Syntax: string, one of \"one_queue\" , \"no_queue\" , \"queues\" , \"parallel\" Default: \"one_queue\" Strategy to handle incoming stanzas. For details, please refer to IQ processing policies .","title":"modules.mod_adhoc.iqdisc.type"},{"location":"modules/mod_adhoc/#modulesmod_adhocreport_commands_node","text":"Syntax: boolean Default: false Example: report_commands_node = true Determines whether the Ad-Hoc Commands should be announced upon Service Discovery.","title":"modules.mod_adhoc.report_commands_node"},{"location":"modules/mod_adhoc/#example-configuration","text":"1 2 [modules.mod_adhoc] report_commands_node = true","title":"Example configuration"},{"location":"modules/mod_amp/","text":"Module Description This module enables support for a subset of the functionality described under XEP-0079: Advanced Message Processing . It currently does not provide features related to timed delivery, i.e the expire-at condition. The error and notify actions are supported, while alert and drop are not. See more below, under XEP Support. Options None. Example Configuration 1 [modules.mod_amp] XEP Support What follows is a short description of which parts of the XEP-0079 specification mod_amp supports. 2.1.1 Service Discovery Both the service discovery information response (Ex.1, 2) and the request/response for individual actions and conditions (Ex.3, 4) are supported . 2.1.2 Specifying Semantics \"Per-hop\" rule semantics are not supported , i.e. ignored. 2.2 Server Processing 2.2.1 Validating Semantics: Performed as in the XEP. The first message to fail validation determines the error message. 2.2.2 supported to spec. 2.2.3 supported to spec. 2.2.4 supported for actions: error and notify . 2.2.5 supported for events: error and notify . 3.3 Defined Conditions 3.3.1 deliver: supported for values: direct , stored , and none . The stored condition works with mod_mam and mod_offline . Note : if both mod_mam and mod_offline are enabled, some delivery conditions may not work correctly. 3.3.2 expire-at: not supported 3.3.3 match-resource: supported 3.4 Defined Actions 3.4.1 alert: not supported 3.4.2 drop: not supported 3.4.3 error: supported 3.4.4 notify: supported . Notifications for the stored and direct conditions are sent as soon as the message has been stored or sent to the recipient. 6. Error Handling 6.2.1 Unsupported Action: supported 6.2.2 Unsupported Condition: supported 6.2.3 Not Acceptable: supported 6.2.4 Service Unavailable is not supported , as it pertains to \"per-hop\" rule processing 6.2.5 Undefined Condition: supported 8. Stream Feature supported 9. Security Considerations Currently, the security measures described in this section have not been implemented. It follows that mod_amp , in its current state, should only be enabled for servers/domains where user presence leaks are not a threat, i.e services where all users can see each other's presence by default. Modifications The following behaviour differs from or extends the guidelines provided in the XEP. The action for the deliver condition with value stored is deferred until the message is stored by mod_mam or mod_offline . The action for the deliver condition with value direct is deferred until the message is sent to the recipient's socket. Server Processing Details When a message with AMP rules is being processed by the server, several system events may occur. For a given event, the rules are processed and each of them can get the matched or undecided status or, if the conditions are not met, it gets no status. If any rules get the matched status, the action for the first of them is performed. After that, the rule list is filtered so that only the undecided ones are left in the message, as they may be matched later. The following system events are defined: initial check - always occurs first, when the message enters the system. mod_mam failed - mod_mam is enabled but fails to store the message. mod_offline failed - the recipient is offline and mod_offline is enabled but fails to store the message. archived - either mod_mam or mod_offline has successfully stored the message. delivery failed - the message was about to be delivered, but it could not be sent. delivered - the message has been sent to the recipient. Mutually exclusive with delivery failed . Rule status is determined for each system event in the following way: initial check If the recipient is online, rules for the direct and none values of the deliver condition become undecided , except rules for the direct value with action error or drop , which become matched . If mod_mam is enabled, rules for the stored value of the deliver condition become undecided . If the recipient has a session for the target resource, rules for the exact and any values of the match-resource condition become matched . Otherwise, rules for the other and any values of the match-resource condition become matched . If the recipient is offline: If mod_mam or mod_offline is enabled, rules for the stored and none values of the deliver conditions become undecided , except rules for the stored value with action error or drop , which become matched . If both mod_mam and mod_offline are disabled, rules for the none delivery condition become matched . mod_mam failed If the recipient is online, rules for direct and none values of the deliver condition become undecided . If the recipient is offline, rules for the none value of the deliver condition become matched . mod_offline failed Rules for the none value of the deliver condition become matched . archived If the recipient is online, rules for direct and stored values of the deliver condition become undecided . If the recipient is offline, rules for the stored value of the deliver condition become matched . delivery failed Rules for the none and stored value of the deliver condition become matched . delivered Rules for the direct value of the deliver condition become matched .","title":"mod_amp"},{"location":"modules/mod_amp/#module-description","text":"This module enables support for a subset of the functionality described under XEP-0079: Advanced Message Processing . It currently does not provide features related to timed delivery, i.e the expire-at condition. The error and notify actions are supported, while alert and drop are not. See more below, under XEP Support.","title":"Module Description"},{"location":"modules/mod_amp/#options","text":"None.","title":"Options"},{"location":"modules/mod_amp/#example-configuration","text":"1 [modules.mod_amp]","title":"Example Configuration"},{"location":"modules/mod_amp/#xep-support","text":"What follows is a short description of which parts of the XEP-0079 specification mod_amp supports. 2.1.1 Service Discovery Both the service discovery information response (Ex.1, 2) and the request/response for individual actions and conditions (Ex.3, 4) are supported . 2.1.2 Specifying Semantics \"Per-hop\" rule semantics are not supported , i.e. ignored. 2.2 Server Processing 2.2.1 Validating Semantics: Performed as in the XEP. The first message to fail validation determines the error message. 2.2.2 supported to spec. 2.2.3 supported to spec. 2.2.4 supported for actions: error and notify . 2.2.5 supported for events: error and notify . 3.3 Defined Conditions 3.3.1 deliver: supported for values: direct , stored , and none . The stored condition works with mod_mam and mod_offline . Note : if both mod_mam and mod_offline are enabled, some delivery conditions may not work correctly. 3.3.2 expire-at: not supported 3.3.3 match-resource: supported 3.4 Defined Actions 3.4.1 alert: not supported 3.4.2 drop: not supported 3.4.3 error: supported 3.4.4 notify: supported . Notifications for the stored and direct conditions are sent as soon as the message has been stored or sent to the recipient. 6. Error Handling 6.2.1 Unsupported Action: supported 6.2.2 Unsupported Condition: supported 6.2.3 Not Acceptable: supported 6.2.4 Service Unavailable is not supported , as it pertains to \"per-hop\" rule processing 6.2.5 Undefined Condition: supported 8. Stream Feature supported 9. Security Considerations Currently, the security measures described in this section have not been implemented. It follows that mod_amp , in its current state, should only be enabled for servers/domains where user presence leaks are not a threat, i.e services where all users can see each other's presence by default.","title":"XEP Support"},{"location":"modules/mod_amp/#modifications","text":"The following behaviour differs from or extends the guidelines provided in the XEP. The action for the deliver condition with value stored is deferred until the message is stored by mod_mam or mod_offline . The action for the deliver condition with value direct is deferred until the message is sent to the recipient's socket.","title":"Modifications"},{"location":"modules/mod_amp/#server-processing-details","text":"When a message with AMP rules is being processed by the server, several system events may occur. For a given event, the rules are processed and each of them can get the matched or undecided status or, if the conditions are not met, it gets no status. If any rules get the matched status, the action for the first of them is performed. After that, the rule list is filtered so that only the undecided ones are left in the message, as they may be matched later. The following system events are defined: initial check - always occurs first, when the message enters the system. mod_mam failed - mod_mam is enabled but fails to store the message. mod_offline failed - the recipient is offline and mod_offline is enabled but fails to store the message. archived - either mod_mam or mod_offline has successfully stored the message. delivery failed - the message was about to be delivered, but it could not be sent. delivered - the message has been sent to the recipient. Mutually exclusive with delivery failed . Rule status is determined for each system event in the following way: initial check If the recipient is online, rules for the direct and none values of the deliver condition become undecided , except rules for the direct value with action error or drop , which become matched . If mod_mam is enabled, rules for the stored value of the deliver condition become undecided . If the recipient has a session for the target resource, rules for the exact and any values of the match-resource condition become matched . Otherwise, rules for the other and any values of the match-resource condition become matched . If the recipient is offline: If mod_mam or mod_offline is enabled, rules for the stored and none values of the deliver conditions become undecided , except rules for the stored value with action error or drop , which become matched . If both mod_mam and mod_offline are disabled, rules for the none delivery condition become matched . mod_mam failed If the recipient is online, rules for direct and none values of the deliver condition become undecided . If the recipient is offline, rules for the none value of the deliver condition become matched . mod_offline failed Rules for the none value of the deliver condition become matched . archived If the recipient is online, rules for direct and stored values of the deliver condition become undecided . If the recipient is offline, rules for the stored value of the deliver condition become matched . delivery failed Rules for the none and stored value of the deliver condition become matched . delivered Rules for the direct value of the deliver condition become matched .","title":"Server Processing Details"},{"location":"modules/mod_auth_token/","text":"Module Description This module implements handling of tokens in an OAuth-like authentication scheme. It provides services necessary to: deserialize/serialize binary tokens received and issued by the server, validate incoming binary tokens, i.e.: check integrity using Message Authentication Codes (MAC) with server-side stored user keys, check validity against the configured validity duration times, check revocation status, handle token requests from logged in users. The module itself does not implement protocol related details - these are implemented in cyrsasl.erl . Generation of keys necessary to sign binary tokens is delegated to module mod_keystore.erl . Options modules.mod_auth_token.validity_period Syntax: Array of TOML tables with the following keys: token , value , unit and following values: {token = values: \"access\", \"refresh\", \"provision\" , value = non-negative integer , unit = values: \"days\", \"hours\", \"minutes\", \"seconds\" }. Default: [{token = \"access\", value = 1, unit = \"hours\"}, {token = \"refresh\", value = 25, unit = \"days\"}] Example: [{token = \"access\", value = 13, unit = \"minutes\"}, {token = \"refresh\", value = 13, unit = \"days\"}] Validity periods of access and refresh tokens can be defined independently. Validity period configuration for provision tokens happens outside the module since the server does not generate provision tokens - it only validates them. Required keys To read more about the keys MongooseIM makes use of, please refer to mod_keystore documentation. Token types Three token types are supported: access tokens : These are short lived tokens which grants aren't tracked by the server (i.e. there's no need to store anything in a database). Access tokens can be used as a payload for the X-OAUTH authentication mechanism and grant access to the system. Access tokens can't be revoked. An access token is valid only until its expiry date is reached. refresh tokens : These are longer lived tokens which are tracked by the server and therefore require persistent storage in a relational database. Refresh tokens can be used as a payload for the X-OAUTH authentication mechanism and to grant access to the system. Also they can result in a new set of tokens being returned upon successful authentication. They can be revoked - if a refresh token hasn't been revoked, it is valid until it has expired. On revocation, it immediately becomes invalid. As the server stores information about granted tokens, it can also persistently mark them as revoked. provision tokens : These tokens are generated by a service external to the server. They grant the owner a permission to create an account. A provision token may contain information which the server can use to provision the VCard for the newly created account. Using a provision token to create an account (and inject VCard data) is done similarly to other token types, i.e. by passing it as payload for the X-OAUTH mechanism. The XMPP server has no way of tracking and revoking provision tokens, as they come from an outside source. Token serialization format All tokens (access, refresh, provision) are to be exchanged as Base64 encoded binary data. Serialization format of the token before encoding with Base64 is dependent on its type: 1 2 3 4 5 'access' \\0 <BARE_JID> \\0 <EXPIRES_AT> \\0 <MAC> 'refresh' \\0 <BARE_JID> \\0 <EXPIRES_AT> \\0 <SEQUENCE_NO> \\0 <MAC> 'provision' \\0 <BARE_JID> \\0 <EXPIRES_AT> \\0 <VCARD> \\0 <MAC> For example (these tokens are randomly generated, hence field values don't make much sense - line breaks are inserted only for the sake of formatting, <vCard/> inner XML is snipped): 1 2 3 4 5 6 7 8 'access' \\0 Q8@localhost \\0 64875466454 \\0 0acd0a66d06934791d046060cf9f1ad3c2abb3274cc7e7d7b2bc7e2ac4453ed774b6c6813b40ebec2bbc3774d59d4087 'refresh' \\0 qp@localhost \\0 64875466457 \\0 6 \\0 8f57cb019cd6dc6e7779be165b9558611baf71ee4a40d03e77b78b069f482f96c9d23b1ac1ef69f64c1a1db3d36a96ad 'provision' \\0 Xmi4@localhost \\0 64875466458 \\0 <vCard>...</vCard> \\0 86cd344c98b345390c1961e12cd4005659b4b0b3c7ec475bde9acc9d47eec27e8ddc67003696af582747fb52e578a715 Requesting access or refresh tokens when logged in 1 2 3 <iq type= 'get' to= 'john@localhost' id= '123' > <query xmlns= 'erlang-solutions.com:xmpp:token-auth:0' /> </iq> To request access and refresh tokens for the first time a client should send an IQ stanza after they have successfully authenticated for the first time using some other method. Token response format Requested tokens are being returned by the server wrapped in IQ stanza with the following fields: id : value taken from the request IQ stanza type : result from : bare user JID to : full user JID Example response (encoded tokens have been truncated in this example): 1 2 3 4 5 6 <iq id= '123' type= 'result' from= 'john@localhost' to= 'john@localhost/res1' > <items xmlns= 'erlang-solutions.com:xmpp:token-auth:0' > <access_token> cmVmcmVzaAGQ1Mzk1MmZlYzhkYjhlOTQzM2UxMw== </access_token> <refresh_token> cmVmcmVzaAGQ1Mzk1MmZlYzhkYjhlOTQzM2UxMw== </refresh_token> </items> </iq> Once a client has obtained a token, they may start authenticating using the X-OAUTH SASL mechanism when reaching the authentication phase of an XMPP connection initiation. Login with access or refresh token In order to log into the XMPP server using a previously requested token, a client should send the following stanza: 1 2 3 <auth xmlns= \"urn:ietf:params:xml:ns:xmpp-sasl\" mechanism= \"X-OAUTH\" > cmVmcmVzaAGQ1Mzk1MmZlYzhkYjhlOTQzM2UxMw== </auth> The Base64 encoded content is a token obtained prior to authentication. Authentication will succeed unless the used tokens are expired, revoked, or the keys required for MAC verification could not be found by the server. When using a refresh token to authenticate with the server , the server will respond with a new access token : 1 2 3 <success xmlns= \"urn:ietf:params:xml:ns:xmpp-sasl\" > cmVmcmVzaAGQ1Mzk1MmZlYzhkYjhlOTQzM2UxMw== </success> The above response is to be expected unless the refresh token used is expired or there were some problems processing the key on the server side. Token revocation using command line tool Refresh tokens issued by the server can be used to: log in a user: as an authentication valet, request a new access token with refreshed expiry date. An administrator may revoke a refresh token: 1 mongooseimctl revoke_token owner@xmpphost A client can no longer use a revoked token either for authentication or requesting new access tokens. After a client's token has been revoked, in order to obtain a new refresh token a client has to log in using some other method. Caveat: as of now, the user's session is not terminated automatically on token revocation. Therefore, the user might request a new set of tokens for as long as the session is active, even though their previous token was just revoked (possibly due to a breach / token leak). Moreover, an access token still kept on a compromised device can be used to establish a new session for as long as it's valid - access tokens can't be revoked. To alleviate rerequesting tokens by the user, an operator can use mod_admin extension allowing to terminate the user's connection. Access token validity can't be sidestepped right now. Example configuration 1 2 3 4 5 [modules.mod_auth_token] validity_period = [ { token = \"access\" , value = 13 , unit = \"minutes\" }, { token = \"refresh\" , value = 13 , unit = \"days\" } ]","title":"mod_auth_token"},{"location":"modules/mod_auth_token/#module-description","text":"This module implements handling of tokens in an OAuth-like authentication scheme. It provides services necessary to: deserialize/serialize binary tokens received and issued by the server, validate incoming binary tokens, i.e.: check integrity using Message Authentication Codes (MAC) with server-side stored user keys, check validity against the configured validity duration times, check revocation status, handle token requests from logged in users. The module itself does not implement protocol related details - these are implemented in cyrsasl.erl . Generation of keys necessary to sign binary tokens is delegated to module mod_keystore.erl .","title":"Module Description"},{"location":"modules/mod_auth_token/#options","text":"","title":"Options"},{"location":"modules/mod_auth_token/#modulesmod_auth_tokenvalidity_period","text":"Syntax: Array of TOML tables with the following keys: token , value , unit and following values: {token = values: \"access\", \"refresh\", \"provision\" , value = non-negative integer , unit = values: \"days\", \"hours\", \"minutes\", \"seconds\" }. Default: [{token = \"access\", value = 1, unit = \"hours\"}, {token = \"refresh\", value = 25, unit = \"days\"}] Example: [{token = \"access\", value = 13, unit = \"minutes\"}, {token = \"refresh\", value = 13, unit = \"days\"}] Validity periods of access and refresh tokens can be defined independently. Validity period configuration for provision tokens happens outside the module since the server does not generate provision tokens - it only validates them.","title":"modules.mod_auth_token.validity_period"},{"location":"modules/mod_auth_token/#required-keys","text":"To read more about the keys MongooseIM makes use of, please refer to mod_keystore documentation.","title":"Required keys"},{"location":"modules/mod_auth_token/#token-types","text":"Three token types are supported: access tokens : These are short lived tokens which grants aren't tracked by the server (i.e. there's no need to store anything in a database). Access tokens can be used as a payload for the X-OAUTH authentication mechanism and grant access to the system. Access tokens can't be revoked. An access token is valid only until its expiry date is reached. refresh tokens : These are longer lived tokens which are tracked by the server and therefore require persistent storage in a relational database. Refresh tokens can be used as a payload for the X-OAUTH authentication mechanism and to grant access to the system. Also they can result in a new set of tokens being returned upon successful authentication. They can be revoked - if a refresh token hasn't been revoked, it is valid until it has expired. On revocation, it immediately becomes invalid. As the server stores information about granted tokens, it can also persistently mark them as revoked. provision tokens : These tokens are generated by a service external to the server. They grant the owner a permission to create an account. A provision token may contain information which the server can use to provision the VCard for the newly created account. Using a provision token to create an account (and inject VCard data) is done similarly to other token types, i.e. by passing it as payload for the X-OAUTH mechanism. The XMPP server has no way of tracking and revoking provision tokens, as they come from an outside source.","title":"Token types"},{"location":"modules/mod_auth_token/#token-serialization-format","text":"All tokens (access, refresh, provision) are to be exchanged as Base64 encoded binary data. Serialization format of the token before encoding with Base64 is dependent on its type: 1 2 3 4 5 'access' \\0 <BARE_JID> \\0 <EXPIRES_AT> \\0 <MAC> 'refresh' \\0 <BARE_JID> \\0 <EXPIRES_AT> \\0 <SEQUENCE_NO> \\0 <MAC> 'provision' \\0 <BARE_JID> \\0 <EXPIRES_AT> \\0 <VCARD> \\0 <MAC> For example (these tokens are randomly generated, hence field values don't make much sense - line breaks are inserted only for the sake of formatting, <vCard/> inner XML is snipped): 1 2 3 4 5 6 7 8 'access' \\0 Q8@localhost \\0 64875466454 \\0 0acd0a66d06934791d046060cf9f1ad3c2abb3274cc7e7d7b2bc7e2ac4453ed774b6c6813b40ebec2bbc3774d59d4087 'refresh' \\0 qp@localhost \\0 64875466457 \\0 6 \\0 8f57cb019cd6dc6e7779be165b9558611baf71ee4a40d03e77b78b069f482f96c9d23b1ac1ef69f64c1a1db3d36a96ad 'provision' \\0 Xmi4@localhost \\0 64875466458 \\0 <vCard>...</vCard> \\0 86cd344c98b345390c1961e12cd4005659b4b0b3c7ec475bde9acc9d47eec27e8ddc67003696af582747fb52e578a715","title":"Token serialization format"},{"location":"modules/mod_auth_token/#requesting-access-or-refresh-tokens-when-logged-in","text":"1 2 3 <iq type= 'get' to= 'john@localhost' id= '123' > <query xmlns= 'erlang-solutions.com:xmpp:token-auth:0' /> </iq> To request access and refresh tokens for the first time a client should send an IQ stanza after they have successfully authenticated for the first time using some other method.","title":"Requesting access or refresh tokens when logged in"},{"location":"modules/mod_auth_token/#token-response-format","text":"Requested tokens are being returned by the server wrapped in IQ stanza with the following fields: id : value taken from the request IQ stanza type : result from : bare user JID to : full user JID Example response (encoded tokens have been truncated in this example): 1 2 3 4 5 6 <iq id= '123' type= 'result' from= 'john@localhost' to= 'john@localhost/res1' > <items xmlns= 'erlang-solutions.com:xmpp:token-auth:0' > <access_token> cmVmcmVzaAGQ1Mzk1MmZlYzhkYjhlOTQzM2UxMw== </access_token> <refresh_token> cmVmcmVzaAGQ1Mzk1MmZlYzhkYjhlOTQzM2UxMw== </refresh_token> </items> </iq> Once a client has obtained a token, they may start authenticating using the X-OAUTH SASL mechanism when reaching the authentication phase of an XMPP connection initiation.","title":"Token response format"},{"location":"modules/mod_auth_token/#login-with-access-or-refresh-token","text":"In order to log into the XMPP server using a previously requested token, a client should send the following stanza: 1 2 3 <auth xmlns= \"urn:ietf:params:xml:ns:xmpp-sasl\" mechanism= \"X-OAUTH\" > cmVmcmVzaAGQ1Mzk1MmZlYzhkYjhlOTQzM2UxMw== </auth> The Base64 encoded content is a token obtained prior to authentication. Authentication will succeed unless the used tokens are expired, revoked, or the keys required for MAC verification could not be found by the server. When using a refresh token to authenticate with the server , the server will respond with a new access token : 1 2 3 <success xmlns= \"urn:ietf:params:xml:ns:xmpp-sasl\" > cmVmcmVzaAGQ1Mzk1MmZlYzhkYjhlOTQzM2UxMw== </success> The above response is to be expected unless the refresh token used is expired or there were some problems processing the key on the server side.","title":"Login with access or refresh token"},{"location":"modules/mod_auth_token/#token-revocation-using-command-line-tool","text":"Refresh tokens issued by the server can be used to: log in a user: as an authentication valet, request a new access token with refreshed expiry date. An administrator may revoke a refresh token: 1 mongooseimctl revoke_token owner@xmpphost A client can no longer use a revoked token either for authentication or requesting new access tokens. After a client's token has been revoked, in order to obtain a new refresh token a client has to log in using some other method. Caveat: as of now, the user's session is not terminated automatically on token revocation. Therefore, the user might request a new set of tokens for as long as the session is active, even though their previous token was just revoked (possibly due to a breach / token leak). Moreover, an access token still kept on a compromised device can be used to establish a new session for as long as it's valid - access tokens can't be revoked. To alleviate rerequesting tokens by the user, an operator can use mod_admin extension allowing to terminate the user's connection. Access token validity can't be sidestepped right now.","title":"Token revocation using command line tool"},{"location":"modules/mod_auth_token/#example-configuration","text":"1 2 3 4 5 [modules.mod_auth_token] validity_period = [ { token = \"access\" , value = 13 , unit = \"minutes\" }, { token = \"refresh\" , value = 13 , unit = \"days\" } ]","title":"Example configuration"},{"location":"modules/mod_blocking/","text":"Module Description This module implements XEP-0191: Blocking command . The extension allows blocking the whole communication with a user (or a group of users) with a single command. The protocol is much simpler than privacy lists. Options None. Example Configuration 1 [modules.mod_blocking] The module is not configurable because internally it is an interface to privacy lists, so settings like storage backend apply to it automatically. Issuing a blocking command creates a privacy list named \"blocking\" (if it didn't exist), adds to it items being blocked and sets this list as the default. Unblocking contacts removes them from \"blocking\" privacy list. If the user has other online resources which use privacy lists it may result in a different behaviour per resource; this is normal, and provided for in XEP. Similar to privacy lists, a blocked contact sees the user as offline no matter what their real status is. If the contact being blocked is subscribed to the user's presence, they receive an \"unavailable\" presence; when unblocked, they receive the current status of the user.","title":"mod_blocking"},{"location":"modules/mod_blocking/#module-description","text":"This module implements XEP-0191: Blocking command . The extension allows blocking the whole communication with a user (or a group of users) with a single command. The protocol is much simpler than privacy lists.","title":"Module Description"},{"location":"modules/mod_blocking/#options","text":"None.","title":"Options"},{"location":"modules/mod_blocking/#example-configuration","text":"1 [modules.mod_blocking] The module is not configurable because internally it is an interface to privacy lists, so settings like storage backend apply to it automatically. Issuing a blocking command creates a privacy list named \"blocking\" (if it didn't exist), adds to it items being blocked and sets this list as the default. Unblocking contacts removes them from \"blocking\" privacy list. If the user has other online resources which use privacy lists it may result in a different behaviour per resource; this is normal, and provided for in XEP. Similar to privacy lists, a blocked contact sees the user as offline no matter what their real status is. If the contact being blocked is subscribed to the user's presence, they receive an \"unavailable\" presence; when unblocked, they receive the current status of the user.","title":"Example Configuration"},{"location":"modules/mod_bosh/","text":"Module Description This module implements XEP-0206: XMPP Over BOSH (using XEP-0124: Bidirectional-streams Over Synchronous HTTP (BOSH) ), allowing clients to connect to MongooseIM over regular HTTP long-lived connections. If you want to use BOSH, you must enable it both in the listen section of mongooseim.toml ( Listener Modules ) and as a module. Options modules.mod_bosh.inactivity Syntax: positive integer or the string \"infinity\" Default: 30 Example: inactivity = 30 Maximum allowed inactivity time for a BOSH connection. Please note that a long-polling request is not considered to be an inactivity. modules.mod_bosh.max_wait Syntax: positive integer or the string \"infinity\" Default: \"infinity\" Example: max_wait = 30 This is the longest time (in seconds) that the connection manager will wait before responding to any request during the session. modules.mod_bosh.server_acks Syntax: boolean Default: false Example: server_acks = true Enables/disables acks sent by server. modules.mod_bosh.max_pause Syntax: positive integer Default: 120 Example: max_pause = 30 Maximum allowed pause in seconds (e.g. to switch between pages and then resume connection) to request by client-side. Example Configuration In the listener section: 1 2 3 4 5 6 7 8 [[listen.http]] port = 5280 transport . num_acceptors = 10 transport . max_connections = 1024 [[listen.http.handlers.mod_bosh]] host = \"_\" path = \"/http-bind\" In the module section: 1 2 3 4 5 [modules.mod_bosh] inactivity = 20 max_wait = \"infinity\" server_acks = true max_pause = 120","title":"mod_bosh"},{"location":"modules/mod_bosh/#module-description","text":"This module implements XEP-0206: XMPP Over BOSH (using XEP-0124: Bidirectional-streams Over Synchronous HTTP (BOSH) ), allowing clients to connect to MongooseIM over regular HTTP long-lived connections. If you want to use BOSH, you must enable it both in the listen section of mongooseim.toml ( Listener Modules ) and as a module.","title":"Module Description"},{"location":"modules/mod_bosh/#options","text":"","title":"Options"},{"location":"modules/mod_bosh/#modulesmod_boshinactivity","text":"Syntax: positive integer or the string \"infinity\" Default: 30 Example: inactivity = 30 Maximum allowed inactivity time for a BOSH connection. Please note that a long-polling request is not considered to be an inactivity.","title":"modules.mod_bosh.inactivity"},{"location":"modules/mod_bosh/#modulesmod_boshmax_wait","text":"Syntax: positive integer or the string \"infinity\" Default: \"infinity\" Example: max_wait = 30 This is the longest time (in seconds) that the connection manager will wait before responding to any request during the session.","title":"modules.mod_bosh.max_wait"},{"location":"modules/mod_bosh/#modulesmod_boshserver_acks","text":"Syntax: boolean Default: false Example: server_acks = true Enables/disables acks sent by server.","title":"modules.mod_bosh.server_acks"},{"location":"modules/mod_bosh/#modulesmod_boshmax_pause","text":"Syntax: positive integer Default: 120 Example: max_pause = 30 Maximum allowed pause in seconds (e.g. to switch between pages and then resume connection) to request by client-side.","title":"modules.mod_bosh.max_pause"},{"location":"modules/mod_bosh/#example-configuration","text":"In the listener section: 1 2 3 4 5 6 7 8 [[listen.http]] port = 5280 transport . num_acceptors = 10 transport . max_connections = 1024 [[listen.http.handlers.mod_bosh]] host = \"_\" path = \"/http-bind\" In the module section: 1 2 3 4 5 [modules.mod_bosh] inactivity = 20 max_wait = \"infinity\" server_acks = true max_pause = 120","title":"Example Configuration"},{"location":"modules/mod_caps/","text":"Module description This module provides a presence-based mechanism for exchanging information about entity capabilities as defined in XEP-0115: Entity Capabilities . Additionally, it filters out PEP messages that the recipient declared (in announced caps) being not capable of handling. It is not this module's responsibility to intercept and answer disco requests routed between clients. Options This module expects two optional arguments that apply to cache tab : modules.mod_caps.cache_size Syntax: positive integer Default: 1000 Example: cache_size = 2000 The size of a cache_tab (the amount of entries) holding the information about capabilities of each user. modules.mod_caps.cache_life_time Syntax: positive integer Default: 86_400 (24 hours) Example: cache_life_time = 10_000 Time (in seconds) after which entries will be removed. Example Configuration 1 2 3 [modules.mod_caps] cache_size = 2000 cache_life_time = 10 _000","title":"mod_caps"},{"location":"modules/mod_caps/#module-description","text":"This module provides a presence-based mechanism for exchanging information about entity capabilities as defined in XEP-0115: Entity Capabilities . Additionally, it filters out PEP messages that the recipient declared (in announced caps) being not capable of handling. It is not this module's responsibility to intercept and answer disco requests routed between clients.","title":"Module description"},{"location":"modules/mod_caps/#options","text":"This module expects two optional arguments that apply to cache tab :","title":"Options"},{"location":"modules/mod_caps/#modulesmod_capscache_size","text":"Syntax: positive integer Default: 1000 Example: cache_size = 2000 The size of a cache_tab (the amount of entries) holding the information about capabilities of each user.","title":"modules.mod_caps.cache_size"},{"location":"modules/mod_caps/#modulesmod_capscache_life_time","text":"Syntax: positive integer Default: 86_400 (24 hours) Example: cache_life_time = 10_000 Time (in seconds) after which entries will be removed.","title":"modules.mod_caps.cache_life_time"},{"location":"modules/mod_caps/#example-configuration","text":"1 2 3 [modules.mod_caps] cache_size = 2000 cache_life_time = 10 _000","title":"Example Configuration"},{"location":"modules/mod_carboncopy/","text":"Module Description Discovering Support The server uses a disco query to inform if carbons are enabled. Enabling and disabling Carbons from the client Carbons are not enabled by default. Every client app has to enable carbons to get messages sent to other clients of the user. Carbons are enabled and disabled with an iq stanza with a child element - <enable xmlns='urn:xmpp:carbons:2'/> or <disable xmlns='urn:xmpp:carbons:2'/> . Receiving messages to a bare JID Each message to a bare JID is forked and sent to all carbon enabled resources of the recipient, and not just to the highest priority resource. Sending multiple copies to same resource is avoided. Receiving messages to full JID Each directed message to a full JID is also forwarded to all carbon enabled resources of the recipient. The message is wrapped in the <forwarded xmlns='urn:xmpp:forward:0'></forwarded> tag and directed towards each carbon enabled resource. Sending Messages Just as when receiving messages to a full JID, each sent message is forwarded to all carbon enabled resources of recipient. The message is wrapped in the <forwarded xmlns='urn:xmpp:forward:0'></forwarded> tag and is directed towards each carbon enabled resource. Private Messages Private messages are tagged <private/> and are not forwarded to any carbon enabled resource of the sender and recipient if the to attribute contains a full JID. However, if the message is sent to a bare JID, it is forked to all highest priority resources. This is not done through mod_carboncopy but is an expected outcome. Multiple enable/disable requests Multiple enable/disable requests are not treated as an error even if they come from the same resource. Behavior with other modules mod_offline : Offline messages are delivered as they are. Since, only one resource can connect at a time and there will be a finite time delay between login from two resources, mod_carboncopy has no role to play and only one resource can receive offline messages. Other resources can retrieve old messages from the archive. mod_mam : mod_mam covers only direct messages from one user to another. All the forked messages for a message sent with a bare JID are ignored by mod_mam . Similarly, all the carbon messages are also ignored by mod_mam . Retrieving archive from multiple resources A resource can retrieve archives of messages sent to a specific resource of a friend which will not contain any carbon messages. It will only contain messages directed towards that resource or messages sent with a bare jid when that resource was at the highest priority. A request to mod_mam with a bare JID of the chosen user will retrieve all messages to them from any resource. There are no instances of copies of same messages being sent by mod_mam . This is because mod_mam does not archive carbon messages. Testing with a client The module and its behavior have been tested with mod_offline and mod_mam using a desktop client made in Java using the Smack library. The standard Smack library for carbons is able to unpack and read the carbon messages. Also, the standard library supports checking for carbon support by the server using disco and sending enable and disable requests for carbon messages. A client needs to synchronize with mod_offline and mod_mam . Once a client is online and enables carbons, it will not receive all the messages. mod_mam does not capture any carbon messages so it does not send any duplicates during any archive request. Only the simple chat messages are archived and they can be accessed by using the bare JID of the user for whom the archive is requested. For an Erlang-based test suite, please see this . Options modules.mod_carboncopy.iqdisc.type Syntax: string, one of \"one_queue\" , \"no_queue\" , \"queues\" , \"parallel\" Default: no_queue Strategy to handle incoming stanzas. For details, please refer to IQ processing policies . Example Configuration 1 2 [modules.mod_carboncopy] iqdisc . type = \"no_queue\"","title":"mod_carboncopy"},{"location":"modules/mod_carboncopy/#module-description","text":"","title":"Module Description"},{"location":"modules/mod_carboncopy/#discovering-support","text":"The server uses a disco query to inform if carbons are enabled.","title":"Discovering Support"},{"location":"modules/mod_carboncopy/#enabling-and-disabling-carbons-from-the-client","text":"Carbons are not enabled by default. Every client app has to enable carbons to get messages sent to other clients of the user. Carbons are enabled and disabled with an iq stanza with a child element - <enable xmlns='urn:xmpp:carbons:2'/> or <disable xmlns='urn:xmpp:carbons:2'/> .","title":"Enabling and disabling Carbons from the client"},{"location":"modules/mod_carboncopy/#receiving-messages-to-a-bare-jid","text":"Each message to a bare JID is forked and sent to all carbon enabled resources of the recipient, and not just to the highest priority resource. Sending multiple copies to same resource is avoided.","title":"Receiving messages to a bare JID"},{"location":"modules/mod_carboncopy/#receiving-messages-to-full-jid","text":"Each directed message to a full JID is also forwarded to all carbon enabled resources of the recipient. The message is wrapped in the <forwarded xmlns='urn:xmpp:forward:0'></forwarded> tag and directed towards each carbon enabled resource.","title":"Receiving messages to full JID"},{"location":"modules/mod_carboncopy/#sending-messages","text":"Just as when receiving messages to a full JID, each sent message is forwarded to all carbon enabled resources of recipient. The message is wrapped in the <forwarded xmlns='urn:xmpp:forward:0'></forwarded> tag and is directed towards each carbon enabled resource.","title":"Sending Messages"},{"location":"modules/mod_carboncopy/#private-messages","text":"Private messages are tagged <private/> and are not forwarded to any carbon enabled resource of the sender and recipient if the to attribute contains a full JID. However, if the message is sent to a bare JID, it is forked to all highest priority resources. This is not done through mod_carboncopy but is an expected outcome.","title":"Private Messages"},{"location":"modules/mod_carboncopy/#multiple-enabledisable-requests","text":"Multiple enable/disable requests are not treated as an error even if they come from the same resource.","title":"Multiple enable/disable requests"},{"location":"modules/mod_carboncopy/#behavior-with-other-modules","text":"mod_offline : Offline messages are delivered as they are. Since, only one resource can connect at a time and there will be a finite time delay between login from two resources, mod_carboncopy has no role to play and only one resource can receive offline messages. Other resources can retrieve old messages from the archive. mod_mam : mod_mam covers only direct messages from one user to another. All the forked messages for a message sent with a bare JID are ignored by mod_mam . Similarly, all the carbon messages are also ignored by mod_mam .","title":"Behavior with other modules"},{"location":"modules/mod_carboncopy/#retrieving-archive-from-multiple-resources","text":"A resource can retrieve archives of messages sent to a specific resource of a friend which will not contain any carbon messages. It will only contain messages directed towards that resource or messages sent with a bare jid when that resource was at the highest priority. A request to mod_mam with a bare JID of the chosen user will retrieve all messages to them from any resource. There are no instances of copies of same messages being sent by mod_mam . This is because mod_mam does not archive carbon messages.","title":"Retrieving archive from multiple resources"},{"location":"modules/mod_carboncopy/#testing-with-a-client","text":"The module and its behavior have been tested with mod_offline and mod_mam using a desktop client made in Java using the Smack library. The standard Smack library for carbons is able to unpack and read the carbon messages. Also, the standard library supports checking for carbon support by the server using disco and sending enable and disable requests for carbon messages. A client needs to synchronize with mod_offline and mod_mam . Once a client is online and enables carbons, it will not receive all the messages. mod_mam does not capture any carbon messages so it does not send any duplicates during any archive request. Only the simple chat messages are archived and they can be accessed by using the bare JID of the user for whom the archive is requested. For an Erlang-based test suite, please see this .","title":"Testing with a client"},{"location":"modules/mod_carboncopy/#options","text":"","title":"Options"},{"location":"modules/mod_carboncopy/#modulesmod_carboncopyiqdisctype","text":"Syntax: string, one of \"one_queue\" , \"no_queue\" , \"queues\" , \"parallel\" Default: no_queue Strategy to handle incoming stanzas. For details, please refer to IQ processing policies .","title":"modules.mod_carboncopy.iqdisc.type"},{"location":"modules/mod_carboncopy/#example-configuration","text":"1 2 [modules.mod_carboncopy] iqdisc . type = \"no_queue\"","title":"Example Configuration"},{"location":"modules/mod_commands/","text":"MongooseIM's command set Purpose This is a basic set of administration and client commands. Our goal is to provide a consistent, easy to use API for MongooseIM. Both backend and client commands provide enough information to allow auto-generating access methods. We currently use it in our admin and client REST API interface. In the future it may replace the current mongooseimctl implementation. Configuration This module contains command definitions loaded when the module is activated. There are no more configuration parameters, so the following entry in the config file is sufficient: 1 [modules.mod_commands] Command definition The module contains a list of command definitions. Each definition contains the following entries: name (uniquely identifies the command) category (used for listing commands and for generating URLs for REST API) subcategory (optional) desc (a brief description) module, function (what is called when the command is executed) action (create|read|update|delete) optional: security_policy (info to be used by the caller) args (a list of two-element tuples specifying name and type of an argument) result (what the command (and its underlying function) is supposed to return) A simple command definition may look like this: 1 2 3 4 5 6 7 8 9 10 11 [ { name , list_contacts }, { category , << \"contacts\" >> }, { desc , << \"Get roster\" >> }, { module , ? MODULE }, { function , list_contacts }, { action , read }, { security_policy , [ user ]}, { args , [{ caller , binary }]}, { result , []} ] Command registration and interface Command registry is managed by mongoose_commands module. To register a command simply call: 1 mongoose_commands : register ( list_of_command_definitions ) The registry provides functions for listing commands, retrieving their signatures, and also calling. To call the above method you should do: 1 mongoose_commands : execute ( admin , list_contacts ) % if you want superuser privileges or 1 mongoose_commands : execute ( << \"alice@wonderland.lit\" >> , list_contacts ) and it will return a list of JIDs. REST API would expose this command as 1 http://localhost/api/contacts % use GET, since it is 'read' and return a JSON list of strings. Since this is a user command, REST would expose it on the \"client\" interface and require authorisation headers.","title":"mod_commands"},{"location":"modules/mod_commands/#mongooseims-command-set","text":"","title":"MongooseIM's command set"},{"location":"modules/mod_commands/#purpose","text":"This is a basic set of administration and client commands. Our goal is to provide a consistent, easy to use API for MongooseIM. Both backend and client commands provide enough information to allow auto-generating access methods. We currently use it in our admin and client REST API interface. In the future it may replace the current mongooseimctl implementation.","title":"Purpose"},{"location":"modules/mod_commands/#configuration","text":"This module contains command definitions loaded when the module is activated. There are no more configuration parameters, so the following entry in the config file is sufficient: 1 [modules.mod_commands]","title":"Configuration"},{"location":"modules/mod_commands/#command-definition","text":"The module contains a list of command definitions. Each definition contains the following entries: name (uniquely identifies the command) category (used for listing commands and for generating URLs for REST API) subcategory (optional) desc (a brief description) module, function (what is called when the command is executed) action (create|read|update|delete) optional: security_policy (info to be used by the caller) args (a list of two-element tuples specifying name and type of an argument) result (what the command (and its underlying function) is supposed to return) A simple command definition may look like this: 1 2 3 4 5 6 7 8 9 10 11 [ { name , list_contacts }, { category , << \"contacts\" >> }, { desc , << \"Get roster\" >> }, { module , ? MODULE }, { function , list_contacts }, { action , read }, { security_policy , [ user ]}, { args , [{ caller , binary }]}, { result , []} ]","title":"Command definition"},{"location":"modules/mod_commands/#command-registration-and-interface","text":"Command registry is managed by mongoose_commands module. To register a command simply call: 1 mongoose_commands : register ( list_of_command_definitions ) The registry provides functions for listing commands, retrieving their signatures, and also calling. To call the above method you should do: 1 mongoose_commands : execute ( admin , list_contacts ) % if you want superuser privileges or 1 mongoose_commands : execute ( << \"alice@wonderland.lit\" >> , list_contacts ) and it will return a list of JIDs. REST API would expose this command as 1 http://localhost/api/contacts % use GET, since it is 'read' and return a JSON list of strings. Since this is a user command, REST would expose it on the \"client\" interface and require authorisation headers.","title":"Command registration and interface"},{"location":"modules/mod_csi/","text":"Module Description Enables XEP-0352: Client State Indication functionality. It is implemented mostly in ejabberd_c2s , this module is just a \"starter\", to advertise the csi stream feature. The Client State Indication functionality will be possible to use even without enabling this module, but the feature will not be present in the stream features list. The XEP doesn't require any specific server behaviour in response to CSI stanzas, there are only some suggestions. The implementation in MongooseIM will simply buffer all packets (up to a configured limit) when the session is \"inactive\" and will flush the buffer when it becomes \"active\" again. Options modules.mod_csi.buffer_max Syntax: non-negative integer or the string \"infinity\" Default: 20 Example: buffer_max = 40 Buffer size for messages queued when session was inactive . Example Configuration 1 2 [modules.mod_csi] buffer_max = 40 Metrics If you'd like to learn more about metrics in MongooseIM, please visit MongooseIM metrics page. Name Type Description (when it gets incremented) [Host, modCSIInactive] spiral A client becomes inactive. [Host, modCSIActive] spiral A client becomes active.","title":"mod_csi"},{"location":"modules/mod_csi/#module-description","text":"Enables XEP-0352: Client State Indication functionality. It is implemented mostly in ejabberd_c2s , this module is just a \"starter\", to advertise the csi stream feature. The Client State Indication functionality will be possible to use even without enabling this module, but the feature will not be present in the stream features list. The XEP doesn't require any specific server behaviour in response to CSI stanzas, there are only some suggestions. The implementation in MongooseIM will simply buffer all packets (up to a configured limit) when the session is \"inactive\" and will flush the buffer when it becomes \"active\" again.","title":"Module Description"},{"location":"modules/mod_csi/#options","text":"","title":"Options"},{"location":"modules/mod_csi/#modulesmod_csibuffer_max","text":"Syntax: non-negative integer or the string \"infinity\" Default: 20 Example: buffer_max = 40 Buffer size for messages queued when session was inactive .","title":"modules.mod_csi.buffer_max"},{"location":"modules/mod_csi/#example-configuration","text":"1 2 [modules.mod_csi] buffer_max = 40","title":"Example Configuration"},{"location":"modules/mod_csi/#metrics","text":"If you'd like to learn more about metrics in MongooseIM, please visit MongooseIM metrics page. Name Type Description (when it gets incremented) [Host, modCSIInactive] spiral A client becomes inactive. [Host, modCSIActive] spiral A client becomes active.","title":"Metrics"},{"location":"modules/mod_disco/","text":"Module Description Implements XEP-0030: Service Discovery . The module itself provides only the essential disco interface, the actual capabilities announced by Service Discovery are gathered via executing a fold-type hook. Options modules.mod_disco.iqdisc.type Syntax: string, one of \"one_queue\" , \"no_queue\" , \"queues\" , \"parallel\" Default: \"no_queue\" Strategy to handle incoming stanzas. For details, please refer to IQ processing policies . modules.mod_disco.extra_domains Syntax: array of strings, valid domain names Default: no extra domains Example: extra_domains = [\"custom_domain\"] Adds domains that are not registered with other means to a local item announcement (response to http://jabber.org/protocol/disco#items IQ get). Please note that mod_disco doesn't verify these domains, so if no handlers are registered later for them, a client will receive a service-unavailable error for every stanza sent to one of these hosts. modules.mod_disco.server_info Syntax: array of tables described below Default: no additional server info Example: 1 2 3 server_info = [ { name = \"abuse-address\" , urls = [ \"admin@example.com\" ]} ] Adds extra disco information to all or chosen modules. New fields will be added in a manner compliant with XEP-0157: Contact Addresses for XMPP Services . Keys and their values for each entry: name - required, a non-empty string with the name of the field urls - required, an array of valid addresses modules - optional, an array of module names for which the additional server information is to be returned. By default the server information is returned for all modules. modules.mod_disco.users_can_see_hidden_services Syntax: boolean Default: true Example: users_can_see_hidden_services = false MongooseIM node with this option set to false will exclude \"hidden components\" from disco results sent to clients (identified by bare or full JID). Other entities, with empty username part in their JIDs (e.g. component.example.com ), will still receive full disco results. Example Configuration 1 2 3 4 5 6 7 8 [modules.mod_disco] iqdisc . type = \"one_queue\" extra_domains = [\"some_domain\", \"another_domain\"] server_info = [ { name = \"abuse-address\" , urls = [ \"admin@example.com\" ]}, { name = \"friendly-spirits\" , urls = [ \"spirit1@localhost\" , \"spirit2@localhost\" ], modules = [ \"mod_muc\" , \"mod_disco\" ]} ] users_can_see_hidden_services = true","title":"mod_disco"},{"location":"modules/mod_disco/#module-description","text":"Implements XEP-0030: Service Discovery . The module itself provides only the essential disco interface, the actual capabilities announced by Service Discovery are gathered via executing a fold-type hook.","title":"Module Description"},{"location":"modules/mod_disco/#options","text":"","title":"Options"},{"location":"modules/mod_disco/#modulesmod_discoiqdisctype","text":"Syntax: string, one of \"one_queue\" , \"no_queue\" , \"queues\" , \"parallel\" Default: \"no_queue\" Strategy to handle incoming stanzas. For details, please refer to IQ processing policies .","title":"modules.mod_disco.iqdisc.type"},{"location":"modules/mod_disco/#modulesmod_discoextra_domains","text":"Syntax: array of strings, valid domain names Default: no extra domains Example: extra_domains = [\"custom_domain\"] Adds domains that are not registered with other means to a local item announcement (response to http://jabber.org/protocol/disco#items IQ get). Please note that mod_disco doesn't verify these domains, so if no handlers are registered later for them, a client will receive a service-unavailable error for every stanza sent to one of these hosts.","title":"modules.mod_disco.extra_domains"},{"location":"modules/mod_disco/#modulesmod_discoserver_info","text":"Syntax: array of tables described below Default: no additional server info Example: 1 2 3 server_info = [ { name = \"abuse-address\" , urls = [ \"admin@example.com\" ]} ] Adds extra disco information to all or chosen modules. New fields will be added in a manner compliant with XEP-0157: Contact Addresses for XMPP Services . Keys and their values for each entry: name - required, a non-empty string with the name of the field urls - required, an array of valid addresses modules - optional, an array of module names for which the additional server information is to be returned. By default the server information is returned for all modules.","title":"modules.mod_disco.server_info"},{"location":"modules/mod_disco/#modulesmod_discousers_can_see_hidden_services","text":"Syntax: boolean Default: true Example: users_can_see_hidden_services = false MongooseIM node with this option set to false will exclude \"hidden components\" from disco results sent to clients (identified by bare or full JID). Other entities, with empty username part in their JIDs (e.g. component.example.com ), will still receive full disco results.","title":"modules.mod_disco.users_can_see_hidden_services"},{"location":"modules/mod_disco/#example-configuration","text":"1 2 3 4 5 6 7 8 [modules.mod_disco] iqdisc . type = \"one_queue\" extra_domains = [\"some_domain\", \"another_domain\"] server_info = [ { name = \"abuse-address\" , urls = [ \"admin@example.com\" ]}, { name = \"friendly-spirits\" , urls = [ \"spirit1@localhost\" , \"spirit2@localhost\" ], modules = [ \"mod_muc\" , \"mod_disco\" ]} ] users_can_see_hidden_services = true","title":"Example Configuration"},{"location":"modules/mod_domain_isolation/","text":"Module Description This module limits message passing between domains.","title":"mod_domain_isolation"},{"location":"modules/mod_domain_isolation/#module-description","text":"This module limits message passing between domains.","title":"Module Description"},{"location":"modules/mod_event_pusher/","text":"Module Description This module is a generic interface for event-pushing backends. It defines a single callback, push_event/3 that forwards the event to all registered backends. Each backend decides how and if to handle the event in its push_event/2 implementation. The events are standardized as records that can be found in the mod_event_pusher_events.hrl file. Common events like user presence changes (offline and online), chat and groupchat messages (incoming and outgoing) are already hooked up to the frontend via mod_event_pusher_hook_translator , a mod_event_pusher dependency, which is a proxy between various hooks and the push_event/3 hook handler. Options modules.mod_event_pusher.backend Syntax: Array of TOML tables. See description. Default: see description Example: see description Specifies backends to register with the frontend, along with arguments that will be passed to the backend. Currently supported backends include sns , push , http_notification and rabbit . Refer to their specific documentation to learn more about their functions and configuration options. Example configuration 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 [modules.mod_event_pusher] backend . sns . access_key_id = \"AKIAIOSFODNN7EXAMPLE\" backend . sns . secret_access_key = \"wJalrXUtnFEMI/K7MDENG/bPxRfiCYEXAMPLEKEY\" # ... backend . push . backend = \"mnesia\" backend . push . wpool . workers = 200 # ... backend . http . pool_name = \"http_pool\" backend . http . path = \"/notifications\" # ... backend . rabbit . presence_exchange . name = \"presence\" backend . rabbit . presence_exchange . type = \"topic\" # ...","title":"mod_event_pusher"},{"location":"modules/mod_event_pusher/#module-description","text":"This module is a generic interface for event-pushing backends. It defines a single callback, push_event/3 that forwards the event to all registered backends. Each backend decides how and if to handle the event in its push_event/2 implementation. The events are standardized as records that can be found in the mod_event_pusher_events.hrl file. Common events like user presence changes (offline and online), chat and groupchat messages (incoming and outgoing) are already hooked up to the frontend via mod_event_pusher_hook_translator , a mod_event_pusher dependency, which is a proxy between various hooks and the push_event/3 hook handler.","title":"Module Description"},{"location":"modules/mod_event_pusher/#options","text":"","title":"Options"},{"location":"modules/mod_event_pusher/#modulesmod_event_pusherbackend","text":"Syntax: Array of TOML tables. See description. Default: see description Example: see description Specifies backends to register with the frontend, along with arguments that will be passed to the backend. Currently supported backends include sns , push , http_notification and rabbit . Refer to their specific documentation to learn more about their functions and configuration options.","title":"modules.mod_event_pusher.backend"},{"location":"modules/mod_event_pusher/#example-configuration","text":"1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 [modules.mod_event_pusher] backend . sns . access_key_id = \"AKIAIOSFODNN7EXAMPLE\" backend . sns . secret_access_key = \"wJalrXUtnFEMI/K7MDENG/bPxRfiCYEXAMPLEKEY\" # ... backend . push . backend = \"mnesia\" backend . push . wpool . workers = 200 # ... backend . http . pool_name = \"http_pool\" backend . http . path = \"/notifications\" # ... backend . rabbit . presence_exchange . name = \"presence\" backend . rabbit . presence_exchange . type = \"topic\" # ...","title":"Example configuration"},{"location":"modules/mod_event_pusher_http/","text":"Module description This module is a backend of mod_event_pusher that enables forwarding certain events (messages, presence, etc.) via HTTP to external services such as push (by mobile, email or SMS), big data, or analytics services. How it works The module hooks on all packets sent by connected users. When the hook is triggered, the module: runs a callback module's should_make_req/6 function to see if a notification should be sent runs a callback module's prepare_headers/7 to get http headers to be used runs a callback module's prepare_body/7 sends a POST request composed of {Host::binary(), Sender::binary(), Receiver::binary(), Message::binary()} to the http notification server You can make multiple configuration entries for this backend to handle more complicated pushing scenarios (e.g. sending various types of messages to different backends). Callback module To find out what and how to send MongooseIM calls the following callback module's functions: Mod:should_make_req(Acc::mongoose_acc:t(), Dir::in|out, Packet::xmlel(), From::jid(), To::jid(), Opts :: [{atom(), term()}]) . Mod:prepare_headers(Acc::mongoose_acc:t(), Dir::in|out, Host::jid:lserver(), Message::binary(), Sender::jid:luser(), Receiver::luser(), Opts :: [{atom(), term()}]) . Mod:prepare_body(Acc::mongoose_acc:t(), Dir::in|out, Host::jid:lserver(), Message::binary(), Sender::jid:luser(), Receiver::luser(), Opts :: [{atom(), term()}]) . By default it uses the function in mod_event_pusher_http itself, which ships all non-empty chat messages. Prerequisites This module uses a connection pool created by mongoose_http_client. It must be defined in the outgoing_pools settings . Options modules.mod_event_pusher_http.pool_name Syntax: non-empty string Default: \"http_pool\" Example: pool_name = \"http_pool\" Name of the pool to use (as defined in outgoing_pools). modules.mod_event_pusher_http.path Syntax: string Default: \"\" Example: path = \"/notifications\" Path part of an URL to which a request should be sent (will be appended to the pool's prefix path). modules.mod_event_pusher_http.callback_module Syntax: string Default: \"mod_event_pusher_http_defaults\" Example: callback_module = \"mod_event_pusher_http_notifications\" Name of a module which should be used to check whether a notification should be sent. Example configuration 1 2 3 4 5 6 7 8 9 10 11 12 [outgoing_pools.http.http_pool] scope = \"global\" workers = 50 [outgoing_pools.http.http_pool.connection] host = \"https://localhost:8000\" path_prefix = \"/webservice\" request_timeout = 2000 [modules.mod_event_pusher.backend.http] pool_name = \"http_pool\" path = \"/notifications\" Notifications will be POSTed to http://localhost:8000/webservice/notifications . 1 2 3 4 5 6 7 8 9 [[modules.mod_event_pusher.backend.http]] pool_name = \"http_pool\" path = \"/notifications\" callback_module = \"mod_event_pusher_http_notifications\" [[modules.mod_event_pusher.backend.http]] pool_name = \"http_pool\" path = \"/alerts\" callback_module = \"mod_event_pusher_http_alerts\" Here, some notifications will be POSTed to http://localhost:8000/webservice/notifications and some to http://localhost:8000/webservice/alerts , depending on implementation of should_make_req/6 in the two callback modules. Default payload format The default HTTP event pusher sends a POST request with Content-Type application/x-www-form-urlencoded . The form has the following fields: * author : username of the user who authored the message * server : name of the server from where the message originates * receiver : username of the user who the message is for * message : content of <body> element of the message The contents of the author, server and receiver fields are processed by stringprep . As a result, these values are all lower case. Example Below is an example of what the body of an HTTP POST request can look like: 1 \"author=alice&server=localhost&receiver=bob&message=Hi, Bob!\" Metrics If you'd like to learn more about metrics in MongooseIM, please visit MongooseIM metrics page. Name Type Description (when it gets incremented) [Host, mod_event_pusher_http, sent] spiral An HTTP notification is sent successfully. [Host, mod_event_pusher_http, failed] spiral An HTTP notification failed. [Host, mod_event_pusher_http, response_time] histogram Does not include timings of failed requests.","title":"HTTP backend"},{"location":"modules/mod_event_pusher_http/#module-description","text":"This module is a backend of mod_event_pusher that enables forwarding certain events (messages, presence, etc.) via HTTP to external services such as push (by mobile, email or SMS), big data, or analytics services.","title":"Module description"},{"location":"modules/mod_event_pusher_http/#how-it-works","text":"The module hooks on all packets sent by connected users. When the hook is triggered, the module: runs a callback module's should_make_req/6 function to see if a notification should be sent runs a callback module's prepare_headers/7 to get http headers to be used runs a callback module's prepare_body/7 sends a POST request composed of {Host::binary(), Sender::binary(), Receiver::binary(), Message::binary()} to the http notification server You can make multiple configuration entries for this backend to handle more complicated pushing scenarios (e.g. sending various types of messages to different backends).","title":"How it works"},{"location":"modules/mod_event_pusher_http/#callback-module","text":"To find out what and how to send MongooseIM calls the following callback module's functions: Mod:should_make_req(Acc::mongoose_acc:t(), Dir::in|out, Packet::xmlel(), From::jid(), To::jid(), Opts :: [{atom(), term()}]) . Mod:prepare_headers(Acc::mongoose_acc:t(), Dir::in|out, Host::jid:lserver(), Message::binary(), Sender::jid:luser(), Receiver::luser(), Opts :: [{atom(), term()}]) . Mod:prepare_body(Acc::mongoose_acc:t(), Dir::in|out, Host::jid:lserver(), Message::binary(), Sender::jid:luser(), Receiver::luser(), Opts :: [{atom(), term()}]) . By default it uses the function in mod_event_pusher_http itself, which ships all non-empty chat messages.","title":"Callback module"},{"location":"modules/mod_event_pusher_http/#prerequisites","text":"This module uses a connection pool created by mongoose_http_client. It must be defined in the outgoing_pools settings .","title":"Prerequisites"},{"location":"modules/mod_event_pusher_http/#options","text":"","title":"Options"},{"location":"modules/mod_event_pusher_http/#modulesmod_event_pusher_httppool_name","text":"Syntax: non-empty string Default: \"http_pool\" Example: pool_name = \"http_pool\" Name of the pool to use (as defined in outgoing_pools).","title":"modules.mod_event_pusher_http.pool_name"},{"location":"modules/mod_event_pusher_http/#modulesmod_event_pusher_httppath","text":"Syntax: string Default: \"\" Example: path = \"/notifications\" Path part of an URL to which a request should be sent (will be appended to the pool's prefix path).","title":"modules.mod_event_pusher_http.path"},{"location":"modules/mod_event_pusher_http/#modulesmod_event_pusher_httpcallback_module","text":"Syntax: string Default: \"mod_event_pusher_http_defaults\" Example: callback_module = \"mod_event_pusher_http_notifications\" Name of a module which should be used to check whether a notification should be sent.","title":"modules.mod_event_pusher_http.callback_module"},{"location":"modules/mod_event_pusher_http/#example-configuration","text":"1 2 3 4 5 6 7 8 9 10 11 12 [outgoing_pools.http.http_pool] scope = \"global\" workers = 50 [outgoing_pools.http.http_pool.connection] host = \"https://localhost:8000\" path_prefix = \"/webservice\" request_timeout = 2000 [modules.mod_event_pusher.backend.http] pool_name = \"http_pool\" path = \"/notifications\" Notifications will be POSTed to http://localhost:8000/webservice/notifications . 1 2 3 4 5 6 7 8 9 [[modules.mod_event_pusher.backend.http]] pool_name = \"http_pool\" path = \"/notifications\" callback_module = \"mod_event_pusher_http_notifications\" [[modules.mod_event_pusher.backend.http]] pool_name = \"http_pool\" path = \"/alerts\" callback_module = \"mod_event_pusher_http_alerts\" Here, some notifications will be POSTed to http://localhost:8000/webservice/notifications and some to http://localhost:8000/webservice/alerts , depending on implementation of should_make_req/6 in the two callback modules.","title":"Example configuration"},{"location":"modules/mod_event_pusher_http/#default-payload-format","text":"The default HTTP event pusher sends a POST request with Content-Type application/x-www-form-urlencoded . The form has the following fields: * author : username of the user who authored the message * server : name of the server from where the message originates * receiver : username of the user who the message is for * message : content of <body> element of the message The contents of the author, server and receiver fields are processed by stringprep . As a result, these values are all lower case.","title":"Default payload format"},{"location":"modules/mod_event_pusher_http/#example","text":"Below is an example of what the body of an HTTP POST request can look like: 1 \"author=alice&server=localhost&receiver=bob&message=Hi, Bob!\"","title":"Example"},{"location":"modules/mod_event_pusher_http/#metrics","text":"If you'd like to learn more about metrics in MongooseIM, please visit MongooseIM metrics page. Name Type Description (when it gets incremented) [Host, mod_event_pusher_http, sent] spiral An HTTP notification is sent successfully. [Host, mod_event_pusher_http, failed] spiral An HTTP notification failed. [Host, mod_event_pusher_http, response_time] histogram Does not include timings of failed requests.","title":"Metrics"},{"location":"modules/mod_event_pusher_push/","text":"Module Description This module is a backend for mod_event_pusher that implements XEP-0357: Push Notifications . It provides push notification data to the service that delivers actual notifications to a client device. We've prepared a detailed tutorial for a proper push notifications setup on both client and server side. Please make sure that clients provide all form fields required by the specified PubSub node. Some publish errors may result in disabling push notifications for the specific device until it attempts to enable them again. This module is very easy to enable, just paste the following to your MongooseIM configuration file: 1 2 [modules.mod_event_pusher] backend . push . wpool . workers = 100 And that's basically it. You have just enabled the push notification support with 100 asynchronous workers that will handle all push notification related work. Options modules.mod_event_pusher_push.backend Syntax: string, one of \"mnesia\" , \"rdbms\" Default: \"mnesia\" Example: backend = \"rdbms\" Backend to use for storing the registrations. modules.mod_event_pusher_push.wpool Syntax: TOML table with worker pool options Default: {} Example: wpool.workers = 200 Array of options that will be passed to the worker_pool library that handles all the requests. The options allowed here are the same as for the outgoing connection pools . modules.mod_event_pusher_push.plugin_module Syntax: non-empty string Default: \"mod_event_pusher_push_plugin_defaults\" Example: plugin_module = \"mod_event_pusher_push_plugin_defaults\" The module implementing mod_event_pusher_push_plugin behaviour, used for dynamic configuration of push notifications. See the relevant section for more details. modules.mod_event_pusher_push.virtual_pubsub_hosts Syntax: array of strings Default: [] Example: virtual_pubsub_hosts = [\"host1\", \"host2\"] The list of \"simulated\" Publish-Subscribe domains. You may use the @HOSTS@ pattern in the domain name. It will automatically be replaced by a respective XMPP domain (e.g. localhost ). See the relevant section for more details. Virtual PubSub hosts If a notification is published to one of the configured domains, the internal push notification hook is executed in MongooseIM instead of the XEP-0357 typical behaviour. If an existing PubSub domain is added to this list, it will be shadowed in the push notifications context. To ensure complete shadowing of all the PubSub subdomains we must use the @HOSTS@ pattern, otherwise only the subdomain of the user is shadowed. It enables easy migration from PubSub-full deployments to PubSub-less variants. Migration from XEP-0357 to virtual hosts This is an example of how you can migrate the existing setup to the new model. PubSub service still exists, just for the case of a user attempting to create a node. However, its domain is overridden for the purpose of sending push notifications. Please note the value of virtual_pubsub_hosts option. \"pubsub.@HOSTS@\" is the default domain for mod_pubsub . 1 2 3 4 5 6 7 8 [modules.mod_pubsub] plugins = [ \"push\" ] # mandatory minimal config [modules.mod_event_pusher] backend . push . backend = \"mnesia\" # optional backend . push . wpool . workers = 200 # optional backend . push . plugin_module = \"mod_event_pusher_push_plugin_defaults\" # optional backend . push . virtual_pubsub_hosts = [\"pubsub.@HOSTS@\"] Advantages Versatility: PubSub-less and PubSub-full mechanisms can be configured with different domains and therefore give fine-grained control over the push notification handling Takes advantage of the PubSub-less efficiency when told to do so Fully compliant with XEP-0357: Push Notifications and therefore with most 3rd party client libraries Ideal for migrations to PubSub-less deployments. Drawbacks More complex configuration on the server side Pays the PubSub performance penalty when the PubSub path is taken Plugin module You can also control the format of the \"sender\" of the push notification (which ultimately becomes the title of push notification) and filter which messages will trigger the notification. In order to achieve that, you need to create a plugin module that implements the mod_event_pusher_push_plugin behaviour and enable this plugin in the plugin_module section as above. A plugin module handles the dynamic configuration of push notifications. It contains the filtering and custom logic for notifying about messages. Two plugin implementations are provided. They offer different behaviour considering unacknowledged messages when using XEP-0198: Stream Management : mod_event_pusher_push_plugin_defaults , which implements an older behaviour. It does not notify the user of unacknowledged messages immediately after detecting a lost connection to the user. mod_event_pusher_push_plugin_enhanced , which pushes notifications as soon as the server detects that the client has disconnected and waits for stream resumption (by an unack_msg_event event generated by the unacknowledged_message hook). This immediate notification prevents the unneeded suspension of the client's application, if there are no unacknowledged messages yet. This allows to create more power efficient mobile applications. In order for the enhanced plugin to work, each device (an entity that may receive push notifications) should be uniquely identified. The only correct way to identify a device from the XMPP standpoint is to use the data provided with the enable stanza . Because of that, each device should (re)enable the push notifications at the beginning of each and every connection. Custom plugins A custom module implementing the optional callbacks of mod_event_pusher_push_plugin may be used as a plugin to change the default behaviour. In the case of not implemented callbacks the defaults are used instead.","title":"Push backend"},{"location":"modules/mod_event_pusher_push/#module-description","text":"This module is a backend for mod_event_pusher that implements XEP-0357: Push Notifications . It provides push notification data to the service that delivers actual notifications to a client device. We've prepared a detailed tutorial for a proper push notifications setup on both client and server side. Please make sure that clients provide all form fields required by the specified PubSub node. Some publish errors may result in disabling push notifications for the specific device until it attempts to enable them again. This module is very easy to enable, just paste the following to your MongooseIM configuration file: 1 2 [modules.mod_event_pusher] backend . push . wpool . workers = 100 And that's basically it. You have just enabled the push notification support with 100 asynchronous workers that will handle all push notification related work.","title":"Module Description"},{"location":"modules/mod_event_pusher_push/#options","text":"","title":"Options"},{"location":"modules/mod_event_pusher_push/#modulesmod_event_pusher_pushbackend","text":"Syntax: string, one of \"mnesia\" , \"rdbms\" Default: \"mnesia\" Example: backend = \"rdbms\" Backend to use for storing the registrations.","title":"modules.mod_event_pusher_push.backend"},{"location":"modules/mod_event_pusher_push/#modulesmod_event_pusher_pushwpool","text":"Syntax: TOML table with worker pool options Default: {} Example: wpool.workers = 200 Array of options that will be passed to the worker_pool library that handles all the requests. The options allowed here are the same as for the outgoing connection pools .","title":"modules.mod_event_pusher_push.wpool"},{"location":"modules/mod_event_pusher_push/#modulesmod_event_pusher_pushplugin_module","text":"Syntax: non-empty string Default: \"mod_event_pusher_push_plugin_defaults\" Example: plugin_module = \"mod_event_pusher_push_plugin_defaults\" The module implementing mod_event_pusher_push_plugin behaviour, used for dynamic configuration of push notifications. See the relevant section for more details.","title":"modules.mod_event_pusher_push.plugin_module"},{"location":"modules/mod_event_pusher_push/#modulesmod_event_pusher_pushvirtual_pubsub_hosts","text":"Syntax: array of strings Default: [] Example: virtual_pubsub_hosts = [\"host1\", \"host2\"] The list of \"simulated\" Publish-Subscribe domains. You may use the @HOSTS@ pattern in the domain name. It will automatically be replaced by a respective XMPP domain (e.g. localhost ). See the relevant section for more details.","title":"modules.mod_event_pusher_push.virtual_pubsub_hosts"},{"location":"modules/mod_event_pusher_push/#virtual-pubsub-hosts","text":"If a notification is published to one of the configured domains, the internal push notification hook is executed in MongooseIM instead of the XEP-0357 typical behaviour. If an existing PubSub domain is added to this list, it will be shadowed in the push notifications context. To ensure complete shadowing of all the PubSub subdomains we must use the @HOSTS@ pattern, otherwise only the subdomain of the user is shadowed. It enables easy migration from PubSub-full deployments to PubSub-less variants.","title":"Virtual PubSub hosts"},{"location":"modules/mod_event_pusher_push/#migration-from-xep-0357-to-virtual-hosts","text":"This is an example of how you can migrate the existing setup to the new model. PubSub service still exists, just for the case of a user attempting to create a node. However, its domain is overridden for the purpose of sending push notifications. Please note the value of virtual_pubsub_hosts option. \"pubsub.@HOSTS@\" is the default domain for mod_pubsub . 1 2 3 4 5 6 7 8 [modules.mod_pubsub] plugins = [ \"push\" ] # mandatory minimal config [modules.mod_event_pusher] backend . push . backend = \"mnesia\" # optional backend . push . wpool . workers = 200 # optional backend . push . plugin_module = \"mod_event_pusher_push_plugin_defaults\" # optional backend . push . virtual_pubsub_hosts = [\"pubsub.@HOSTS@\"]","title":"Migration from XEP-0357 to virtual hosts"},{"location":"modules/mod_event_pusher_push/#advantages","text":"Versatility: PubSub-less and PubSub-full mechanisms can be configured with different domains and therefore give fine-grained control over the push notification handling Takes advantage of the PubSub-less efficiency when told to do so Fully compliant with XEP-0357: Push Notifications and therefore with most 3rd party client libraries Ideal for migrations to PubSub-less deployments.","title":"Advantages"},{"location":"modules/mod_event_pusher_push/#drawbacks","text":"More complex configuration on the server side Pays the PubSub performance penalty when the PubSub path is taken","title":"Drawbacks"},{"location":"modules/mod_event_pusher_push/#plugin-module","text":"You can also control the format of the \"sender\" of the push notification (which ultimately becomes the title of push notification) and filter which messages will trigger the notification. In order to achieve that, you need to create a plugin module that implements the mod_event_pusher_push_plugin behaviour and enable this plugin in the plugin_module section as above. A plugin module handles the dynamic configuration of push notifications. It contains the filtering and custom logic for notifying about messages. Two plugin implementations are provided. They offer different behaviour considering unacknowledged messages when using XEP-0198: Stream Management : mod_event_pusher_push_plugin_defaults , which implements an older behaviour. It does not notify the user of unacknowledged messages immediately after detecting a lost connection to the user. mod_event_pusher_push_plugin_enhanced , which pushes notifications as soon as the server detects that the client has disconnected and waits for stream resumption (by an unack_msg_event event generated by the unacknowledged_message hook). This immediate notification prevents the unneeded suspension of the client's application, if there are no unacknowledged messages yet. This allows to create more power efficient mobile applications. In order for the enhanced plugin to work, each device (an entity that may receive push notifications) should be uniquely identified. The only correct way to identify a device from the XMPP standpoint is to use the data provided with the enable stanza . Because of that, each device should (re)enable the push notifications at the beginning of each and every connection.","title":"Plugin module"},{"location":"modules/mod_event_pusher_push/#custom-plugins","text":"A custom module implementing the optional callbacks of mod_event_pusher_push_plugin may be used as a plugin to change the default behaviour. In the case of not implemented callbacks the defaults are used instead.","title":"Custom plugins"},{"location":"modules/mod_event_pusher_rabbit/","text":"Current status This module is still in an experimental phase. Module Description This module is a backend of mod_event_pusher that enables support for the RabbitMQ integration. Currently there are 5 available notifications: user presence changed - Carries the user id (full jid by default) and a boolean field corresponding to the current user online status. private message sent/received - Carries the user ids (both sender and receiver) along with the message body. group message sent/received - Carries the user id and the room id (full jids by default) along with the message body. All these notifications are sent as JSON strings to RabbitMQ exchanges. Type of exchanges can be chosen as desired. Each type of the notifications is sent to its dedicated exchange. There are three exchanges created on startup of the module, for presences, private messages and group chat messages related events. Messages are published to a RabbitMQ server with routing key being set to a user bare jid ( user@domain ) and configurable topic e.g alice@localhost.private_message_sent . The module requires rabbit pool of AMQP connections to be configured in order to make the module work. It's well advised to read through Advanced configuration/Outgoing connections section before enabling the module. Presence exchange options modules.mod_event_pusher.backend.rabbit.presence_exchange.name Syntax: non-empty string Default: \"presence\" Example: name = \"custom_presence_name\" Defines RabbitMQ presence exchange name. modules.mod_event_pusher.backend.rabbit.presence_exchange.type Syntax: non-empty string Default: \"topic\" Example: type = \"custom_presence_topic\" Defines RabbitMQ presence exchange type. Chat message options modules.mod_event_pusher.backend.rabbit.chat_msg_exchange.name Syntax: non-empty string Default: \"chat_msg\" Example: name = \"custom_msg_name\" Defines RabbitMQ chat message exchange name. modules.mod_event_pusher.backend.rabbit.chat_msg_exchange.type Syntax: non-empty string Default: \"topic\" Example: type = \"custom_msg_topic\" Defines RabbitMQ chat message exchange type. modules.mod_event_pusher.backend.rabbit.chat_msg_exchange.sent_topic Syntax: non-empty string Default: \"chat_msg_sent\" Example: sent_topic = \"custom_sent_topic\" Defines RabbitMQ chat message sent topic name. modules.mod_event_pusher.backend.rabbit.chat_msg_exchange.recv_topic Syntax: non-empty string Default: \"chat_msg_recv\" Example: recv_topic = \"custom_recv_topic\" Defines RabbitMQ chat message received topic name. Group chat message options modules.mod_event_pusher.backend.rabbit.groupchat_msg_exchange.name Syntax: non-empty string Default: \"groupchat_msg\" Example: name = \"custom_group_msg_name\" Defines RabbitMQ group chat message exchange name. modules.mod_event_pusher.backend.rabbit.groupchat_msg_exchange.type Syntax: non-empty string Default: \"topic\" Example: type = \"custom_group_msg_topic\" Defines RabbitMQ group chat message exchange type. modules.mod_event_pusher.backend.rabbit.groupchat_msg_exchange.sent_topic Syntax: non-empty string Default: \"groupchat_msg_sent\" Example: sent_topic = \"custom_group_sent_topic\" Defines RabbitMQ group chat message sent topic name. modules.mod_event_pusher.backend.rabbit.groupchat_msg_exchange.recv_topic Syntax: non-empty string Default: \"groupchat_msg_recv\" Example: recv_topic = \"custom_group_recv_topic\" Defines RabbitMQ group chat message received topic name. Example configuration 1 2 3 4 5 6 7 8 9 [modules.mod_event_pusher] backend . rabbit . presence_exchange . name = \"presence\" backend . rabbit . presence_exchange . type = \"topic\" backend . rabbit . chat_msg_exchange . name = \"chat_msg\" backend . rabbit . chat_msg_exchange . sent_topic = \"chat_msg_sent\" backend . rabbit . chat_msg_exchange . recv_topic = \"chat_msg_recv\" backend . rabbit . groupchat_msg_exchange . name = \"groupchat_msg\" backend . rabbit . groupchat_msg_exchange . sent_topic = \"groupchat_msg_sent\" backend . rabbit . groupchat_msg_exchange . recv_topic = \"groupchat_msg_recv\" JSON Schema examples The different kinds of notifications deliver slightly different messages. The messages are delivered in a JSON format. Presence updates The JSON format for an online presence update notification is: 1 2 3 4 { \"user_id\" : \"alice@localhost/res1\" , \"present\" : true } For offline presence updates, the present boolean value is set to false: 1 2 3 4 { \"user_id\" : \"alice@localhost/res1\" , \"present\" : false } Sent/received messages The JSON format for a private message notification is: 1 2 3 4 5 { \"to_user_id\" : \"bob@localhost/res1\" , \"message\" : \"Hello, Bob\" , \"from_user_id\" : \"alice@localhost/res1\" } The notification is similar for group messages. For example for \"sent\" events: 1 2 3 4 5 { \"to_user_id\" : \"muc_publish@muc.localhost\" , \"message\" : \"Hi, Everyone!\" , \"from_user_id\" : \"bob@localhost/res1\" } and for \"received\" events: 1 2 3 4 5 { \"to_user_id\" : \"bob@localhost/res1\" , \"message\" : \"Hi, Everyone!\" , \"from_user_id\" : \"muc_publish@muc.localhost/alice\" } Metrics The module provides some metrics related to RabbitMQ connections and messages as well. Provided metrics: name type description (when it gets incremented/decremented) [ Host , connections_active ] spiral A connection to a RabbitMQ server is opened(+1)/closed(-1). [ Host , connections_opened ] spiral A connection to a RabbitMQ server is opened. [ Host , connections_closed ] spiral A connection to a RabbitMQ server is closed. [ Host , connection_failed ] spiral A try to open a connection to a RabbitMQ server failed. [ Host , messages_published ] spiral A message to a RabbitMQ server is published. [ Host , messages_failed ] spiral A message to a RabbitMQ server is rejected. [ Host , messages_timeout ] spiral A message to a RabbitMQ server timed out (weren't confirmed by the server). [ Host , message_publish_time ] histogram Amount of time it takes to publish a message to a RabbitMQ server and receive a confirmation. It's measured only for successful messages. [ Host , message_payload_size ] histogram Size of a message (in bytes) that was published to a RabbitMQ server (including message properties). It's measured only for successful messages. All the above metrics have a prefix which looks as follows: <xmpp_host>.backends.mod_event_pusher_rabbit.<metric_name> . For example a proper metric name would look like: localhost.backends.mod_event_pusher_rabbit.connections_active Guarantees There are no guarantees. The current implementation uses \"best effort\" approach which means that we don't care if a message is delivered to a RabbitMQ server. If publisher confirms are enabled and a message couldn't be delivered to the server for some reason (the server sent negative acknowledgment/didn't sent it at all or there was a channel exception) the module just updates appropriate metrics and prints some log messages. Notice that there might be situations when a message silently gets lost. Type of exchanges By default all the exchanges used are of type topic . Using topic exchanges gives a lot of flexibility when binding queues to such an exchange by using # and * in binding keys. But flexibility comes at the cost of performance - imagine a scenario where there are thousands of users and AMQP consumers use binding keys for particular users which look like user_N@host.# . In such case RabbitMQ has to go through all the users in order to find out where a message should be sent to. This operations is proved to be costly. In a load test with 100k users a delay caused by this operation was substantial (about an order of magnitude higher than compared to a load test with 60k users). If performance is a top priority go for direct exchanges. Using this type of exchanges is proved to work efficiently with 100k users. Keep in mind it gives up flexibility over performance. Publisher confirms By default publisher confirmations are disabled. However, one-to-one confirmations can be enabled (see RabbitMQ connection setup section). When a worker sends a message to a RabbitMQ server it waits for a confirmation from the server before it starts to process next message. This approach allows to introduce backpressure on a RabbitMQ server connection cause the server can reject/not confirm messages when it's overloaded. On the other hand it can cause performance degradation. Worker selection strategy The module uses mongoose_wpool for managing worker processes and best_worker strategy, for choosing a worker, is in use by default. Different strategies imply different behaviors of the system. Event messages queuing When available_worker strategy is in use all the event messages are queued in single worker pool manager process state. When different strategy is set e.g best_worker those messages are placed in worker processes inboxes. Worker selection strategy can be set in rabbit pool configuration. Event messages ordering None of worker selection strategies ensures that user events will be delivered to a RabbitMQ server properly ordered in time.","title":"RabbitMQ backend"},{"location":"modules/mod_event_pusher_rabbit/#current-status","text":"This module is still in an experimental phase.","title":"Current status"},{"location":"modules/mod_event_pusher_rabbit/#module-description","text":"This module is a backend of mod_event_pusher that enables support for the RabbitMQ integration. Currently there are 5 available notifications: user presence changed - Carries the user id (full jid by default) and a boolean field corresponding to the current user online status. private message sent/received - Carries the user ids (both sender and receiver) along with the message body. group message sent/received - Carries the user id and the room id (full jids by default) along with the message body. All these notifications are sent as JSON strings to RabbitMQ exchanges. Type of exchanges can be chosen as desired. Each type of the notifications is sent to its dedicated exchange. There are three exchanges created on startup of the module, for presences, private messages and group chat messages related events. Messages are published to a RabbitMQ server with routing key being set to a user bare jid ( user@domain ) and configurable topic e.g alice@localhost.private_message_sent . The module requires rabbit pool of AMQP connections to be configured in order to make the module work. It's well advised to read through Advanced configuration/Outgoing connections section before enabling the module.","title":"Module Description"},{"location":"modules/mod_event_pusher_rabbit/#presence-exchange-options","text":"","title":"Presence exchange options"},{"location":"modules/mod_event_pusher_rabbit/#modulesmod_event_pusherbackendrabbitpresence_exchangename","text":"Syntax: non-empty string Default: \"presence\" Example: name = \"custom_presence_name\" Defines RabbitMQ presence exchange name.","title":"modules.mod_event_pusher.backend.rabbit.presence_exchange.name"},{"location":"modules/mod_event_pusher_rabbit/#modulesmod_event_pusherbackendrabbitpresence_exchangetype","text":"Syntax: non-empty string Default: \"topic\" Example: type = \"custom_presence_topic\" Defines RabbitMQ presence exchange type.","title":"modules.mod_event_pusher.backend.rabbit.presence_exchange.type"},{"location":"modules/mod_event_pusher_rabbit/#chat-message-options","text":"","title":"Chat message options"},{"location":"modules/mod_event_pusher_rabbit/#modulesmod_event_pusherbackendrabbitchat_msg_exchangename","text":"Syntax: non-empty string Default: \"chat_msg\" Example: name = \"custom_msg_name\" Defines RabbitMQ chat message exchange name.","title":"modules.mod_event_pusher.backend.rabbit.chat_msg_exchange.name"},{"location":"modules/mod_event_pusher_rabbit/#modulesmod_event_pusherbackendrabbitchat_msg_exchangetype","text":"Syntax: non-empty string Default: \"topic\" Example: type = \"custom_msg_topic\" Defines RabbitMQ chat message exchange type.","title":"modules.mod_event_pusher.backend.rabbit.chat_msg_exchange.type"},{"location":"modules/mod_event_pusher_rabbit/#modulesmod_event_pusherbackendrabbitchat_msg_exchangesent_topic","text":"Syntax: non-empty string Default: \"chat_msg_sent\" Example: sent_topic = \"custom_sent_topic\" Defines RabbitMQ chat message sent topic name.","title":"modules.mod_event_pusher.backend.rabbit.chat_msg_exchange.sent_topic"},{"location":"modules/mod_event_pusher_rabbit/#modulesmod_event_pusherbackendrabbitchat_msg_exchangerecv_topic","text":"Syntax: non-empty string Default: \"chat_msg_recv\" Example: recv_topic = \"custom_recv_topic\" Defines RabbitMQ chat message received topic name.","title":"modules.mod_event_pusher.backend.rabbit.chat_msg_exchange.recv_topic"},{"location":"modules/mod_event_pusher_rabbit/#group-chat-message-options","text":"","title":"Group chat message options"},{"location":"modules/mod_event_pusher_rabbit/#modulesmod_event_pusherbackendrabbitgroupchat_msg_exchangename","text":"Syntax: non-empty string Default: \"groupchat_msg\" Example: name = \"custom_group_msg_name\" Defines RabbitMQ group chat message exchange name.","title":"modules.mod_event_pusher.backend.rabbit.groupchat_msg_exchange.name"},{"location":"modules/mod_event_pusher_rabbit/#modulesmod_event_pusherbackendrabbitgroupchat_msg_exchangetype","text":"Syntax: non-empty string Default: \"topic\" Example: type = \"custom_group_msg_topic\" Defines RabbitMQ group chat message exchange type.","title":"modules.mod_event_pusher.backend.rabbit.groupchat_msg_exchange.type"},{"location":"modules/mod_event_pusher_rabbit/#modulesmod_event_pusherbackendrabbitgroupchat_msg_exchangesent_topic","text":"Syntax: non-empty string Default: \"groupchat_msg_sent\" Example: sent_topic = \"custom_group_sent_topic\" Defines RabbitMQ group chat message sent topic name.","title":"modules.mod_event_pusher.backend.rabbit.groupchat_msg_exchange.sent_topic"},{"location":"modules/mod_event_pusher_rabbit/#modulesmod_event_pusherbackendrabbitgroupchat_msg_exchangerecv_topic","text":"Syntax: non-empty string Default: \"groupchat_msg_recv\" Example: recv_topic = \"custom_group_recv_topic\" Defines RabbitMQ group chat message received topic name.","title":"modules.mod_event_pusher.backend.rabbit.groupchat_msg_exchange.recv_topic"},{"location":"modules/mod_event_pusher_rabbit/#example-configuration","text":"1 2 3 4 5 6 7 8 9 [modules.mod_event_pusher] backend . rabbit . presence_exchange . name = \"presence\" backend . rabbit . presence_exchange . type = \"topic\" backend . rabbit . chat_msg_exchange . name = \"chat_msg\" backend . rabbit . chat_msg_exchange . sent_topic = \"chat_msg_sent\" backend . rabbit . chat_msg_exchange . recv_topic = \"chat_msg_recv\" backend . rabbit . groupchat_msg_exchange . name = \"groupchat_msg\" backend . rabbit . groupchat_msg_exchange . sent_topic = \"groupchat_msg_sent\" backend . rabbit . groupchat_msg_exchange . recv_topic = \"groupchat_msg_recv\"","title":"Example configuration"},{"location":"modules/mod_event_pusher_rabbit/#json-schema-examples","text":"The different kinds of notifications deliver slightly different messages. The messages are delivered in a JSON format.","title":"JSON Schema examples"},{"location":"modules/mod_event_pusher_rabbit/#presence-updates","text":"The JSON format for an online presence update notification is: 1 2 3 4 { \"user_id\" : \"alice@localhost/res1\" , \"present\" : true } For offline presence updates, the present boolean value is set to false: 1 2 3 4 { \"user_id\" : \"alice@localhost/res1\" , \"present\" : false }","title":"Presence updates"},{"location":"modules/mod_event_pusher_rabbit/#sentreceived-messages","text":"The JSON format for a private message notification is: 1 2 3 4 5 { \"to_user_id\" : \"bob@localhost/res1\" , \"message\" : \"Hello, Bob\" , \"from_user_id\" : \"alice@localhost/res1\" } The notification is similar for group messages. For example for \"sent\" events: 1 2 3 4 5 { \"to_user_id\" : \"muc_publish@muc.localhost\" , \"message\" : \"Hi, Everyone!\" , \"from_user_id\" : \"bob@localhost/res1\" } and for \"received\" events: 1 2 3 4 5 { \"to_user_id\" : \"bob@localhost/res1\" , \"message\" : \"Hi, Everyone!\" , \"from_user_id\" : \"muc_publish@muc.localhost/alice\" }","title":"Sent/received messages"},{"location":"modules/mod_event_pusher_rabbit/#metrics","text":"The module provides some metrics related to RabbitMQ connections and messages as well. Provided metrics: name type description (when it gets incremented/decremented) [ Host , connections_active ] spiral A connection to a RabbitMQ server is opened(+1)/closed(-1). [ Host , connections_opened ] spiral A connection to a RabbitMQ server is opened. [ Host , connections_closed ] spiral A connection to a RabbitMQ server is closed. [ Host , connection_failed ] spiral A try to open a connection to a RabbitMQ server failed. [ Host , messages_published ] spiral A message to a RabbitMQ server is published. [ Host , messages_failed ] spiral A message to a RabbitMQ server is rejected. [ Host , messages_timeout ] spiral A message to a RabbitMQ server timed out (weren't confirmed by the server). [ Host , message_publish_time ] histogram Amount of time it takes to publish a message to a RabbitMQ server and receive a confirmation. It's measured only for successful messages. [ Host , message_payload_size ] histogram Size of a message (in bytes) that was published to a RabbitMQ server (including message properties). It's measured only for successful messages. All the above metrics have a prefix which looks as follows: <xmpp_host>.backends.mod_event_pusher_rabbit.<metric_name> . For example a proper metric name would look like: localhost.backends.mod_event_pusher_rabbit.connections_active","title":"Metrics"},{"location":"modules/mod_event_pusher_rabbit/#guarantees","text":"There are no guarantees. The current implementation uses \"best effort\" approach which means that we don't care if a message is delivered to a RabbitMQ server. If publisher confirms are enabled and a message couldn't be delivered to the server for some reason (the server sent negative acknowledgment/didn't sent it at all or there was a channel exception) the module just updates appropriate metrics and prints some log messages. Notice that there might be situations when a message silently gets lost.","title":"Guarantees"},{"location":"modules/mod_event_pusher_rabbit/#type-of-exchanges","text":"By default all the exchanges used are of type topic . Using topic exchanges gives a lot of flexibility when binding queues to such an exchange by using # and * in binding keys. But flexibility comes at the cost of performance - imagine a scenario where there are thousands of users and AMQP consumers use binding keys for particular users which look like user_N@host.# . In such case RabbitMQ has to go through all the users in order to find out where a message should be sent to. This operations is proved to be costly. In a load test with 100k users a delay caused by this operation was substantial (about an order of magnitude higher than compared to a load test with 60k users). If performance is a top priority go for direct exchanges. Using this type of exchanges is proved to work efficiently with 100k users. Keep in mind it gives up flexibility over performance.","title":"Type of exchanges"},{"location":"modules/mod_event_pusher_rabbit/#publisher-confirms","text":"By default publisher confirmations are disabled. However, one-to-one confirmations can be enabled (see RabbitMQ connection setup section). When a worker sends a message to a RabbitMQ server it waits for a confirmation from the server before it starts to process next message. This approach allows to introduce backpressure on a RabbitMQ server connection cause the server can reject/not confirm messages when it's overloaded. On the other hand it can cause performance degradation.","title":"Publisher confirms"},{"location":"modules/mod_event_pusher_rabbit/#worker-selection-strategy","text":"The module uses mongoose_wpool for managing worker processes and best_worker strategy, for choosing a worker, is in use by default. Different strategies imply different behaviors of the system.","title":"Worker selection strategy"},{"location":"modules/mod_event_pusher_rabbit/#event-messages-queuing","text":"When available_worker strategy is in use all the event messages are queued in single worker pool manager process state. When different strategy is set e.g best_worker those messages are placed in worker processes inboxes. Worker selection strategy can be set in rabbit pool configuration.","title":"Event messages queuing"},{"location":"modules/mod_event_pusher_rabbit/#event-messages-ordering","text":"None of worker selection strategies ensures that user events will be delivered to a RabbitMQ server properly ordered in time.","title":"Event messages ordering"},{"location":"modules/mod_event_pusher_sns/","text":"Module Description This module is a backend of mod_event_pusher that enables support for the Amazon SNS service. Currently there are 3 available notifications: user presence changed - Carries the user id (bare jid by default) and a boolean field corresponding to the current user online status. private message sent - Carries the user ids (both sender and receiver) along with the message body. group message sent - Carries the user id and the room id (bare jids by default) along with the message body. All these notifications are sent as a JSON string to Amazon SNS along with custom MessageAttributes (see http://docs.aws.amazon.com/sns/latest/api/API_Publish.html). MessageAttributes can be specified via a plugin module (more details in Options section). Full topics for notifications (ARN as defined in Amazon Resource Names ) are constructed as arn:aws:sns:{region}:{account_id}:{topic} where {region} and {account_id} are substituted with corresponding values from configuration options. {topic} is pulled from configuration option presence_updates_topic , pm_messages_topic or muc_messages_topic based on the notification type. Options modules.mod_event_pusher_sns.presence_updates_topic Syntax: string Default: no default is given Example: presence_updates_topic = \"user_presence_updated\" Defines Amazon SNS Topic for presence change notifications. Remove this option to disable these notifications. modules.mod_event_pusher_sns.pm_messages_topic Syntax: string Default: no default is given Example: pm_messages_topic = \"user_message_sent\" Defines Amazon SNS Topic for private message notifications. Remove this option to disable these notifications. modules.mod_event_pusher_sns.muc_messages_topic Syntax: string Default: no default is given Example: muc_messages_topic = \"user_messagegroup_sent\" Defines Amazon SNS Topic for group message notifications. Remove this option to disable these notifications. modules.mod_event_pusher_sns.plugin_module Syntax: string Default: \"mod_event_pusher_sns_defaults\" Example: plugin_module = \"mod_event_pusher_sns_defaults\" Sets a callback module used for creating user's GUID used in notifications (from user's JID) and for defining custom attributes attached to a published SNS message. modules.mod_event_pusher_sns.sns_host Syntax: string Default: none, this option is mandatory Example: sns_host = \"sns.eu-west-1.amazonaws.com\" URL to the Amazon SNS service. The URL may be in virtual host form , and for AWS needs to point at a specific regional endpoint. The scheme, port and path specified in the URL will be used to publish notifications via HTTP POST method. modules.mod_event_pusher_sns.region Syntax: string Default: none, this option is mandatory Example: region = \"eu-west-1\" The AWS region to use for requests. modules.mod_event_pusher_sns.access_key_id Syntax: string Default: none, this option is mandatory Example: access_key_id = \"AKIAIOSFODNN7EXAMPLE\" ID of the access key to use for authorization. modules.mod_event_pusher_sns.secret_access_key Syntax: string Default: none, this option is mandatory Example: secret_access_key = \"wJalrXUtnFEMI/K7MDENG/bPxRfiCYEXAMPLEKEY\" Secret access key to use for authorization. modules.mod_event_pusher_sns.account_id Syntax: string Default: none, this option is mandatory Example: account_id = \"123456789012\" 12 digit number as defined in AWS Account Identifiers to use for creating TopicArn for publishing notifications. modules.mod_event_pusher_sns.pool_size Syntax: positive integer Default: 100 Example: pool_size = 100 Worker pool size for publishing notifications modules.mod_event_pusher_sns.publish_retry_count Syntax: non-negative integer Default: 2 Example: publish_retry_count = 2 Retry count in case of a publish error. modules.mod_event_pusher_sns.publish_retry_time_ms Syntax: non-negative integer Default: 50 Example: publish_retry_time_ms = 50 Base exponential backoff time (in ms) for publish errors. Example configuration 1 2 3 4 5 6 7 8 9 10 11 12 13 14 [modules.mod_event_pusher] backend . sns . access_key_id = \"AKIAIOSFODNN7EXAMPLE\" backend . sns . secret_access_key = \"wJalrXUtnFEMI/K7MDENG/bPxRfiCYEXAMPLEKEY\" backend . sns . region = \"eu-west-1\" backend . sns . account_id = \"123456789012\" backend . sns . sns_host = \"sns.eu-west-1.amazonaws.com\" backend . sns . muc_host = \"conference.HOST\" backend . sns . plugin_module = \"mod_event_pusher_sns_defaults\" backend . sns . presence_updates_topic = \"user_presence_updated\" backend . sns . pm_messages_topic = \"user_message_sent\" backend . sns . muc_messages_topic = \"user_messagegroup_sent\" backend . sns . pool_size = 100 backend . sns . publish_retry_count = 2 backend . sns . publish_retry_time_ms = 50 JSON Schema examples The different kinds of notifications deliver slightly different messages. The messages are delivered in a JSON format. Presence updates The JSON format for an online presence update notification is: 1 2 3 4 { \"user_id\" : \"alice@localhost\" , \"present\" : true } For offline presence updates, the present boolean value is set to false: 1 2 3 4 { \"user_id\" : \"alice@localhost\" , \"present\" : false } Sent messages The JSON format for a private message notification is: 1 2 3 4 5 { \"to_user_id\" : \"bob@localhost\" , \"message\" : \"Hello, Bob\" , \"from_user_id\" : \"alice@localhost\" } The notification is similar for group messages except that the to_user_id is the recipient room JID. For example: 1 2 3 4 5 { \"to_user_id\" : \"muc_publish@muc.localhost\" , \"message\" : \"Hi, Everyone!\" , \"from_user_id\" : \"bob@localhost\" }","title":"SNS backend"},{"location":"modules/mod_event_pusher_sns/#module-description","text":"This module is a backend of mod_event_pusher that enables support for the Amazon SNS service. Currently there are 3 available notifications: user presence changed - Carries the user id (bare jid by default) and a boolean field corresponding to the current user online status. private message sent - Carries the user ids (both sender and receiver) along with the message body. group message sent - Carries the user id and the room id (bare jids by default) along with the message body. All these notifications are sent as a JSON string to Amazon SNS along with custom MessageAttributes (see http://docs.aws.amazon.com/sns/latest/api/API_Publish.html). MessageAttributes can be specified via a plugin module (more details in Options section). Full topics for notifications (ARN as defined in Amazon Resource Names ) are constructed as arn:aws:sns:{region}:{account_id}:{topic} where {region} and {account_id} are substituted with corresponding values from configuration options. {topic} is pulled from configuration option presence_updates_topic , pm_messages_topic or muc_messages_topic based on the notification type.","title":"Module Description"},{"location":"modules/mod_event_pusher_sns/#options","text":"","title":"Options"},{"location":"modules/mod_event_pusher_sns/#modulesmod_event_pusher_snspresence_updates_topic","text":"Syntax: string Default: no default is given Example: presence_updates_topic = \"user_presence_updated\" Defines Amazon SNS Topic for presence change notifications. Remove this option to disable these notifications.","title":"modules.mod_event_pusher_sns.presence_updates_topic"},{"location":"modules/mod_event_pusher_sns/#modulesmod_event_pusher_snspm_messages_topic","text":"Syntax: string Default: no default is given Example: pm_messages_topic = \"user_message_sent\" Defines Amazon SNS Topic for private message notifications. Remove this option to disable these notifications.","title":"modules.mod_event_pusher_sns.pm_messages_topic"},{"location":"modules/mod_event_pusher_sns/#modulesmod_event_pusher_snsmuc_messages_topic","text":"Syntax: string Default: no default is given Example: muc_messages_topic = \"user_messagegroup_sent\" Defines Amazon SNS Topic for group message notifications. Remove this option to disable these notifications.","title":"modules.mod_event_pusher_sns.muc_messages_topic"},{"location":"modules/mod_event_pusher_sns/#modulesmod_event_pusher_snsplugin_module","text":"Syntax: string Default: \"mod_event_pusher_sns_defaults\" Example: plugin_module = \"mod_event_pusher_sns_defaults\" Sets a callback module used for creating user's GUID used in notifications (from user's JID) and for defining custom attributes attached to a published SNS message.","title":"modules.mod_event_pusher_sns.plugin_module"},{"location":"modules/mod_event_pusher_sns/#modulesmod_event_pusher_snssns_host","text":"Syntax: string Default: none, this option is mandatory Example: sns_host = \"sns.eu-west-1.amazonaws.com\" URL to the Amazon SNS service. The URL may be in virtual host form , and for AWS needs to point at a specific regional endpoint. The scheme, port and path specified in the URL will be used to publish notifications via HTTP POST method.","title":"modules.mod_event_pusher_sns.sns_host"},{"location":"modules/mod_event_pusher_sns/#modulesmod_event_pusher_snsregion","text":"Syntax: string Default: none, this option is mandatory Example: region = \"eu-west-1\" The AWS region to use for requests.","title":"modules.mod_event_pusher_sns.region"},{"location":"modules/mod_event_pusher_sns/#modulesmod_event_pusher_snsaccess_key_id","text":"Syntax: string Default: none, this option is mandatory Example: access_key_id = \"AKIAIOSFODNN7EXAMPLE\" ID of the access key to use for authorization.","title":"modules.mod_event_pusher_sns.access_key_id"},{"location":"modules/mod_event_pusher_sns/#modulesmod_event_pusher_snssecret_access_key","text":"Syntax: string Default: none, this option is mandatory Example: secret_access_key = \"wJalrXUtnFEMI/K7MDENG/bPxRfiCYEXAMPLEKEY\" Secret access key to use for authorization.","title":"modules.mod_event_pusher_sns.secret_access_key"},{"location":"modules/mod_event_pusher_sns/#modulesmod_event_pusher_snsaccount_id","text":"Syntax: string Default: none, this option is mandatory Example: account_id = \"123456789012\" 12 digit number as defined in AWS Account Identifiers to use for creating TopicArn for publishing notifications.","title":"modules.mod_event_pusher_sns.account_id"},{"location":"modules/mod_event_pusher_sns/#modulesmod_event_pusher_snspool_size","text":"Syntax: positive integer Default: 100 Example: pool_size = 100 Worker pool size for publishing notifications","title":"modules.mod_event_pusher_sns.pool_size"},{"location":"modules/mod_event_pusher_sns/#modulesmod_event_pusher_snspublish_retry_count","text":"Syntax: non-negative integer Default: 2 Example: publish_retry_count = 2 Retry count in case of a publish error.","title":"modules.mod_event_pusher_sns.publish_retry_count"},{"location":"modules/mod_event_pusher_sns/#modulesmod_event_pusher_snspublish_retry_time_ms","text":"Syntax: non-negative integer Default: 50 Example: publish_retry_time_ms = 50 Base exponential backoff time (in ms) for publish errors.","title":"modules.mod_event_pusher_sns.publish_retry_time_ms"},{"location":"modules/mod_event_pusher_sns/#example-configuration","text":"1 2 3 4 5 6 7 8 9 10 11 12 13 14 [modules.mod_event_pusher] backend . sns . access_key_id = \"AKIAIOSFODNN7EXAMPLE\" backend . sns . secret_access_key = \"wJalrXUtnFEMI/K7MDENG/bPxRfiCYEXAMPLEKEY\" backend . sns . region = \"eu-west-1\" backend . sns . account_id = \"123456789012\" backend . sns . sns_host = \"sns.eu-west-1.amazonaws.com\" backend . sns . muc_host = \"conference.HOST\" backend . sns . plugin_module = \"mod_event_pusher_sns_defaults\" backend . sns . presence_updates_topic = \"user_presence_updated\" backend . sns . pm_messages_topic = \"user_message_sent\" backend . sns . muc_messages_topic = \"user_messagegroup_sent\" backend . sns . pool_size = 100 backend . sns . publish_retry_count = 2 backend . sns . publish_retry_time_ms = 50","title":"Example configuration"},{"location":"modules/mod_event_pusher_sns/#json-schema-examples","text":"The different kinds of notifications deliver slightly different messages. The messages are delivered in a JSON format.","title":"JSON Schema examples"},{"location":"modules/mod_event_pusher_sns/#presence-updates","text":"The JSON format for an online presence update notification is: 1 2 3 4 { \"user_id\" : \"alice@localhost\" , \"present\" : true } For offline presence updates, the present boolean value is set to false: 1 2 3 4 { \"user_id\" : \"alice@localhost\" , \"present\" : false }","title":"Presence updates"},{"location":"modules/mod_event_pusher_sns/#sent-messages","text":"The JSON format for a private message notification is: 1 2 3 4 5 { \"to_user_id\" : \"bob@localhost\" , \"message\" : \"Hello, Bob\" , \"from_user_id\" : \"alice@localhost\" } The notification is similar for group messages except that the to_user_id is the recipient room JID. For example: 1 2 3 4 5 { \"to_user_id\" : \"muc_publish@muc.localhost\" , \"message\" : \"Hi, Everyone!\" , \"from_user_id\" : \"bob@localhost\" }","title":"Sent messages"},{"location":"modules/mod_extdisco/","text":"Module Description Implements XEP-0215: External Service Discovery for discovering information about services external to the XMPP network. The main use-case is to help discover STUN/TURN servers to allow for negotiating media exchanges. Options modules.mod_extdisco.service.type Syntax: string Default: none, this option is required Example: type = \"stun\" Service type, common values are \"stun\" , \"turn\" , \"ftp\" . modules.mod_extdisco.service.host Syntax: string Default: none, this option is required Example: host = \"192.168.0.2\" Hostname or an IP address where the service is hosted. modules.mod_extdisco.service.port Syntax: string Default: none, this option is recommended Example: port = \"3478\" The communications port to be used at the host. modules.mod_extdisco.service.transport Syntax: string, one of \"udp\" , \"tcp\" Default: none, this option is optional Example: transport = \"udp\" The underlying transport protocol to be used when communicating with the service. modules.mod_extdisco.service.username Syntax: string Default: none, this option is optional Example: username = \"username\" A service-generated username for use at the service. modules.mod_extdisco.service.password Syntax: string Default: none, this option is optional Example: password = \"password\" A service-generated password for use at the service. Example Configuration 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 [modules.mod_extdisco] [[modules.mod_extdisco.service]] type = \"stun\" host = \"127.0.0.1\" port = 3478 transport = \"udp\" username = \"username\" password = \"password\" [[modules.mod_extdisco.service]] type = \"stun\" host = \"stun.host.com\" port = 3478 transport = \"tcp\" username = \"username2\" password = \"password2\" [[modules.mod_extdisco.service]] type = \"turn\" host = \"turn.host.com\"","title":"mod_extdisco"},{"location":"modules/mod_extdisco/#module-description","text":"Implements XEP-0215: External Service Discovery for discovering information about services external to the XMPP network. The main use-case is to help discover STUN/TURN servers to allow for negotiating media exchanges.","title":"Module Description"},{"location":"modules/mod_extdisco/#options","text":"","title":"Options"},{"location":"modules/mod_extdisco/#modulesmod_extdiscoservicetype","text":"Syntax: string Default: none, this option is required Example: type = \"stun\" Service type, common values are \"stun\" , \"turn\" , \"ftp\" .","title":"modules.mod_extdisco.service.type"},{"location":"modules/mod_extdisco/#modulesmod_extdiscoservicehost","text":"Syntax: string Default: none, this option is required Example: host = \"192.168.0.2\" Hostname or an IP address where the service is hosted.","title":"modules.mod_extdisco.service.host"},{"location":"modules/mod_extdisco/#modulesmod_extdiscoserviceport","text":"Syntax: string Default: none, this option is recommended Example: port = \"3478\" The communications port to be used at the host.","title":"modules.mod_extdisco.service.port"},{"location":"modules/mod_extdisco/#modulesmod_extdiscoservicetransport","text":"Syntax: string, one of \"udp\" , \"tcp\" Default: none, this option is optional Example: transport = \"udp\" The underlying transport protocol to be used when communicating with the service.","title":"modules.mod_extdisco.service.transport"},{"location":"modules/mod_extdisco/#modulesmod_extdiscoserviceusername","text":"Syntax: string Default: none, this option is optional Example: username = \"username\" A service-generated username for use at the service.","title":"modules.mod_extdisco.service.username"},{"location":"modules/mod_extdisco/#modulesmod_extdiscoservicepassword","text":"Syntax: string Default: none, this option is optional Example: password = \"password\" A service-generated password for use at the service.","title":"modules.mod_extdisco.service.password"},{"location":"modules/mod_extdisco/#example-configuration","text":"1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 [modules.mod_extdisco] [[modules.mod_extdisco.service]] type = \"stun\" host = \"127.0.0.1\" port = 3478 transport = \"udp\" username = \"username\" password = \"password\" [[modules.mod_extdisco.service]] type = \"stun\" host = \"stun.host.com\" port = 3478 transport = \"tcp\" username = \"username2\" password = \"password2\" [[modules.mod_extdisco.service]] type = \"turn\" host = \"turn.host.com\"","title":"Example Configuration"},{"location":"modules/mod_global_distrib/","text":"Module Description This module enables global distribution of a single XMPP domain. With mod_global_distrib , multiple distinct MongooseIM clusters can share a single domain name and route messages to the specific datacenter where the recipient is available. How it works There are multiple subsystems that cooperate to enable global distribution: Metadata sharing Sharing of metadata is done by leveraging a database with cross-datacenter replication. Currently, only Redis is supported, with Dynomite layer for replication. The most important metadata stored in the database is a session/routing table . The table stores mappings between currently logged users' JIDs and datacenters on which they are logged in. Because access to the session table is very frequent, its entries are additionally cached on each node. To preserve consistency between database instances, all data is stored with a set expiration time and is periodically refreshed. Each node of each cluster is responsible for refreshing its own data. Thus, in an event of a netsplit, datacenters' information about unreachable datacenters' users will expire, as those users are now unreachable; but once the connection is reestablished, the data will be replicated again as datacenters refresh their entries. Additionally, to prevent edge cases where an incoming message is received and replied to before the datacenter learns about the sender's host, an incoming message also carries information about its origin which may be used to temporarily update the local routing table. Redis entries Following structures are stored in Redis: JID mappings are stored as normal key-value entries, where user's JID (full and bare) is the key, and the value is the local hostname where the user is logged in. Example: \"user1@example.com/res\" -> \"dc2.example.com\" . Domains of components and services registered on the globally distributed host are stored in per-node set structures where the key is <local_host>#<node_name>#{domains} , and the values are the domain names. Example: \"dc1.example.com#mongoose1@dc1.example.com#{domains}\" -> {\"muc1.example.com\", \"muc2.example.com\"} . Domains of non-hidden components and services (see the XMPP Components documentation) are stored in per-node set structures where the key is <local_host>#<node_name>#{public_domains} , and the values are the domain names. Declared endpoints available on a node are similarly stored in a per-node set structure where the key is <local_host>#<node_name>#{endpoints} and the values represent the TCP endpoints of the node. Example: \"dc1.example.com#mongoose1@dc1.example.com#{endpoints}\" -> {\"172.16.2.14#8231\", \"2001:0db8:85a3:0000:0000:8a2e:0370:7334#8882\"} . Nodes that comprise a host are stored in a set structure with key <local_host>#{nodes} and values being the names of the nodes. Example: \"dc2.example.com#{nodes}\" -> {\"node1@dc2.example.com\", \"node3@dc2.example.com\"} . Hosts are stored in a set with key hosts and values being the individual local XMPP domains. Example: \"hosts\" -> {\"dc1.example.com\", \"dc2.example.com\"} . Message routing mod_global_distrib establishes its own listeners and dedicated TCP/TLS connections for message routing. Each node listens on preconfigured endpoints, where each node in a datacenter can have any number of endpoints, including none. The endpoints are shared between all datacenters. If a node becomes unavailable, its endpoint entries in the database will expire and will be readded once the node comes back online. Connections between nodes in distinct datacenters are opened on the first request and then maintained as long as the destination endpoint is present in Redis. When a node needs to connect to a remote cluster, specified number of connections are opened to every endpoint reported by that datacenter. Global distribution features automatic rebalancing feature that will \"disable\" connections when their respective endpoints disappear from Redis. A new pool of connections is created each time a new endpoint is recognised. Whenever a node receives a message that is determined (by consulting the session table) to be destined for another datacenter, the routing procedure in the current datacenter is interrupted, the message is transported to the other datacenter via the dedicated connections, and the routing procedure is restarted there by a dedicated (but potentially short lived) worker process bound to the sender's JID (or subdomain if the sender's JIDs does not belong to the globally distributed domain). Client's process binds itself to a connection to a remote datacenter on first use, and henceforth always uses this connection to route messages directed to this datacenter. This - along with the dedicated worker process on the receiver's side - ensures that simple cross-datacenter messages between two entities are delivered in their sending order. It may happen that a message is rerouted through multiple datacenters (e.g. if the user has reconnected to a different datacenter while the message was already in flight). Messages are given a TTL parameter by the source datacenter so that they cannot be rerouted indefinitely. The TTL is decreased on each reroute. Note that in the edge case of multi-datacenter routing, the messages may be received out-of-order at the destination datacenter. Bounce Consider the following edge case: user U1 logged into datacenter DC2 and then quickly reconnected to datacenter DC3 . Because session table has not yet been replicated, DC2 does not see U1 in the session table, while a different datacenter DC1 still sees U1 logged into DC2 . When U2 logged into DC1 and sent a message to U1 , it will now be rerouted to DC2 even though the user is now available at DC3 . Bounce mechanism solves this and similar edge cases by storing messages for which there is no known routing in the current datacenter. The stored messages are then assigned a bounce-TTL value and periodically - with backoff - are attempted to be routed again. In the example above, the message from U2 would be temporarily stored at DC2 and rerouted successfully once DC2 learns (via replication) that U1 is available at DC3 . Note: bounce mechanism, similarly to multi-datacenter routing, may result in out-of-order messages being received at the destination datacenter. Metrics Global distribution modules expose several per-datacenter metrics that can be used to monitor health of the system. All metrics begin with global.mod_global_distrib prefix: outgoing.messages.<host> : number of cross-datacenter messages sent by this cluster to a given host. incoming.messages.<host> : number of cross-datacenter messages received by this cluster from a given host. incoming.transfer_time.<host> [us] : time elapsed between sending and receiving the message over the network from a given host. The duration is calculated using wall clock times on sender and receiver node. outgoing.queue_time.<host> [us] : time elapsed while message waits in a queue of a sender's connection to a given host. High value of this metric may be remedied by increasing the number of connections to other hosts. incoming.queue_time [us] : time elapsed while message waits in routing worker's queue. This value is not reported per-host as routing workers are bound to the sender's JID. incoming.established : incremented when a new connection is established from another cluster. At this point the origin domain of the cluster is not known, so this metric is common for all of them. incoming.first_packet.<host> : incremented when a receiver process gets the first packet from a remote cluster and learns its local domain. incoming.closed.<host> : incremented when an incoming connection gets closed. incoming.errored.<host> : incremented when an incoming connection gets closed with an error. outgoing.established.<host> : incremented when an outgoing connection is established. outgoing.closed.<host> : incremented when an outgoing connection gets closed. outgoing.errored.<host> : incremented when an outgoing connection gets closed with an error. mapping_fetch_time [us] : time spent on fetching an entry from the session table, cached or otherwise. mapping_fetches : number of fetches of session table entries, cached or otherwise. mapping_cache_misses : number of fetches of session table entries that hit the database. delivered_with_ttl : A histogram of packets' TTL values recorded when the global routing layer decides to route them locally (but not due to TTL = 0). stop_ttl_zero : A number of packets that weren't processed by global routing due to TTL=0. bounce_queue_size : a number of messages enqueued for rerouting (the value of this metric is individual per MongooseIM node!). Notes You should only start mod_global_distrib by configuring it under modules option in mongooseim.toml . Do not add it as host-specific module via host_config . Do not use mod_offline on domains given via global_host or local_host options, as it will decrease messaging robustness; the users logged in other datacenters will not be registered as available by mod_offline , and so the messages will not be flushed. Options modules.mod_global_distrib.global_host Syntax: string Default: none, this option is mandatory Example: global_host = \"example.com\" The XMPP domain that will be shared between datacenters. Note: this needs to be one of the domains given in general.hosts option in mongooseim.toml . modules.mod_global_distrib.local_host Syntax: string Default: none, this option is mandatory Example: local_host = \"datacenter1.example.com\" XMPP domain that maps uniquely to the local datacenter; it will be used for inter-center routing. Note: this needs to be one of the domains given in general.hosts option in mongooseim.toml . modules.mod_global_distrib.message_ttl Syntax: non-negative integer Default: 4 Example: message_ttl = 5 Number of times a message can be rerouted between datacenters. modules.mod_global_distrib.hosts_refresh_interval Syntax: non-negative integer, value given in milliseconds Default: 3000 Example: hosts_refresh_interval = 3000 The interval telling how often Redis should be asked if new hosts appeared. Connections' options modules.mod_global_distrib.connections.endpoints Syntax: Array of TOML tables with the following keys: host and port , and the following values: {host = string , port = non_negative_integer } Default: [{host = \"LocalHost\", port = 5555}] Example: endpoints = [{host = \"172.16.0.2\", port = 5555}] A list of endpoints on which the server will listen for connections. host can be given as a hostname, in which case it will be resolved to an IP address on module start. The endpoint list will be shared with other datacenters via the replicated backend. modules.mod_global_distrib.connections.advertised_endpoints Syntax: Array of TOML tables with the following keys: host and port , and the following values: {host = string , port = non_negative_integer } Default: not set Example: advertised_endpoints = [{host = \"172.16.0.2\", port = 5555}] A list of endpoints which will be advertised in Redis and therefore used to establish connection with this node by other nodes. If not specified, endpoints value (after resolution) is considered advertised_endpoints . The host may be either IP or domain, just like in case of endpoints. The difference is, the domain name won't be resolved but inserted directly to the mappings backend instead. modules.mod_global_distrib.connections.connections_per_endpoint Syntax: non-negative integer Default: 1 Example: connections_per_endpoint = 30 Number of outgoing connections that will be established from the current node to each endpoint assigned to a remote domain. modules.mod_global_distrib.connections.endpoint_refresh_interval Syntax: positive integer, value given in seconds Default: 60 Example: endpoint_refresh_interval = 30 An interval between remote endpoint list refresh (and connection rebalancing). A separate timer is maintained for every remote domain. modules.mod_global_distrib.connections.endpoint_refresh_interval_when_empty Syntax: positive integer, value given in seconds Default: 3 Example: endpoint_refresh_interval_when_empty = 3 Endpoint refresh interval, when array of endpoints is empty. modules.mod_global_distrib.connections.disabled_gc_interval Syntax: positive integer, value given in seconds Default: 60 Example: disabled_gc_interval = 60 An interval between disabled endpoints \"garbage collection\". It means that disabled endpoints are periodically verified and if Global Distribution detects that connections is no longer alive, the connection pool is closed completely. TLS options Note: By default tls is disabled and all data will be sent via standard TCP connections. To enable TLS support, the cacertfile and certfile options have to be present. These options will be passed to the fast_tls driver. modules.mod_global_distrib.connections.tls.certfile Syntax: string, path in the file system Default: none, this options is mandatory to enable TLS support Example: certfile = \"priv/dc1.pem\" modules.mod_global_distrib.connections.tls.cacertfile Syntax: string, path in the file system Default: none, this options is mandatory to enable TLS support Example: cacertfile = \"priv/ca.pem\" modules.mod_global_distrib.connections.tls.ciphers Syntax: string Default: not set Example: ciphers = \"ECDHE-RSA-AES256-GCM-SHA384:ECDHE-ECDSA-AES256-GCM-SHA384\" Cipher suites to use with StartTLS or TLS. Please refer to the OpenSSL documentation for the cipher string format. modules.mod_global_distrib.connections.tls.dhfile Syntax: string, path in the file system Default: not set Example: dhfile = \"dh.pem\" Redis session storage options modules.mod_global_distrib.redis.pool Syntax: string Default: \"global_distrib\" Example: pool = \"global_distrib\" Name of the redis pool defined in outgoing pools . modules.mod_global_distrib.redis.expire_after Syntax: positive integer Default: 120 Example: expire_after = 120 Number of seconds after which a session entry written by this cluster will expire. modules.mod_global_distrib.redis.refresh_after Syntax: non-negative integer Default: 60 Example: refresh_after = 60 Number of seconds after which session's expiration timer will be refreshed. Database cache options Options for caching database lookups, by default no options are passed. modules.mod_global_distrib.cache.cache_missed Syntax: boolean Default: true Example: cache_missed = true Determines whether an internal session cache should cache lookup failures. When false , only successful database lookups will result in the value being cached. Changing this option has great negative impact on performance. modules.mod_global_distrib.cache.domain_lifetime_seconds Syntax: non-negative integer, value given in seconds Default: 600 Example: domain_lifetime_seconds = 600 How long should subdomain mappings be cached (e.g. muc.example.com -> datacenter1.test ). modules.mod_global_distrib.cache.jid_lifetime_seconds Syntax: non-negative integer, value given in seconds Default: 5 Example: jid_lifetime_seconds = 5 How long should full and bare JID mappings be cached (e.g. user1@example.com/res1 -> datacenter1.test ). modules.mod_global_distrib.cache.max_jids Syntax: non-negative integer Default: 10000 Example: max_jids = 10000 The maximum number of JID entries that can be stored in cache at any point in time. Message bouncing options modules.mod_global_distrib.bounce.enabled Syntax: boolean Default: true Example: enabled = false Whether message bouncing should be enabled or not. Setting this option to false makes other bounce options have no effect. modules.mod_global_distrib.bounce.resend_after_ms Syntax: non-negative integer Default: 200 Example: resend_after_ms = 200 Time after which message will be resent in case of delivery error. modules.mod_global_distrib.bounce.max_retries Syntax: non-negative integer Default: 4 Example: max_retries = 4 Number of times message delivery will be retried in case of errors. Global Distribution and Service Discovery mod_global_distrib extension relies on mod_disco 's option users_can_see_hidden_services , when provided. If it is not configured, the default value is true . mod_disco does not have to be enabled for mod_global_distrib to work, as this parameter is used only for processing Disco requests by Global Distribution. Overriding remote datacenter endpoints There may be cases when the endpoint list given via endpoints option does not accurately specify endpoints on which the node may be reached from other datacenters; e.g. in case the node is behind NAT, or in testing environment. The endpoints used for connection to a remote datacenter may be overridden by global option { {global_distrib_addr, Host}, [{IP, Port}] } . Example configuration Configuring mod_global_distrib 1 2 3 4 5 6 7 8 9 10 11 12 [modules.mod_global_distrib] global_host = \"example.com\" local_host = \"datacenter1.example.com\" connections . endpoints = [{host = \"172.16.0.2\", port = 5555}] connections . advertised_endpoints = [{host = \"172.16.0.2\", port = 5555}] connections . tls . certfile = \"priv/dc1.pem\" connections . tls . cacertfile = \"priv/ca.pem\" connections . connections_per_endpoint = 30 cache . domain_lifetime_seconds = 60 bounce . resend_after_ms = 300 bounce . max_retries = 3 redis . pool = \"global_distrib\" Overriding endpoints to a remote datacenter 1 { { global_distrib_addr , \"datacenter2.example.com\" }, [{ \"124.12.4.3\" , 5556 }, { \"182.172.23.55\" , 5555 }] }. Configuring Dynomite For more information about Dynomite configuration, consult Dynomite wiki . 1 2 3 4 5 6 7 8 9 10 11 12 13 14 dyn_o_mite : datacenter : dc1 rack : rack1 dyn_listen : 172.16.0.3:8101 dyn_seeds : - 124.12.4.4:8101:rack1:dc2:1383429731 listen : 172.16.0.3:8102 servers : - 172.16.0.4:6379:1 tokens : '138342973' secure_server_option : datacenter pem_key_file : dynomite.pem data_store : 0 stats_listen : 0.0.0.0:22221 1 2 3 4 5 6 7 8 9 10 11 12 13 14 dyn_o_mite : datacenter : dc2 rack : rack1 dyn_listen : 124.12.4.4:8101 dyn_seeds : - 172.16.0.3:8101:rack1:dc1:1383429731 listen : 124.12.4.4:8102 servers : - 124.12.4.5:6379:1 tokens : '138342973' secure_server_option : datacenter pem_key_file : dynomite.pem data_store : 0 stats_listen : 0.0.0.0:22221","title":"mod_global_distrib"},{"location":"modules/mod_global_distrib/#module-description","text":"This module enables global distribution of a single XMPP domain. With mod_global_distrib , multiple distinct MongooseIM clusters can share a single domain name and route messages to the specific datacenter where the recipient is available.","title":"Module Description"},{"location":"modules/mod_global_distrib/#how-it-works","text":"There are multiple subsystems that cooperate to enable global distribution:","title":"How it works"},{"location":"modules/mod_global_distrib/#metadata-sharing","text":"Sharing of metadata is done by leveraging a database with cross-datacenter replication. Currently, only Redis is supported, with Dynomite layer for replication. The most important metadata stored in the database is a session/routing table . The table stores mappings between currently logged users' JIDs and datacenters on which they are logged in. Because access to the session table is very frequent, its entries are additionally cached on each node. To preserve consistency between database instances, all data is stored with a set expiration time and is periodically refreshed. Each node of each cluster is responsible for refreshing its own data. Thus, in an event of a netsplit, datacenters' information about unreachable datacenters' users will expire, as those users are now unreachable; but once the connection is reestablished, the data will be replicated again as datacenters refresh their entries. Additionally, to prevent edge cases where an incoming message is received and replied to before the datacenter learns about the sender's host, an incoming message also carries information about its origin which may be used to temporarily update the local routing table.","title":"Metadata sharing"},{"location":"modules/mod_global_distrib/#redis-entries","text":"Following structures are stored in Redis: JID mappings are stored as normal key-value entries, where user's JID (full and bare) is the key, and the value is the local hostname where the user is logged in. Example: \"user1@example.com/res\" -> \"dc2.example.com\" . Domains of components and services registered on the globally distributed host are stored in per-node set structures where the key is <local_host>#<node_name>#{domains} , and the values are the domain names. Example: \"dc1.example.com#mongoose1@dc1.example.com#{domains}\" -> {\"muc1.example.com\", \"muc2.example.com\"} . Domains of non-hidden components and services (see the XMPP Components documentation) are stored in per-node set structures where the key is <local_host>#<node_name>#{public_domains} , and the values are the domain names. Declared endpoints available on a node are similarly stored in a per-node set structure where the key is <local_host>#<node_name>#{endpoints} and the values represent the TCP endpoints of the node. Example: \"dc1.example.com#mongoose1@dc1.example.com#{endpoints}\" -> {\"172.16.2.14#8231\", \"2001:0db8:85a3:0000:0000:8a2e:0370:7334#8882\"} . Nodes that comprise a host are stored in a set structure with key <local_host>#{nodes} and values being the names of the nodes. Example: \"dc2.example.com#{nodes}\" -> {\"node1@dc2.example.com\", \"node3@dc2.example.com\"} . Hosts are stored in a set with key hosts and values being the individual local XMPP domains. Example: \"hosts\" -> {\"dc1.example.com\", \"dc2.example.com\"} .","title":"Redis entries"},{"location":"modules/mod_global_distrib/#message-routing","text":"mod_global_distrib establishes its own listeners and dedicated TCP/TLS connections for message routing. Each node listens on preconfigured endpoints, where each node in a datacenter can have any number of endpoints, including none. The endpoints are shared between all datacenters. If a node becomes unavailable, its endpoint entries in the database will expire and will be readded once the node comes back online. Connections between nodes in distinct datacenters are opened on the first request and then maintained as long as the destination endpoint is present in Redis. When a node needs to connect to a remote cluster, specified number of connections are opened to every endpoint reported by that datacenter. Global distribution features automatic rebalancing feature that will \"disable\" connections when their respective endpoints disappear from Redis. A new pool of connections is created each time a new endpoint is recognised. Whenever a node receives a message that is determined (by consulting the session table) to be destined for another datacenter, the routing procedure in the current datacenter is interrupted, the message is transported to the other datacenter via the dedicated connections, and the routing procedure is restarted there by a dedicated (but potentially short lived) worker process bound to the sender's JID (or subdomain if the sender's JIDs does not belong to the globally distributed domain). Client's process binds itself to a connection to a remote datacenter on first use, and henceforth always uses this connection to route messages directed to this datacenter. This - along with the dedicated worker process on the receiver's side - ensures that simple cross-datacenter messages between two entities are delivered in their sending order. It may happen that a message is rerouted through multiple datacenters (e.g. if the user has reconnected to a different datacenter while the message was already in flight). Messages are given a TTL parameter by the source datacenter so that they cannot be rerouted indefinitely. The TTL is decreased on each reroute. Note that in the edge case of multi-datacenter routing, the messages may be received out-of-order at the destination datacenter.","title":"Message routing"},{"location":"modules/mod_global_distrib/#bounce","text":"Consider the following edge case: user U1 logged into datacenter DC2 and then quickly reconnected to datacenter DC3 . Because session table has not yet been replicated, DC2 does not see U1 in the session table, while a different datacenter DC1 still sees U1 logged into DC2 . When U2 logged into DC1 and sent a message to U1 , it will now be rerouted to DC2 even though the user is now available at DC3 . Bounce mechanism solves this and similar edge cases by storing messages for which there is no known routing in the current datacenter. The stored messages are then assigned a bounce-TTL value and periodically - with backoff - are attempted to be routed again. In the example above, the message from U2 would be temporarily stored at DC2 and rerouted successfully once DC2 learns (via replication) that U1 is available at DC3 . Note: bounce mechanism, similarly to multi-datacenter routing, may result in out-of-order messages being received at the destination datacenter.","title":"Bounce"},{"location":"modules/mod_global_distrib/#metrics","text":"Global distribution modules expose several per-datacenter metrics that can be used to monitor health of the system. All metrics begin with global.mod_global_distrib prefix: outgoing.messages.<host> : number of cross-datacenter messages sent by this cluster to a given host. incoming.messages.<host> : number of cross-datacenter messages received by this cluster from a given host. incoming.transfer_time.<host> [us] : time elapsed between sending and receiving the message over the network from a given host. The duration is calculated using wall clock times on sender and receiver node. outgoing.queue_time.<host> [us] : time elapsed while message waits in a queue of a sender's connection to a given host. High value of this metric may be remedied by increasing the number of connections to other hosts. incoming.queue_time [us] : time elapsed while message waits in routing worker's queue. This value is not reported per-host as routing workers are bound to the sender's JID. incoming.established : incremented when a new connection is established from another cluster. At this point the origin domain of the cluster is not known, so this metric is common for all of them. incoming.first_packet.<host> : incremented when a receiver process gets the first packet from a remote cluster and learns its local domain. incoming.closed.<host> : incremented when an incoming connection gets closed. incoming.errored.<host> : incremented when an incoming connection gets closed with an error. outgoing.established.<host> : incremented when an outgoing connection is established. outgoing.closed.<host> : incremented when an outgoing connection gets closed. outgoing.errored.<host> : incremented when an outgoing connection gets closed with an error. mapping_fetch_time [us] : time spent on fetching an entry from the session table, cached or otherwise. mapping_fetches : number of fetches of session table entries, cached or otherwise. mapping_cache_misses : number of fetches of session table entries that hit the database. delivered_with_ttl : A histogram of packets' TTL values recorded when the global routing layer decides to route them locally (but not due to TTL = 0). stop_ttl_zero : A number of packets that weren't processed by global routing due to TTL=0. bounce_queue_size : a number of messages enqueued for rerouting (the value of this metric is individual per MongooseIM node!).","title":"Metrics"},{"location":"modules/mod_global_distrib/#notes","text":"You should only start mod_global_distrib by configuring it under modules option in mongooseim.toml . Do not add it as host-specific module via host_config . Do not use mod_offline on domains given via global_host or local_host options, as it will decrease messaging robustness; the users logged in other datacenters will not be registered as available by mod_offline , and so the messages will not be flushed.","title":"Notes"},{"location":"modules/mod_global_distrib/#options","text":"","title":"Options"},{"location":"modules/mod_global_distrib/#modulesmod_global_distribglobal_host","text":"Syntax: string Default: none, this option is mandatory Example: global_host = \"example.com\" The XMPP domain that will be shared between datacenters. Note: this needs to be one of the domains given in general.hosts option in mongooseim.toml .","title":"modules.mod_global_distrib.global_host"},{"location":"modules/mod_global_distrib/#modulesmod_global_distriblocal_host","text":"Syntax: string Default: none, this option is mandatory Example: local_host = \"datacenter1.example.com\" XMPP domain that maps uniquely to the local datacenter; it will be used for inter-center routing. Note: this needs to be one of the domains given in general.hosts option in mongooseim.toml .","title":"modules.mod_global_distrib.local_host"},{"location":"modules/mod_global_distrib/#modulesmod_global_distribmessage_ttl","text":"Syntax: non-negative integer Default: 4 Example: message_ttl = 5 Number of times a message can be rerouted between datacenters.","title":"modules.mod_global_distrib.message_ttl"},{"location":"modules/mod_global_distrib/#modulesmod_global_distribhosts_refresh_interval","text":"Syntax: non-negative integer, value given in milliseconds Default: 3000 Example: hosts_refresh_interval = 3000 The interval telling how often Redis should be asked if new hosts appeared.","title":"modules.mod_global_distrib.hosts_refresh_interval"},{"location":"modules/mod_global_distrib/#connections-options","text":"","title":"Connections' options"},{"location":"modules/mod_global_distrib/#modulesmod_global_distribconnectionsendpoints","text":"Syntax: Array of TOML tables with the following keys: host and port , and the following values: {host = string , port = non_negative_integer } Default: [{host = \"LocalHost\", port = 5555}] Example: endpoints = [{host = \"172.16.0.2\", port = 5555}] A list of endpoints on which the server will listen for connections. host can be given as a hostname, in which case it will be resolved to an IP address on module start. The endpoint list will be shared with other datacenters via the replicated backend.","title":"modules.mod_global_distrib.connections.endpoints"},{"location":"modules/mod_global_distrib/#modulesmod_global_distribconnectionsadvertised_endpoints","text":"Syntax: Array of TOML tables with the following keys: host and port , and the following values: {host = string , port = non_negative_integer } Default: not set Example: advertised_endpoints = [{host = \"172.16.0.2\", port = 5555}] A list of endpoints which will be advertised in Redis and therefore used to establish connection with this node by other nodes. If not specified, endpoints value (after resolution) is considered advertised_endpoints . The host may be either IP or domain, just like in case of endpoints. The difference is, the domain name won't be resolved but inserted directly to the mappings backend instead.","title":"modules.mod_global_distrib.connections.advertised_endpoints"},{"location":"modules/mod_global_distrib/#modulesmod_global_distribconnectionsconnections_per_endpoint","text":"Syntax: non-negative integer Default: 1 Example: connections_per_endpoint = 30 Number of outgoing connections that will be established from the current node to each endpoint assigned to a remote domain.","title":"modules.mod_global_distrib.connections.connections_per_endpoint"},{"location":"modules/mod_global_distrib/#modulesmod_global_distribconnectionsendpoint_refresh_interval","text":"Syntax: positive integer, value given in seconds Default: 60 Example: endpoint_refresh_interval = 30 An interval between remote endpoint list refresh (and connection rebalancing). A separate timer is maintained for every remote domain.","title":"modules.mod_global_distrib.connections.endpoint_refresh_interval"},{"location":"modules/mod_global_distrib/#modulesmod_global_distribconnectionsendpoint_refresh_interval_when_empty","text":"Syntax: positive integer, value given in seconds Default: 3 Example: endpoint_refresh_interval_when_empty = 3 Endpoint refresh interval, when array of endpoints is empty.","title":"modules.mod_global_distrib.connections.endpoint_refresh_interval_when_empty"},{"location":"modules/mod_global_distrib/#modulesmod_global_distribconnectionsdisabled_gc_interval","text":"Syntax: positive integer, value given in seconds Default: 60 Example: disabled_gc_interval = 60 An interval between disabled endpoints \"garbage collection\". It means that disabled endpoints are periodically verified and if Global Distribution detects that connections is no longer alive, the connection pool is closed completely.","title":"modules.mod_global_distrib.connections.disabled_gc_interval"},{"location":"modules/mod_global_distrib/#tls-options","text":"Note: By default tls is disabled and all data will be sent via standard TCP connections. To enable TLS support, the cacertfile and certfile options have to be present. These options will be passed to the fast_tls driver.","title":"TLS options"},{"location":"modules/mod_global_distrib/#modulesmod_global_distribconnectionstlscertfile","text":"Syntax: string, path in the file system Default: none, this options is mandatory to enable TLS support Example: certfile = \"priv/dc1.pem\"","title":"modules.mod_global_distrib.connections.tls.certfile"},{"location":"modules/mod_global_distrib/#modulesmod_global_distribconnectionstlscacertfile","text":"Syntax: string, path in the file system Default: none, this options is mandatory to enable TLS support Example: cacertfile = \"priv/ca.pem\"","title":"modules.mod_global_distrib.connections.tls.cacertfile"},{"location":"modules/mod_global_distrib/#modulesmod_global_distribconnectionstlsciphers","text":"Syntax: string Default: not set Example: ciphers = \"ECDHE-RSA-AES256-GCM-SHA384:ECDHE-ECDSA-AES256-GCM-SHA384\" Cipher suites to use with StartTLS or TLS. Please refer to the OpenSSL documentation for the cipher string format.","title":"modules.mod_global_distrib.connections.tls.ciphers"},{"location":"modules/mod_global_distrib/#modulesmod_global_distribconnectionstlsdhfile","text":"Syntax: string, path in the file system Default: not set Example: dhfile = \"dh.pem\"","title":"modules.mod_global_distrib.connections.tls.dhfile"},{"location":"modules/mod_global_distrib/#redis-session-storage-options","text":"","title":"Redis session storage options"},{"location":"modules/mod_global_distrib/#modulesmod_global_distribredispool","text":"Syntax: string Default: \"global_distrib\" Example: pool = \"global_distrib\" Name of the redis pool defined in outgoing pools .","title":"modules.mod_global_distrib.redis.pool"},{"location":"modules/mod_global_distrib/#modulesmod_global_distribredisexpire_after","text":"Syntax: positive integer Default: 120 Example: expire_after = 120 Number of seconds after which a session entry written by this cluster will expire.","title":"modules.mod_global_distrib.redis.expire_after"},{"location":"modules/mod_global_distrib/#modulesmod_global_distribredisrefresh_after","text":"Syntax: non-negative integer Default: 60 Example: refresh_after = 60 Number of seconds after which session's expiration timer will be refreshed.","title":"modules.mod_global_distrib.redis.refresh_after"},{"location":"modules/mod_global_distrib/#database-cache-options","text":"Options for caching database lookups, by default no options are passed.","title":"Database cache options"},{"location":"modules/mod_global_distrib/#modulesmod_global_distribcachecache_missed","text":"Syntax: boolean Default: true Example: cache_missed = true Determines whether an internal session cache should cache lookup failures. When false , only successful database lookups will result in the value being cached. Changing this option has great negative impact on performance.","title":"modules.mod_global_distrib.cache.cache_missed"},{"location":"modules/mod_global_distrib/#modulesmod_global_distribcachedomain_lifetime_seconds","text":"Syntax: non-negative integer, value given in seconds Default: 600 Example: domain_lifetime_seconds = 600 How long should subdomain mappings be cached (e.g. muc.example.com -> datacenter1.test ).","title":"modules.mod_global_distrib.cache.domain_lifetime_seconds"},{"location":"modules/mod_global_distrib/#modulesmod_global_distribcachejid_lifetime_seconds","text":"Syntax: non-negative integer, value given in seconds Default: 5 Example: jid_lifetime_seconds = 5 How long should full and bare JID mappings be cached (e.g. user1@example.com/res1 -> datacenter1.test ).","title":"modules.mod_global_distrib.cache.jid_lifetime_seconds"},{"location":"modules/mod_global_distrib/#modulesmod_global_distribcachemax_jids","text":"Syntax: non-negative integer Default: 10000 Example: max_jids = 10000 The maximum number of JID entries that can be stored in cache at any point in time.","title":"modules.mod_global_distrib.cache.max_jids"},{"location":"modules/mod_global_distrib/#message-bouncing-options","text":"","title":"Message bouncing options"},{"location":"modules/mod_global_distrib/#modulesmod_global_distribbounceenabled","text":"Syntax: boolean Default: true Example: enabled = false Whether message bouncing should be enabled or not. Setting this option to false makes other bounce options have no effect.","title":"modules.mod_global_distrib.bounce.enabled"},{"location":"modules/mod_global_distrib/#modulesmod_global_distribbounceresend_after_ms","text":"Syntax: non-negative integer Default: 200 Example: resend_after_ms = 200 Time after which message will be resent in case of delivery error.","title":"modules.mod_global_distrib.bounce.resend_after_ms"},{"location":"modules/mod_global_distrib/#modulesmod_global_distribbouncemax_retries","text":"Syntax: non-negative integer Default: 4 Example: max_retries = 4 Number of times message delivery will be retried in case of errors.","title":"modules.mod_global_distrib.bounce.max_retries"},{"location":"modules/mod_global_distrib/#global-distribution-and-service-discovery","text":"mod_global_distrib extension relies on mod_disco 's option users_can_see_hidden_services , when provided. If it is not configured, the default value is true . mod_disco does not have to be enabled for mod_global_distrib to work, as this parameter is used only for processing Disco requests by Global Distribution.","title":"Global Distribution and Service Discovery"},{"location":"modules/mod_global_distrib/#overriding-remote-datacenter-endpoints","text":"There may be cases when the endpoint list given via endpoints option does not accurately specify endpoints on which the node may be reached from other datacenters; e.g. in case the node is behind NAT, or in testing environment. The endpoints used for connection to a remote datacenter may be overridden by global option { {global_distrib_addr, Host}, [{IP, Port}] } .","title":"Overriding remote datacenter endpoints"},{"location":"modules/mod_global_distrib/#example-configuration","text":"","title":"Example configuration"},{"location":"modules/mod_global_distrib/#configuring-mod_global_distrib","text":"1 2 3 4 5 6 7 8 9 10 11 12 [modules.mod_global_distrib] global_host = \"example.com\" local_host = \"datacenter1.example.com\" connections . endpoints = [{host = \"172.16.0.2\", port = 5555}] connections . advertised_endpoints = [{host = \"172.16.0.2\", port = 5555}] connections . tls . certfile = \"priv/dc1.pem\" connections . tls . cacertfile = \"priv/ca.pem\" connections . connections_per_endpoint = 30 cache . domain_lifetime_seconds = 60 bounce . resend_after_ms = 300 bounce . max_retries = 3 redis . pool = \"global_distrib\"","title":"Configuring mod_global_distrib"},{"location":"modules/mod_global_distrib/#overriding-endpoints-to-a-remote-datacenter","text":"1 { { global_distrib_addr , \"datacenter2.example.com\" }, [{ \"124.12.4.3\" , 5556 }, { \"182.172.23.55\" , 5555 }] }.","title":"Overriding endpoints to a remote datacenter"},{"location":"modules/mod_global_distrib/#configuring-dynomite","text":"For more information about Dynomite configuration, consult Dynomite wiki . 1 2 3 4 5 6 7 8 9 10 11 12 13 14 dyn_o_mite : datacenter : dc1 rack : rack1 dyn_listen : 172.16.0.3:8101 dyn_seeds : - 124.12.4.4:8101:rack1:dc2:1383429731 listen : 172.16.0.3:8102 servers : - 172.16.0.4:6379:1 tokens : '138342973' secure_server_option : datacenter pem_key_file : dynomite.pem data_store : 0 stats_listen : 0.0.0.0:22221 1 2 3 4 5 6 7 8 9 10 11 12 13 14 dyn_o_mite : datacenter : dc2 rack : rack1 dyn_listen : 124.12.4.4:8101 dyn_seeds : - 172.16.0.3:8101:rack1:dc1:1383429731 listen : 124.12.4.4:8102 servers : - 124.12.4.5:6379:1 tokens : '138342973' secure_server_option : datacenter pem_key_file : dynomite.pem data_store : 0 stats_listen : 0.0.0.0:22221","title":"Configuring Dynomite"},{"location":"modules/mod_http_upload/","text":"Module Description This module implements XEP-0363: HTTP File Upload , version 0.3.0+. It enables a service that on user request creates an upload \"slot\". A slot is a pair of URLs, one of which can be used with a PUT method to upload a user's file, the other with a GET method to retrieve such file. Currently, the module supports only the S3 backend using AWS Signature Version 4 . Options modules.mod_http_upload.iqdisc.type Syntax: string, one of \"one_queue\" , \"no_queue\" , \"queues\" , \"parallel\" Default: \"one_queue\" Strategy to handle incoming stanzas. For details, please refer to IQ processing policies . modules.mod_http_upload.host Syntax: string Default: \"upload.@HOST@\" Example: host = \"upload.@HOST@\" Subdomain for the upload service to reside under. @HOST@ is replaced with each served domain. modules.mod_http_upload.backend Syntax: non-empty string Default: \"s3\" Example: backend = \"s3\" Backend to use for generating slots. Currently only \"s3\" can be used. modules.mod_http_upload.expiration_time Syntax: positive integer Default: 60 Example: expiration_time = 120 Duration (in seconds) after which the generated PUT URL will become invalid. modules.mod_http_upload.token_bytes Syntax: positive integer Default: 32 Example: token_bytes = 32 Number of random bytes of a token that will be used in a generated URL. The text representation of the token will be twice as long as the number of bytes, e.g. for the default value the token in the URL will be 64 characters long. modules.mod_http_upload.max_file_size Syntax: positive integer Default: not set - no size limit Example: max_file_size = 10485760 Maximum file size (in bytes) accepted by the module. modules.mod_http_upload.s3 Syntax: Array of TOML tables. See description. Default: see description Example: see description Options specific to S3 backend. Note: this section is mandatory. S3 backend options s3.bucket_url Syntax: non-empty string Default: none, this option is mandatory Example: s3.bucket_url = \"https://s3-eu-west-1.amazonaws.com/mybucket\" A complete URL pointing at the used bucket. The URL may be in virtual host form , and for AWS it needs to point to a specific regional endpoint for the bucket. The scheme, port and path specified in the URL will be used to create PUT URLs for slots, e.g. specifying a value of \"https://s3-eu-west-1.amazonaws.com/mybucket/custom/prefix\" will result in PUT URLs of form \"https://s3-eu-west-1.amazonaws.com/mybucket/custom/prefix/<RANDOM_TOKEN>/<FILENAME>?<AUTHENTICATION_PARAMETERS>\" . s3.add_acl Syntax: boolean Default: false Example: s3.add_acl = true If true , adds x-amz-acl: public-read header to the PUT URL. This allows users to read the uploaded files even if the bucket is private. The same header must be added to the PUT request. s3.region Syntax: string Default: \"\" , this option is mandatory Example: s3.region = \"https://s3-eu-west-1.amazonaws.com/mybucket\" The AWS region to use for requests. s3.access_key_id Syntax: string Default: \"\" , this option is mandatory Example: s3.access_key_id = \"AKIAIOSFODNN7EXAMPLE\" ID of the access key to use for authorization. s3.secret_access_key Syntax: string Default: \"\" , this option is mandatory Example: s3.secret_access_key = \"wJalrXUtnFEMI/K7MDENG/bPxRfiCYEXAMPLEKEY\" Secret access key to use for authorization. Example configuration 1 2 3 4 5 6 7 8 9 [modules.mod_http_upload] host = \"upload.@HOST@\" backend = \"s3\" expiration_time = 120 s3 . bucket_url = \"https://s3-eu-west-1.amazonaws.com/mybucket\" s3 . region = \"eu-west-1\" s3 . add_acl = true s3 . access_key_id = \"AKIAIOSFODNN7EXAMPLE\" s3 . secret_access_key = \"wJalrXUtnFEMI/K7MDENG/bPxRfiCYEXAMPLEKEY\" Testing S3 configuration Since there is no direct connection between MongooseIM and an S3 bucket, it is not possible to verify the provided S3 credentials during startup. However, the testing can be done manually. MongooseIM provides a dedicated mongooseimctl http_upload command for the manual URLs generation, it accepts the following parameters: Host - XMPP host name. FileName - The name of the file. FileSize - The size of the file (positive integer). ContentType - Content-Type , optional parameter. If not provided, must be an empty string \"\" . ExpirationTime - Duration (in seconds, positive integer) after which the generated PUT URL will become invalid. This parameter shadows the expiration_time configuration. The generated URLs can be used to upload/download a file using the curl utility: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 # Create some text file echo qwerty > tmp.txt # Get the size of the file filesize = \" $( wc -c tmp.txt | awk '{print $1}' ) \" # Set the content type content_type = \"text/plain\" # Generate upload/download URLs urls = \" $( ./mongooseimctl http_upload localhost test.txt \" $filesize \" \" $content_type \" 600 ) \" put_url = \" $( echo \" $urls \" | awk '/PutURL:/ {print $2}' ) \" get_url = \" $( echo \" $urls \" | awk '/GetURL:/ {print $2}' ) \" # Try to upload a file. Note that if 'add_acl' option is # enabled, then you must also add 'x-amz-acl' header: # -H \"x-amz-acl: public-read\" curl -v -T \"./tmp.txt\" -H \"Content-Type: $content_type \" \" $put_url \" # Try to download a file curl -i \" $get_url \" Using S3 backend with min.io min.io doesn't support ObjectACL , so enabling add_acl makes no sense. The bucket policies must be used instead, it is enough to set the bucket policy to download . Please note that there is no error if you keep add_acl enabled. min.io just ignores the x-amz-acl header. This might be useful to simplify the migration from S3 to min.io Metrics If you'd like to learn more about metrics in MongooseIM, please visit MongooseIM metrics page. Backend action Description (when it gets incremented) create_slot An upload slot is allocated.","title":"mod_http_upload"},{"location":"modules/mod_http_upload/#module-description","text":"This module implements XEP-0363: HTTP File Upload , version 0.3.0+. It enables a service that on user request creates an upload \"slot\". A slot is a pair of URLs, one of which can be used with a PUT method to upload a user's file, the other with a GET method to retrieve such file. Currently, the module supports only the S3 backend using AWS Signature Version 4 .","title":"Module Description"},{"location":"modules/mod_http_upload/#options","text":"","title":"Options"},{"location":"modules/mod_http_upload/#modulesmod_http_uploadiqdisctype","text":"Syntax: string, one of \"one_queue\" , \"no_queue\" , \"queues\" , \"parallel\" Default: \"one_queue\" Strategy to handle incoming stanzas. For details, please refer to IQ processing policies .","title":"modules.mod_http_upload.iqdisc.type"},{"location":"modules/mod_http_upload/#modulesmod_http_uploadhost","text":"Syntax: string Default: \"upload.@HOST@\" Example: host = \"upload.@HOST@\" Subdomain for the upload service to reside under. @HOST@ is replaced with each served domain.","title":"modules.mod_http_upload.host"},{"location":"modules/mod_http_upload/#modulesmod_http_uploadbackend","text":"Syntax: non-empty string Default: \"s3\" Example: backend = \"s3\" Backend to use for generating slots. Currently only \"s3\" can be used.","title":"modules.mod_http_upload.backend"},{"location":"modules/mod_http_upload/#modulesmod_http_uploadexpiration_time","text":"Syntax: positive integer Default: 60 Example: expiration_time = 120 Duration (in seconds) after which the generated PUT URL will become invalid.","title":"modules.mod_http_upload.expiration_time"},{"location":"modules/mod_http_upload/#modulesmod_http_uploadtoken_bytes","text":"Syntax: positive integer Default: 32 Example: token_bytes = 32 Number of random bytes of a token that will be used in a generated URL. The text representation of the token will be twice as long as the number of bytes, e.g. for the default value the token in the URL will be 64 characters long.","title":"modules.mod_http_upload.token_bytes"},{"location":"modules/mod_http_upload/#modulesmod_http_uploadmax_file_size","text":"Syntax: positive integer Default: not set - no size limit Example: max_file_size = 10485760 Maximum file size (in bytes) accepted by the module.","title":"modules.mod_http_upload.max_file_size"},{"location":"modules/mod_http_upload/#modulesmod_http_uploads3","text":"Syntax: Array of TOML tables. See description. Default: see description Example: see description Options specific to S3 backend. Note: this section is mandatory.","title":"modules.mod_http_upload.s3"},{"location":"modules/mod_http_upload/#s3-backend-options","text":"","title":"S3 backend options"},{"location":"modules/mod_http_upload/#s3bucket_url","text":"Syntax: non-empty string Default: none, this option is mandatory Example: s3.bucket_url = \"https://s3-eu-west-1.amazonaws.com/mybucket\" A complete URL pointing at the used bucket. The URL may be in virtual host form , and for AWS it needs to point to a specific regional endpoint for the bucket. The scheme, port and path specified in the URL will be used to create PUT URLs for slots, e.g. specifying a value of \"https://s3-eu-west-1.amazonaws.com/mybucket/custom/prefix\" will result in PUT URLs of form \"https://s3-eu-west-1.amazonaws.com/mybucket/custom/prefix/<RANDOM_TOKEN>/<FILENAME>?<AUTHENTICATION_PARAMETERS>\" .","title":"s3.bucket_url"},{"location":"modules/mod_http_upload/#s3add_acl","text":"Syntax: boolean Default: false Example: s3.add_acl = true If true , adds x-amz-acl: public-read header to the PUT URL. This allows users to read the uploaded files even if the bucket is private. The same header must be added to the PUT request.","title":"s3.add_acl"},{"location":"modules/mod_http_upload/#s3region","text":"Syntax: string Default: \"\" , this option is mandatory Example: s3.region = \"https://s3-eu-west-1.amazonaws.com/mybucket\" The AWS region to use for requests.","title":"s3.region"},{"location":"modules/mod_http_upload/#s3access_key_id","text":"Syntax: string Default: \"\" , this option is mandatory Example: s3.access_key_id = \"AKIAIOSFODNN7EXAMPLE\" ID of the access key to use for authorization.","title":"s3.access_key_id"},{"location":"modules/mod_http_upload/#s3secret_access_key","text":"Syntax: string Default: \"\" , this option is mandatory Example: s3.secret_access_key = \"wJalrXUtnFEMI/K7MDENG/bPxRfiCYEXAMPLEKEY\" Secret access key to use for authorization.","title":"s3.secret_access_key"},{"location":"modules/mod_http_upload/#example-configuration","text":"1 2 3 4 5 6 7 8 9 [modules.mod_http_upload] host = \"upload.@HOST@\" backend = \"s3\" expiration_time = 120 s3 . bucket_url = \"https://s3-eu-west-1.amazonaws.com/mybucket\" s3 . region = \"eu-west-1\" s3 . add_acl = true s3 . access_key_id = \"AKIAIOSFODNN7EXAMPLE\" s3 . secret_access_key = \"wJalrXUtnFEMI/K7MDENG/bPxRfiCYEXAMPLEKEY\"","title":"Example configuration"},{"location":"modules/mod_http_upload/#testing-s3-configuration","text":"Since there is no direct connection between MongooseIM and an S3 bucket, it is not possible to verify the provided S3 credentials during startup. However, the testing can be done manually. MongooseIM provides a dedicated mongooseimctl http_upload command for the manual URLs generation, it accepts the following parameters: Host - XMPP host name. FileName - The name of the file. FileSize - The size of the file (positive integer). ContentType - Content-Type , optional parameter. If not provided, must be an empty string \"\" . ExpirationTime - Duration (in seconds, positive integer) after which the generated PUT URL will become invalid. This parameter shadows the expiration_time configuration. The generated URLs can be used to upload/download a file using the curl utility: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 # Create some text file echo qwerty > tmp.txt # Get the size of the file filesize = \" $( wc -c tmp.txt | awk '{print $1}' ) \" # Set the content type content_type = \"text/plain\" # Generate upload/download URLs urls = \" $( ./mongooseimctl http_upload localhost test.txt \" $filesize \" \" $content_type \" 600 ) \" put_url = \" $( echo \" $urls \" | awk '/PutURL:/ {print $2}' ) \" get_url = \" $( echo \" $urls \" | awk '/GetURL:/ {print $2}' ) \" # Try to upload a file. Note that if 'add_acl' option is # enabled, then you must also add 'x-amz-acl' header: # -H \"x-amz-acl: public-read\" curl -v -T \"./tmp.txt\" -H \"Content-Type: $content_type \" \" $put_url \" # Try to download a file curl -i \" $get_url \"","title":"Testing S3 configuration"},{"location":"modules/mod_http_upload/#using-s3-backend-with-minio","text":"min.io doesn't support ObjectACL , so enabling add_acl makes no sense. The bucket policies must be used instead, it is enough to set the bucket policy to download . Please note that there is no error if you keep add_acl enabled. min.io just ignores the x-amz-acl header. This might be useful to simplify the migration from S3 to min.io","title":"Using S3 backend with min.io"},{"location":"modules/mod_http_upload/#metrics","text":"If you'd like to learn more about metrics in MongooseIM, please visit MongooseIM metrics page. Backend action Description (when it gets incremented) create_slot An upload slot is allocated.","title":"Metrics"},{"location":"modules/mod_inbox/","text":"Module Description Inbox is an experimental feature implemented as a few separate modules. To use it, enable mod_inbox in the config file. Options modules.mod_inbox.reset_markers Syntax: array of strings, out of \"displayed\" , \"received\" , \"acknowledged\" Default: [\"displayed\"] Example: reset_markers = [\"received\"] List of chat markers that when sent, will reset the unread message counter for a conversation. This works when Chat Markers are enabled on the client side. Setting as empty list (not recommended) means that no chat marker can decrease the counter value. modules.mod_inbox.groupchat Syntax: array of strings Default: [\"muclight\"] Example: groupchat = [\"muclight\"] The list indicating which groupchats will be included in inbox. Possible values are muclight Multi-User Chat Light or muc Multi-User Chat . modules.mod_inbox.aff_changes Syntax: boolean Default: true Example: aff_changes = true Use this option when muclight is enabled. Indicates if MUC Light affiliation change messages should be included in the conversation inbox. Only changes that affect the user directly will be stored in their inbox. modules.mod_inbox.remove_on_kicked Syntax: boolean Default: true Example: remove_on_kicked = true Use this option when muclight is enabled. If true, the inbox conversation is removed for a user when they are removed from the groupchat. modules.mod_inbox.iqdisc.type Syntax: string, one of \"one_queue\" , \"no_queue\" , \"queues\" , \"parallel\" Default: \"no_queue\" Strategy to handle incoming stanzas. For details, please refer to IQ processing policies . Note about supported RDBMS mod_inbox executes upsert queries, which have different syntax in every supported RDBMS. Inbox currently supports the following DBs: MySQL via native driver PgSQL via native driver MSSQL via ODBC driver Legacy MUC support Inbox comes with support for the legacy MUC as well. It stores all groupchat messages sent to room in each sender's and recipient's inboxes and private messages. Currently it is not possible to configure it to store system messages like subject or affiliation change. Example configuration 1 2 3 4 5 [modules.mod_inbox] reset_markers = [\"displayed\"] aff_changes = true remove_on_kicked = true groupchat = [\"muclight\"]","title":"mod_inbox"},{"location":"modules/mod_inbox/#module-description","text":"Inbox is an experimental feature implemented as a few separate modules. To use it, enable mod_inbox in the config file.","title":"Module Description"},{"location":"modules/mod_inbox/#options","text":"","title":"Options"},{"location":"modules/mod_inbox/#modulesmod_inboxreset_markers","text":"Syntax: array of strings, out of \"displayed\" , \"received\" , \"acknowledged\" Default: [\"displayed\"] Example: reset_markers = [\"received\"] List of chat markers that when sent, will reset the unread message counter for a conversation. This works when Chat Markers are enabled on the client side. Setting as empty list (not recommended) means that no chat marker can decrease the counter value.","title":"modules.mod_inbox.reset_markers"},{"location":"modules/mod_inbox/#modulesmod_inboxgroupchat","text":"Syntax: array of strings Default: [\"muclight\"] Example: groupchat = [\"muclight\"] The list indicating which groupchats will be included in inbox. Possible values are muclight Multi-User Chat Light or muc Multi-User Chat .","title":"modules.mod_inbox.groupchat"},{"location":"modules/mod_inbox/#modulesmod_inboxaff_changes","text":"Syntax: boolean Default: true Example: aff_changes = true Use this option when muclight is enabled. Indicates if MUC Light affiliation change messages should be included in the conversation inbox. Only changes that affect the user directly will be stored in their inbox.","title":"modules.mod_inbox.aff_changes"},{"location":"modules/mod_inbox/#modulesmod_inboxremove_on_kicked","text":"Syntax: boolean Default: true Example: remove_on_kicked = true Use this option when muclight is enabled. If true, the inbox conversation is removed for a user when they are removed from the groupchat.","title":"modules.mod_inbox.remove_on_kicked"},{"location":"modules/mod_inbox/#modulesmod_inboxiqdisctype","text":"Syntax: string, one of \"one_queue\" , \"no_queue\" , \"queues\" , \"parallel\" Default: \"no_queue\" Strategy to handle incoming stanzas. For details, please refer to IQ processing policies .","title":"modules.mod_inbox.iqdisc.type"},{"location":"modules/mod_inbox/#note-about-supported-rdbms","text":"mod_inbox executes upsert queries, which have different syntax in every supported RDBMS. Inbox currently supports the following DBs: MySQL via native driver PgSQL via native driver MSSQL via ODBC driver","title":"Note about supported RDBMS"},{"location":"modules/mod_inbox/#legacy-muc-support","text":"Inbox comes with support for the legacy MUC as well. It stores all groupchat messages sent to room in each sender's and recipient's inboxes and private messages. Currently it is not possible to configure it to store system messages like subject or affiliation change.","title":"Legacy MUC support"},{"location":"modules/mod_inbox/#example-configuration","text":"1 2 3 4 5 [modules.mod_inbox] reset_markers = [\"displayed\"] aff_changes = true remove_on_kicked = true groupchat = [\"muclight\"]","title":"Example configuration"},{"location":"modules/mod_jingle_sip/","text":"Module Description This module enables Jingle to SIP and SIP to Jingle translation. When this module is enabled, MongooseIM will intercept any Jingle IQ set stanza with action: session-initiate session-terminate session-accept transport-info and translate it to SIP messages with appropriate SDP content based on the details in the Jingle stanza. The translation back from SIP to Jingle is done for the following SIP requests: INVITE re-INVITE - INVITE message sent for an accepted session CANCEL BYE INFO and following responses to the INVITE request: 200 when the call invite was accepted 180 and 183 to indicate that the invitation was sent to the device 486 when the call's recipient rejects it from 400 to 600 - other error codes indicating session termination Jingle to SIP translation The table below summarises the bilateral translation for standard Jingle and SIP messages: Jingle action SIP message comment session-initiate INVITE request session-accept 200 OK response session-terminate with reason success BYE request Only for accepted session session-terminate with reason decline CANCEL request When sent by call's initiator session-terminate with reason decline 486 Busy Here response When sent by the invite user transport-info INFO request Ringing notification Both Jingle and SIP have the ringing notification. It's generated as a response code 180 Ringing by a SIP entity when the INVITE is sent to the device. In SIP world a 183 Session Progress response code is also generated in some cases. Both 180 and 183 codes are translated as session-info Jingle stanza with ringing sub element. MongooseIM generates only 180 Ringing response code the INVITE request, if the recipient's online. If the recipient is online, MongooseIM generates the 180 Ringing response code to the INVITE request. Recipient unavailable When MongooseIM receives a SIP INVITE request addressed to an offline user, it replies with a 480 Temporarily Unavailable code. The same code is expected from the SIP Proxy when MongooseIM sends the INVITE request. Other error codes When an error response to the INVITE request is from the range 400 to 699 but not 486 , MongooseIM will send a Jingle session-terminate stanza to the call's initiator. The stanza has reason general-error with the SIP error code in the sip-error sub element. Non-standard Jingle stanzas used by jingle.js The following non-standard Jingle stanzas were integrated with Jingle.js : source-remove source-add source-update When MongooseIM observes the above Jingle stanzas, it will translate them to a SIP in-dialog INVITE request. In the SDP content of the request, there will be a custom attribute a=jingle-action . The value of the custom attribute is one of the three presented above. Similarly when MongooseIM gets a SIP in-dialog INVITE request, it will check if there is a custom attribute and use it as the action attribute of the Jingle stanza sent to the user. If there is no such attribute, the action will be set to regular Jingle transport-info . Non-standard Jingle existing-session-initiate stanza MongooseIM allows a user to ask for an unanswered session-initiate request. This may be useful in web applications when there is a need to handle the call in a new browser window. In order to get the session-initiate , which was not answered yet, the user can send a get Jingle stanza to self with action set to existing-session-initiate . As a result, MongooseIM will resend the original session-initiate request to the device which sent the query. Prerequisites By default, MongooseIM is built without SIP support. In order to build the server with SIP support, please use tools/configure script before the release generation. You may either pick only certain drivers (with SIP included) or simply use with-all option. Examples: 1 2 3 tools/configure with-mysql with-jingle-sip tools/configure with-all without-odbc tools/configure with-all MongooseIM packages are built with Jingle/SIP support. Options modules.mod_jingle_sip.proxy_host Syntax: string Default: \"localhost\" Example: proxy_host = \"localhost\" The name or IP address of the SIP Proxy to which MongooseIM will send SIP messages. modules.mod_jingle_sip.proxy_port Syntax: non-negative integer Default: 5600 Example: proxy_port = 5600 The port of the SIP Proxy. modules.mod_jingle_sip.listen_port Syntax: non-negative integer Default: 5600 Example: listen_port = 5600 The port on which MongooseIM will listen for incomming SIP messages. modules.mod_jingle_sip.local_host Syntax: string Default: \"127.0.0.1\" Example: local_host = \"localhost\" The value used to create SIP URIs (including VIA headers). modules.mod_jingle_sip.sdp_origin Syntax: string Default: \"127.0.0.1\" Example: sdp_origin = \"127.0.0.1\" The value of the c= SDP attribute. The simplest configuration is the following: 1 [modules.mod_jingle_sip] With this configuration MongooseIM will try sending SIP messages to a SIP proxy listening on localhost and port 5600. Use cases covered by tests Currently to test the functionality we use a SIP Proxy mock written in Erlang. The following scenarios are covered by our tests in big_tests/tests/jingle_SUITE.erl All the sequence diagrams where generated with textart.io/sequence . The source code is embedded in the markdown file below every diagram inside a comment <!--- ---> 1. Establishing a session with another XMPP user With the mod_jingle_sip enabled, all Jingle IQ set stanzas listed above are intercepted, translated to SIP packets and sent to a SIP Proxy. This means that the current implementation will also translate stanzas addressed to a user in the same domain. This allows the SIP entity to control how the call between XMPP users is established. Below there are sequence diagrams showing the communication between XMPP users, MongooseIM and SIP Proxy as in our tests. It's possible that the SIP Proxy or other SIP entity decides that the call needs to be forked and delivered to the user's phone number instead of generating a corresponding call back to MongooseIM. 1.1 Signaling session-initiate to other XMPP user via SIP Proxy 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 +-------+ +-------------+ +-----------+ +-------+ | UserA | | MongooseIM | | SIPProxy | | UserB | +-------+ +-------------+ +-----------+ +-------+ | | | | | session-initiate to UserB | | | |--------------------------------->| | | | -------------------------\\ | | | |-| Jingle stanza | | | | | | action:session-initate | | | | | | sid: 123 | | | | | |------------------------| | SIP INVITE | | | |------------------->| | | | -------------\\ | | | |-| from:UserA | | | | | | to:UserB | | | | | | sid: 123 | | | | | |------------| | create new call | | | |---------------- | | | | | | | | |<--------------- | | | | ------------------------\\ | | | |-| SDP content can be | | | | | | changed for instance | | | | | | to inject a transport | | | | SIP INVITE | | canidate | | | |<-------------------| |-----------------------| | | | -------------\\ | | | | | from:UserA |-| | | | | to:UserB | | | | --------------------\\ | | sid:456 | | | | | yes, new SID: 456 |-| |------------| | | | |-------------------| | | | | | | | | | session-initiate to UserB | | |------------------------------------------------->| | | | | 1.2 Signaling session-accept to other XMPP user via SIP Proxy When the other user accepts the call invite sent by the first, the following sequence is executed. This is a continuation of the previous example 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 +-------+ +-------------+ +-----------+ +-------+ | UserA | | MongooseIM | | SIPProxy | | UserB | +-------+ +-------------+ +-----------+ +-------+ | | | | | | | session-accpet to UserA | | |<--------------------------------------------------| | | | ------------------------\\ | | | | | Jingle stanza |-| | | | | action:session-accept | | | | | | sid: 456 | | | | 200 OK | |-----------------------| | | |-------------------->| | | | --------------\\ | | | |-| from: UserA | | | | | | to: UserB | | | | | | sid: 456 | | | | | |-------------| | find corresponding call | | | |------------------------ | | | | | | | | |<----------------------- | | | | | | | 200 OK | | | |<--------------------| | | | --------------\\ | | | | | from: UserA |-| | | | | to: UserB | | | | | | sid: 123 | | | | session-accept from UserB | |-------------| | | |<---------------------------------| | | | | | | 1.3 Terminating a call Any Jingle session (accepted or not) can be terminated by sending a Jingle stanza with action session-terminate and a reason. In the SIP world it's more complex. See the following examples for more information. 1.3.1 Terminating an accepted call The easiest scenario is when the call was accepted as in 1.2 . In this case one of the users sends a session-terminate Jingle action with a reason success . This is translated to a SIP BYE request with to and from headers set appropriately - from is the user who wants to terminate the call and to is the user on the other end of the session. The BYE request is sent to the SIP Proxy and then to the other user in a similar way to session acceptance. 1.3.2 Terminating an unanswered call by initiator To terminate the call before it's accepted, the initiator sends a Jingle session-terminate stanza with a reason decline . Then MongooseIM translates this to a SIP CANCEL request which is sent to the SIP Proxy. 1.3.3 Rejecting the call When the invitee wants to terminate the call, on the XMPP level this is also a Jingle session-terminate stanza with a reason decline . MongooseIM translates this to SIP 486 Busy Here Response (because this is a response to the invite request). 2. Establishing a session with a SIP user Establishing a session with a SIP user (or a SIP entity) works the same as in the previous section. The only difference is that the SIP Proxy will not call MongooseIM back (as it may happen for call to other XMPP user). Instead the SIP message sent by MongooseIM to SIP Proxy will be delivered directly to the SIP user's device.","title":"mod_jingle_sip"},{"location":"modules/mod_jingle_sip/#module-description","text":"This module enables Jingle to SIP and SIP to Jingle translation. When this module is enabled, MongooseIM will intercept any Jingle IQ set stanza with action: session-initiate session-terminate session-accept transport-info and translate it to SIP messages with appropriate SDP content based on the details in the Jingle stanza. The translation back from SIP to Jingle is done for the following SIP requests: INVITE re-INVITE - INVITE message sent for an accepted session CANCEL BYE INFO and following responses to the INVITE request: 200 when the call invite was accepted 180 and 183 to indicate that the invitation was sent to the device 486 when the call's recipient rejects it from 400 to 600 - other error codes indicating session termination","title":"Module Description"},{"location":"modules/mod_jingle_sip/#jingle-to-sip-translation","text":"The table below summarises the bilateral translation for standard Jingle and SIP messages: Jingle action SIP message comment session-initiate INVITE request session-accept 200 OK response session-terminate with reason success BYE request Only for accepted session session-terminate with reason decline CANCEL request When sent by call's initiator session-terminate with reason decline 486 Busy Here response When sent by the invite user transport-info INFO request","title":"Jingle to SIP translation"},{"location":"modules/mod_jingle_sip/#ringing-notification","text":"Both Jingle and SIP have the ringing notification. It's generated as a response code 180 Ringing by a SIP entity when the INVITE is sent to the device. In SIP world a 183 Session Progress response code is also generated in some cases. Both 180 and 183 codes are translated as session-info Jingle stanza with ringing sub element. MongooseIM generates only 180 Ringing response code the INVITE request, if the recipient's online. If the recipient is online, MongooseIM generates the 180 Ringing response code to the INVITE request.","title":"Ringing notification"},{"location":"modules/mod_jingle_sip/#recipient-unavailable","text":"When MongooseIM receives a SIP INVITE request addressed to an offline user, it replies with a 480 Temporarily Unavailable code. The same code is expected from the SIP Proxy when MongooseIM sends the INVITE request.","title":"Recipient unavailable"},{"location":"modules/mod_jingle_sip/#other-error-codes","text":"When an error response to the INVITE request is from the range 400 to 699 but not 486 , MongooseIM will send a Jingle session-terminate stanza to the call's initiator. The stanza has reason general-error with the SIP error code in the sip-error sub element.","title":"Other error codes"},{"location":"modules/mod_jingle_sip/#non-standard-jingle-stanzas-used-by-jinglejs","text":"The following non-standard Jingle stanzas were integrated with Jingle.js : source-remove source-add source-update When MongooseIM observes the above Jingle stanzas, it will translate them to a SIP in-dialog INVITE request. In the SDP content of the request, there will be a custom attribute a=jingle-action . The value of the custom attribute is one of the three presented above. Similarly when MongooseIM gets a SIP in-dialog INVITE request, it will check if there is a custom attribute and use it as the action attribute of the Jingle stanza sent to the user. If there is no such attribute, the action will be set to regular Jingle transport-info .","title":"Non-standard Jingle stanzas used by jingle.js"},{"location":"modules/mod_jingle_sip/#non-standard-jingle-existing-session-initiate-stanza","text":"MongooseIM allows a user to ask for an unanswered session-initiate request. This may be useful in web applications when there is a need to handle the call in a new browser window. In order to get the session-initiate , which was not answered yet, the user can send a get Jingle stanza to self with action set to existing-session-initiate . As a result, MongooseIM will resend the original session-initiate request to the device which sent the query.","title":"Non-standard Jingle existing-session-initiate stanza"},{"location":"modules/mod_jingle_sip/#prerequisites","text":"By default, MongooseIM is built without SIP support. In order to build the server with SIP support, please use tools/configure script before the release generation. You may either pick only certain drivers (with SIP included) or simply use with-all option. Examples: 1 2 3 tools/configure with-mysql with-jingle-sip tools/configure with-all without-odbc tools/configure with-all MongooseIM packages are built with Jingle/SIP support.","title":"Prerequisites"},{"location":"modules/mod_jingle_sip/#options","text":"","title":"Options"},{"location":"modules/mod_jingle_sip/#modulesmod_jingle_sipproxy_host","text":"Syntax: string Default: \"localhost\" Example: proxy_host = \"localhost\" The name or IP address of the SIP Proxy to which MongooseIM will send SIP messages.","title":"modules.mod_jingle_sip.proxy_host"},{"location":"modules/mod_jingle_sip/#modulesmod_jingle_sipproxy_port","text":"Syntax: non-negative integer Default: 5600 Example: proxy_port = 5600 The port of the SIP Proxy.","title":"modules.mod_jingle_sip.proxy_port"},{"location":"modules/mod_jingle_sip/#modulesmod_jingle_siplisten_port","text":"Syntax: non-negative integer Default: 5600 Example: listen_port = 5600 The port on which MongooseIM will listen for incomming SIP messages.","title":"modules.mod_jingle_sip.listen_port"},{"location":"modules/mod_jingle_sip/#modulesmod_jingle_siplocal_host","text":"Syntax: string Default: \"127.0.0.1\" Example: local_host = \"localhost\" The value used to create SIP URIs (including VIA headers).","title":"modules.mod_jingle_sip.local_host"},{"location":"modules/mod_jingle_sip/#modulesmod_jingle_sipsdp_origin","text":"Syntax: string Default: \"127.0.0.1\" Example: sdp_origin = \"127.0.0.1\" The value of the c= SDP attribute. The simplest configuration is the following: 1 [modules.mod_jingle_sip] With this configuration MongooseIM will try sending SIP messages to a SIP proxy listening on localhost and port 5600.","title":"modules.mod_jingle_sip.sdp_origin"},{"location":"modules/mod_jingle_sip/#use-cases-covered-by-tests","text":"Currently to test the functionality we use a SIP Proxy mock written in Erlang. The following scenarios are covered by our tests in big_tests/tests/jingle_SUITE.erl All the sequence diagrams where generated with textart.io/sequence . The source code is embedded in the markdown file below every diagram inside a comment <!--- --->","title":"Use cases covered by tests"},{"location":"modules/mod_jingle_sip/#1-establishing-a-session-with-another-xmpp-user","text":"With the mod_jingle_sip enabled, all Jingle IQ set stanzas listed above are intercepted, translated to SIP packets and sent to a SIP Proxy. This means that the current implementation will also translate stanzas addressed to a user in the same domain. This allows the SIP entity to control how the call between XMPP users is established. Below there are sequence diagrams showing the communication between XMPP users, MongooseIM and SIP Proxy as in our tests. It's possible that the SIP Proxy or other SIP entity decides that the call needs to be forked and delivered to the user's phone number instead of generating a corresponding call back to MongooseIM.","title":"1. Establishing a session with another XMPP user"},{"location":"modules/mod_jingle_sip/#11-signaling-session-initiate-to-other-xmpp-user-via-sip-proxy","text":"1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 +-------+ +-------------+ +-----------+ +-------+ | UserA | | MongooseIM | | SIPProxy | | UserB | +-------+ +-------------+ +-----------+ +-------+ | | | | | session-initiate to UserB | | | |--------------------------------->| | | | -------------------------\\ | | | |-| Jingle stanza | | | | | | action:session-initate | | | | | | sid: 123 | | | | | |------------------------| | SIP INVITE | | | |------------------->| | | | -------------\\ | | | |-| from:UserA | | | | | | to:UserB | | | | | | sid: 123 | | | | | |------------| | create new call | | | |---------------- | | | | | | | | |<--------------- | | | | ------------------------\\ | | | |-| SDP content can be | | | | | | changed for instance | | | | | | to inject a transport | | | | SIP INVITE | | canidate | | | |<-------------------| |-----------------------| | | | -------------\\ | | | | | from:UserA |-| | | | | to:UserB | | | | --------------------\\ | | sid:456 | | | | | yes, new SID: 456 |-| |------------| | | | |-------------------| | | | | | | | | | session-initiate to UserB | | |------------------------------------------------->| | | | |","title":"1.1 Signaling session-initiate to other XMPP user via SIP Proxy"},{"location":"modules/mod_jingle_sip/#12-signaling-session-accept-to-other-xmpp-user-via-sip-proxy","text":"When the other user accepts the call invite sent by the first, the following sequence is executed. This is a continuation of the previous example 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 +-------+ +-------------+ +-----------+ +-------+ | UserA | | MongooseIM | | SIPProxy | | UserB | +-------+ +-------------+ +-----------+ +-------+ | | | | | | | session-accpet to UserA | | |<--------------------------------------------------| | | | ------------------------\\ | | | | | Jingle stanza |-| | | | | action:session-accept | | | | | | sid: 456 | | | | 200 OK | |-----------------------| | | |-------------------->| | | | --------------\\ | | | |-| from: UserA | | | | | | to: UserB | | | | | | sid: 456 | | | | | |-------------| | find corresponding call | | | |------------------------ | | | | | | | | |<----------------------- | | | | | | | 200 OK | | | |<--------------------| | | | --------------\\ | | | | | from: UserA |-| | | | | to: UserB | | | | | | sid: 123 | | | | session-accept from UserB | |-------------| | | |<---------------------------------| | | | | | |","title":"1.2 Signaling session-accept to other XMPP user via SIP Proxy"},{"location":"modules/mod_jingle_sip/#13-terminating-a-call","text":"Any Jingle session (accepted or not) can be terminated by sending a Jingle stanza with action session-terminate and a reason. In the SIP world it's more complex. See the following examples for more information.","title":"1.3 Terminating a call"},{"location":"modules/mod_jingle_sip/#131-terminating-an-accepted-call","text":"The easiest scenario is when the call was accepted as in 1.2 . In this case one of the users sends a session-terminate Jingle action with a reason success . This is translated to a SIP BYE request with to and from headers set appropriately - from is the user who wants to terminate the call and to is the user on the other end of the session. The BYE request is sent to the SIP Proxy and then to the other user in a similar way to session acceptance.","title":"1.3.1 Terminating an accepted call"},{"location":"modules/mod_jingle_sip/#132-terminating-an-unanswered-call-by-initiator","text":"To terminate the call before it's accepted, the initiator sends a Jingle session-terminate stanza with a reason decline . Then MongooseIM translates this to a SIP CANCEL request which is sent to the SIP Proxy.","title":"1.3.2 Terminating an unanswered call by initiator"},{"location":"modules/mod_jingle_sip/#133-rejecting-the-call","text":"When the invitee wants to terminate the call, on the XMPP level this is also a Jingle session-terminate stanza with a reason decline . MongooseIM translates this to SIP 486 Busy Here Response (because this is a response to the invite request).","title":"1.3.3 Rejecting the call"},{"location":"modules/mod_jingle_sip/#2-establishing-a-session-with-a-sip-user","text":"Establishing a session with a SIP user (or a SIP entity) works the same as in the previous section. The only difference is that the SIP Proxy will not call MongooseIM back (as it may happen for call to other XMPP user). Instead the SIP message sent by MongooseIM to SIP Proxy will be delivered directly to the SIP user's device.","title":"2. Establishing a session with a SIP user"},{"location":"modules/mod_keystore/","text":"Module Description mod_keystore serves as storage for crypto keys - it doesn't implement any XMPP-level protocol. The module can store transient RAM-only keys generated on module startup, stored in memory only, distributed to all cluster members and existing for only as long as the cluster is alive, as well as predefined and pre-shared keys which can be read from a file. RAM-only keys provide better security since they are never written to persistent storage, at the cost of loss in case of a cluster-global failure or restart. As of now mod_auth_token is the only module dependent on mod_keystore . It's crucial to understand the distinction between single-tenant and multi-tenant hosting scenarios. In a multi-tenant server mod_keystore must be configured separately for each virtual XMPP domain to avoid sharing keys between domains! Options modules.mod_keystore.ram_key_size Syntax: non-negative integer Default: 2048 Example: ram_key_size = 10000 Size to use when generating RAM-only keys (designated by type ram ). modules.mod_keystore.keys Syntax: Array of TOML tables with the following keys: \"name\" , \"type\" , \"path\" , and following values: {name = string , type = values: \"file\", \"ram\" , path = string }. Default: [] Example: modules.mod_keystore.keys = [{name = \"access_psk\", type = \"file\", path = \"priv/access_psk\"}] Names, types, and optional filepaths of the keys. API The module public API is hook-based: 1 mongoose_hooks : get_key ( Domain , [], KeyName ). An example of usage can be found in mod_auth_token:get_key_for_user/2 . Example Configuration Simple configuration - single tenant (i.e. server hosting just one XMPP domain): 1 2 3 4 [modules.mod_keystore] keys = [{ name = \"access_secret\" , type = \"ram\" }, { name = \"access_psk\" , type = \"file\" , path = \"priv/access_psk\" }, { name = \"provision_psk\" , type = \"file\" , path = \"priv/provision_psk\" }] Multi-tenant setup ( mod_keystore configured differently for each virtual XMPP domain): 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 [[host_config]] host = \"first.com\" [host_config.modules.mod_keystore] keys = [{ name = \"access_secret\" , type = \"ram\" }, { name = \"access_psk\" , type = \"file\" , path = \"priv/first_access_psk\" }, { name = \"provision_psk\" , type = \"file\" , path = \"priv/first_provision_psk\" }] [[host_config]] host = \"second.com\" [host_config.modules.mod_keystore] keys = [{ name = \"access_secret\" , type = \"ram\" }, { name = \"access_psk\" , type = \"file\" , path = \"priv/second_access_psk\" }, { name = \"provision_psk\" , type = \"file\" , path = \"priv/second_provision_psk\" }]","title":"mod_keystore"},{"location":"modules/mod_keystore/#module-description","text":"mod_keystore serves as storage for crypto keys - it doesn't implement any XMPP-level protocol. The module can store transient RAM-only keys generated on module startup, stored in memory only, distributed to all cluster members and existing for only as long as the cluster is alive, as well as predefined and pre-shared keys which can be read from a file. RAM-only keys provide better security since they are never written to persistent storage, at the cost of loss in case of a cluster-global failure or restart. As of now mod_auth_token is the only module dependent on mod_keystore . It's crucial to understand the distinction between single-tenant and multi-tenant hosting scenarios. In a multi-tenant server mod_keystore must be configured separately for each virtual XMPP domain to avoid sharing keys between domains!","title":"Module Description"},{"location":"modules/mod_keystore/#options","text":"","title":"Options"},{"location":"modules/mod_keystore/#modulesmod_keystoreram_key_size","text":"Syntax: non-negative integer Default: 2048 Example: ram_key_size = 10000 Size to use when generating RAM-only keys (designated by type ram ).","title":"modules.mod_keystore.ram_key_size"},{"location":"modules/mod_keystore/#modulesmod_keystorekeys","text":"Syntax: Array of TOML tables with the following keys: \"name\" , \"type\" , \"path\" , and following values: {name = string , type = values: \"file\", \"ram\" , path = string }. Default: [] Example: modules.mod_keystore.keys = [{name = \"access_psk\", type = \"file\", path = \"priv/access_psk\"}] Names, types, and optional filepaths of the keys.","title":"modules.mod_keystore.keys"},{"location":"modules/mod_keystore/#api","text":"The module public API is hook-based: 1 mongoose_hooks : get_key ( Domain , [], KeyName ). An example of usage can be found in mod_auth_token:get_key_for_user/2 .","title":"API"},{"location":"modules/mod_keystore/#example-configuration","text":"Simple configuration - single tenant (i.e. server hosting just one XMPP domain): 1 2 3 4 [modules.mod_keystore] keys = [{ name = \"access_secret\" , type = \"ram\" }, { name = \"access_psk\" , type = \"file\" , path = \"priv/access_psk\" }, { name = \"provision_psk\" , type = \"file\" , path = \"priv/provision_psk\" }] Multi-tenant setup ( mod_keystore configured differently for each virtual XMPP domain): 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 [[host_config]] host = \"first.com\" [host_config.modules.mod_keystore] keys = [{ name = \"access_secret\" , type = \"ram\" }, { name = \"access_psk\" , type = \"file\" , path = \"priv/first_access_psk\" }, { name = \"provision_psk\" , type = \"file\" , path = \"priv/first_provision_psk\" }] [[host_config]] host = \"second.com\" [host_config.modules.mod_keystore] keys = [{ name = \"access_secret\" , type = \"ram\" }, { name = \"access_psk\" , type = \"file\" , path = \"priv/second_access_psk\" }, { name = \"provision_psk\" , type = \"file\" , path = \"priv/second_provision_psk\" }]","title":"Example Configuration"},{"location":"modules/mod_last/","text":"Module Description Implements XEP-0012: Last Activity . Use with caution, as it was observed that a user disconnect spike might result in overloading the database with \"last activity\" writes. Options modules.mod_last.iqdisc.type Syntax: string, one of \"one_queue\" , \"no_queue\" , \"queues\" , \"parallel\" Default: \"no_queue\" Strategy to handle incoming stanzas. For details, please refer to IQ processing policies . modules.mod_last.backend Syntax: string, one of \"mnesia\" , \"rdbms\" , \"riak\" Default: \"mnesia\" Example: backend = \"rdbms\" Storage backend. Riak-specific options bucket_type Syntax: string Default: \"last\" Example: bucket_type = \"last\" Riak bucket type. Example Configuration 1 2 [modules.mod_last] backend = \"rdbms\" Metrics If you'd like to learn more about metrics in MongooseIM, please visit MongooseIM metrics page. Backend action Description (when it gets incremented) get_last A timestamp is fetched from DB. set_last_info A timestamp is stored in DB.","title":"mod_last"},{"location":"modules/mod_last/#module-description","text":"Implements XEP-0012: Last Activity . Use with caution, as it was observed that a user disconnect spike might result in overloading the database with \"last activity\" writes.","title":"Module Description"},{"location":"modules/mod_last/#options","text":"","title":"Options"},{"location":"modules/mod_last/#modulesmod_lastiqdisctype","text":"Syntax: string, one of \"one_queue\" , \"no_queue\" , \"queues\" , \"parallel\" Default: \"no_queue\" Strategy to handle incoming stanzas. For details, please refer to IQ processing policies .","title":"modules.mod_last.iqdisc.type"},{"location":"modules/mod_last/#modulesmod_lastbackend","text":"Syntax: string, one of \"mnesia\" , \"rdbms\" , \"riak\" Default: \"mnesia\" Example: backend = \"rdbms\" Storage backend.","title":"modules.mod_last.backend"},{"location":"modules/mod_last/#riak-specific-options","text":"","title":"Riak-specific options"},{"location":"modules/mod_last/#bucket_type","text":"Syntax: string Default: \"last\" Example: bucket_type = \"last\" Riak bucket type.","title":"bucket_type"},{"location":"modules/mod_last/#example-configuration","text":"1 2 [modules.mod_last] backend = \"rdbms\"","title":"Example Configuration"},{"location":"modules/mod_last/#metrics","text":"If you'd like to learn more about metrics in MongooseIM, please visit MongooseIM metrics page. Backend action Description (when it gets incremented) get_last A timestamp is fetched from DB. set_last_info A timestamp is stored in DB.","title":"Metrics"},{"location":"modules/mod_mam/","text":"Module Description This module implements XEP-0313: Message Archive Management . It enables a service to store all user messages for one-to-one chats as well as group chats (MUC, MultiUser Chat). It uses XEP-0059: Result Set Management for paging. It is a highly customizable module, that requires some skill and knowledge to operate properly and efficiently. MongooseIM is compatible with MAM 0.4-0.6. Configure MAM with different storage backends: RDBMS (databases like MySQL, PostgreSQL, MS SQL Server) Riak KV (NOSQL) Cassandra (NOSQL) ElasticSearch (NOSQL) mod_mam_meta is a meta-module that ensures all relevant mod_mam_* modules are loaded and properly configured. Message retraction This module supports XEP-0424: Message Retraction with RDBMS storage backends. When a retraction message is received, the MAM module finds the message to retract and replaces it with a tombstone. The following criteria are used to find the original message: The id attribute specified in the apply-to element of the retraction message has to be the same as the id attribute of the origin-id element of the original message. Both messages need to originate from the same user. Both messages need to be addressed to the same user. If more than one message matches the criteria, only the most recent one is retracted. To avoid this case, it is recommended to use a unique identifier (UUID) as the origin ID. Full Text Search This module allows message filtering by their text body (if enabled, see Common backend options ). This means that an XMPP client, while requesting messages from the archive may not only specify standard form fields ( with , start , end ), but also full-text-search (of type text-single ). If this happens, the client will receive only messages that contain words specified in the request. The exact behaviour, like whether word ordering matters, may depend on the storage backend in use. For now rdbms backend has very limited support for this feature, while cassandra does not support it at all. riak and elasticsearch backends, on the other hand, should provide you with the best results when it comes to text filtering. mod_mam_rdbms_arch returns all messages that contain all search words, order of words does not matter. Messages are sorted by timestamp (not by relevance). Note on full text search with ElasticSearch backend When using ElasticSearch MAM backend, the value provided in full-text-search form field will be passed to ElasticSearch as Simple Search Query . If you're using our official ElasticSearch mappings from priv/elasticsearch then the query analyzer is set to english . Also note that the default separator for the search query is AND (which roughly means that ElasticSearch will search for messages containing all the terms provided in the query string). Options modules.mod_mam_meta.backend Syntax: string, one of \"rdbms\" , \"riak\" , \"cassandra\" and \"elasticsearch\" Default: \"rdbms\" Example: backend = \"riak\" Database backend to use. modules.mod_mam_meta.no_stanzaid_element Syntax: boolean Default: false Example: no_stanzaid_element = true Do not add a <stanza-id/> element from MAM v0.6. modules.mod_mam_meta.is_archivable_message Syntax: non-empty string Default: \"mod_mam_utils\" Example: is_archivable_message = \"mod_mam_utils\" Name of a module implementing is_archivable_message/3 callback that determines if the message should be archived. modules.mod_mam_meta.send_message Syntax: non-empty string Default: \"mod_mam_utils\" Example: send_message = \"mod_mam_utils\" Name of a module implementing send_message/4 callback that routes a message during lookup operation. Consult with mod_mam_utils:send_message/4 code for more information. Check big_tests/tests/mam_send_message_SUITE_data/mam_send_message_example.erl file in the MongooseIM repository for the usage example. modules.mod_mam_meta.archive_chat_markers Syntax: boolean Default: false Example: archive_chat_markers = true If set to true, XEP-0333 chat markers will be archived. See more details here . modules.mod_mam_meta.message_retraction Syntax: boolean Default: true Example: message_retraction = false Enables XEP-0424: Message Retraction . This functionality is currently implemented only for the rdbms backend. Retraction messages are always archived regardless of this option. backend , no_stanzaid_element , is_archivable_message and message_retraction will be applied to both pm and muc (if they are enabled), unless overridden explicitly (see example below). Enable one-to-one message archive Archive for one-to-one messages can be enabled in one of two ways: Specify [mod_mam_meta.pm] section 1 2 [modules.mod_mam_meta] [ modules . mod_mam_meta . pm ] # defining this section enables PM support Define any PM related option 1 2 [modules.mod_mam_meta] pm . backend = \"rdbms\" # enables PM support and overrides its backend Disable one-to-one message archive To disable archive for one-to-one messages please remove PM section or any PM related option from the config file. PM-specific options modules.mod_mam_meta.pm.archive_groupchats Syntax: boolean Default: false Example: modules.mod_mam_meta.pm.archive_groupchats = true When enabled, MAM will store groupchat messages in recipients' individual archives. USE WITH CAUTION! May increase archive size significantly. Disabling this option for existing installation will neither remove such messages from MAM storage, nor will filter out them from search results. Enable MUC message archive Archive for MUC messages can be enabled in one of two ways: Specify [mod_mam_meta.muc] section 1 2 [modules.mod_mam_meta] [ modules . mod_mam_meta . muc ] # defining this section enables MUC support Define any MUC related option 1 2 [modules.mod_mam_meta] muc . backend = \"rdbms\" # enables MUC support and overrides its backend Disable MUC message archive To disable archive for MUC messages please remove MUC section or any MUC related option from the config file. MUC-specific options modules.mod_mam_meta.muc.host Syntax: string Default: \"conference.@HOST@\" Example: modules.mod_mam_meta.muc.host = \"conference.@HOST@\" Warning : if you are using MUC Light, make sure this option is set to the MUC Light domain The MUC host that will be archived if MUC archiving is enabled. Example The example below presents how to override common option for muc module specifically. Please note that you can override all common options in similar way. 1 2 3 4 [modules.mod_mam_meta] backend = \"rdbms\" async_writer = true # this option enables async writer for RDBMS backend muc . async_writer = false # disable async writer for MUC archive only RDBMS backend options These options will only have effect when the rdbms backend is used: modules.mod_mam_meta.cache_users Syntax: boolean Default: true Example: modules.mod_mam_meta.cache_users = false Enables Archive ID to integer mappings cache. modules.mod_mam_meta.rdbms_message_format Syntax: string, one of \"internal\" and \"simple\" Default: \"internal\" Example: modules.mod_mam_meta.rdbms_message_format = \"simple\" Warning : archive MUST be empty to change this option When set to simple , stores messages in XML and full JIDs. When set to internal , stores messages and JIDs in internal format. modules.mod_mam_meta.async_writer Syntax: boolean Default: true Example: modules.mod_mam_meta.async_writer = false Enables an asynchronous writer that is faster than the synchronous one but harder to debug. The async writers store batches of messages with a certain delay (see flush_interval ), so the results of the lookup operations executed right after message routing may be incomplete until the configured time passes. modules.mod_mam_meta.flush_interval Syntax: non-negative integer Default: 2000 Example: modules.mod_mam_meta.flush_interval = 2000 How often (in milliseconds) the buffered messages are flushed to a DB. modules.mod_mam_meta.max_batch_size Syntax: non-negative integer Default: 30 Example: modules.mod_mam_meta.max_batch_size = 30 Max size of the batch insert query for an async writer. If the buffer is full, messages are flushed to a database immediately and the flush timer is reset. Common backend options modules.mod_mam_meta.user_prefs_store Syntax: one of \"rdbms\" , \"cassandra\" , \"mnesia\" Default: not set Example: modules.mod_mam_meta.user_prefs_store = \"rdbms\" Leaving this option unset will prevent users from setting their archiving preferences. It will also increase performance. The possible values are: \"rdbms\" (RDBMS backend only) - User archiving preferences saved in RDBMS. Slow and not recommended, but might be used for simplicity (keeping everything in RDBMS). \"cassandra\" (Cassandra backend only) - User archiving preferences are saved in Cassandra. \"mnesia\" (recommended) - User archiving preferences saved in Mnesia and accessed without transactions. Recommended in most deployments, could be overloaded with lots of users updating their preferences at once. There's a small risk of an inconsistent (in a rather harmless way) state of the preferences table. modules.mod_mam_meta.full_text_search Syntax: boolean Default: true Example: modules.mod_mam_meta.full_text_search = false Enables full text search in message archive (see Full Text Search paragraph). Please note that the full text search is currently only implemented for \"rdbms\" and \"riak\" backends. Also, full text search works only for messages archived while this option is enabled. is_archivable_message/3 callback is_archivable_message option has to name a module exporting is_archivable_message/3 function conforming to the spec: 1 2 - spec is_archivable_message ( Mod :: module (), Dir :: incoming | outgoing , Packet :: exml : element ()) -> boolean (). Servers SHOULD NOT archive messages that do not have a <body/> child tag. Servers SHOULD NOT archive delayed messages. By default, all messages that hold meaningful content, rather than state changes such as Chat State Notifications, are archived. Archiving chat markers Archiving chat markers can be enabled by setting archive_chat_markers option to true . However it only works if is_archivable_message callback module is set to mod_mam_utils or isn't set at all. When performing full text search chat markers are treated as if they had empty message body. Riak backend The Riak KV backend for MAM stores messages in weekly buckets so it's easier to remove old buckets. Archive querying is done using Riak KV 2.0 search mechanism called Yokozuna. Your instance of Riak KV must be configured with Yokozuna enabled. This backend works with Riak KV 2.0 and above, but we recommend version 2.1.1. Riak-specific options modules.mod_mam_meta.riak.bucket_type Syntax: non-empty string Default: \"mam_yz\" Example: modules.mod_mam_meta.riak.bucket_type = \"mam_yz\" Riak bucket type. modules.mod_mam_meta.riak.search_index Syntax: non-empty string Default: \"mam\" Example: modules.mod_mam_meta.riak.search_index = \"mam\" Riak index name. Cassandra backend Please consult Outgoing connections page to learn how to properly configure Cassandra connection pool. By default, mod_mam Cassandra backend requires global pool with default tag. ElasticSearch backend First, make sure that your ElasticSearch cluster has expected indexes and mappings in place. Please consult Outgoing connections page to learn how to properly configure ElasticSearch connection pool. Example configuration 1 2 3 4 5 6 7 8 9 10 [modules.mod_mam_meta] backend = \"rdbms\" no_stanzaid_element = true pm . user_prefs_store = \"rdbms\" muc . host = \"muc.example.com\" muc . rdbms_message_format = \"simple\" muc . async_writer = false muc . user_prefs_store = \"mnesia\" Metrics If you'd like to learn more about metrics in MongooseIM, please visit MongooseIM metrics page. Name Type Description (when it gets incremented) [Host, modMamArchiveRemoved] spiral User's entire archive is removed. [Host, modMamArchived] spiral A message is stored in user's archive. [Host, modMamDropped] spiral A message couldn't be enqueued due to an overloaded async worker. [Host, modMamDropped2] spiral A message couldn't be stored in the DB (and got dropped). [Host, modMamDroppedIQ] spiral MAM IQ has been dropped due to: high query frequency/invalid syntax or type. [Host, modMamFlushed] spiral Message was stored in a DB asynchronously. [Host, modMamForwarded] spiral A message is sent to a client as a part of a MAM query result. [Host, modMamLookups] spiral A MAM lookup is performed. [Host, modMamPrefsGets] spiral Archiving preferences have been requested by a client. [Host, modMamPrefsSets] spiral Archiving preferences have been updated by a client. [Host, modMucMamArchiveRemoved] spiral Room's entire archive is removed. [Host, modMucMamArchived] spiral A message is stored in room's archive. [Host, modMucMamForwarded] spiral A message is sent to a client as a part of a MAM query result from MUC room. [Host, modMucMamLookups] spiral A MAM lookup in MUC room is performed. [Host, modMucMamPrefsGets] spiral MUC archiving preferences have been requested by a client. [Host, modMucMamPrefsSets] spiral MUC archiving preferences have been updated by a client. [Host, mod_mam_rdbms_async_pool_writer, per_message_flush_time] histogram Average time per message insert measured in an async MAM worker. [Host, mod_mam_rdbms_async_pool_writer, flush_time] histogram Average time per flush of all buffered messages measured in an async MAM worker. [Host, mod_mam_muc_rdbms_async_pool_writer, per_message_flush_time] histogram Average time per message insert measured in an async MUC MAM worker. [Host, mod_mam_muc_rdbms_async_pool_writer, flush_time] histogram Average time per flush of all buffered messages measured in an async MUC MAM worker. Backend action Description (when it gets incremented) lookup A lookup in an archive. archive One message is saved in an archive.","title":"mod_mam"},{"location":"modules/mod_mam/#module-description","text":"This module implements XEP-0313: Message Archive Management . It enables a service to store all user messages for one-to-one chats as well as group chats (MUC, MultiUser Chat). It uses XEP-0059: Result Set Management for paging. It is a highly customizable module, that requires some skill and knowledge to operate properly and efficiently. MongooseIM is compatible with MAM 0.4-0.6. Configure MAM with different storage backends: RDBMS (databases like MySQL, PostgreSQL, MS SQL Server) Riak KV (NOSQL) Cassandra (NOSQL) ElasticSearch (NOSQL) mod_mam_meta is a meta-module that ensures all relevant mod_mam_* modules are loaded and properly configured.","title":"Module Description"},{"location":"modules/mod_mam/#message-retraction","text":"This module supports XEP-0424: Message Retraction with RDBMS storage backends. When a retraction message is received, the MAM module finds the message to retract and replaces it with a tombstone. The following criteria are used to find the original message: The id attribute specified in the apply-to element of the retraction message has to be the same as the id attribute of the origin-id element of the original message. Both messages need to originate from the same user. Both messages need to be addressed to the same user. If more than one message matches the criteria, only the most recent one is retracted. To avoid this case, it is recommended to use a unique identifier (UUID) as the origin ID.","title":"Message retraction"},{"location":"modules/mod_mam/#full-text-search","text":"This module allows message filtering by their text body (if enabled, see Common backend options ). This means that an XMPP client, while requesting messages from the archive may not only specify standard form fields ( with , start , end ), but also full-text-search (of type text-single ). If this happens, the client will receive only messages that contain words specified in the request. The exact behaviour, like whether word ordering matters, may depend on the storage backend in use. For now rdbms backend has very limited support for this feature, while cassandra does not support it at all. riak and elasticsearch backends, on the other hand, should provide you with the best results when it comes to text filtering. mod_mam_rdbms_arch returns all messages that contain all search words, order of words does not matter. Messages are sorted by timestamp (not by relevance).","title":"Full Text Search"},{"location":"modules/mod_mam/#note-on-full-text-search-with-elasticsearch-backend","text":"When using ElasticSearch MAM backend, the value provided in full-text-search form field will be passed to ElasticSearch as Simple Search Query . If you're using our official ElasticSearch mappings from priv/elasticsearch then the query analyzer is set to english . Also note that the default separator for the search query is AND (which roughly means that ElasticSearch will search for messages containing all the terms provided in the query string).","title":"Note on full text search with ElasticSearch backend"},{"location":"modules/mod_mam/#options","text":"","title":"Options"},{"location":"modules/mod_mam/#modulesmod_mam_metabackend","text":"Syntax: string, one of \"rdbms\" , \"riak\" , \"cassandra\" and \"elasticsearch\" Default: \"rdbms\" Example: backend = \"riak\" Database backend to use.","title":"modules.mod_mam_meta.backend"},{"location":"modules/mod_mam/#modulesmod_mam_metano_stanzaid_element","text":"Syntax: boolean Default: false Example: no_stanzaid_element = true Do not add a <stanza-id/> element from MAM v0.6.","title":"modules.mod_mam_meta.no_stanzaid_element"},{"location":"modules/mod_mam/#modulesmod_mam_metais_archivable_message","text":"Syntax: non-empty string Default: \"mod_mam_utils\" Example: is_archivable_message = \"mod_mam_utils\" Name of a module implementing is_archivable_message/3 callback that determines if the message should be archived.","title":"modules.mod_mam_meta.is_archivable_message"},{"location":"modules/mod_mam/#modulesmod_mam_metasend_message","text":"Syntax: non-empty string Default: \"mod_mam_utils\" Example: send_message = \"mod_mam_utils\" Name of a module implementing send_message/4 callback that routes a message during lookup operation. Consult with mod_mam_utils:send_message/4 code for more information. Check big_tests/tests/mam_send_message_SUITE_data/mam_send_message_example.erl file in the MongooseIM repository for the usage example.","title":"modules.mod_mam_meta.send_message"},{"location":"modules/mod_mam/#modulesmod_mam_metaarchive_chat_markers","text":"Syntax: boolean Default: false Example: archive_chat_markers = true If set to true, XEP-0333 chat markers will be archived. See more details here .","title":"modules.mod_mam_meta.archive_chat_markers"},{"location":"modules/mod_mam/#modulesmod_mam_metamessage_retraction","text":"Syntax: boolean Default: true Example: message_retraction = false Enables XEP-0424: Message Retraction . This functionality is currently implemented only for the rdbms backend. Retraction messages are always archived regardless of this option. backend , no_stanzaid_element , is_archivable_message and message_retraction will be applied to both pm and muc (if they are enabled), unless overridden explicitly (see example below).","title":"modules.mod_mam_meta.message_retraction"},{"location":"modules/mod_mam/#enable-one-to-one-message-archive","text":"Archive for one-to-one messages can be enabled in one of two ways: Specify [mod_mam_meta.pm] section 1 2 [modules.mod_mam_meta] [ modules . mod_mam_meta . pm ] # defining this section enables PM support Define any PM related option 1 2 [modules.mod_mam_meta] pm . backend = \"rdbms\" # enables PM support and overrides its backend","title":"Enable one-to-one message archive"},{"location":"modules/mod_mam/#disable-one-to-one-message-archive","text":"To disable archive for one-to-one messages please remove PM section or any PM related option from the config file.","title":"Disable one-to-one message archive"},{"location":"modules/mod_mam/#pm-specific-options","text":"","title":"PM-specific options"},{"location":"modules/mod_mam/#modulesmod_mam_metapmarchive_groupchats","text":"Syntax: boolean Default: false Example: modules.mod_mam_meta.pm.archive_groupchats = true When enabled, MAM will store groupchat messages in recipients' individual archives. USE WITH CAUTION! May increase archive size significantly. Disabling this option for existing installation will neither remove such messages from MAM storage, nor will filter out them from search results.","title":"modules.mod_mam_meta.pm.archive_groupchats"},{"location":"modules/mod_mam/#enable-muc-message-archive","text":"Archive for MUC messages can be enabled in one of two ways: Specify [mod_mam_meta.muc] section 1 2 [modules.mod_mam_meta] [ modules . mod_mam_meta . muc ] # defining this section enables MUC support Define any MUC related option 1 2 [modules.mod_mam_meta] muc . backend = \"rdbms\" # enables MUC support and overrides its backend","title":"Enable MUC message archive"},{"location":"modules/mod_mam/#disable-muc-message-archive","text":"To disable archive for MUC messages please remove MUC section or any MUC related option from the config file.","title":"Disable MUC message archive"},{"location":"modules/mod_mam/#muc-specific-options","text":"","title":"MUC-specific options"},{"location":"modules/mod_mam/#modulesmod_mam_metamuchost","text":"Syntax: string Default: \"conference.@HOST@\" Example: modules.mod_mam_meta.muc.host = \"conference.@HOST@\" Warning : if you are using MUC Light, make sure this option is set to the MUC Light domain The MUC host that will be archived if MUC archiving is enabled.","title":"modules.mod_mam_meta.muc.host"},{"location":"modules/mod_mam/#example","text":"The example below presents how to override common option for muc module specifically. Please note that you can override all common options in similar way. 1 2 3 4 [modules.mod_mam_meta] backend = \"rdbms\" async_writer = true # this option enables async writer for RDBMS backend muc . async_writer = false # disable async writer for MUC archive only","title":"Example"},{"location":"modules/mod_mam/#rdbms-backend-options","text":"These options will only have effect when the rdbms backend is used:","title":"RDBMS backend options"},{"location":"modules/mod_mam/#modulesmod_mam_metacache_users","text":"Syntax: boolean Default: true Example: modules.mod_mam_meta.cache_users = false Enables Archive ID to integer mappings cache.","title":"modules.mod_mam_meta.cache_users"},{"location":"modules/mod_mam/#modulesmod_mam_metardbms_message_format","text":"Syntax: string, one of \"internal\" and \"simple\" Default: \"internal\" Example: modules.mod_mam_meta.rdbms_message_format = \"simple\" Warning : archive MUST be empty to change this option When set to simple , stores messages in XML and full JIDs. When set to internal , stores messages and JIDs in internal format.","title":"modules.mod_mam_meta.rdbms_message_format"},{"location":"modules/mod_mam/#modulesmod_mam_metaasync_writer","text":"Syntax: boolean Default: true Example: modules.mod_mam_meta.async_writer = false Enables an asynchronous writer that is faster than the synchronous one but harder to debug. The async writers store batches of messages with a certain delay (see flush_interval ), so the results of the lookup operations executed right after message routing may be incomplete until the configured time passes.","title":"modules.mod_mam_meta.async_writer"},{"location":"modules/mod_mam/#modulesmod_mam_metaflush_interval","text":"Syntax: non-negative integer Default: 2000 Example: modules.mod_mam_meta.flush_interval = 2000 How often (in milliseconds) the buffered messages are flushed to a DB.","title":"modules.mod_mam_meta.flush_interval"},{"location":"modules/mod_mam/#modulesmod_mam_metamax_batch_size","text":"Syntax: non-negative integer Default: 30 Example: modules.mod_mam_meta.max_batch_size = 30 Max size of the batch insert query for an async writer. If the buffer is full, messages are flushed to a database immediately and the flush timer is reset.","title":"modules.mod_mam_meta.max_batch_size"},{"location":"modules/mod_mam/#common-backend-options","text":"","title":"Common backend options"},{"location":"modules/mod_mam/#modulesmod_mam_metauser_prefs_store","text":"Syntax: one of \"rdbms\" , \"cassandra\" , \"mnesia\" Default: not set Example: modules.mod_mam_meta.user_prefs_store = \"rdbms\" Leaving this option unset will prevent users from setting their archiving preferences. It will also increase performance. The possible values are: \"rdbms\" (RDBMS backend only) - User archiving preferences saved in RDBMS. Slow and not recommended, but might be used for simplicity (keeping everything in RDBMS). \"cassandra\" (Cassandra backend only) - User archiving preferences are saved in Cassandra. \"mnesia\" (recommended) - User archiving preferences saved in Mnesia and accessed without transactions. Recommended in most deployments, could be overloaded with lots of users updating their preferences at once. There's a small risk of an inconsistent (in a rather harmless way) state of the preferences table.","title":"modules.mod_mam_meta.user_prefs_store"},{"location":"modules/mod_mam/#modulesmod_mam_metafull_text_search","text":"Syntax: boolean Default: true Example: modules.mod_mam_meta.full_text_search = false Enables full text search in message archive (see Full Text Search paragraph). Please note that the full text search is currently only implemented for \"rdbms\" and \"riak\" backends. Also, full text search works only for messages archived while this option is enabled.","title":"modules.mod_mam_meta.full_text_search"},{"location":"modules/mod_mam/#is_archivable_message3-callback","text":"is_archivable_message option has to name a module exporting is_archivable_message/3 function conforming to the spec: 1 2 - spec is_archivable_message ( Mod :: module (), Dir :: incoming | outgoing , Packet :: exml : element ()) -> boolean (). Servers SHOULD NOT archive messages that do not have a <body/> child tag. Servers SHOULD NOT archive delayed messages. By default, all messages that hold meaningful content, rather than state changes such as Chat State Notifications, are archived.","title":"is_archivable_message/3 callback"},{"location":"modules/mod_mam/#archiving-chat-markers","text":"Archiving chat markers can be enabled by setting archive_chat_markers option to true . However it only works if is_archivable_message callback module is set to mod_mam_utils or isn't set at all. When performing full text search chat markers are treated as if they had empty message body.","title":"Archiving chat markers"},{"location":"modules/mod_mam/#riak-backend","text":"The Riak KV backend for MAM stores messages in weekly buckets so it's easier to remove old buckets. Archive querying is done using Riak KV 2.0 search mechanism called Yokozuna. Your instance of Riak KV must be configured with Yokozuna enabled. This backend works with Riak KV 2.0 and above, but we recommend version 2.1.1.","title":"Riak backend"},{"location":"modules/mod_mam/#riak-specific-options","text":"","title":"Riak-specific options"},{"location":"modules/mod_mam/#modulesmod_mam_metariakbucket_type","text":"Syntax: non-empty string Default: \"mam_yz\" Example: modules.mod_mam_meta.riak.bucket_type = \"mam_yz\" Riak bucket type.","title":"modules.mod_mam_meta.riak.bucket_type"},{"location":"modules/mod_mam/#modulesmod_mam_metariaksearch_index","text":"Syntax: non-empty string Default: \"mam\" Example: modules.mod_mam_meta.riak.search_index = \"mam\" Riak index name.","title":"modules.mod_mam_meta.riak.search_index"},{"location":"modules/mod_mam/#cassandra-backend","text":"Please consult Outgoing connections page to learn how to properly configure Cassandra connection pool. By default, mod_mam Cassandra backend requires global pool with default tag.","title":"Cassandra backend"},{"location":"modules/mod_mam/#elasticsearch-backend","text":"First, make sure that your ElasticSearch cluster has expected indexes and mappings in place. Please consult Outgoing connections page to learn how to properly configure ElasticSearch connection pool.","title":"ElasticSearch backend"},{"location":"modules/mod_mam/#example-configuration","text":"1 2 3 4 5 6 7 8 9 10 [modules.mod_mam_meta] backend = \"rdbms\" no_stanzaid_element = true pm . user_prefs_store = \"rdbms\" muc . host = \"muc.example.com\" muc . rdbms_message_format = \"simple\" muc . async_writer = false muc . user_prefs_store = \"mnesia\"","title":"Example configuration"},{"location":"modules/mod_mam/#metrics","text":"If you'd like to learn more about metrics in MongooseIM, please visit MongooseIM metrics page. Name Type Description (when it gets incremented) [Host, modMamArchiveRemoved] spiral User's entire archive is removed. [Host, modMamArchived] spiral A message is stored in user's archive. [Host, modMamDropped] spiral A message couldn't be enqueued due to an overloaded async worker. [Host, modMamDropped2] spiral A message couldn't be stored in the DB (and got dropped). [Host, modMamDroppedIQ] spiral MAM IQ has been dropped due to: high query frequency/invalid syntax or type. [Host, modMamFlushed] spiral Message was stored in a DB asynchronously. [Host, modMamForwarded] spiral A message is sent to a client as a part of a MAM query result. [Host, modMamLookups] spiral A MAM lookup is performed. [Host, modMamPrefsGets] spiral Archiving preferences have been requested by a client. [Host, modMamPrefsSets] spiral Archiving preferences have been updated by a client. [Host, modMucMamArchiveRemoved] spiral Room's entire archive is removed. [Host, modMucMamArchived] spiral A message is stored in room's archive. [Host, modMucMamForwarded] spiral A message is sent to a client as a part of a MAM query result from MUC room. [Host, modMucMamLookups] spiral A MAM lookup in MUC room is performed. [Host, modMucMamPrefsGets] spiral MUC archiving preferences have been requested by a client. [Host, modMucMamPrefsSets] spiral MUC archiving preferences have been updated by a client. [Host, mod_mam_rdbms_async_pool_writer, per_message_flush_time] histogram Average time per message insert measured in an async MAM worker. [Host, mod_mam_rdbms_async_pool_writer, flush_time] histogram Average time per flush of all buffered messages measured in an async MAM worker. [Host, mod_mam_muc_rdbms_async_pool_writer, per_message_flush_time] histogram Average time per message insert measured in an async MUC MAM worker. [Host, mod_mam_muc_rdbms_async_pool_writer, flush_time] histogram Average time per flush of all buffered messages measured in an async MUC MAM worker. Backend action Description (when it gets incremented) lookup A lookup in an archive. archive One message is saved in an archive.","title":"Metrics"},{"location":"modules/mod_muc/","text":"Module Description This module implements XEP-0045: Multi-User Chat (MUC). It's a common XMPP group chat solution. This extension consists of two Erlang modules: mod_muc and mod_muc_room , the latter being the room code itself. Note that only mod_muc needs to be enabled in the configuration file. Also mod_muc_log is a logging submodule. Options modules.mod_muc.host Syntax: string, a valid subdomain Default: \"conference.@HOST@\" Example: host = \"group.@HOST@\" Subdomain for MUC service to reside under. @HOST@ is replaced with each served domain. modules.mod_muc.backend Syntax: string, one of \"mnesia\" or \"rdbms\" Default: \"mnesia\" Example: backend = \"rdbms\" Storage backend. modules.mod_muc.access Syntax: non-empty string Default: \"all\" Example: access = \"muc\" Access Rule to determine who is allowed to use the MUC service. modules.mod_muc.access_create Syntax: non-empty string Default: \"all\" Example: access_create = \"muc_create\" Access Rule to determine who is allowed to create rooms. modules.mod_muc.access_admin Syntax: non-empty string Default: \"none\" Example: access_admin = \"muc_create\" Access Rule to determine who is the administrator in all rooms. modules.mod_muc.access_persistent Syntax: non-empty string Default: \"all\" Example: access_persistent = \"none\" Access Rule to determine who is allowed to make the rooms persistent. In order to change this parameter, the user must not only match the Access Rule but also be the owner of the room. modules.mod_muc.history_size Syntax: non-negative integer Default: 20 Example: history_size = 30 Room message history to be kept in RAM. After node restart, the history is lost. modules.mod_muc.room_shaper Syntax: non-empty string Default: \"none\" Example: room_shaper = \"muc_room_shaper\" Limits per-room data throughput with traffic shaper. modules.mod_muc.max_room_id Syntax: non-negative integer or the string \"infinity\" Default: \"infinity\" Example: max_room_id = 30 Maximum room username length (in JID). modules.mod_muc.max_room_name Syntax: non-negative integer or the string \"infinity\" Default: \"infinity\" Example: max_room_name = 30 Maximum room name length. modules.mod_muc.max_room_desc Syntax: non-negative integer or the string \"infinity\" Default: \"infinity\" Example: max_room_desc = 140 Maximum room description length. modules.mod_muc.min_message_interval Syntax: non-negative integer Default: 0 Example: min_message_interval = 1 Minimal interval (in seconds) between messages processed by the room. modules.mod_muc.min_presence_interval Syntax: non-negative integer Default: 0 Example: min_presence_interval = 1 Minimal interval (in seconds) between presences processed by the room. modules.mod_muc.max_users Syntax: positive integer Default: 200 Example: max_users = 100 Absolute maximum user count per room on the node. modules.mod_muc.max_users_admin_threshold Syntax: positive integer Default: 5 Example: max_users_admin_threshold = 10 When the server checks if a new user can join a room and they are an admin, max_users_admin_threshold is added to max_users during occupant limit check. modules.mod_muc.user_message_shaper Syntax: non-empty string Default: \"none\" Example: user_message_shaper = \"muc_user_msg_shaper\" Shaper for user messages processed by a room (global for the room). modules.mod_muc.user_presence_shaper Syntax: non-empty string Default: \"none\" Example: user_presence_shaper = \"muc_user_presence_shaper\" Shaper for user presences processed by a room (global for the room). modules.mod_muc.max_user_conferences Syntax: non-negative integer Default: 10 Example: max_user_conferences = 5 Specifies the number of rooms that a user can occupy simultaneously. modules.mod_muc.http_auth_pool Syntax: non-empty string Default: \"none\" Example: http_auth_pool = \"external_auth\" If an external HTTP service is chosen to check passwords for password-protected rooms, this option specifies the HTTP pool name to use (see External HTTP Authentication below). modules.mod_muc.load_permanent_rooms_at_startup Syntax: boolean Default: false Example: load_permanent_rooms_at_startup = true Load all rooms at startup. Because it can be unsafe when there are many rooms, it is disabled by default. modules.mod_muc.hibernate_timeout Syntax: non-negative integer or the string \"infinity\" Default: 90000 (milliseconds, 90 seconds) Example: hibernate_timeout = 60000 Timeout (in milliseconds) defining the inactivity period after which the room's process should be hibernated. modules.mod_muc.hibernated_room_check_interval Syntax: non-negative integer or the string \"infinity\" Default: \"infinity\" Example: hibernated_room_check_interval = 120000 Interval defining how often the hibernated rooms will be checked (a timer is global for a node). modules.mod_muc.hibernated_room_timeout Syntax: non-negative integer or the string \"infinity\" Default: \"infinity\" Example: hibernated_room_timeout = 120000 A time after which a hibernated room is stopped (deeply hibernated). See MUC performance optimisation . modules.mod_muc.default_room Syntax: A TOML table of options described below Default: Default room options Example: 1 2 3 4 5 6 7 8 9 [modules.mod_muc.default_room] password_protected = true description = \"An example description.\" [[modules.mod_muc.default_room.affiliations]] user = \"alice\" server = \"localhost\" resource = \"resource1\" affiliation = \"member\" or: 1 2 3 4 5 6 7 8 default_room . password_protected = true default_room . description = \"An example description.\" [[modules.mod_muc.default_room.affiliations]] user = \"alice\" server = \"localhost\" resource = \"resource1\" affiliation = \"member\" Available room configuration options to be overridden in the initial state: modules.mod_muc.default_room.title Syntax: string Default: \"\" Example: title = \"example_title\" Room title, short free text. modules.mod_muc.default_room.description Syntax: string Default: \"\" Example: description = \"An example description.\" Room description, long free text. modules.mod_muc.default_room.allow_change_subj Syntax: boolean Default: true Example: allow_change_subj = false Allow all occupants to change the room subject. modules.mod_muc.default_room.allow_query_users Syntax: boolean Default: true Example: allow_query_users = false Allow occupants to send IQ queries to other occupants. modules.mod_muc.default_room.allow_private_messages Syntax: boolean Default: true Example: allow_private_messages = false Allow private messaging between occupants. modules.mod_muc.default_room.allow_visitor_status Syntax: boolean Default: true Example: allow_visitor_status = false Allow occupants to use text statuses in presences. When disabled, text is removed by the room before broadcasting. modules.mod_muc.default_room.allow_visitor_nickchange Syntax: boolean Default: true Example: allow_visitor_nickchange = false Allow occupants to change nicknames. modules.mod_muc.default_room.public Syntax: boolean Default: true Example: public = false Room is included in the list available via Service Discovery. modules.mod_muc.default_room.public_list Syntax: boolean Default: true Example: public_list = false Member list can be fetched by non-members. modules.mod_muc.default_room.persistent Syntax: boolean Default: false Example: persistent = true Room will be stored in DB and survive even when the last occupant leaves or the node is restarted. modules.mod_muc.default_room.moderated Syntax: boolean Default: true Example: moderated = false Only occupants with a \"voice\" can send group chat messages. modules.mod_muc.default_room.members_by_default Syntax: boolean Default: true Example: members_by_default = false All new occupants are members by default, unless they have a different affiliation assigned. modules.mod_muc.default_room.members_only Syntax: boolean Default: false Example: members_only = true Only users with a member affiliation can join the room. modules.mod_muc.default_room.allow_user_invites Syntax: boolean Default: false Example: allow_user_invites = true Allow ordinary members to send mediated invitations. modules.mod_muc.default_room.allow_multiple_sessions Syntax: boolean Default: false Example: allow_multiple_sessions = true Allow multiple user session to use the same nick. modules.mod_muc.default_room.password_protected Syntax: boolean Default: false Example: password_protected = true Room is protected with a password. modules.mod_muc.default_room.password Syntax: string Default: \"\" Example: password = \"secret\" Room password is required upon joining. This option has no effect when password_protected is false . modules.mod_muc.default_room.anonymous Syntax: boolean Default: true Example: anonymous = false Room is anonymous, meaning occupants can't see each others real JIDs, except for the room moderators. modules.mod_muc.default_room.max_users Syntax: positive integer Default: 200 Example: max_users = 100 Maximum user count per room. Admins and the room owner are not affected. modules.mod_muc.default_room.logging Syntax: boolean Default: false Example: logging = true Enables logging of room events (messages, presences) to a file on the disk. Uses mod_muc_log . modules.mod_muc.default_room.maygetmemberlist Syntax: array of non-empty strings Default: [] Example: maygetmemberlist = [\"moderator\"] An array of roles and/or privileges that enable retrieving the room's member list. modules.mod_muc.default_room.affiliations Syntax: array of tables with keys: user - non-empty string, server - string, a valid domain, resource - string, affiliation - non-empty string Default: [] Example: 1 2 3 4 5 6 7 8 9 10 11 [[modules.mod_muc.default_room.affiliations]] user = \"alice\" server = \"localhost\" resource = \"resource1\" affiliation = \"member\" [[modules.mod_muc.default_room.affiliations]] user = \"bob\" server = \"localhost\" resource = \"resource2\" affiliation = \"owner\" This is the default list of affiliations set for every new room. modules.mod_muc.default_room.subject Syntax: string Default: \"\" Example: subject = \"Lambda days\" A default subject for new room. modules.mod_muc.default_room.subject_author Syntax: string Default: \"\" Example: subject_author = \"Alice\" A nick name of the default subject's author. Example Configuration 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 [modules.mod_muc] host = \"muc.example.com\" access = \"muc\" access_create = \"muc_create\" http_auth_pool = \"my_auth_pool\" default_room . password_protected = true [[modules.mod_muc.default_room.affiliations]] user = \"alice\" server = \"localhost\" resource = \"resource1\" affiliation = \"member\" [[modules.mod_muc.default_room.affiliations]] user = \"bob\" server = \"localhost\" resource = \"resource2\" affiliation = \"owner\" Performance optimisations Each room is represented by an Erlang process with its own state and can consume memory even if it's not used. In large installations with many rooms, this might cause performance issues. To address that problem MongooseIM has 2 levels of MUC rooms memory optimisations. Room's process hibernation By default the room's process is hibernated by the Erlang VM 90 seconds after the last activity. This timeout can be modified by hibernate_timeout option. Room deep hibernation MongooseIM introduces an additional option of deep hibernation for unused rooms. This optimisation works only for persistent rooms as only these can be restored on demand. The improvement works as follows: 1. All room processes are traversed at a chosen hibernated_room_check_interval . 1. If a hibernated_room_timeout is exceeded, a \"stop\" signal is sent to a unused room. 1. The room's process is stopped only if there are no online users or if the only one is its owner. If the owner is online, a presence of a type unavailable is sent to it indicating that the room's process is being terminated. The room's process can be recreated on demand, for example when a presence sent to it, or the owner wants to add more users to the room. External HTTP Authentication MUC rooms can be protected by a password that is set by the room owner. Note that MongooseIM supports another custom solution, where each attempt to enter or create a room requires the password to be checked by an external HTTP service. To enable this option, you need to: Configure an HTTP connection pool . Set the name of the connection pool as the value of the http_auth_pool option of mod_muc . Enable the password_protected default room option (without setting the password itself). Whenever a user tries to enter or create a room, the server will receive a GET request to the check_password path. It should return a 200 response with a JSON object {\"code\": Code, \"msg\": Message} in the response body. If the server returns something else, an error presence will be sent back to the client. Code is the status code: 0 indicates a successful authentication, any other value means the authentication failed. Message is a string containing the message to be sent back to the XMPP client indicating the reason for a failed authentication. When authentication succeeds it is ignored and can contain anything ( eg. the string \"OK\" ). Example: 1 2 3 4 5 6 7 8 9 10 [outgoing_pools.http.my_auth_pool] strategy = \"available_worker\" connection . host = \"http://my_server:8000\" [modules.mod_muc] host = \"muc.example.com\" access = \"muc\" access_create = \"muc_create\" http_auth_pool = \"my_auth_pool\" default_room . password_protected = true Metrics If you'd like to learn more about metrics in MongooseIM, please visit MongooseIM metrics page. Name Type Description (when it gets incremented) [global, mod_muc, deep_hibernations] spiral A room process is stopped (applies only to persistent rooms). [global, mod_muc, process_recreations] spiral A room process is recreated from a persisted state. [global, mod_muc, hibernations] spiral A room process becomes hibernated (garbage collected and put in wait state). [global, mod_muc, hibernated_rooms] value How many rooms are in hibernated state. Does not include rooms in \"deep hibernation\". [global, mod_muc, online_rooms] value How many rooms have running processes (includes rooms in a hibernated state).","title":"mod_muc"},{"location":"modules/mod_muc/#module-description","text":"This module implements XEP-0045: Multi-User Chat (MUC). It's a common XMPP group chat solution. This extension consists of two Erlang modules: mod_muc and mod_muc_room , the latter being the room code itself. Note that only mod_muc needs to be enabled in the configuration file. Also mod_muc_log is a logging submodule.","title":"Module Description"},{"location":"modules/mod_muc/#options","text":"","title":"Options"},{"location":"modules/mod_muc/#modulesmod_muchost","text":"Syntax: string, a valid subdomain Default: \"conference.@HOST@\" Example: host = \"group.@HOST@\" Subdomain for MUC service to reside under. @HOST@ is replaced with each served domain.","title":"modules.mod_muc.host"},{"location":"modules/mod_muc/#modulesmod_mucbackend","text":"Syntax: string, one of \"mnesia\" or \"rdbms\" Default: \"mnesia\" Example: backend = \"rdbms\" Storage backend.","title":"modules.mod_muc.backend"},{"location":"modules/mod_muc/#modulesmod_mucaccess","text":"Syntax: non-empty string Default: \"all\" Example: access = \"muc\" Access Rule to determine who is allowed to use the MUC service.","title":"modules.mod_muc.access"},{"location":"modules/mod_muc/#modulesmod_mucaccess_create","text":"Syntax: non-empty string Default: \"all\" Example: access_create = \"muc_create\" Access Rule to determine who is allowed to create rooms.","title":"modules.mod_muc.access_create"},{"location":"modules/mod_muc/#modulesmod_mucaccess_admin","text":"Syntax: non-empty string Default: \"none\" Example: access_admin = \"muc_create\" Access Rule to determine who is the administrator in all rooms.","title":"modules.mod_muc.access_admin"},{"location":"modules/mod_muc/#modulesmod_mucaccess_persistent","text":"Syntax: non-empty string Default: \"all\" Example: access_persistent = \"none\" Access Rule to determine who is allowed to make the rooms persistent. In order to change this parameter, the user must not only match the Access Rule but also be the owner of the room.","title":"modules.mod_muc.access_persistent"},{"location":"modules/mod_muc/#modulesmod_muchistory_size","text":"Syntax: non-negative integer Default: 20 Example: history_size = 30 Room message history to be kept in RAM. After node restart, the history is lost.","title":"modules.mod_muc.history_size"},{"location":"modules/mod_muc/#modulesmod_mucroom_shaper","text":"Syntax: non-empty string Default: \"none\" Example: room_shaper = \"muc_room_shaper\" Limits per-room data throughput with traffic shaper.","title":"modules.mod_muc.room_shaper"},{"location":"modules/mod_muc/#modulesmod_mucmax_room_id","text":"Syntax: non-negative integer or the string \"infinity\" Default: \"infinity\" Example: max_room_id = 30 Maximum room username length (in JID).","title":"modules.mod_muc.max_room_id"},{"location":"modules/mod_muc/#modulesmod_mucmax_room_name","text":"Syntax: non-negative integer or the string \"infinity\" Default: \"infinity\" Example: max_room_name = 30 Maximum room name length.","title":"modules.mod_muc.max_room_name"},{"location":"modules/mod_muc/#modulesmod_mucmax_room_desc","text":"Syntax: non-negative integer or the string \"infinity\" Default: \"infinity\" Example: max_room_desc = 140 Maximum room description length.","title":"modules.mod_muc.max_room_desc"},{"location":"modules/mod_muc/#modulesmod_mucmin_message_interval","text":"Syntax: non-negative integer Default: 0 Example: min_message_interval = 1 Minimal interval (in seconds) between messages processed by the room.","title":"modules.mod_muc.min_message_interval"},{"location":"modules/mod_muc/#modulesmod_mucmin_presence_interval","text":"Syntax: non-negative integer Default: 0 Example: min_presence_interval = 1 Minimal interval (in seconds) between presences processed by the room.","title":"modules.mod_muc.min_presence_interval"},{"location":"modules/mod_muc/#modulesmod_mucmax_users","text":"Syntax: positive integer Default: 200 Example: max_users = 100 Absolute maximum user count per room on the node.","title":"modules.mod_muc.max_users"},{"location":"modules/mod_muc/#modulesmod_mucmax_users_admin_threshold","text":"Syntax: positive integer Default: 5 Example: max_users_admin_threshold = 10 When the server checks if a new user can join a room and they are an admin, max_users_admin_threshold is added to max_users during occupant limit check.","title":"modules.mod_muc.max_users_admin_threshold"},{"location":"modules/mod_muc/#modulesmod_mucuser_message_shaper","text":"Syntax: non-empty string Default: \"none\" Example: user_message_shaper = \"muc_user_msg_shaper\" Shaper for user messages processed by a room (global for the room).","title":"modules.mod_muc.user_message_shaper"},{"location":"modules/mod_muc/#modulesmod_mucuser_presence_shaper","text":"Syntax: non-empty string Default: \"none\" Example: user_presence_shaper = \"muc_user_presence_shaper\" Shaper for user presences processed by a room (global for the room).","title":"modules.mod_muc.user_presence_shaper"},{"location":"modules/mod_muc/#modulesmod_mucmax_user_conferences","text":"Syntax: non-negative integer Default: 10 Example: max_user_conferences = 5 Specifies the number of rooms that a user can occupy simultaneously.","title":"modules.mod_muc.max_user_conferences"},{"location":"modules/mod_muc/#modulesmod_muchttp_auth_pool","text":"Syntax: non-empty string Default: \"none\" Example: http_auth_pool = \"external_auth\" If an external HTTP service is chosen to check passwords for password-protected rooms, this option specifies the HTTP pool name to use (see External HTTP Authentication below).","title":"modules.mod_muc.http_auth_pool"},{"location":"modules/mod_muc/#modulesmod_mucload_permanent_rooms_at_startup","text":"Syntax: boolean Default: false Example: load_permanent_rooms_at_startup = true Load all rooms at startup. Because it can be unsafe when there are many rooms, it is disabled by default.","title":"modules.mod_muc.load_permanent_rooms_at_startup"},{"location":"modules/mod_muc/#modulesmod_muchibernate_timeout","text":"Syntax: non-negative integer or the string \"infinity\" Default: 90000 (milliseconds, 90 seconds) Example: hibernate_timeout = 60000 Timeout (in milliseconds) defining the inactivity period after which the room's process should be hibernated.","title":"modules.mod_muc.hibernate_timeout"},{"location":"modules/mod_muc/#modulesmod_muchibernated_room_check_interval","text":"Syntax: non-negative integer or the string \"infinity\" Default: \"infinity\" Example: hibernated_room_check_interval = 120000 Interval defining how often the hibernated rooms will be checked (a timer is global for a node).","title":"modules.mod_muc.hibernated_room_check_interval"},{"location":"modules/mod_muc/#modulesmod_muchibernated_room_timeout","text":"Syntax: non-negative integer or the string \"infinity\" Default: \"infinity\" Example: hibernated_room_timeout = 120000 A time after which a hibernated room is stopped (deeply hibernated). See MUC performance optimisation .","title":"modules.mod_muc.hibernated_room_timeout"},{"location":"modules/mod_muc/#modulesmod_mucdefault_room","text":"Syntax: A TOML table of options described below Default: Default room options Example: 1 2 3 4 5 6 7 8 9 [modules.mod_muc.default_room] password_protected = true description = \"An example description.\" [[modules.mod_muc.default_room.affiliations]] user = \"alice\" server = \"localhost\" resource = \"resource1\" affiliation = \"member\" or: 1 2 3 4 5 6 7 8 default_room . password_protected = true default_room . description = \"An example description.\" [[modules.mod_muc.default_room.affiliations]] user = \"alice\" server = \"localhost\" resource = \"resource1\" affiliation = \"member\" Available room configuration options to be overridden in the initial state: modules.mod_muc.default_room.title Syntax: string Default: \"\" Example: title = \"example_title\" Room title, short free text. modules.mod_muc.default_room.description Syntax: string Default: \"\" Example: description = \"An example description.\" Room description, long free text. modules.mod_muc.default_room.allow_change_subj Syntax: boolean Default: true Example: allow_change_subj = false Allow all occupants to change the room subject. modules.mod_muc.default_room.allow_query_users Syntax: boolean Default: true Example: allow_query_users = false Allow occupants to send IQ queries to other occupants. modules.mod_muc.default_room.allow_private_messages Syntax: boolean Default: true Example: allow_private_messages = false Allow private messaging between occupants. modules.mod_muc.default_room.allow_visitor_status Syntax: boolean Default: true Example: allow_visitor_status = false Allow occupants to use text statuses in presences. When disabled, text is removed by the room before broadcasting. modules.mod_muc.default_room.allow_visitor_nickchange Syntax: boolean Default: true Example: allow_visitor_nickchange = false Allow occupants to change nicknames. modules.mod_muc.default_room.public Syntax: boolean Default: true Example: public = false Room is included in the list available via Service Discovery. modules.mod_muc.default_room.public_list Syntax: boolean Default: true Example: public_list = false Member list can be fetched by non-members. modules.mod_muc.default_room.persistent Syntax: boolean Default: false Example: persistent = true Room will be stored in DB and survive even when the last occupant leaves or the node is restarted. modules.mod_muc.default_room.moderated Syntax: boolean Default: true Example: moderated = false Only occupants with a \"voice\" can send group chat messages. modules.mod_muc.default_room.members_by_default Syntax: boolean Default: true Example: members_by_default = false All new occupants are members by default, unless they have a different affiliation assigned. modules.mod_muc.default_room.members_only Syntax: boolean Default: false Example: members_only = true Only users with a member affiliation can join the room. modules.mod_muc.default_room.allow_user_invites Syntax: boolean Default: false Example: allow_user_invites = true Allow ordinary members to send mediated invitations. modules.mod_muc.default_room.allow_multiple_sessions Syntax: boolean Default: false Example: allow_multiple_sessions = true Allow multiple user session to use the same nick. modules.mod_muc.default_room.password_protected Syntax: boolean Default: false Example: password_protected = true Room is protected with a password. modules.mod_muc.default_room.password Syntax: string Default: \"\" Example: password = \"secret\" Room password is required upon joining. This option has no effect when password_protected is false . modules.mod_muc.default_room.anonymous Syntax: boolean Default: true Example: anonymous = false Room is anonymous, meaning occupants can't see each others real JIDs, except for the room moderators. modules.mod_muc.default_room.max_users Syntax: positive integer Default: 200 Example: max_users = 100 Maximum user count per room. Admins and the room owner are not affected. modules.mod_muc.default_room.logging Syntax: boolean Default: false Example: logging = true Enables logging of room events (messages, presences) to a file on the disk. Uses mod_muc_log . modules.mod_muc.default_room.maygetmemberlist Syntax: array of non-empty strings Default: [] Example: maygetmemberlist = [\"moderator\"] An array of roles and/or privileges that enable retrieving the room's member list. modules.mod_muc.default_room.affiliations Syntax: array of tables with keys: user - non-empty string, server - string, a valid domain, resource - string, affiliation - non-empty string Default: [] Example: 1 2 3 4 5 6 7 8 9 10 11 [[modules.mod_muc.default_room.affiliations]] user = \"alice\" server = \"localhost\" resource = \"resource1\" affiliation = \"member\" [[modules.mod_muc.default_room.affiliations]] user = \"bob\" server = \"localhost\" resource = \"resource2\" affiliation = \"owner\" This is the default list of affiliations set for every new room. modules.mod_muc.default_room.subject Syntax: string Default: \"\" Example: subject = \"Lambda days\" A default subject for new room. modules.mod_muc.default_room.subject_author Syntax: string Default: \"\" Example: subject_author = \"Alice\" A nick name of the default subject's author.","title":"modules.mod_muc.default_room"},{"location":"modules/mod_muc/#example-configuration","text":"1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 [modules.mod_muc] host = \"muc.example.com\" access = \"muc\" access_create = \"muc_create\" http_auth_pool = \"my_auth_pool\" default_room . password_protected = true [[modules.mod_muc.default_room.affiliations]] user = \"alice\" server = \"localhost\" resource = \"resource1\" affiliation = \"member\" [[modules.mod_muc.default_room.affiliations]] user = \"bob\" server = \"localhost\" resource = \"resource2\" affiliation = \"owner\"","title":"Example Configuration"},{"location":"modules/mod_muc/#performance-optimisations","text":"Each room is represented by an Erlang process with its own state and can consume memory even if it's not used. In large installations with many rooms, this might cause performance issues. To address that problem MongooseIM has 2 levels of MUC rooms memory optimisations.","title":"Performance optimisations"},{"location":"modules/mod_muc/#rooms-process-hibernation","text":"By default the room's process is hibernated by the Erlang VM 90 seconds after the last activity. This timeout can be modified by hibernate_timeout option.","title":"Room's process hibernation"},{"location":"modules/mod_muc/#room-deep-hibernation","text":"MongooseIM introduces an additional option of deep hibernation for unused rooms. This optimisation works only for persistent rooms as only these can be restored on demand. The improvement works as follows: 1. All room processes are traversed at a chosen hibernated_room_check_interval . 1. If a hibernated_room_timeout is exceeded, a \"stop\" signal is sent to a unused room. 1. The room's process is stopped only if there are no online users or if the only one is its owner. If the owner is online, a presence of a type unavailable is sent to it indicating that the room's process is being terminated. The room's process can be recreated on demand, for example when a presence sent to it, or the owner wants to add more users to the room.","title":"Room deep hibernation"},{"location":"modules/mod_muc/#external-http-authentication","text":"MUC rooms can be protected by a password that is set by the room owner. Note that MongooseIM supports another custom solution, where each attempt to enter or create a room requires the password to be checked by an external HTTP service. To enable this option, you need to: Configure an HTTP connection pool . Set the name of the connection pool as the value of the http_auth_pool option of mod_muc . Enable the password_protected default room option (without setting the password itself). Whenever a user tries to enter or create a room, the server will receive a GET request to the check_password path. It should return a 200 response with a JSON object {\"code\": Code, \"msg\": Message} in the response body. If the server returns something else, an error presence will be sent back to the client. Code is the status code: 0 indicates a successful authentication, any other value means the authentication failed. Message is a string containing the message to be sent back to the XMPP client indicating the reason for a failed authentication. When authentication succeeds it is ignored and can contain anything ( eg. the string \"OK\" ). Example: 1 2 3 4 5 6 7 8 9 10 [outgoing_pools.http.my_auth_pool] strategy = \"available_worker\" connection . host = \"http://my_server:8000\" [modules.mod_muc] host = \"muc.example.com\" access = \"muc\" access_create = \"muc_create\" http_auth_pool = \"my_auth_pool\" default_room . password_protected = true","title":"External HTTP Authentication"},{"location":"modules/mod_muc/#metrics","text":"If you'd like to learn more about metrics in MongooseIM, please visit MongooseIM metrics page. Name Type Description (when it gets incremented) [global, mod_muc, deep_hibernations] spiral A room process is stopped (applies only to persistent rooms). [global, mod_muc, process_recreations] spiral A room process is recreated from a persisted state. [global, mod_muc, hibernations] spiral A room process becomes hibernated (garbage collected and put in wait state). [global, mod_muc, hibernated_rooms] value How many rooms are in hibernated state. Does not include rooms in \"deep hibernation\". [global, mod_muc, online_rooms] value How many rooms have running processes (includes rooms in a hibernated state).","title":"Metrics"},{"location":"modules/mod_muc_commands/","text":"MongooseIM's multi-user chat commands set Purpose This is a set of commands, providing actions related to multi-user chat features. Configuration This module contains command definitions which are loaded when the module is activated. There are no options to be provided, therefore the following entry in the config file is sufficient: 1 [modules.mod_muc_commands] Commands This file consists of commands definitions . Following commands (along with functions necessary for them to run) are defined: create_muc_room Creates a MUC room. Arguments: host (binary) name (binary) - room name owner (binary) - the XMPP entity that would normally request an instant MUC room nick (binary) kick_user_from_room Kicks a user from a MUC room (on behalf of a moderator). Arguments: host (binary) name (binary) nick (binary) invite_to_muc_room Sends a MUC room invite (direct) from one user to another. Arguments: host (binary) name (binary) sender (binary) recipient (binary) reason (binary) send_message_to_room Sends a message to a MUC room from a given room. Arguments: host (binary) name (binary) from (binary) body (binary) Running commands Commands must be registered and then run using the module mongoose_commands .","title":"mod_muc_commands"},{"location":"modules/mod_muc_commands/#mongooseims-multi-user-chat-commands-set","text":"","title":"MongooseIM's multi-user chat commands set"},{"location":"modules/mod_muc_commands/#purpose","text":"This is a set of commands, providing actions related to multi-user chat features.","title":"Purpose"},{"location":"modules/mod_muc_commands/#configuration","text":"This module contains command definitions which are loaded when the module is activated. There are no options to be provided, therefore the following entry in the config file is sufficient: 1 [modules.mod_muc_commands]","title":"Configuration"},{"location":"modules/mod_muc_commands/#commands","text":"This file consists of commands definitions . Following commands (along with functions necessary for them to run) are defined:","title":"Commands"},{"location":"modules/mod_muc_commands/#create_muc_room","text":"Creates a MUC room. Arguments: host (binary) name (binary) - room name owner (binary) - the XMPP entity that would normally request an instant MUC room nick (binary)","title":"create_muc_room"},{"location":"modules/mod_muc_commands/#kick_user_from_room","text":"Kicks a user from a MUC room (on behalf of a moderator). Arguments: host (binary) name (binary) nick (binary)","title":"kick_user_from_room"},{"location":"modules/mod_muc_commands/#invite_to_muc_room","text":"Sends a MUC room invite (direct) from one user to another. Arguments: host (binary) name (binary) sender (binary) recipient (binary) reason (binary)","title":"invite_to_muc_room"},{"location":"modules/mod_muc_commands/#send_message_to_room","text":"Sends a message to a MUC room from a given room. Arguments: host (binary) name (binary) from (binary) body (binary)","title":"send_message_to_room"},{"location":"modules/mod_muc_commands/#running-commands","text":"Commands must be registered and then run using the module mongoose_commands .","title":"Running commands"},{"location":"modules/mod_muc_light/","text":"Module Description This module implements Multi-User Chat Light . It's an experimental XMPP group chat solution. This extension consists of several modules but only mod_muc_light needs to be enabled in the config file. Options modules.mod_muc_light.host Syntax: string, a valid subdomain Default: \"muclight.@HOST@\" Example: host = \"group.@HOST@\" Domain for the MUC Light service to reside under. @HOST@ is replaced with each served domain. modules.mod_muc_light.backend Syntax: string, one of \"mnesia\" , \"rdbms\" Default: \"mnesia\" Example: backend = \"rdbms\" Database backend to use. modules.mod_muc_light.equal_occupants Syntax: boolean Default: false Example: equal_occupants = true When enabled, MUC Light rooms won't have owners. It means that every occupant will be a member , even the room creator. Warning: This option does not implicitly set all_can_invite to true . If that option is set to false , nobody will be able to join the room after the initial creation request. modules.mod_muc_light.legacy_mode Syntax: boolean Default: false Example: legacy_mode = true Enables XEP-0045 compatibility mode. It allows using a subset of classic MUC stanzas with some MUC Light functions limited. modules.mod_muc_light.rooms_per_user Syntax: positive integer or the string \"infinity\" Default: \"infinity\" Example: rooms_per_user = 100 Specifies a cap on a number of rooms a user can occupy. Warning: Setting such a limit may trigger expensive DB queries for every occupant addition. modules.mod_muc_light.blocking Syntax: boolean Default: true Example: blocking = false Blocking feature enabled/disabled. modules.mod_muc_light.all_can_configure Syntax: boolean Default: false Example: all_can_configure = true When enabled, all room occupants can change all configuration options. If disabled, everyone can still change the room subject. modules.mod_muc_light.all_can_invite Syntax: boolean Default: false Example: all_can_invite = true When enabled, all room occupants can add new occupants to the room. Occupants added by members become members as well. modules.mod_muc_light.max_occupants Syntax: positive integer or the string \"infinity\" Default: \"infinity\" Example: max_occupants = 100 Specifies a cap on the occupant count per room. modules.mod_muc_light.rooms_per_page Syntax: positive integer or the string \"infinity\" Default: 10 Example: rooms_per_page = 100 Specifies maximal number of rooms returned for a single Disco request. modules.mod_muc_light.rooms_in_rosters Syntax: boolean Default: false Example: rooms_in_rosters = true When enabled, rooms the user occupies are included in their roster. modules.mod_muc_light.config_schema Syntax: an array of config_schema items, as described below Default: 1 2 3 4 5 6 7 [[modules.mod_muc_light.config_schema]] field = \"roomname\" string_value = \"Untitled\" [[modules.mod_muc_light.config_schema]] field = \"subject\" string_value = \"\" Example: 1 2 3 4 [[modules.mod_muc_light.config_schema]] field = \"display-lines\" integer_value = 30 internal_key = \"display_lines\" Defines fields allowed in the room configuration. Each config_schema item is a TOML table with the following keys: field - mandatory, non-empty string - field name. string_value , integer_value , float_value - exactly one of them has to be present, depending on the type of the field: string_value - string, integer_value - integer, float_value - floating-point number. internal_key - optional, non-empty string - field name used in the internal representation, useful only for debugging or custom applications. By default it is the same as field . WARNING! Lack of the roomname field will cause room names in Disco results and Roster items be set to the room username. Example Configuration 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 [modules.mod_muc_light] host = \"muclight.example.com\" equal_occupants = true legacy_mode = true rooms_per_user = 10 blocking = false all_can_configure = true all_can_invite = true max_occupants = 50 rooms_per_page = 5 rooms_in_rosters = true [[ modules . mod_muc_light . config_schema ]] field = \"roomname\" string_value = \"The Room\" [[ modules . mod_muc_light . config_schema ]] field = \"display-lines\" integer_value = 30 internal_key = \"display_lines\" Metrics If you'd like to learn more about metrics in MongooseIM, please visit MongooseIM metrics page. Backend action Description (when it gets incremented) create_room A new room is stored in a DB. destroy_room Room data is removed from a DB. room_exists A room existence is checked. get_user_rooms A list of rooms the user is a participant of is retrieved from a DB. remove_user All MUC Light related user data is removed from a DB. get_config A room config is retrieved from a DB. set_config A room config is updated in a DB. get_blocking Blocking data is fetched from a DB. set_blocking Blocking data is updated in a DB. get_aff_users An affiliated users list is fetched from a DB. modify_aff_users Affiliations in a room are updated in a DB.","title":"mod_muc_light"},{"location":"modules/mod_muc_light/#module-description","text":"This module implements Multi-User Chat Light . It's an experimental XMPP group chat solution. This extension consists of several modules but only mod_muc_light needs to be enabled in the config file.","title":"Module Description"},{"location":"modules/mod_muc_light/#options","text":"","title":"Options"},{"location":"modules/mod_muc_light/#modulesmod_muc_lighthost","text":"Syntax: string, a valid subdomain Default: \"muclight.@HOST@\" Example: host = \"group.@HOST@\" Domain for the MUC Light service to reside under. @HOST@ is replaced with each served domain.","title":"modules.mod_muc_light.host"},{"location":"modules/mod_muc_light/#modulesmod_muc_lightbackend","text":"Syntax: string, one of \"mnesia\" , \"rdbms\" Default: \"mnesia\" Example: backend = \"rdbms\" Database backend to use.","title":"modules.mod_muc_light.backend"},{"location":"modules/mod_muc_light/#modulesmod_muc_lightequal_occupants","text":"Syntax: boolean Default: false Example: equal_occupants = true When enabled, MUC Light rooms won't have owners. It means that every occupant will be a member , even the room creator. Warning: This option does not implicitly set all_can_invite to true . If that option is set to false , nobody will be able to join the room after the initial creation request.","title":"modules.mod_muc_light.equal_occupants"},{"location":"modules/mod_muc_light/#modulesmod_muc_lightlegacy_mode","text":"Syntax: boolean Default: false Example: legacy_mode = true Enables XEP-0045 compatibility mode. It allows using a subset of classic MUC stanzas with some MUC Light functions limited.","title":"modules.mod_muc_light.legacy_mode"},{"location":"modules/mod_muc_light/#modulesmod_muc_lightrooms_per_user","text":"Syntax: positive integer or the string \"infinity\" Default: \"infinity\" Example: rooms_per_user = 100 Specifies a cap on a number of rooms a user can occupy. Warning: Setting such a limit may trigger expensive DB queries for every occupant addition.","title":"modules.mod_muc_light.rooms_per_user"},{"location":"modules/mod_muc_light/#modulesmod_muc_lightblocking","text":"Syntax: boolean Default: true Example: blocking = false Blocking feature enabled/disabled.","title":"modules.mod_muc_light.blocking"},{"location":"modules/mod_muc_light/#modulesmod_muc_lightall_can_configure","text":"Syntax: boolean Default: false Example: all_can_configure = true When enabled, all room occupants can change all configuration options. If disabled, everyone can still change the room subject.","title":"modules.mod_muc_light.all_can_configure"},{"location":"modules/mod_muc_light/#modulesmod_muc_lightall_can_invite","text":"Syntax: boolean Default: false Example: all_can_invite = true When enabled, all room occupants can add new occupants to the room. Occupants added by members become members as well.","title":"modules.mod_muc_light.all_can_invite"},{"location":"modules/mod_muc_light/#modulesmod_muc_lightmax_occupants","text":"Syntax: positive integer or the string \"infinity\" Default: \"infinity\" Example: max_occupants = 100 Specifies a cap on the occupant count per room.","title":"modules.mod_muc_light.max_occupants"},{"location":"modules/mod_muc_light/#modulesmod_muc_lightrooms_per_page","text":"Syntax: positive integer or the string \"infinity\" Default: 10 Example: rooms_per_page = 100 Specifies maximal number of rooms returned for a single Disco request.","title":"modules.mod_muc_light.rooms_per_page"},{"location":"modules/mod_muc_light/#modulesmod_muc_lightrooms_in_rosters","text":"Syntax: boolean Default: false Example: rooms_in_rosters = true When enabled, rooms the user occupies are included in their roster.","title":"modules.mod_muc_light.rooms_in_rosters"},{"location":"modules/mod_muc_light/#modulesmod_muc_lightconfig_schema","text":"Syntax: an array of config_schema items, as described below Default: 1 2 3 4 5 6 7 [[modules.mod_muc_light.config_schema]] field = \"roomname\" string_value = \"Untitled\" [[modules.mod_muc_light.config_schema]] field = \"subject\" string_value = \"\" Example: 1 2 3 4 [[modules.mod_muc_light.config_schema]] field = \"display-lines\" integer_value = 30 internal_key = \"display_lines\" Defines fields allowed in the room configuration. Each config_schema item is a TOML table with the following keys: field - mandatory, non-empty string - field name. string_value , integer_value , float_value - exactly one of them has to be present, depending on the type of the field: string_value - string, integer_value - integer, float_value - floating-point number. internal_key - optional, non-empty string - field name used in the internal representation, useful only for debugging or custom applications. By default it is the same as field . WARNING! Lack of the roomname field will cause room names in Disco results and Roster items be set to the room username.","title":"modules.mod_muc_light.config_schema"},{"location":"modules/mod_muc_light/#example-configuration","text":"1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 [modules.mod_muc_light] host = \"muclight.example.com\" equal_occupants = true legacy_mode = true rooms_per_user = 10 blocking = false all_can_configure = true all_can_invite = true max_occupants = 50 rooms_per_page = 5 rooms_in_rosters = true [[ modules . mod_muc_light . config_schema ]] field = \"roomname\" string_value = \"The Room\" [[ modules . mod_muc_light . config_schema ]] field = \"display-lines\" integer_value = 30 internal_key = \"display_lines\"","title":"Example Configuration"},{"location":"modules/mod_muc_light/#metrics","text":"If you'd like to learn more about metrics in MongooseIM, please visit MongooseIM metrics page. Backend action Description (when it gets incremented) create_room A new room is stored in a DB. destroy_room Room data is removed from a DB. room_exists A room existence is checked. get_user_rooms A list of rooms the user is a participant of is retrieved from a DB. remove_user All MUC Light related user data is removed from a DB. get_config A room config is retrieved from a DB. set_config A room config is updated in a DB. get_blocking Blocking data is fetched from a DB. set_blocking Blocking data is updated in a DB. get_aff_users An affiliated users list is fetched from a DB. modify_aff_users Affiliations in a room are updated in a DB.","title":"Metrics"},{"location":"modules/mod_muc_light_commands/","text":"MongooseIM's multi-user chat light commands set Purpose This is a set of commands, providing actions related to multi-user chat light features. These commands are used by REST API modules. Configuration This module contains command definitions which are loaded when the module is activated. There are no options to be provided, therefore the following entry in the config file is sufficient: 1 [modules.mod_muc_light_commands] Commands This file consists of commands definitions . Following commands (along with functions necessary for them to run) are defined: create_muc_light_room Create a MUC Light room with unique username part in JID. Arguments: domain (binary) name (binary) owner (binary) subject (binary) create_identifiable_muc_light_room Creates a MUC Light room with user-provided username part in JID. Arguments: domain (binary) id (binary) name (binary) owner (binary) subject (binary) invite_to_room Invites to a MUC Light room. Arguments: domain (binary) name (binary) sender (binary) recipient (binary) send_message_to_muc_light_room Sends a message to a MUC Light room. Arguments: domain (binary) name (binary) from (binary) body (binary) Running commands Commands must be registered and then run using the module mongoose_commands .","title":"mod_muc_light_commands"},{"location":"modules/mod_muc_light_commands/#mongooseims-multi-user-chat-light-commands-set","text":"","title":"MongooseIM's multi-user chat light commands set"},{"location":"modules/mod_muc_light_commands/#purpose","text":"This is a set of commands, providing actions related to multi-user chat light features. These commands are used by REST API modules.","title":"Purpose"},{"location":"modules/mod_muc_light_commands/#configuration","text":"This module contains command definitions which are loaded when the module is activated. There are no options to be provided, therefore the following entry in the config file is sufficient: 1 [modules.mod_muc_light_commands]","title":"Configuration"},{"location":"modules/mod_muc_light_commands/#commands","text":"This file consists of commands definitions . Following commands (along with functions necessary for them to run) are defined:","title":"Commands"},{"location":"modules/mod_muc_light_commands/#create_muc_light_room","text":"Create a MUC Light room with unique username part in JID. Arguments: domain (binary) name (binary) owner (binary) subject (binary)","title":"create_muc_light_room"},{"location":"modules/mod_muc_light_commands/#create_identifiable_muc_light_room","text":"Creates a MUC Light room with user-provided username part in JID. Arguments: domain (binary) id (binary) name (binary) owner (binary) subject (binary)","title":"create_identifiable_muc_light_room"},{"location":"modules/mod_muc_light_commands/#invite_to_room","text":"Invites to a MUC Light room. Arguments: domain (binary) name (binary) sender (binary) recipient (binary)","title":"invite_to_room"},{"location":"modules/mod_muc_light_commands/#send_message_to_muc_light_room","text":"Sends a message to a MUC Light room. Arguments: domain (binary) name (binary) from (binary) body (binary)","title":"send_message_to_muc_light_room"},{"location":"modules/mod_muc_light_commands/#running-commands","text":"Commands must be registered and then run using the module mongoose_commands .","title":"Running commands"},{"location":"modules/mod_muc_log/","text":"Module Description A logging submodule for mod_muc . Is must be explicitly configured to work. It writes room-related information (configuration) and events (messages, presences) to files on the disk. Options modules.mod_muc_log.outdir Syntax: string Default: \"www/muc\" Example: outdir = \"www/muc\" Filesystem directory where the files are stored. modules.mod_muc_log.access_log Syntax: non-empty string Default: \"muc_admin\" Example: access_log = \"muc_admin\" ACL that defines who can enable/disable logging for specific rooms. modules.mod_muc_log.dirtype Syntax: string, one of \"subdirs\" , \"plain\" Default: \"subdirs\" Example: dirtype = \"subdirs\" Specifies the log directory structure: \"subdirs\" : Module will use the following directory structure [Logs root]/[dirname]/YYYY/MM/ with file names being DD.[extension] . \"plain\" : Module will use the following directory structure [Logs root]/[dirname]/ with file names being YYYY-MM-DD.[extension] . modules.mod_muc_log.dirname Syntax: string, one of \"room_jid\" , \"room_name\" Default: \"room_jid\" Example: dirname = \"room_jid\" Specifies directory name created for each room: \"room_jid\" : Uses the room bare JID. \"room_name\" : Uses the room name from its configuration. modules.mod_muc_log.file_format Syntax: string, one of \"html\" , \"plaintext\" Default: \"html\" Example: file_format = \"html\" Specifies the format of output files: \"html\" : The output is a fancy-formatted HTML page. \"plaintext\" : Just a text file, better suited for processing than HTML. modules.mod_muc_log.css_file Syntax: non-empty string Default: not set - the default styles for HTML logs are used Example: css_file = \"path/to/css/file\" Specifies the css file used for logs rendering. Please note it won't be copied to the logs directory but the given path will be linked in HTML files instead. modules.mod_muc_log.timezone Syntax: string, one of \"local\" , \"universal\" Default: \"local\" Example: timezone = \"universal\" Specifies the timezone to be used in timestamps written into the logs: local : Uses the local server timezone. universal : Uses GMT. modules.mod_muc_log.top_link Syntax: TOML table with the following mandatory keys: \"target\" , \"text\" and string values. Default: {target = \"/\", text = \"Home\"} Example: top_link = {target = \"/top\", text = \"Top page\"} Allows setting a custom link at the top of the HTML log file. First tuple element is the link target and the second one is the text to be displayed. You can put any HTML instead of just plain text. modules.mod_muc_log.spam_prevention Syntax: boolean Default: true Example: spam_prevention = false When enabled, MongooseIM will enforce rel=\"nofollow\" attribute in links sent by user and written to MUC logs. Example Configuration 1 2 3 4 5 6 7 8 9 10 [modules.mod_muc_log] outdir = \"/tmp/muclogs\" access_log = \"muc\" dirtype = \"plain\" dirname = \"room_name\" file_format = \"html\" css_file = \"path/to/css/file\" timezone = \"universal\" top_link . target = \"/\" top_link . text = \"Home\"","title":"mod_muc_log"},{"location":"modules/mod_muc_log/#module-description","text":"A logging submodule for mod_muc . Is must be explicitly configured to work. It writes room-related information (configuration) and events (messages, presences) to files on the disk.","title":"Module Description"},{"location":"modules/mod_muc_log/#options","text":"","title":"Options"},{"location":"modules/mod_muc_log/#modulesmod_muc_logoutdir","text":"Syntax: string Default: \"www/muc\" Example: outdir = \"www/muc\" Filesystem directory where the files are stored.","title":"modules.mod_muc_log.outdir"},{"location":"modules/mod_muc_log/#modulesmod_muc_logaccess_log","text":"Syntax: non-empty string Default: \"muc_admin\" Example: access_log = \"muc_admin\" ACL that defines who can enable/disable logging for specific rooms.","title":"modules.mod_muc_log.access_log"},{"location":"modules/mod_muc_log/#modulesmod_muc_logdirtype","text":"Syntax: string, one of \"subdirs\" , \"plain\" Default: \"subdirs\" Example: dirtype = \"subdirs\" Specifies the log directory structure: \"subdirs\" : Module will use the following directory structure [Logs root]/[dirname]/YYYY/MM/ with file names being DD.[extension] . \"plain\" : Module will use the following directory structure [Logs root]/[dirname]/ with file names being YYYY-MM-DD.[extension] .","title":"modules.mod_muc_log.dirtype"},{"location":"modules/mod_muc_log/#modulesmod_muc_logdirname","text":"Syntax: string, one of \"room_jid\" , \"room_name\" Default: \"room_jid\" Example: dirname = \"room_jid\" Specifies directory name created for each room: \"room_jid\" : Uses the room bare JID. \"room_name\" : Uses the room name from its configuration.","title":"modules.mod_muc_log.dirname"},{"location":"modules/mod_muc_log/#modulesmod_muc_logfile_format","text":"Syntax: string, one of \"html\" , \"plaintext\" Default: \"html\" Example: file_format = \"html\" Specifies the format of output files: \"html\" : The output is a fancy-formatted HTML page. \"plaintext\" : Just a text file, better suited for processing than HTML.","title":"modules.mod_muc_log.file_format"},{"location":"modules/mod_muc_log/#modulesmod_muc_logcss_file","text":"Syntax: non-empty string Default: not set - the default styles for HTML logs are used Example: css_file = \"path/to/css/file\" Specifies the css file used for logs rendering. Please note it won't be copied to the logs directory but the given path will be linked in HTML files instead.","title":"modules.mod_muc_log.css_file"},{"location":"modules/mod_muc_log/#modulesmod_muc_logtimezone","text":"Syntax: string, one of \"local\" , \"universal\" Default: \"local\" Example: timezone = \"universal\" Specifies the timezone to be used in timestamps written into the logs: local : Uses the local server timezone. universal : Uses GMT.","title":"modules.mod_muc_log.timezone"},{"location":"modules/mod_muc_log/#modulesmod_muc_logtop_link","text":"Syntax: TOML table with the following mandatory keys: \"target\" , \"text\" and string values. Default: {target = \"/\", text = \"Home\"} Example: top_link = {target = \"/top\", text = \"Top page\"} Allows setting a custom link at the top of the HTML log file. First tuple element is the link target and the second one is the text to be displayed. You can put any HTML instead of just plain text.","title":"modules.mod_muc_log.top_link"},{"location":"modules/mod_muc_log/#modulesmod_muc_logspam_prevention","text":"Syntax: boolean Default: true Example: spam_prevention = false When enabled, MongooseIM will enforce rel=\"nofollow\" attribute in links sent by user and written to MUC logs.","title":"modules.mod_muc_log.spam_prevention"},{"location":"modules/mod_muc_log/#example-configuration","text":"1 2 3 4 5 6 7 8 9 10 [modules.mod_muc_log] outdir = \"/tmp/muclogs\" access_log = \"muc\" dirtype = \"plain\" dirname = \"room_name\" file_format = \"html\" css_file = \"path/to/css/file\" timezone = \"universal\" top_link . target = \"/\" top_link . text = \"Home\"","title":"Example Configuration"},{"location":"modules/mod_offline/","text":"Module Description This module implements an offline messages storage compliant with XEP-0160: Best Practices for Handling Offline Messages . It can store one-to-one and groupchat messages only when the recipient has no online resources. It is not well suited for applications supporting multiple user devices, because anything saved in the DB can be retrieved only once, so the message history is not synchronised between devices. Although mod_offline may be sufficient in some cases, it is preferable to use mod_mam . Options modules.mod_offline.access_max_user_messages Syntax: non-empty string Default: \"max_user_offline_messages\" Example: access_max_user_messages = \"custom_max_user_offline_messages\" Access Rule to use for limiting the storage size per user. modules.mod_offline.backend Syntax: string, one of mnesia , rdbms , riak Default: \"mnesia\" Example: backend = \"rdbms\" Storage backend. modules.mod_offline.store_groupchat_messages Syntax: boolean Default: false Example: store_groupchat_messages = true Specifies whether or not we should store groupchat messages. Warning: This option can work only with MUC-light and is not expected to work with MUC. Riak-specific options modules.mod_offline.riak.bucket_type Syntax: non-empty string Default: \"offline\" Example: bucket_type = \"offline_bucket_type\" Riak bucket type. Example Configuration 1 2 3 4 [modules.mod_offline] access_max_user_messages = \"max_user_offline_messages\" backend = \"riak\" riak . bucket_type = \"offline\" Metrics If you'd like to learn more about metrics in MongooseIM, please visit MongooseIM metrics page. Backend action Type Description (when it gets incremented) pop_messages histogram Offline messages for a user are retrieved and deleted from a DB. write_messages histogram New offline messages to a user are written in a DB.","title":"mod_offline"},{"location":"modules/mod_offline/#module-description","text":"This module implements an offline messages storage compliant with XEP-0160: Best Practices for Handling Offline Messages . It can store one-to-one and groupchat messages only when the recipient has no online resources. It is not well suited for applications supporting multiple user devices, because anything saved in the DB can be retrieved only once, so the message history is not synchronised between devices. Although mod_offline may be sufficient in some cases, it is preferable to use mod_mam .","title":"Module Description"},{"location":"modules/mod_offline/#options","text":"","title":"Options"},{"location":"modules/mod_offline/#modulesmod_offlineaccess_max_user_messages","text":"Syntax: non-empty string Default: \"max_user_offline_messages\" Example: access_max_user_messages = \"custom_max_user_offline_messages\" Access Rule to use for limiting the storage size per user.","title":"modules.mod_offline.access_max_user_messages"},{"location":"modules/mod_offline/#modulesmod_offlinebackend","text":"Syntax: string, one of mnesia , rdbms , riak Default: \"mnesia\" Example: backend = \"rdbms\" Storage backend.","title":"modules.mod_offline.backend"},{"location":"modules/mod_offline/#modulesmod_offlinestore_groupchat_messages","text":"Syntax: boolean Default: false Example: store_groupchat_messages = true Specifies whether or not we should store groupchat messages. Warning: This option can work only with MUC-light and is not expected to work with MUC.","title":"modules.mod_offline.store_groupchat_messages"},{"location":"modules/mod_offline/#riak-specific-options","text":"","title":"Riak-specific options"},{"location":"modules/mod_offline/#modulesmod_offlineriakbucket_type","text":"Syntax: non-empty string Default: \"offline\" Example: bucket_type = \"offline_bucket_type\" Riak bucket type.","title":"modules.mod_offline.riak.bucket_type"},{"location":"modules/mod_offline/#example-configuration","text":"1 2 3 4 [modules.mod_offline] access_max_user_messages = \"max_user_offline_messages\" backend = \"riak\" riak . bucket_type = \"offline\"","title":"Example Configuration"},{"location":"modules/mod_offline/#metrics","text":"If you'd like to learn more about metrics in MongooseIM, please visit MongooseIM metrics page. Backend action Type Description (when it gets incremented) pop_messages histogram Offline messages for a user are retrieved and deleted from a DB. write_messages histogram New offline messages to a user are written in a DB.","title":"Metrics"},{"location":"modules/mod_offline_stub/","text":"Module Description RFC 6121 requires a <service-unavailable/> stanza error to be sent to a user messaging an unavailable recipient if the message is not stored for delayed delivery (i.e. as an \"offline message\"). If the recipient exists (i.e. auth module returns true from does_user_exist ), mod_mam stores the message, but is still returned. This is not compliant with the RFC. This module prevents returning . Please note that mod_offline_stub is not tightly coupled with mod_mam . It can be used as a standalone extension, if the specific application requires it. Options None. Example Configuration 1 [modules.mod_offline_stub]","title":"mod_offline_stub"},{"location":"modules/mod_offline_stub/#module-description","text":"RFC 6121 requires a <service-unavailable/> stanza error to be sent to a user messaging an unavailable recipient if the message is not stored for delayed delivery (i.e. as an \"offline message\"). If the recipient exists (i.e. auth module returns true from does_user_exist ), mod_mam stores the message, but is still returned. This is not compliant with the RFC. This module prevents returning . Please note that mod_offline_stub is not tightly coupled with mod_mam . It can be used as a standalone extension, if the specific application requires it.","title":"Module Description"},{"location":"modules/mod_offline_stub/#options","text":"None.","title":"Options"},{"location":"modules/mod_offline_stub/#example-configuration","text":"1 [modules.mod_offline_stub]","title":"Example Configuration"},{"location":"modules/mod_ping/","text":"Module Description This module implements XMPP Ping functionality as described in XEP-0199: XMPP Ping . Options modules.mod_ping.send_pings Syntax: boolean Default: false Example: send_pings = true If set to true, the server will send ping iqs to the client if they are not active for a ping_interval . modules.mod_ping.ping_interval Syntax: positive integer (seconds) Default: 60 Example: ping_interval = 30 Defines the client inactivity timeout after which the server will send a ping request if the above option is set to true . modules.mod_ping.timeout_action Syntax: string, one of \"none\" , \"kill\" Default: \"none\" Example: timeout_action = \"kill\" Defines if the client connection should be closed if it doesn't reply to a ping request in less than ping_req_timeout . modules.mod_ping.ping_req_timeout Syntax: positive integer (seconds) Default: 32 Example: ping_req_timeout = 60 Defines how long the server waits for the client to reply to the ping request. modules.mod_ping.iqdisc.type Syntax: string, one of \"one_queue\" , \"no_queue\" , \"queues\" , \"parallel\" Default: \"no_queue\" Strategy to handle incoming stanzas. For details, please refer to IQ processing policies . Example Configuration 1 2 3 4 5 [modules.mod_ping] send_pings = true ping_interval = 60 timeout_action = \"none\" ping_req_timeout = 32 Metrics If you'd like to learn more about metrics in MongooseIM, please visit MongooseIM metrics page. Name Type Description (when it gets incremented) [Host, mod_ping, ping_response] spiral Client responds to a ping. [Host, mod_ping, ping_response_timeout] spiral Ping request timeouts without a response from client. [Host, mod_ping, ping_response_time] histogram Response times (doesn't include timeouts).","title":"mod_ping"},{"location":"modules/mod_ping/#module-description","text":"This module implements XMPP Ping functionality as described in XEP-0199: XMPP Ping .","title":"Module Description"},{"location":"modules/mod_ping/#options","text":"","title":"Options"},{"location":"modules/mod_ping/#modulesmod_pingsend_pings","text":"Syntax: boolean Default: false Example: send_pings = true If set to true, the server will send ping iqs to the client if they are not active for a ping_interval .","title":"modules.mod_ping.send_pings"},{"location":"modules/mod_ping/#modulesmod_pingping_interval","text":"Syntax: positive integer (seconds) Default: 60 Example: ping_interval = 30 Defines the client inactivity timeout after which the server will send a ping request if the above option is set to true .","title":"modules.mod_ping.ping_interval"},{"location":"modules/mod_ping/#modulesmod_pingtimeout_action","text":"Syntax: string, one of \"none\" , \"kill\" Default: \"none\" Example: timeout_action = \"kill\" Defines if the client connection should be closed if it doesn't reply to a ping request in less than ping_req_timeout .","title":"modules.mod_ping.timeout_action"},{"location":"modules/mod_ping/#modulesmod_pingping_req_timeout","text":"Syntax: positive integer (seconds) Default: 32 Example: ping_req_timeout = 60 Defines how long the server waits for the client to reply to the ping request.","title":"modules.mod_ping.ping_req_timeout"},{"location":"modules/mod_ping/#modulesmod_pingiqdisctype","text":"Syntax: string, one of \"one_queue\" , \"no_queue\" , \"queues\" , \"parallel\" Default: \"no_queue\" Strategy to handle incoming stanzas. For details, please refer to IQ processing policies .","title":"modules.mod_ping.iqdisc.type"},{"location":"modules/mod_ping/#example-configuration","text":"1 2 3 4 5 [modules.mod_ping] send_pings = true ping_interval = 60 timeout_action = \"none\" ping_req_timeout = 32","title":"Example Configuration"},{"location":"modules/mod_ping/#metrics","text":"If you'd like to learn more about metrics in MongooseIM, please visit MongooseIM metrics page. Name Type Description (when it gets incremented) [Host, mod_ping, ping_response] spiral Client responds to a ping. [Host, mod_ping, ping_response_timeout] spiral Ping request timeouts without a response from client. [Host, mod_ping, ping_response_time] histogram Response times (doesn't include timeouts).","title":"Metrics"},{"location":"modules/mod_privacy/","text":"Module Description This module implements XEP-0016: Privacy Lists . This extension allows user to block IQs, messages, presences, or all, based on JIDs, subscription, and roster groups. Options modules.mod_privacy.backend Syntax: string, one of \"mnesia\" , \"rdbms\" , \"riak\" . Default: \"mnesia\" Example: backend = \"mnesia\" Riak-specific options modules.mod_privacy.riak.defaults_bucket_type Syntax: string. Default: \"privacy_defaults\" Example: riak.defaults_bucket_type = \"privacy_defaults\" Riak bucket type for information about default list name. modules.mod_privacy.riak.names_bucket_type Syntax: string. Default: \"privacy_lists_names\" Example: riak.names_bucket_type = \"privacy_lists_names\" Riak bucket type for information about privacy list names. modules.mod_privacy.riak.bucket_type Syntax: string. Default: \"privacy_lists\" Example: riak.bucket_type = \"privacy_lists\" Riak bucket type for privacy lists. Example Configuration 1 2 3 [modules.mod_privacy] backend = \"riak\" riak . defaults_bucket_type = \"privacy_defaults\" Metrics If you'd like to learn more about metrics in MongooseIM, please visit MongooseIM metrics page. Backend action Description (when it gets incremented) get_privacy_list A privacy list is retrieved from a DB. get_list_names Names of user's privacy lists are fetched from a DB. get_default_list A default privacy list for a user is fetched from a DB. set_default_list A default list's name for a user is set in a DB. forget_default_list A default list's name for a user is removed from a DB. remove_privacy_list A privacy list is deleted from a DB. replace_privacy_list A privacy list is updated (replaced) in a DB.","title":"mod_privacy"},{"location":"modules/mod_privacy/#module-description","text":"This module implements XEP-0016: Privacy Lists . This extension allows user to block IQs, messages, presences, or all, based on JIDs, subscription, and roster groups.","title":"Module Description"},{"location":"modules/mod_privacy/#options","text":"","title":"Options"},{"location":"modules/mod_privacy/#modulesmod_privacybackend","text":"Syntax: string, one of \"mnesia\" , \"rdbms\" , \"riak\" . Default: \"mnesia\" Example: backend = \"mnesia\"","title":"modules.mod_privacy.backend"},{"location":"modules/mod_privacy/#riak-specific-options","text":"","title":"Riak-specific options"},{"location":"modules/mod_privacy/#modulesmod_privacyriakdefaults_bucket_type","text":"Syntax: string. Default: \"privacy_defaults\" Example: riak.defaults_bucket_type = \"privacy_defaults\" Riak bucket type for information about default list name.","title":"modules.mod_privacy.riak.defaults_bucket_type"},{"location":"modules/mod_privacy/#modulesmod_privacyriaknames_bucket_type","text":"Syntax: string. Default: \"privacy_lists_names\" Example: riak.names_bucket_type = \"privacy_lists_names\" Riak bucket type for information about privacy list names.","title":"modules.mod_privacy.riak.names_bucket_type"},{"location":"modules/mod_privacy/#modulesmod_privacyriakbucket_type","text":"Syntax: string. Default: \"privacy_lists\" Example: riak.bucket_type = \"privacy_lists\" Riak bucket type for privacy lists.","title":"modules.mod_privacy.riak.bucket_type"},{"location":"modules/mod_privacy/#example-configuration","text":"1 2 3 [modules.mod_privacy] backend = \"riak\" riak . defaults_bucket_type = \"privacy_defaults\"","title":"Example Configuration"},{"location":"modules/mod_privacy/#metrics","text":"If you'd like to learn more about metrics in MongooseIM, please visit MongooseIM metrics page. Backend action Description (when it gets incremented) get_privacy_list A privacy list is retrieved from a DB. get_list_names Names of user's privacy lists are fetched from a DB. get_default_list A default privacy list for a user is fetched from a DB. set_default_list A default list's name for a user is set in a DB. forget_default_list A default list's name for a user is removed from a DB. remove_privacy_list A privacy list is deleted from a DB. replace_privacy_list A privacy list is updated (replaced) in a DB.","title":"Metrics"},{"location":"modules/mod_private/","text":"Module Description This module implements XEP-0049: Private XML Storage . It allows users to store custom XML data in the server's database. Used e.g. for storing roster groups separator. Options modules.mod_private.iqdisc.type Syntax: string, one of \"one_queue\" , \"no_queue\" , \"queues\" , \"parallel\" Default: \"one_queue\" Strategy to handle incoming stanzas. For details, please refer to IQ processing policies . modules.mod_private.backend Syntax: string, one of \"mnesia\" , \"rdbms\" , \"riak\" . Default: \"mnesia\" Example: backend = \"mnesia\" Database backend to use. CAUTION: Riak KV backend doesn't support transactions (rollbacks), so please avoid inserting more than one value in a single set request, otherwise you may end up with partially saved data. Backend returns the first error. Riak-specific options modules.mod_privacy.riak.bucket_type Syntax: string Default: \"private\" Example: bucket_type = \"private\" Riak bucket type. Example Configuration 1 2 [modules.mod_private] backend = \"mnesia\" Metrics If you'd like to learn more about metrics in MongooseIM, please visit MongooseIM metrics page. Backend operation Description (when it gets incremented) multi_get_data XML data is fetched from a DB. multi_set_data XML data is stored in a DB.","title":"mod_private"},{"location":"modules/mod_private/#module-description","text":"This module implements XEP-0049: Private XML Storage . It allows users to store custom XML data in the server's database. Used e.g. for storing roster groups separator.","title":"Module Description"},{"location":"modules/mod_private/#options","text":"","title":"Options"},{"location":"modules/mod_private/#modulesmod_privateiqdisctype","text":"Syntax: string, one of \"one_queue\" , \"no_queue\" , \"queues\" , \"parallel\" Default: \"one_queue\" Strategy to handle incoming stanzas. For details, please refer to IQ processing policies .","title":"modules.mod_private.iqdisc.type"},{"location":"modules/mod_private/#modulesmod_privatebackend","text":"Syntax: string, one of \"mnesia\" , \"rdbms\" , \"riak\" . Default: \"mnesia\" Example: backend = \"mnesia\" Database backend to use. CAUTION: Riak KV backend doesn't support transactions (rollbacks), so please avoid inserting more than one value in a single set request, otherwise you may end up with partially saved data. Backend returns the first error.","title":"modules.mod_private.backend"},{"location":"modules/mod_private/#riak-specific-options","text":"","title":"Riak-specific options"},{"location":"modules/mod_private/#modulesmod_privacyriakbucket_type","text":"Syntax: string Default: \"private\" Example: bucket_type = \"private\" Riak bucket type.","title":"modules.mod_privacy.riak.bucket_type"},{"location":"modules/mod_private/#example-configuration","text":"1 2 [modules.mod_private] backend = \"mnesia\"","title":"Example Configuration"},{"location":"modules/mod_private/#metrics","text":"If you'd like to learn more about metrics in MongooseIM, please visit MongooseIM metrics page. Backend operation Description (when it gets incremented) multi_get_data XML data is fetched from a DB. multi_set_data XML data is stored in a DB.","title":"Metrics"},{"location":"modules/mod_pubsub/","text":"What is PubSub? PubSub is a design pattern which mostly promotes a loose coupling between two kinds of entities - publishers and subscribers. Like their names suggest, in the pubsub world we have publishers who fire events, and subscribers who wish to be notified about those events when publishers push data. There might be several subscribers, several publishers, and even several channels (or nodes) where the events are sent. Module Description This module implements XEP-0060: Publish-Subscribe . Due to the complexity of the protocol, the PubSub engine makes successive calls to the nodetree and node plugins in order to check the validity of requests, perform the corresponding action and return a result or appropriate error. Such an architecture makes it much easier to write custom pubsub plugins and add new storage backends. It's all about tailoring PubSub to your needs! Options modules.mod_pubsub.iqdisc.type Syntax: string, one of \"one_queue\" , \"no_queue\" , \"queues\" , \"parallel\" Default: \"no_queue\" Strategy to handle incoming stanzas. For details, please refer to IQ processing policies . modules.mod_pubsub.host Syntax: string Default: \"pubsub.@HOST@\" Example: host = \"pubsub.localhost\" Subdomain for Pubsub service to reside under. @HOST@ is replaced with each served domain. modules.mod_pubsub.backend Syntax: string, one of \"mnesia\" , \"rdbms\" Default: \"mnesia\" Example: backend = \"rdbms\" Database backend to use. modules.mod_pubsub.access_createnode Syntax: string, rule name, or \"all\" Default: \"all\" Example: access_createnode = \"all\" Specifies who is allowed to create pubsub nodes. The access rule referenced here needs to be defined in the access section. modules.mod_pubsub.max_items_node Syntax: non-negative integer Default: 10 Example: max_items_node = 10 Defines the maximum number of items that can be stored in a node. modules.mod_pubsub.max_subscriptions_node Syntax: non-negative integer Default: not specified (no limit) Example: max_subscriptions_node = 10 The maximum number of subscriptions managed by a node. By default there is no limit. modules.mod_pubsub.nodetree Syntax: string Default: \"tree\" Example: nodetree = \"tree\" Specifies the storage and organisation of the pubsub nodes. See the section below. modules.mod_pubsub.ignore_pep_from_offline Syntax: boolean Default: true Example: ignore_pep_from_offline = false Specifies whether or not we should get last published PEP items from users in our roster which are offline when we connect. The default option is true hence we will get only the last items from the online contacts. modules.mod_pubsub.last_item_cache Syntax: string, one of \"mnesia\" , \"rdbms\" , \"false\" Default: \"false\" Example: last_item_cache = \"mnesia\" If enabled, PubSub will cache the last published items in the nodes. It may increase PubSub performance but at a price of an increased memory usage. modules.mod_pubsub.plugins Syntax: array of strings Default: [\"flat\"] Example: plugins = [\"flat\", \"pep\"] List of enabled pubsub plugins. modules.mod_pubsub.pep_mapping Syntax: Array of TOML tables with the following keys: \"namespace\" , \"node\" and string values. Default: [] Example: pep_mapping = [{namespace = \"urn:xmpp:microblog:0\", node = \"mb\"}] This permits creating a Key-Value list to define a custom node plugin on a given PEP namespace. E.g. pair {\"urn:xmpp:microblog:0\", \"mb\"} will use module node_mb instead of node_pep when the specified namespace is used. modules.mod_pubsub.default_node_config Syntax: TOML table with the following values: string, boolean or non-negative integer. Default: {} Example: default_node_config = {deliver_payloads = true, max_payload_size = 10000, node_type = \"leaf\"} Overrides the default node configuration, regardless of the node plugin. Node configuration still uses the default configuration defined by the node plugin, and overrides any items by the value defined in this configurable list. The possible options, altogether with their default values for each node plugin, are listed in the table below: syntax node_flat / node_hometree node_pep node_dag node_push access_model non-empty string open presence open whitelist deliver_notifications boolean true true true true deliver_payloads boolean true true true true max_items non-negative integer 10 1 10 1 max_payload_size non-negative integer 60000 60000 60000 60000 node_type non-empty string N/A N/A leaf N/A notification_type non-empty string headline headline headline headline notify_config boolean false false false false notify_delete boolean false false false false notify_retract boolean false false false false persist_items boolean true true true false presence_based_delivery boolean false true false true publish_model non-empty string publishers publishers publishers open purge_offline boolean false false false false roster_groups_allowed non-empty string [] [] [] [] send_last_published_item non-empty string never on_sub_and_presence never on_sub_and_presence subscribe boolean true true true true modules.mod_pubsub.item_publisher Syntax: boolean Default: false Example: item_publisher = false When enabled, a JID of the publisher will be saved in the item metadata. This effectively makes them an owner of this item. modules.mod_pubsub.sync_broadcast Syntax: boolean Default: false Example: sync_broadcast = false If false, routing of notifications to subscribers is done in a separate Erlang process. As a consequence, some notifications may arrive to the subscribers in the wrong order (however, the two events would have to be published at the exact same time). Cache Backend Caching is disabled by default. You may enable it by specifying the backend it should use. It is not coupled with the main DB backend, so it is possible to store the cached data in mnesia , while the actual PubSub information is kept in RDBMS (and vice versa!). Example Configuration 1 2 3 4 5 6 7 8 9 10 11 [modules.mod_pubsub] access_createnode = \"pubsub_createnode\" ignore_pep_from_offline = false backend = \"rdbms\" last_item_cache = \"mnesia\" max_items_node = 1000 plugins = [\"flat\", \"pep\"] [[modules.mod_pubsub.pep_mapping]] namespace = \"urn:xmpp:microblog:0\" node = \"mb\" Nodetrees Called on get , create and delete node. Only one nodetree can be used per host and is shared by all node plugins. \"tree\" Stores nodes in a tree structure. Every node name must be formatted like a UNIX path (e.g. /top/middle/leaf ). When a node is created, its direct ancestor must already exist, so in order to create /top/middle/leaf , /top/middle is needed. A user may create any top-level node. A user may create a subnode of a node, only if they own it or it was created by the service. \"dag\" Provides experimental support for XEP-0248: PubSub Collection Nodes . In this case you should also add the \"dag\" node plugin as default, for example: plugins = [\"dag\", \"flat\", \"hometree\", \"pep\"] . Plugins They handle affiliations, subscriptions and items and also provide default node con\ufb01guration and features. PubSub clients can define which plugin to use when creating a node by adding type='plugin-name' attribute to the create stanza element. If such an attribute is not specified, the default plugin will be the first on the plugin list. \"flat\" No node hierarchy. It handles the standard PubSub case. \"hometree\" Uses the exact same features as the flat plugin but additionally organises nodes in a tree. Basically it follows a scheme similar to the filesystem's structure. Every user can create nodes in their own home root: e.g /home/user . Each node can contain items and/or sub-nodes. \"pep\" Implementation of XEP-0163: Personal Eventing Protocol . In this case, items are not persisted but kept in an in-memory cache. When the pep plugin is enabled, a user can have their own node (exposed as their bare jid) with a common namespace. Requires module mod_caps to be enabled. For XEP-0384: OMEMO Encryption , it might be required to configure the access_model to open or override the default access_model in the following way: 1 2 3 4 [modules.mod_pubsub] access_createnode = \"pubsub_createnode\" plugins = [\"pep\"] default_node_config = { access_model = \"open\" } \"dag\" Implementation of XEP-0248: PubSub Collection Nodes . Every node takes a place in a collection and becomes either a collection node (and have only sub-nodes) or a leaf node (contains only items). \"push\" Special node type that may be used as a target node for XEP-0357: Push Notifications capable services (e.g. mod_event_pusher_push ). For each published notification, a hook push_notification is run. You may enable as many modules that support this hook (all module with mod_push_service_* name prefix) as you like (see for example mod_push_service_mongoosepush ). This node type requires publish-options with at least device_id and service fields supplied. Metrics If you'd like to learn more about metrics in MongooseIM, please visit the MongooseIM metrics page. Overall PubSub action metrics For every PubSub action, like node creation, subscription, publication the following metrics are available: count - a spiral metric showing the number of given action invocations errors - a spiral metric counting the errors for a given action time - a histogram metric showing the time it took to finish the action in case of success Below there is a table describing all metrics related to PubSub actions Name Description (when it gets incremented) [HOST, pubsub, get, affiliations, TYPE] When node's affiliations are read [HOST, pubsub, get, configure, TYPE] When node's configuration is read [HOST, pubsub, get, default, TYPE] When node's defaults are read [HOST, pubsub, get, items, TYPE] When node's items are read [HOST, pubsub, get, options, TYPE] When node's options are read [HOST, pubsub, get, subscriptions, TYPE] When node's subscriptions are read [HOST, pubsub, set, affiliations, TYPE] When node's subscriptions are set [HOST, pubsub, set, configure, TYPE] When node's configuration is set [HOST, pubsub, set, create, TYPE] When node is created [HOST, pubsub, set, delete, TYPE] When node is deleted [HOST, pubsub, set, options, TYPE] When node's options are set [HOST, pubsub, set, publish, TYPE] When an item is published [HOST, pubsub, set, purge, TYPE] When node's items are purged [HOST, pubsub, set, retract, TYPE] When node's items are retracted [HOST, pubsub, set, subscribe, TYPE] When a subscriber subscribes to a node [HOST, pubsub, set, subscriptions, TYPE] When a subscription is set (for instance accepted) [HOST, pubsub, set, unsubscribe, TYPE] When a subscriber unsubscribes Where: HOST is the XMPP host for which mod_pubsub is running. Can be set to global if all metrics are set to be global. TYPE is one of the following count , errors , time (described above the table) Backend operations The are also more detailed metrics measuring execution time of backend operations. Metrics for these actions may be found under mod_pubsub_db subkey. Backend action Description (when it gets incremented) get_state User's state for a specific node is fetched. get_states Node's states are fetched. get_states_by_lus Nodes' states for user + domain are fetched. get_states_by_bare Nodes' states for bare JID are fetched. get_states_by_full Nodes' states for full JID are fetched. get_own_nodes_states State data for user's nodes is fetched. create_node A node's owner is set. del_node All data related to a node is removed. get_items Node's items are fetched. get_item A specific item from a node is fetched. add_item An item is upserted into a node. set_item An item is updated in a node. del_item An item is deleted from a node. del_items Specified items are deleted from a node. set_node A node is upserted. find_node_by_id A node is fetched by its ID. find_nodes_by_key Nodes are fetched by key. find_node_by_name A node is fetched by its name. del_node A node is deleted. get_subnodes Subnodes of a node are fetched. get_subnodes_tree Full tree of subnodes of a node is fetched. get_parentnodes_tree All parents of a node are fetched.","title":"mod_pubsub"},{"location":"modules/mod_pubsub/#what-is-pubsub","text":"PubSub is a design pattern which mostly promotes a loose coupling between two kinds of entities - publishers and subscribers. Like their names suggest, in the pubsub world we have publishers who fire events, and subscribers who wish to be notified about those events when publishers push data. There might be several subscribers, several publishers, and even several channels (or nodes) where the events are sent.","title":"What is PubSub?"},{"location":"modules/mod_pubsub/#module-description","text":"This module implements XEP-0060: Publish-Subscribe . Due to the complexity of the protocol, the PubSub engine makes successive calls to the nodetree and node plugins in order to check the validity of requests, perform the corresponding action and return a result or appropriate error. Such an architecture makes it much easier to write custom pubsub plugins and add new storage backends. It's all about tailoring PubSub to your needs!","title":"Module Description"},{"location":"modules/mod_pubsub/#options","text":"","title":"Options"},{"location":"modules/mod_pubsub/#modulesmod_pubsubiqdisctype","text":"Syntax: string, one of \"one_queue\" , \"no_queue\" , \"queues\" , \"parallel\" Default: \"no_queue\" Strategy to handle incoming stanzas. For details, please refer to IQ processing policies .","title":"modules.mod_pubsub.iqdisc.type"},{"location":"modules/mod_pubsub/#modulesmod_pubsubhost","text":"Syntax: string Default: \"pubsub.@HOST@\" Example: host = \"pubsub.localhost\" Subdomain for Pubsub service to reside under. @HOST@ is replaced with each served domain.","title":"modules.mod_pubsub.host"},{"location":"modules/mod_pubsub/#modulesmod_pubsubbackend","text":"Syntax: string, one of \"mnesia\" , \"rdbms\" Default: \"mnesia\" Example: backend = \"rdbms\" Database backend to use.","title":"modules.mod_pubsub.backend"},{"location":"modules/mod_pubsub/#modulesmod_pubsubaccess_createnode","text":"Syntax: string, rule name, or \"all\" Default: \"all\" Example: access_createnode = \"all\" Specifies who is allowed to create pubsub nodes. The access rule referenced here needs to be defined in the access section.","title":"modules.mod_pubsub.access_createnode"},{"location":"modules/mod_pubsub/#modulesmod_pubsubmax_items_node","text":"Syntax: non-negative integer Default: 10 Example: max_items_node = 10 Defines the maximum number of items that can be stored in a node.","title":"modules.mod_pubsub.max_items_node"},{"location":"modules/mod_pubsub/#modulesmod_pubsubmax_subscriptions_node","text":"Syntax: non-negative integer Default: not specified (no limit) Example: max_subscriptions_node = 10 The maximum number of subscriptions managed by a node. By default there is no limit.","title":"modules.mod_pubsub.max_subscriptions_node"},{"location":"modules/mod_pubsub/#modulesmod_pubsubnodetree","text":"Syntax: string Default: \"tree\" Example: nodetree = \"tree\" Specifies the storage and organisation of the pubsub nodes. See the section below.","title":"modules.mod_pubsub.nodetree"},{"location":"modules/mod_pubsub/#modulesmod_pubsubignore_pep_from_offline","text":"Syntax: boolean Default: true Example: ignore_pep_from_offline = false Specifies whether or not we should get last published PEP items from users in our roster which are offline when we connect. The default option is true hence we will get only the last items from the online contacts.","title":"modules.mod_pubsub.ignore_pep_from_offline"},{"location":"modules/mod_pubsub/#modulesmod_pubsublast_item_cache","text":"Syntax: string, one of \"mnesia\" , \"rdbms\" , \"false\" Default: \"false\" Example: last_item_cache = \"mnesia\" If enabled, PubSub will cache the last published items in the nodes. It may increase PubSub performance but at a price of an increased memory usage.","title":"modules.mod_pubsub.last_item_cache"},{"location":"modules/mod_pubsub/#modulesmod_pubsubplugins","text":"Syntax: array of strings Default: [\"flat\"] Example: plugins = [\"flat\", \"pep\"] List of enabled pubsub plugins.","title":"modules.mod_pubsub.plugins"},{"location":"modules/mod_pubsub/#modulesmod_pubsubpep_mapping","text":"Syntax: Array of TOML tables with the following keys: \"namespace\" , \"node\" and string values. Default: [] Example: pep_mapping = [{namespace = \"urn:xmpp:microblog:0\", node = \"mb\"}] This permits creating a Key-Value list to define a custom node plugin on a given PEP namespace. E.g. pair {\"urn:xmpp:microblog:0\", \"mb\"} will use module node_mb instead of node_pep when the specified namespace is used.","title":"modules.mod_pubsub.pep_mapping"},{"location":"modules/mod_pubsub/#modulesmod_pubsubdefault_node_config","text":"Syntax: TOML table with the following values: string, boolean or non-negative integer. Default: {} Example: default_node_config = {deliver_payloads = true, max_payload_size = 10000, node_type = \"leaf\"} Overrides the default node configuration, regardless of the node plugin. Node configuration still uses the default configuration defined by the node plugin, and overrides any items by the value defined in this configurable list. The possible options, altogether with their default values for each node plugin, are listed in the table below: syntax node_flat / node_hometree node_pep node_dag node_push access_model non-empty string open presence open whitelist deliver_notifications boolean true true true true deliver_payloads boolean true true true true max_items non-negative integer 10 1 10 1 max_payload_size non-negative integer 60000 60000 60000 60000 node_type non-empty string N/A N/A leaf N/A notification_type non-empty string headline headline headline headline notify_config boolean false false false false notify_delete boolean false false false false notify_retract boolean false false false false persist_items boolean true true true false presence_based_delivery boolean false true false true publish_model non-empty string publishers publishers publishers open purge_offline boolean false false false false roster_groups_allowed non-empty string [] [] [] [] send_last_published_item non-empty string never on_sub_and_presence never on_sub_and_presence subscribe boolean true true true true","title":"modules.mod_pubsub.default_node_config"},{"location":"modules/mod_pubsub/#modulesmod_pubsubitem_publisher","text":"Syntax: boolean Default: false Example: item_publisher = false When enabled, a JID of the publisher will be saved in the item metadata. This effectively makes them an owner of this item.","title":"modules.mod_pubsub.item_publisher"},{"location":"modules/mod_pubsub/#modulesmod_pubsubsync_broadcast","text":"Syntax: boolean Default: false Example: sync_broadcast = false If false, routing of notifications to subscribers is done in a separate Erlang process. As a consequence, some notifications may arrive to the subscribers in the wrong order (however, the two events would have to be published at the exact same time).","title":"modules.mod_pubsub.sync_broadcast"},{"location":"modules/mod_pubsub/#cache-backend","text":"Caching is disabled by default. You may enable it by specifying the backend it should use. It is not coupled with the main DB backend, so it is possible to store the cached data in mnesia , while the actual PubSub information is kept in RDBMS (and vice versa!).","title":"Cache Backend"},{"location":"modules/mod_pubsub/#example-configuration","text":"1 2 3 4 5 6 7 8 9 10 11 [modules.mod_pubsub] access_createnode = \"pubsub_createnode\" ignore_pep_from_offline = false backend = \"rdbms\" last_item_cache = \"mnesia\" max_items_node = 1000 plugins = [\"flat\", \"pep\"] [[modules.mod_pubsub.pep_mapping]] namespace = \"urn:xmpp:microblog:0\" node = \"mb\"","title":"Example Configuration"},{"location":"modules/mod_pubsub/#nodetrees","text":"Called on get , create and delete node. Only one nodetree can be used per host and is shared by all node plugins.","title":"Nodetrees"},{"location":"modules/mod_pubsub/#tree","text":"Stores nodes in a tree structure. Every node name must be formatted like a UNIX path (e.g. /top/middle/leaf ). When a node is created, its direct ancestor must already exist, so in order to create /top/middle/leaf , /top/middle is needed. A user may create any top-level node. A user may create a subnode of a node, only if they own it or it was created by the service.","title":"\"tree\""},{"location":"modules/mod_pubsub/#dag","text":"Provides experimental support for XEP-0248: PubSub Collection Nodes . In this case you should also add the \"dag\" node plugin as default, for example: plugins = [\"dag\", \"flat\", \"hometree\", \"pep\"] .","title":"\"dag\""},{"location":"modules/mod_pubsub/#plugins","text":"They handle affiliations, subscriptions and items and also provide default node con\ufb01guration and features. PubSub clients can define which plugin to use when creating a node by adding type='plugin-name' attribute to the create stanza element. If such an attribute is not specified, the default plugin will be the first on the plugin list.","title":"Plugins"},{"location":"modules/mod_pubsub/#flat","text":"No node hierarchy. It handles the standard PubSub case.","title":"\"flat\""},{"location":"modules/mod_pubsub/#hometree","text":"Uses the exact same features as the flat plugin but additionally organises nodes in a tree. Basically it follows a scheme similar to the filesystem's structure. Every user can create nodes in their own home root: e.g /home/user . Each node can contain items and/or sub-nodes.","title":"\"hometree\""},{"location":"modules/mod_pubsub/#pep","text":"Implementation of XEP-0163: Personal Eventing Protocol . In this case, items are not persisted but kept in an in-memory cache. When the pep plugin is enabled, a user can have their own node (exposed as their bare jid) with a common namespace. Requires module mod_caps to be enabled. For XEP-0384: OMEMO Encryption , it might be required to configure the access_model to open or override the default access_model in the following way: 1 2 3 4 [modules.mod_pubsub] access_createnode = \"pubsub_createnode\" plugins = [\"pep\"] default_node_config = { access_model = \"open\" }","title":"\"pep\""},{"location":"modules/mod_pubsub/#dag_1","text":"Implementation of XEP-0248: PubSub Collection Nodes . Every node takes a place in a collection and becomes either a collection node (and have only sub-nodes) or a leaf node (contains only items).","title":"\"dag\""},{"location":"modules/mod_pubsub/#push","text":"Special node type that may be used as a target node for XEP-0357: Push Notifications capable services (e.g. mod_event_pusher_push ). For each published notification, a hook push_notification is run. You may enable as many modules that support this hook (all module with mod_push_service_* name prefix) as you like (see for example mod_push_service_mongoosepush ). This node type requires publish-options with at least device_id and service fields supplied.","title":"\"push\""},{"location":"modules/mod_pubsub/#metrics","text":"If you'd like to learn more about metrics in MongooseIM, please visit the MongooseIM metrics page.","title":"Metrics"},{"location":"modules/mod_pubsub/#overall-pubsub-action-metrics","text":"For every PubSub action, like node creation, subscription, publication the following metrics are available: count - a spiral metric showing the number of given action invocations errors - a spiral metric counting the errors for a given action time - a histogram metric showing the time it took to finish the action in case of success Below there is a table describing all metrics related to PubSub actions Name Description (when it gets incremented) [HOST, pubsub, get, affiliations, TYPE] When node's affiliations are read [HOST, pubsub, get, configure, TYPE] When node's configuration is read [HOST, pubsub, get, default, TYPE] When node's defaults are read [HOST, pubsub, get, items, TYPE] When node's items are read [HOST, pubsub, get, options, TYPE] When node's options are read [HOST, pubsub, get, subscriptions, TYPE] When node's subscriptions are read [HOST, pubsub, set, affiliations, TYPE] When node's subscriptions are set [HOST, pubsub, set, configure, TYPE] When node's configuration is set [HOST, pubsub, set, create, TYPE] When node is created [HOST, pubsub, set, delete, TYPE] When node is deleted [HOST, pubsub, set, options, TYPE] When node's options are set [HOST, pubsub, set, publish, TYPE] When an item is published [HOST, pubsub, set, purge, TYPE] When node's items are purged [HOST, pubsub, set, retract, TYPE] When node's items are retracted [HOST, pubsub, set, subscribe, TYPE] When a subscriber subscribes to a node [HOST, pubsub, set, subscriptions, TYPE] When a subscription is set (for instance accepted) [HOST, pubsub, set, unsubscribe, TYPE] When a subscriber unsubscribes Where: HOST is the XMPP host for which mod_pubsub is running. Can be set to global if all metrics are set to be global. TYPE is one of the following count , errors , time (described above the table)","title":"Overall PubSub action metrics"},{"location":"modules/mod_pubsub/#backend-operations","text":"The are also more detailed metrics measuring execution time of backend operations. Metrics for these actions may be found under mod_pubsub_db subkey. Backend action Description (when it gets incremented) get_state User's state for a specific node is fetched. get_states Node's states are fetched. get_states_by_lus Nodes' states for user + domain are fetched. get_states_by_bare Nodes' states for bare JID are fetched. get_states_by_full Nodes' states for full JID are fetched. get_own_nodes_states State data for user's nodes is fetched. create_node A node's owner is set. del_node All data related to a node is removed. get_items Node's items are fetched. get_item A specific item from a node is fetched. add_item An item is upserted into a node. set_item An item is updated in a node. del_item An item is deleted from a node. del_items Specified items are deleted from a node. set_node A node is upserted. find_node_by_id A node is fetched by its ID. find_nodes_by_key Nodes are fetched by key. find_node_by_name A node is fetched by its name. del_node A node is deleted. get_subnodes Subnodes of a node are fetched. get_subnodes_tree Full tree of subnodes of a node is fetched. get_parentnodes_tree All parents of a node are fetched.","title":"Backend operations"},{"location":"modules/mod_push_service_mongoosepush/","text":"Module Description This module handles the push_notification hook generated by mod_pubsub with an active push node. Each push_notification hook is converted as a REST API call to the MongoosePush service. You can find the full list of supported publish-options here . Prerequisites This module uses a connection pool via mongoose_http_client . It must be defined in outgoing_pools setting . Options modules.mod_push_service_mongoosepush.pool_name Syntax: non-empty string Default: \"undefined\" Example: pool_name = \"mongoose_push_http\" The name of the pool to use (as defined in outgoing_pools ). modules.mod_push_service_mongoosepush.api_version Syntax: string, \"v2\" or \"v3\" Default: \"v3\" Example: api_version = \"v3\" REST API version to be used. modules.mod_push_service_mongoosepush.max_http_connections Syntax: non-negative integer Default: 100 Example: max_http_connections = 100 The maximum amount of concurrent HTTP connections. Example configuration 1 2 3 4 5 6 7 8 9 10 11 12 13 [outgoing_pools.http.mongoose_push_http] scope = \"global\" workers = 50 [outgoing_pools.http.mongoose_push_http.connection] host = \"https://localhost:8443\" path_prefix = \"/\" request_timeout = 2000 [modules.mod_push_service_mongoosepush] pool_name = \"mongoose_push_http\" api_version = \"v3\" max_http_connections = 100","title":"mod_push_service_mongoosepush"},{"location":"modules/mod_push_service_mongoosepush/#module-description","text":"This module handles the push_notification hook generated by mod_pubsub with an active push node. Each push_notification hook is converted as a REST API call to the MongoosePush service. You can find the full list of supported publish-options here .","title":"Module Description"},{"location":"modules/mod_push_service_mongoosepush/#prerequisites","text":"This module uses a connection pool via mongoose_http_client . It must be defined in outgoing_pools setting .","title":"Prerequisites"},{"location":"modules/mod_push_service_mongoosepush/#options","text":"","title":"Options"},{"location":"modules/mod_push_service_mongoosepush/#modulesmod_push_service_mongoosepushpool_name","text":"Syntax: non-empty string Default: \"undefined\" Example: pool_name = \"mongoose_push_http\" The name of the pool to use (as defined in outgoing_pools ).","title":"modules.mod_push_service_mongoosepush.pool_name"},{"location":"modules/mod_push_service_mongoosepush/#modulesmod_push_service_mongoosepushapi_version","text":"Syntax: string, \"v2\" or \"v3\" Default: \"v3\" Example: api_version = \"v3\" REST API version to be used.","title":"modules.mod_push_service_mongoosepush.api_version"},{"location":"modules/mod_push_service_mongoosepush/#modulesmod_push_service_mongoosepushmax_http_connections","text":"Syntax: non-negative integer Default: 100 Example: max_http_connections = 100 The maximum amount of concurrent HTTP connections.","title":"modules.mod_push_service_mongoosepush.max_http_connections"},{"location":"modules/mod_push_service_mongoosepush/#example-configuration","text":"1 2 3 4 5 6 7 8 9 10 11 12 13 [outgoing_pools.http.mongoose_push_http] scope = \"global\" workers = 50 [outgoing_pools.http.mongoose_push_http.connection] host = \"https://localhost:8443\" path_prefix = \"/\" request_timeout = 2000 [modules.mod_push_service_mongoosepush] pool_name = \"mongoose_push_http\" api_version = \"v3\" max_http_connections = 100","title":"Example configuration"},{"location":"modules/mod_register/","text":"Module Description This module implements XEP-0077: In-Band Registration , allowing users to register accounts on the server via XMPP. Use of this module on Internet-facing servers is not recommended . Options modules.mod_register.iqdisc.type Syntax: string, one of \"one_queue\" , \"no_queue\" , \"queues\" , \"parallel\" Default: \"one_queue\" Strategy to handle incoming stanzas. For details, please refer to IQ processing policies . modules.mod_register.access Syntax: string, rule name or \"all\" Default: \"all\" Example: access = \"all\" Defines which access rule should be used for checking if a chosen username is allowed for registration. modules.mod_register.welcome_message Syntax: TOML table with the following keys: \"body\" , \"subject\" and string values. Default: {subject = \"\", body = \"\"} Example: welcome_message = {subject = \"Hello from MIM!\", body = \"Message body.\"} Body and subject of a <message> stanza sent to new users. Only one of the fields (but non-empty) is mandatory for the message to be sent. modules.mod_register.registration_watchers Syntax: array of strings Default: [] Example: registration_watchers = [\"JID1\", \"JID2\"] List of JIDs, which should receive a <message> notification about every successful registration. modules.mod_register.password_strength Syntax: non-negative integer Default: 0 Example: password_strength = 32 Specifies minimal entropy of allowed password. Entropy is measured with ejabberd_auth:entropy/1 . Recommended minimum is 32. The entropy calculation algorithm is described in a section below. modules.mod_register.ip_access Syntax: Array of TOML tables with the following mandatory content: address - string, IP address policy - string, one of: \"allow\" , \"deny\" . Default: [] Example: ip_access = [ {address = \"127.0.0.0/8\", policy = \"allow\"}, {address = \"0.0.0.0/0\", policy = \"deny\"} ] Access list for specified IPs or networks. Default value allows registration from every IP. Example configuration Allow registrations from localhost: 1 2 3 4 5 6 [modules.mod_register] welcome_message = { subject = \"Hello from MIM!\" , body = \"Message body.\" } ip_access = [ { address = \"127.0.0.1\" , policy = \"allow\" } ] access = \"register\" Deny registration from network 10.20.0.0 with mask 255.255.0.0. 1 2 3 4 [modules.mod_register] ip_access = [ { address = \"10.20.0.0/16\" , policy = \"deny\" } ] Metrics If you'd like to learn more about metrics in MongooseIM, please visit MongooseIM metrics page. Name Type Description (when it gets incremented) [Host, modRegisterCount] spiral A user registers via mod_register module. [Host, modUnregisterCount] spiral A user unregisters via mod_register module. Entropy calculation algorithm 1 Entropy = length(Password) * log(X) / log(2) Where X is initially set to 0 and certain values are added if at least one of these bytes are present: Lower case character: 26 Upper case character: 26 Digit: 9 Printable ASCII (0x21 - 0x7e): 33 Any other value: 128 Note: These values are added only once, no matter how many bytes of specific type are found. Example entropies kotek : ~23.5 abc123 : ~30.8 L33tSp34k : ~53.4 CamelCase : ~51.3 lowUP1#: : ~45.9 lowUP1#\u2764 : ~78","title":"mod_register"},{"location":"modules/mod_register/#module-description","text":"This module implements XEP-0077: In-Band Registration , allowing users to register accounts on the server via XMPP. Use of this module on Internet-facing servers is not recommended .","title":"Module Description"},{"location":"modules/mod_register/#options","text":"","title":"Options"},{"location":"modules/mod_register/#modulesmod_registeriqdisctype","text":"Syntax: string, one of \"one_queue\" , \"no_queue\" , \"queues\" , \"parallel\" Default: \"one_queue\" Strategy to handle incoming stanzas. For details, please refer to IQ processing policies .","title":"modules.mod_register.iqdisc.type"},{"location":"modules/mod_register/#modulesmod_registeraccess","text":"Syntax: string, rule name or \"all\" Default: \"all\" Example: access = \"all\" Defines which access rule should be used for checking if a chosen username is allowed for registration.","title":"modules.mod_register.access"},{"location":"modules/mod_register/#modulesmod_registerwelcome_message","text":"Syntax: TOML table with the following keys: \"body\" , \"subject\" and string values. Default: {subject = \"\", body = \"\"} Example: welcome_message = {subject = \"Hello from MIM!\", body = \"Message body.\"} Body and subject of a <message> stanza sent to new users. Only one of the fields (but non-empty) is mandatory for the message to be sent.","title":"modules.mod_register.welcome_message"},{"location":"modules/mod_register/#modulesmod_registerregistration_watchers","text":"Syntax: array of strings Default: [] Example: registration_watchers = [\"JID1\", \"JID2\"] List of JIDs, which should receive a <message> notification about every successful registration.","title":"modules.mod_register.registration_watchers"},{"location":"modules/mod_register/#modulesmod_registerpassword_strength","text":"Syntax: non-negative integer Default: 0 Example: password_strength = 32 Specifies minimal entropy of allowed password. Entropy is measured with ejabberd_auth:entropy/1 . Recommended minimum is 32. The entropy calculation algorithm is described in a section below.","title":"modules.mod_register.password_strength"},{"location":"modules/mod_register/#modulesmod_registerip_access","text":"Syntax: Array of TOML tables with the following mandatory content: address - string, IP address policy - string, one of: \"allow\" , \"deny\" . Default: [] Example: ip_access = [ {address = \"127.0.0.0/8\", policy = \"allow\"}, {address = \"0.0.0.0/0\", policy = \"deny\"} ] Access list for specified IPs or networks. Default value allows registration from every IP.","title":"modules.mod_register.ip_access"},{"location":"modules/mod_register/#example-configuration","text":"Allow registrations from localhost: 1 2 3 4 5 6 [modules.mod_register] welcome_message = { subject = \"Hello from MIM!\" , body = \"Message body.\" } ip_access = [ { address = \"127.0.0.1\" , policy = \"allow\" } ] access = \"register\" Deny registration from network 10.20.0.0 with mask 255.255.0.0. 1 2 3 4 [modules.mod_register] ip_access = [ { address = \"10.20.0.0/16\" , policy = \"deny\" } ]","title":"Example configuration"},{"location":"modules/mod_register/#metrics","text":"If you'd like to learn more about metrics in MongooseIM, please visit MongooseIM metrics page. Name Type Description (when it gets incremented) [Host, modRegisterCount] spiral A user registers via mod_register module. [Host, modUnregisterCount] spiral A user unregisters via mod_register module.","title":"Metrics"},{"location":"modules/mod_register/#entropy-calculation-algorithm","text":"1 Entropy = length(Password) * log(X) / log(2) Where X is initially set to 0 and certain values are added if at least one of these bytes are present: Lower case character: 26 Upper case character: 26 Digit: 9 Printable ASCII (0x21 - 0x7e): 33 Any other value: 128 Note: These values are added only once, no matter how many bytes of specific type are found.","title":"Entropy calculation algorithm"},{"location":"modules/mod_register/#example-entropies","text":"kotek : ~23.5 abc123 : ~30.8 L33tSp34k : ~53.4 CamelCase : ~51.3 lowUP1#: : ~45.9 lowUP1#\u2764 : ~78","title":"Example entropies"},{"location":"modules/mod_roster/","text":"Module Description The module implements roster support, specified in RFC 6121 . Includes support for XEP-0237: Roster Versioning . It can sometimes become quite a heavyweight feature, so there is an option to disable it. Options modules.mod_roster.iqdisc.type Syntax: string, one of \"one_queue\" , \"no_queue\" , \"queues\" , \"parallel\" Default: \"one_queue\" Strategy to handle incoming stanzas. For details, please refer to IQ processing policies . modules.mod_roster.versioning Syntax: boolean Default: false Example: versioning = true Turn on/off support for Roster Versioning. modules.mod_roster.store_current_id Syntax: boolean Default: false Example: store_current_id = true Stores the last roster hash in DB (used in Roster Versioning). Improves performance but should be disabled, when shared rosters are used. modules.mod_roster.backend Syntax: string, one of \"mnesia\" , \"rdbms\" , \"riak\" Default: \"mnesia\" Example: backend = \"mnesia\" Riak-specific options modules.mod_roster.riak.bucket_type Syntax: string Default: \"rosters\" Example: riak.bucket_type = \"rosters\" modules.mod_roster.riak.version_bucket_type Syntax: string Default: \"roster_versions\" Example: riak.version_bucket_type = \"roster_versions\" Example configuration 1 2 3 [modules.mod_roster] versioning = true store_current_id = true Metrics If you'd like to learn more about metrics in MongooseIM, please visit MongooseIM metrics page. Backend action Description (when it gets incremented) read_roster_version Version of a user's roster is retrieved. write_roster_version Vversion of a user's roster is stored. get_roster A user's roster is fetched. get_roster_entry A specific roster entry is fetched. get_roster_entry_t A specific roster entry is fetched inside a transaction. get_subscription_lists A subscription list of a user is retrieved. roster_subscribe_t A subscription status between users is updated inside a transaction. update_roster_t A roster entry is updated in a transaction. del_roster_t A roster entry is removed inside a transaction.","title":"mod_roster"},{"location":"modules/mod_roster/#module-description","text":"The module implements roster support, specified in RFC 6121 . Includes support for XEP-0237: Roster Versioning . It can sometimes become quite a heavyweight feature, so there is an option to disable it.","title":"Module Description"},{"location":"modules/mod_roster/#options","text":"","title":"Options"},{"location":"modules/mod_roster/#modulesmod_rosteriqdisctype","text":"Syntax: string, one of \"one_queue\" , \"no_queue\" , \"queues\" , \"parallel\" Default: \"one_queue\" Strategy to handle incoming stanzas. For details, please refer to IQ processing policies .","title":"modules.mod_roster.iqdisc.type"},{"location":"modules/mod_roster/#modulesmod_rosterversioning","text":"Syntax: boolean Default: false Example: versioning = true Turn on/off support for Roster Versioning.","title":"modules.mod_roster.versioning"},{"location":"modules/mod_roster/#modulesmod_rosterstore_current_id","text":"Syntax: boolean Default: false Example: store_current_id = true Stores the last roster hash in DB (used in Roster Versioning). Improves performance but should be disabled, when shared rosters are used.","title":"modules.mod_roster.store_current_id"},{"location":"modules/mod_roster/#modulesmod_rosterbackend","text":"Syntax: string, one of \"mnesia\" , \"rdbms\" , \"riak\" Default: \"mnesia\" Example: backend = \"mnesia\"","title":"modules.mod_roster.backend"},{"location":"modules/mod_roster/#riak-specific-options","text":"","title":"Riak-specific options"},{"location":"modules/mod_roster/#modulesmod_rosterriakbucket_type","text":"Syntax: string Default: \"rosters\" Example: riak.bucket_type = \"rosters\"","title":"modules.mod_roster.riak.bucket_type"},{"location":"modules/mod_roster/#modulesmod_rosterriakversion_bucket_type","text":"Syntax: string Default: \"roster_versions\" Example: riak.version_bucket_type = \"roster_versions\"","title":"modules.mod_roster.riak.version_bucket_type"},{"location":"modules/mod_roster/#example-configuration","text":"1 2 3 [modules.mod_roster] versioning = true store_current_id = true","title":"Example configuration"},{"location":"modules/mod_roster/#metrics","text":"If you'd like to learn more about metrics in MongooseIM, please visit MongooseIM metrics page. Backend action Description (when it gets incremented) read_roster_version Version of a user's roster is retrieved. write_roster_version Vversion of a user's roster is stored. get_roster A user's roster is fetched. get_roster_entry A specific roster entry is fetched. get_roster_entry_t A specific roster entry is fetched inside a transaction. get_subscription_lists A subscription list of a user is retrieved. roster_subscribe_t A subscription status between users is updated inside a transaction. update_roster_t A roster entry is updated in a transaction. del_roster_t A roster entry is removed inside a transaction.","title":"Metrics"},{"location":"modules/mod_shared_roster_ldap/","text":"Module Description This module, when enabled, will inject roster entries fetched from LDAP. It might get quite complicated to configure it properly, so fasten your seatbelts and prepare for a ride. When a default value for an option is defined with \"top-level/XXX\", it means that the default value is equal to a top-level parameter in mongooseim.toml of the same name. If it is not defined, XXX becomes the default value. Options: general modules.mod_shared_roster_ldap.ldap_pool_tag modules.mod_shared_roster_ldap.ldap_base modules.mod_shared_roster_ldap.ldap_deref These 3 options are the same as for the LDAP authentication module . Options: attributes modules.mod_shared_roster_ldap.ldap_groupattr Syntax: string Default: \"cn\" Example: ldap_groupattr = \"cn\" Provides a group name. modules.mod_shared_roster_ldap.ldap_groupdesc Syntax: string Default: the value of ldap_groupattr Example: ldap_groupdesc = \"cn\" Provides a group description. modules.mod_shared_roster_ldap.ldap_userdesc Syntax: string Default: \"cn\" Example: ldap_userdesc = \"cn\" Provides a human-readable user name. modules.mod_shared_roster_ldap.ldap_useruid Syntax: string Default: \"cn\" Example: ldap_useruid = \"cn\" Provides a username. modules.mod_shared_roster_ldap.ldap_memberattr Syntax: string Default: \"memberUid\" Example: ldap_memberattr = \"memberUid\" Holds group members' IDs. modules.mod_shared_roster_ldap.ldap_memberattr_format Syntax: string Default: \"%u\" Example: ldap_memberattr_format = \"%u\" Simple LDAP expression for extracting a user ID. modules.mod_shared_roster_ldap.ldap_memberattr_format_re Syntax: string Default: \"\" Example: ldap_memberattr_format_re = \"\" Allows extracting the user ID with a regular expression. Options: parameters modules.mod_shared_roster_ldap.ldap_auth_check Syntax: boolean Default: true Example: ldap_auth_check = true Enables checking if a shared roster entry actually exists in the XMPP database. modules.mod_shared_roster_ldap.ldap_user_cache_validity Syntax: positive integer Default: top-level/ 300 Example: ldap_user_cache_validity = 300 Specifies in seconds how long are the roster entries kept in the cache. modules.mod_shared_roster_ldap.ldap_group_cache_validity Syntax: positive integer Default: top-level/ 300 Example: ldap_group_cache_validity = 300 Specifies in seconds how long is the user's membership in a group kept in the cache. modules.mod_shared_roster_ldap.ldap_user_cache_size Syntax: positive integer Default: top-level/ 1000 Example: ldap_user_cache_size = 1000 Specifies how many shared roster items are kept in the cache. modules.mod_shared_roster_ldap.ldap_group_cache_size Syntax: positive integer Default: top-level/ 1000 Example: ldap_group_cache_size = 1000 Specifies how many roster group entries are kept in cache. Options: LDAP filters modules.mod_shared_roster_ldap.ldap_rfilter Syntax: string Default: top-level/ \"\" Example: ldap_rfilter = \"(objectClass=inetOrgPerson)\" Used to find names of all shared roster groups. modules.mod_shared_roster_ldap.ldap_gfilter Syntax: string Default: top-level/ \"\" Example: ldap_gfilter = \"\" Used for retrieving the human-readable name and the members of a group. modules.mod_shared_roster_ldap.ldap_ufilter Syntax: string Default: top-level/ \"\" Example: ldap_ufilter = \"\" Used for retrieving the human-readable name of the roster entries. modules.mod_shared_roster_ldap.ldap_filter Syntax: string Default: top-level/ \"\" Example: ldap_filter = \"(objectClass=inetOrgPerson)\" Filter AND-ed with previous filters. Example Configuration 1 2 3 4 5 6 7 8 9 [modules.mod_shared_roster_ldap] ldap_base = \"ou=Users,dc=ejd,dc=com\" ldap_groupattr = \"ou\" ldap_memberattr = \"cn\" ldap_userdesc = \"cn\" ldap_filter = \"(objectClass=inetOrgPerson)\" ldap_rfilter = \"(objectClass=inetOrgPerson)\" ldap_group_cache_validity = 1 ldap_user_cache_validity = 1","title":"mod_shared_roster_ldap"},{"location":"modules/mod_shared_roster_ldap/#module-description","text":"This module, when enabled, will inject roster entries fetched from LDAP. It might get quite complicated to configure it properly, so fasten your seatbelts and prepare for a ride. When a default value for an option is defined with \"top-level/XXX\", it means that the default value is equal to a top-level parameter in mongooseim.toml of the same name. If it is not defined, XXX becomes the default value.","title":"Module Description"},{"location":"modules/mod_shared_roster_ldap/#options-general","text":"","title":"Options: general"},{"location":"modules/mod_shared_roster_ldap/#modulesmod_shared_roster_ldapldap_pool_tag","text":"","title":"modules.mod_shared_roster_ldap.ldap_pool_tag"},{"location":"modules/mod_shared_roster_ldap/#modulesmod_shared_roster_ldapldap_base","text":"","title":"modules.mod_shared_roster_ldap.ldap_base"},{"location":"modules/mod_shared_roster_ldap/#modulesmod_shared_roster_ldapldap_deref","text":"These 3 options are the same as for the LDAP authentication module .","title":"modules.mod_shared_roster_ldap.ldap_deref"},{"location":"modules/mod_shared_roster_ldap/#options-attributes","text":"","title":"Options: attributes"},{"location":"modules/mod_shared_roster_ldap/#modulesmod_shared_roster_ldapldap_groupattr","text":"Syntax: string Default: \"cn\" Example: ldap_groupattr = \"cn\" Provides a group name.","title":"modules.mod_shared_roster_ldap.ldap_groupattr"},{"location":"modules/mod_shared_roster_ldap/#modulesmod_shared_roster_ldapldap_groupdesc","text":"Syntax: string Default: the value of ldap_groupattr Example: ldap_groupdesc = \"cn\" Provides a group description.","title":"modules.mod_shared_roster_ldap.ldap_groupdesc"},{"location":"modules/mod_shared_roster_ldap/#modulesmod_shared_roster_ldapldap_userdesc","text":"Syntax: string Default: \"cn\" Example: ldap_userdesc = \"cn\" Provides a human-readable user name.","title":"modules.mod_shared_roster_ldap.ldap_userdesc"},{"location":"modules/mod_shared_roster_ldap/#modulesmod_shared_roster_ldapldap_useruid","text":"Syntax: string Default: \"cn\" Example: ldap_useruid = \"cn\" Provides a username.","title":"modules.mod_shared_roster_ldap.ldap_useruid"},{"location":"modules/mod_shared_roster_ldap/#modulesmod_shared_roster_ldapldap_memberattr","text":"Syntax: string Default: \"memberUid\" Example: ldap_memberattr = \"memberUid\" Holds group members' IDs.","title":"modules.mod_shared_roster_ldap.ldap_memberattr"},{"location":"modules/mod_shared_roster_ldap/#modulesmod_shared_roster_ldapldap_memberattr_format","text":"Syntax: string Default: \"%u\" Example: ldap_memberattr_format = \"%u\" Simple LDAP expression for extracting a user ID.","title":"modules.mod_shared_roster_ldap.ldap_memberattr_format"},{"location":"modules/mod_shared_roster_ldap/#modulesmod_shared_roster_ldapldap_memberattr_format_re","text":"Syntax: string Default: \"\" Example: ldap_memberattr_format_re = \"\" Allows extracting the user ID with a regular expression.","title":"modules.mod_shared_roster_ldap.ldap_memberattr_format_re"},{"location":"modules/mod_shared_roster_ldap/#options-parameters","text":"","title":"Options: parameters"},{"location":"modules/mod_shared_roster_ldap/#modulesmod_shared_roster_ldapldap_auth_check","text":"Syntax: boolean Default: true Example: ldap_auth_check = true Enables checking if a shared roster entry actually exists in the XMPP database.","title":"modules.mod_shared_roster_ldap.ldap_auth_check"},{"location":"modules/mod_shared_roster_ldap/#modulesmod_shared_roster_ldapldap_user_cache_validity","text":"Syntax: positive integer Default: top-level/ 300 Example: ldap_user_cache_validity = 300 Specifies in seconds how long are the roster entries kept in the cache.","title":"modules.mod_shared_roster_ldap.ldap_user_cache_validity"},{"location":"modules/mod_shared_roster_ldap/#modulesmod_shared_roster_ldapldap_group_cache_validity","text":"Syntax: positive integer Default: top-level/ 300 Example: ldap_group_cache_validity = 300 Specifies in seconds how long is the user's membership in a group kept in the cache.","title":"modules.mod_shared_roster_ldap.ldap_group_cache_validity"},{"location":"modules/mod_shared_roster_ldap/#modulesmod_shared_roster_ldapldap_user_cache_size","text":"Syntax: positive integer Default: top-level/ 1000 Example: ldap_user_cache_size = 1000 Specifies how many shared roster items are kept in the cache.","title":"modules.mod_shared_roster_ldap.ldap_user_cache_size"},{"location":"modules/mod_shared_roster_ldap/#modulesmod_shared_roster_ldapldap_group_cache_size","text":"Syntax: positive integer Default: top-level/ 1000 Example: ldap_group_cache_size = 1000 Specifies how many roster group entries are kept in cache.","title":"modules.mod_shared_roster_ldap.ldap_group_cache_size"},{"location":"modules/mod_shared_roster_ldap/#options-ldap-filters","text":"","title":"Options: LDAP filters"},{"location":"modules/mod_shared_roster_ldap/#modulesmod_shared_roster_ldapldap_rfilter","text":"Syntax: string Default: top-level/ \"\" Example: ldap_rfilter = \"(objectClass=inetOrgPerson)\" Used to find names of all shared roster groups.","title":"modules.mod_shared_roster_ldap.ldap_rfilter"},{"location":"modules/mod_shared_roster_ldap/#modulesmod_shared_roster_ldapldap_gfilter","text":"Syntax: string Default: top-level/ \"\" Example: ldap_gfilter = \"\" Used for retrieving the human-readable name and the members of a group.","title":"modules.mod_shared_roster_ldap.ldap_gfilter"},{"location":"modules/mod_shared_roster_ldap/#modulesmod_shared_roster_ldapldap_ufilter","text":"Syntax: string Default: top-level/ \"\" Example: ldap_ufilter = \"\" Used for retrieving the human-readable name of the roster entries.","title":"modules.mod_shared_roster_ldap.ldap_ufilter"},{"location":"modules/mod_shared_roster_ldap/#modulesmod_shared_roster_ldapldap_filter","text":"Syntax: string Default: top-level/ \"\" Example: ldap_filter = \"(objectClass=inetOrgPerson)\" Filter AND-ed with previous filters.","title":"modules.mod_shared_roster_ldap.ldap_filter"},{"location":"modules/mod_shared_roster_ldap/#example-configuration","text":"1 2 3 4 5 6 7 8 9 [modules.mod_shared_roster_ldap] ldap_base = \"ou=Users,dc=ejd,dc=com\" ldap_groupattr = \"ou\" ldap_memberattr = \"cn\" ldap_userdesc = \"cn\" ldap_filter = \"(objectClass=inetOrgPerson)\" ldap_rfilter = \"(objectClass=inetOrgPerson)\" ldap_group_cache_validity = 1 ldap_user_cache_validity = 1","title":"Example Configuration"},{"location":"modules/mod_sic/","text":"Module Description This module implements XEP-0279: Server IP Check . It allows clients to ask the server, what is the client IP and port from the server's perspective. Options modules.mod_sic.iqdisc.type Syntax: string, one of \"one_queue\" , \"no_queue\" , \"queues\" , \"parallel\" Default: \"one_queue\" Strategy to handle incoming stanzas. For details, please refer to IQ processing policies . Example Configuration 1 [modules.mod_sic]","title":"mod_sic"},{"location":"modules/mod_sic/#module-description","text":"This module implements XEP-0279: Server IP Check . It allows clients to ask the server, what is the client IP and port from the server's perspective.","title":"Module Description"},{"location":"modules/mod_sic/#options","text":"","title":"Options"},{"location":"modules/mod_sic/#modulesmod_siciqdisctype","text":"Syntax: string, one of \"one_queue\" , \"no_queue\" , \"queues\" , \"parallel\" Default: \"one_queue\" Strategy to handle incoming stanzas. For details, please refer to IQ processing policies .","title":"modules.mod_sic.iqdisc.type"},{"location":"modules/mod_sic/#example-configuration","text":"1 [modules.mod_sic]","title":"Example Configuration"},{"location":"modules/mod_stream_management/","text":"Module Description Enables XEP-0198: Stream Management . Most of the logic regarding session resumption and acknowledgement is implemented in ejabberd_c2s , while the management of the session tables and configuration is implemented in mod_stream_management . Options modules.mod_stream_management.buffer Syntax: boolean Default: true Example: buffer = false Enables buffer for messages to be acknowledged. modules.mod_stream_management.buffer_max Syntax: positive integer or string \"infinity\" Default: 100 Example: buffer_max = 500 Buffer size for messages yet to be acknowledged. modules.mod_stream_management.ack Syntax: boolean Default: true Example: ack = false Enables ack requests to be sent from the server to the client. modules.mod_stream_management.ack_freq Syntax: positive integer Default: 1 Example: ack_freq = 3 Frequency of ack requests sent from the server to the client, e.g. 1 means a request after each stanza, 3 means a request after each 3 stanzas. modules.mod_stream_management.resume_timeout Syntax: positive integer, value given in seconds Default: 600 Example: resume_timeout = 600 Timeout for the session resumption. Sessions will be removed after the specified number of seconds. Stale_h options Enables keeping old server's <h> values after the resumption timed out. Disabled by default. When enabled, parameters for the garbage collection of these tables should be provided. modules.mod_stream_management.stale_h.enabled Syntax: boolean Default: false Example: enabled = true Enables stale_h configuration modules.mod_stream_management.stale_h.repeat_after Syntax: positive integer, value given in seconds Default: 1800 (half an hour) Example: repeat_after = 1800 How often the garbage collection will run in the background to clean this table. modules.mod_stream_management.stale_h.geriatric Syntax: positive integer, value given in seconds Default: 3600 (one hour) Example: geriatric = 3600 The maximum lifespan of a record in memory. After this, they will be chased for cleanup. Example Configuration 1 2 3 4 5 6 7 [modules.mod_stream_management] buffer_max = 30 ack_freq = 1 resume_timeout = 600 stale_h . enabled = true stale_h . repeat_after = 1800 stale_h . geriatric = 3600 Implementation details In ejabberd_c2s The record #smgc_state{} in the ejabberd_c2s gen_fsm server keeps fields like: 1 2 3 4 5 6 7 8 9 10 11 12 stream_mgmt = false , %% whether SM is enabled, used in pattern matching inside `ejabberd_c2s` stream_mgmt_in = 0 , %% amount of msgs on the server and not acked by the user (server's <h>) stream_mgmt_id , %% the mod_stream_management:smid() unique identifier stream_mgmt_out_acked = 0 , %% messages delivered to the user, and acked by the user (user's <h>) stream_mgmt_buffer = [], %% buffered stanzas not yet acked by the user stream_mgmt_buffer_size = 0 , %% amount of messages buffered for the user stream_mgmt_buffer_max = ? STREAM_MGMT_CACHE_MAX , %% server's capacity for buffering stream_mgmt_ack_freq = ? STREAM_MGMT_ACK_FREQ , %% how often the server requests acks stream_mgmt_resume_timeout = ? STREAM_MGMT_RESUME_TIMEOUT , %% resumption timeout stream_mgmt_resume_tref , %% a ref() to pattern-match a given timeout stream_mgmt_resumed_from , %% a ejabberd_sm:sid() to keep identifiying the old session stream_mgmt_constraint_check_tref , %% another ref() for a timeout, this time for buffer_full check In mod_stream_management This module is just a \"starter\", to provide the configuration values to new client connections. It also provides a basic session table API and adds a new stream feature. At a bare minimum, this module keeps the config values in its gen_mod records, and keeps a mnesia table defined as follows: 1 2 3 4 - record ( sm_session , { smid :: smid (), sid :: ejabberd_sm : sid () }). where smid is a unique identifier \u2014 in this case a random binary, and sid is an opaque session identifier from ejabberd_sm , which is needed to find the previous session we want to resume from. This module implements hooks that run on connection removals and session cleanups, in order to clean records from a dying session; and it also implements registration callbacks, used in ejabberd_c2s when a session is registered for resumption. XEP version 1.6 requires the server to attempt giving the user the value of the server's <h> when a session timed out and cannot be resumed anymore. To be compliant with it, there's a second optional table: 1 2 3 4 5 - record ( stream_mgmt_stale_h , { smid :: smid (), h :: non_neg_integer (), stamp :: non_neg_integer () }). This table is created, together with a gen_server responsible for cleaning up the tables, when stale_h is set to true with the proper garbage collection configuration. Then, when removing a record from the sm_session table (which happens when the state of the previous session is also dropped), a new record is added to this new table with the smid and h values of the dropped session, together with a timestamp. Next, when a new session attempting resumption queries mod_stream_management for the data behind a smid , mod_stream_management can answer with one of the following: 1 { sid , ejabberd_sm : sid ()} | { stale_h , non_neg_integer ()} | { error , smid_not_found }. And ejabberd_c2s will pattern-match and act accordingly.","title":"mod_stream_management"},{"location":"modules/mod_stream_management/#module-description","text":"Enables XEP-0198: Stream Management . Most of the logic regarding session resumption and acknowledgement is implemented in ejabberd_c2s , while the management of the session tables and configuration is implemented in mod_stream_management .","title":"Module Description"},{"location":"modules/mod_stream_management/#options","text":"","title":"Options"},{"location":"modules/mod_stream_management/#modulesmod_stream_managementbuffer","text":"Syntax: boolean Default: true Example: buffer = false Enables buffer for messages to be acknowledged.","title":"modules.mod_stream_management.buffer"},{"location":"modules/mod_stream_management/#modulesmod_stream_managementbuffer_max","text":"Syntax: positive integer or string \"infinity\" Default: 100 Example: buffer_max = 500 Buffer size for messages yet to be acknowledged.","title":"modules.mod_stream_management.buffer_max"},{"location":"modules/mod_stream_management/#modulesmod_stream_managementack","text":"Syntax: boolean Default: true Example: ack = false Enables ack requests to be sent from the server to the client.","title":"modules.mod_stream_management.ack"},{"location":"modules/mod_stream_management/#modulesmod_stream_managementack_freq","text":"Syntax: positive integer Default: 1 Example: ack_freq = 3 Frequency of ack requests sent from the server to the client, e.g. 1 means a request after each stanza, 3 means a request after each 3 stanzas.","title":"modules.mod_stream_management.ack_freq"},{"location":"modules/mod_stream_management/#modulesmod_stream_managementresume_timeout","text":"Syntax: positive integer, value given in seconds Default: 600 Example: resume_timeout = 600 Timeout for the session resumption. Sessions will be removed after the specified number of seconds.","title":"modules.mod_stream_management.resume_timeout"},{"location":"modules/mod_stream_management/#stale_h-options","text":"Enables keeping old server's <h> values after the resumption timed out. Disabled by default. When enabled, parameters for the garbage collection of these tables should be provided.","title":"Stale_h options"},{"location":"modules/mod_stream_management/#modulesmod_stream_managementstale_henabled","text":"Syntax: boolean Default: false Example: enabled = true Enables stale_h configuration","title":"modules.mod_stream_management.stale_h.enabled"},{"location":"modules/mod_stream_management/#modulesmod_stream_managementstale_hrepeat_after","text":"Syntax: positive integer, value given in seconds Default: 1800 (half an hour) Example: repeat_after = 1800 How often the garbage collection will run in the background to clean this table.","title":"modules.mod_stream_management.stale_h.repeat_after"},{"location":"modules/mod_stream_management/#modulesmod_stream_managementstale_hgeriatric","text":"Syntax: positive integer, value given in seconds Default: 3600 (one hour) Example: geriatric = 3600 The maximum lifespan of a record in memory. After this, they will be chased for cleanup.","title":"modules.mod_stream_management.stale_h.geriatric"},{"location":"modules/mod_stream_management/#example-configuration","text":"1 2 3 4 5 6 7 [modules.mod_stream_management] buffer_max = 30 ack_freq = 1 resume_timeout = 600 stale_h . enabled = true stale_h . repeat_after = 1800 stale_h . geriatric = 3600","title":"Example Configuration"},{"location":"modules/mod_stream_management/#implementation-details","text":"","title":"Implementation details"},{"location":"modules/mod_stream_management/#in-ejabberd_c2s","text":"The record #smgc_state{} in the ejabberd_c2s gen_fsm server keeps fields like: 1 2 3 4 5 6 7 8 9 10 11 12 stream_mgmt = false , %% whether SM is enabled, used in pattern matching inside `ejabberd_c2s` stream_mgmt_in = 0 , %% amount of msgs on the server and not acked by the user (server's <h>) stream_mgmt_id , %% the mod_stream_management:smid() unique identifier stream_mgmt_out_acked = 0 , %% messages delivered to the user, and acked by the user (user's <h>) stream_mgmt_buffer = [], %% buffered stanzas not yet acked by the user stream_mgmt_buffer_size = 0 , %% amount of messages buffered for the user stream_mgmt_buffer_max = ? STREAM_MGMT_CACHE_MAX , %% server's capacity for buffering stream_mgmt_ack_freq = ? STREAM_MGMT_ACK_FREQ , %% how often the server requests acks stream_mgmt_resume_timeout = ? STREAM_MGMT_RESUME_TIMEOUT , %% resumption timeout stream_mgmt_resume_tref , %% a ref() to pattern-match a given timeout stream_mgmt_resumed_from , %% a ejabberd_sm:sid() to keep identifiying the old session stream_mgmt_constraint_check_tref , %% another ref() for a timeout, this time for buffer_full check","title":"In ejabberd_c2s"},{"location":"modules/mod_stream_management/#in-mod_stream_management","text":"This module is just a \"starter\", to provide the configuration values to new client connections. It also provides a basic session table API and adds a new stream feature. At a bare minimum, this module keeps the config values in its gen_mod records, and keeps a mnesia table defined as follows: 1 2 3 4 - record ( sm_session , { smid :: smid (), sid :: ejabberd_sm : sid () }). where smid is a unique identifier \u2014 in this case a random binary, and sid is an opaque session identifier from ejabberd_sm , which is needed to find the previous session we want to resume from. This module implements hooks that run on connection removals and session cleanups, in order to clean records from a dying session; and it also implements registration callbacks, used in ejabberd_c2s when a session is registered for resumption. XEP version 1.6 requires the server to attempt giving the user the value of the server's <h> when a session timed out and cannot be resumed anymore. To be compliant with it, there's a second optional table: 1 2 3 4 5 - record ( stream_mgmt_stale_h , { smid :: smid (), h :: non_neg_integer (), stamp :: non_neg_integer () }). This table is created, together with a gen_server responsible for cleaning up the tables, when stale_h is set to true with the proper garbage collection configuration. Then, when removing a record from the sm_session table (which happens when the state of the previous session is also dropped), a new record is added to this new table with the smid and h values of the dropped session, together with a timestamp. Next, when a new session attempting resumption queries mod_stream_management for the data behind a smid , mod_stream_management can answer with one of the following: 1 { sid , ejabberd_sm : sid ()} | { stale_h , non_neg_integer ()} | { error , smid_not_found }. And ejabberd_c2s will pattern-match and act accordingly.","title":"In mod_stream_management"},{"location":"modules/mod_time/","text":"Module Description This module enables support for communicating the local time of an entity. It reports time in UTC according to the entity as well as the offset from UTC. Protocol is described under XEP-0202: Entity Time . Options modules.mod_time.iqdisc.type Syntax: string, one of \"one_queue\" , \"no_queue\" , \"queues\" , \"parallel\" Default: \"one_queue\" Strategy to handle incoming stanzas. For details, please refer to IQ processing policies . Example Configuration 1 [modules.mod_time]","title":"mod_time"},{"location":"modules/mod_time/#module-description","text":"This module enables support for communicating the local time of an entity. It reports time in UTC according to the entity as well as the offset from UTC. Protocol is described under XEP-0202: Entity Time .","title":"Module Description"},{"location":"modules/mod_time/#options","text":"","title":"Options"},{"location":"modules/mod_time/#modulesmod_timeiqdisctype","text":"Syntax: string, one of \"one_queue\" , \"no_queue\" , \"queues\" , \"parallel\" Default: \"one_queue\" Strategy to handle incoming stanzas. For details, please refer to IQ processing policies .","title":"modules.mod_time.iqdisc.type"},{"location":"modules/mod_time/#example-configuration","text":"1 [modules.mod_time]","title":"Example Configuration"},{"location":"modules/mod_vcard/","text":"Module Description This module provides support for vCards, as specified in XEP-0054: vcard-temp and XEP-0055: Jabber Search . Options modules.mod_vcard.iqdisc.type Syntax: string, one of \"one_queue\" , \"no_queue\" , \"queues\" , \"parallel\" Default: \"one_queue\" Strategy to handle incoming stanzas. For details, please refer to IQ processing policies . modules.mod_vcard.host Syntax: string Default: \"vjud.@HOST@\" Example: host = \"vjud.@HOST@\" Domain of the vCard User Directory, used for searching. @HOST@ is replaced with the domain(s) supported by the cluster. modules.mod_vcard.search Syntax: boolean Default: true Example: search = false Enables/disables the domain set in the previous option. false makes searching for users impossible. modules.mod_vcard.backend Syntax: string, one of \"ldap\" , \"rdbms\" , \"riak\" , \"mnesia\" Default: \"mnesia\" Example: backend = \"rdbms\" vCard storage backend. Warning: LDAP backend is read-only. modules.mod_vcard.matches Syntax: non-negative integer or the string \"infinity\" Default: 30 Example: matches = 10 Maximum search results to be returned to the user. LDAP-specific options The following options are the same as for the LDAP authentication module : modules.mod_vcard.ldap_pool_tag modules.mod_vcard.ldap_base modules.mod_vcard.ldap_uids modules.mod_vcard.ldap_filter modules.mod_vcard.ldap_deref modules.mod_vcard.ldap_vcard_map Syntax: Array of TOML tables with the following keys: \"vcard_field\" , \"ldap_pattern\" , \"ldap_field\" and string values. Default: see description Example: ldap_vcard_map = [{vcard_field = \"FN\", ldap_pattern = \"%s\", ldap_field = \"displayName\"}] Mappings between VCard and LDAP fields. For the default settings, please see [MongooseIM root]/src/mod_vcard_ldap.erl , line 79. modules.mod_vcard.ldap_search_fields Syntax: Array of TOML tables with the following keys: \"search_field\" , \"ldap_field\" and string values. Default: see description Example: ldap_search_fields = [{search_field = \"User\", ldap_field = \"%u\"}] Mappings between the human-readable search fields and LDAP fields. For the default settings, please see [MongooseIM root]/src/mod_vcard_ldap.erl , line 101. modules.mod_vcard.ldap_search_reported Syntax: Array of TOML tables with the following keys: \"search_field\" , \"vcard_field\" and string values. Default: see description Example: ldap_search_reported = [{search_field = \"Full Name\", vcard_field = \"FN\"}] Mappings between the human-readable search fields and VCard fields. For the default settings, please see [MongooseIM root]/src/mod_vcard_ldap.erl , line 114. modules.mod_vcard.ldap_search_operator Syntax: string, one of \"or\" , \"and\" Default: \"and\" Example: ldap_search_operator = \"or\" A default operator used for search query items. modules.mod_vcard.ldap_binary_search_fields Syntax: array of strings Default: [] Example: ldap_binary_search_fields = [\"User\", \"Full Name\"] An array of search fields, which values should be Base64-encoded by MongooseIM before sending to LDAP. Riak-specific options modules.mod_vcard.riak.bucket_type Syntax: string Default: \"vcard\" Example: bucket_type = \"vcard\" Riak bucket type. modules.mod_vcard.riak.search_index Syntax: string Default: \"vcard\" Example: search_index = \"vcard\" Riak index name. Example Configuration 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 [modules.mod_vcard] allow_return_all = true search_all_hosts = true matches = 1 search = true host = \"directory.example.com\" [[modules.mod_vcard.ldap_vcard_map]] vcard_field = \"FAMILY\" ldap_pattern = \"%s\" ldap_field = \"sn\" [[modules.mod_vcard.ldap_vcard_map]] vcard_field = \"FN\" ldap_pattern = \"%s\" ldap_field = \"displayName\" [[modules.mod_vcard.ldap_search_fields]] search_field = \"User\" ldap_field = \"%u\" [[modules.mod_vcard.ldap_search_fields]] search_field = \"Full Name\" ldap_field = \"displayName\" [[modules.mod_vcard.ldap_search_reported]] search_field = \"Full Name\" vcard_field = \"FN\" [[modules.mod_vcard.ldap_search_reported]] search_field = \"Given Name\" vcard_field = \"FIRST\" Metrics If you'd like to learn more about metrics in MongooseIM, please visit MongooseIM metrics page. Backend action Description (when it gets incremented) set_vcard A vCard is set in a DB. get_vcard A specific vCard is retrieved from a DB. search A vCard search is performed.","title":"mod_vcard"},{"location":"modules/mod_vcard/#module-description","text":"This module provides support for vCards, as specified in XEP-0054: vcard-temp and XEP-0055: Jabber Search .","title":"Module Description"},{"location":"modules/mod_vcard/#options","text":"","title":"Options"},{"location":"modules/mod_vcard/#modulesmod_vcardiqdisctype","text":"Syntax: string, one of \"one_queue\" , \"no_queue\" , \"queues\" , \"parallel\" Default: \"one_queue\" Strategy to handle incoming stanzas. For details, please refer to IQ processing policies .","title":"modules.mod_vcard.iqdisc.type"},{"location":"modules/mod_vcard/#modulesmod_vcardhost","text":"Syntax: string Default: \"vjud.@HOST@\" Example: host = \"vjud.@HOST@\" Domain of the vCard User Directory, used for searching. @HOST@ is replaced with the domain(s) supported by the cluster.","title":"modules.mod_vcard.host"},{"location":"modules/mod_vcard/#modulesmod_vcardsearch","text":"Syntax: boolean Default: true Example: search = false Enables/disables the domain set in the previous option. false makes searching for users impossible.","title":"modules.mod_vcard.search"},{"location":"modules/mod_vcard/#modulesmod_vcardbackend","text":"Syntax: string, one of \"ldap\" , \"rdbms\" , \"riak\" , \"mnesia\" Default: \"mnesia\" Example: backend = \"rdbms\" vCard storage backend. Warning: LDAP backend is read-only.","title":"modules.mod_vcard.backend"},{"location":"modules/mod_vcard/#modulesmod_vcardmatches","text":"Syntax: non-negative integer or the string \"infinity\" Default: 30 Example: matches = 10 Maximum search results to be returned to the user.","title":"modules.mod_vcard.matches"},{"location":"modules/mod_vcard/#ldap-specific-options","text":"The following options are the same as for the LDAP authentication module : modules.mod_vcard.ldap_pool_tag modules.mod_vcard.ldap_base modules.mod_vcard.ldap_uids modules.mod_vcard.ldap_filter modules.mod_vcard.ldap_deref","title":"LDAP-specific options"},{"location":"modules/mod_vcard/#modulesmod_vcardldap_vcard_map","text":"Syntax: Array of TOML tables with the following keys: \"vcard_field\" , \"ldap_pattern\" , \"ldap_field\" and string values. Default: see description Example: ldap_vcard_map = [{vcard_field = \"FN\", ldap_pattern = \"%s\", ldap_field = \"displayName\"}] Mappings between VCard and LDAP fields. For the default settings, please see [MongooseIM root]/src/mod_vcard_ldap.erl , line 79.","title":"modules.mod_vcard.ldap_vcard_map"},{"location":"modules/mod_vcard/#modulesmod_vcardldap_search_fields","text":"Syntax: Array of TOML tables with the following keys: \"search_field\" , \"ldap_field\" and string values. Default: see description Example: ldap_search_fields = [{search_field = \"User\", ldap_field = \"%u\"}] Mappings between the human-readable search fields and LDAP fields. For the default settings, please see [MongooseIM root]/src/mod_vcard_ldap.erl , line 101.","title":"modules.mod_vcard.ldap_search_fields"},{"location":"modules/mod_vcard/#modulesmod_vcardldap_search_reported","text":"Syntax: Array of TOML tables with the following keys: \"search_field\" , \"vcard_field\" and string values. Default: see description Example: ldap_search_reported = [{search_field = \"Full Name\", vcard_field = \"FN\"}] Mappings between the human-readable search fields and VCard fields. For the default settings, please see [MongooseIM root]/src/mod_vcard_ldap.erl , line 114.","title":"modules.mod_vcard.ldap_search_reported"},{"location":"modules/mod_vcard/#modulesmod_vcardldap_search_operator","text":"Syntax: string, one of \"or\" , \"and\" Default: \"and\" Example: ldap_search_operator = \"or\" A default operator used for search query items.","title":"modules.mod_vcard.ldap_search_operator"},{"location":"modules/mod_vcard/#modulesmod_vcardldap_binary_search_fields","text":"Syntax: array of strings Default: [] Example: ldap_binary_search_fields = [\"User\", \"Full Name\"] An array of search fields, which values should be Base64-encoded by MongooseIM before sending to LDAP.","title":"modules.mod_vcard.ldap_binary_search_fields"},{"location":"modules/mod_vcard/#riak-specific-options","text":"","title":"Riak-specific options"},{"location":"modules/mod_vcard/#modulesmod_vcardriakbucket_type","text":"Syntax: string Default: \"vcard\" Example: bucket_type = \"vcard\" Riak bucket type.","title":"modules.mod_vcard.riak.bucket_type"},{"location":"modules/mod_vcard/#modulesmod_vcardriaksearch_index","text":"Syntax: string Default: \"vcard\" Example: search_index = \"vcard\" Riak index name.","title":"modules.mod_vcard.riak.search_index"},{"location":"modules/mod_vcard/#example-configuration","text":"1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 [modules.mod_vcard] allow_return_all = true search_all_hosts = true matches = 1 search = true host = \"directory.example.com\" [[modules.mod_vcard.ldap_vcard_map]] vcard_field = \"FAMILY\" ldap_pattern = \"%s\" ldap_field = \"sn\" [[modules.mod_vcard.ldap_vcard_map]] vcard_field = \"FN\" ldap_pattern = \"%s\" ldap_field = \"displayName\" [[modules.mod_vcard.ldap_search_fields]] search_field = \"User\" ldap_field = \"%u\" [[modules.mod_vcard.ldap_search_fields]] search_field = \"Full Name\" ldap_field = \"displayName\" [[modules.mod_vcard.ldap_search_reported]] search_field = \"Full Name\" vcard_field = \"FN\" [[modules.mod_vcard.ldap_search_reported]] search_field = \"Given Name\" vcard_field = \"FIRST\"","title":"Example Configuration"},{"location":"modules/mod_vcard/#metrics","text":"If you'd like to learn more about metrics in MongooseIM, please visit MongooseIM metrics page. Backend action Description (when it gets incremented) set_vcard A vCard is set in a DB. get_vcard A specific vCard is retrieved from a DB. search A vCard search is performed.","title":"Metrics"},{"location":"modules/mod_version/","text":"Module description This module provides the functionality specified in XEP-0092: Software Version . Options modules.mod_version.iqdisc.type Syntax: string, one of \"one_queue\" , \"no_queue\" , \"queues\" , \"parallel\" Default: \"one_queue\" Strategy to handle incoming stanzas. For details, please refer to IQ processing policies . modules.mod_version.os_info Syntax: boolean Default: false Example: os_info = true Determines whether information about the operating system will be included. Example configuration 1 2 [modules.mod_version] os_info = true","title":"mod_version"},{"location":"modules/mod_version/#module-description","text":"This module provides the functionality specified in XEP-0092: Software Version .","title":"Module description"},{"location":"modules/mod_version/#options","text":"","title":"Options"},{"location":"modules/mod_version/#modulesmod_versioniqdisctype","text":"Syntax: string, one of \"one_queue\" , \"no_queue\" , \"queues\" , \"parallel\" Default: \"one_queue\" Strategy to handle incoming stanzas. For details, please refer to IQ processing policies .","title":"modules.mod_version.iqdisc.type"},{"location":"modules/mod_version/#modulesmod_versionos_info","text":"Syntax: boolean Default: false Example: os_info = true Determines whether information about the operating system will be included.","title":"modules.mod_version.os_info"},{"location":"modules/mod_version/#example-configuration","text":"1 2 [modules.mod_version] os_info = true","title":"Example configuration"},{"location":"open-extensions/inbox/","text":"When a messaging client starts, it typically builds a UI showing a list of recent chats, with metadata attached to them like, whether any chat has new messages and how many, or if it is fully read, or if they are for example muted and until when. Terminology: The Inbox It is personal to a given user and represents the current status of the conversations of that user. It's the front-page of the chat feature. Inbox entry It is a specific conversation, that the user can identify by the recipient jid, that is, the user jid in case of a one-to-one chat, or the room jid in case of a group-chat. Box (also referred to as \"folder\") A category where entries can be classified. The default box is the active box, simply called inbox . There is a second box, called archive , where entries can be thrown into and not displayed by default. No more boxes are expected. Entity Use Cases Discovering Inbox Services An entity can discover the inbox service via a Features Discovery request: 1 2 3 4 5 6 7 8 9 10 11 12 <!-- Client --> <iq type= 'get' id= 'a96d4244760853af7b3ae84faa1a40fb' to= 'localhost' > <query xmlns= 'http://jabber.org/protocol/disco#info' /> </iq> <!-- Server --> <iq from= 'localhost' to= 'alice@localhost/res1' id= 'a96d4244760853af7b3ae84faa1a40fb' type= 'result' > <query xmlns= 'http://jabber.org/protocol/disco#info' > <identity category= 'server' type= 'im' name= 'MongooseIM' /> <feature var= 'erlang-solutions.com:xmpp:inbox:0' /> </query> </iq> Fetching the inbox Querying The inbox is fetched using regular XMPP Data Forms . To request the supported form, the client should send: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 <!-- Client --> <iq type= 'get' id= 'some_unique_id' > <query xmlns= 'erlang-solutions.com:xmpp:inbox:0' /> </iq> <!-- Server --> <iq from= 'alice@localhost' to= 'alice@localhost/res1' id= 'some_unique_id' type= 'result' > <query xmlns= 'erlang-solutions.com:xmpp:inbox:0' > <x xmlns= 'jabber:x:data' type= 'form' > <field type= 'hidden' var= 'FORM_TYPE' ><value> erlang-solutions.com:xmpp:inbox:0 </value></field> <field var= 'start' type= 'text-single' /> <field var= 'end' type= 'text-single' /> <field var= 'order' type= 'list-single' > <value> desc </value> <option label= 'Ascending by timestamp' ><value> asc </value></option> <option label= 'Descending by timestamp' ><value> desc </value></option> </field> <field var= 'hidden_read' type= 'text-single' value= 'false' /> <field var= 'archive' type= 'boolean' /> </x> </query> </iq> To fetch the inbox, the client should send: 1 2 3 <iq type= 'set' id= '10bca' > <inbox xmlns= 'erlang-solutions.com:xmpp:inbox:0' queryid= 'b6' /> </iq> Then the client should receive: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 <message from= \"alice@localhost\" to= \"alice@localhost/res1\" id= \"9b759\" > <result xmlns= \"erlang-solutions.com:xmpp:inbox:0\" unread= \"0\" queryid= \"b6\" > <forwarded xmlns= \"urn:xmpp:forward:0\" > <delay xmlns= \"urn:xmpp:delay\" stamp= \"2018-07-10T23:08:25.123456Z\" /> <message xml:lang= \"en\" type= \"chat\" to= \"bob@localhost/res1\" from= \"alice@localhost/res1\" id= \u201d123\u201d > <body> Hello </body> </message> </forwarded> <archive> false </archive> <mute> 0 </mute> </result> </message> <iq from= \"alice@localhost\" to= \"alice@localhost/res1\" id= \"b6\" type= \"result\" > <fin xmlns= 'erlang-solutions.com:xmpp:inbox:0' > <count> 1 </count> <unread-messages> 0 </unread-messages> <active-conversations> 0 </active-conversations> </fin> </iq> where none-or-many message stanzas are sent to the requesting resource describing each inbox entry, and a final iq-fin stanza marks the end of the inbox query, Inbox query result IQ stanza returns the following values: count : the total number of conversations (if hidden_read value was set to true, this value will be equal to active_conversations ) unread-messages : total number of unread messages from all conversations active-conversations : the number of conversations with unread message(s) Filtering and ordering Inbox query results may be filtered by time range and box, and sorted by timestamp. By default, mod_inbox returns all conversations, listing the ones updated most recently first. A client may specify the following parameters: variable start : Start date for the result set (value: ISO timestamp) variable end : End date for the result set (value: ISO timestamp) variable order : Order by timestamp (values: asc , desc ) variable hidden_read : Show only conversations with unread messages (values: true , false ) variable archive : whether to query the archive inbox. true means querying only the archive box, false means querying only the active box. If the flag is not set, it is assumed all entries are requested. They are encoded inside a standard XMPP Data Forms format. Dates must be formatted according to XMPP Date and Time Profiles . It is not mandatory to add an empty data form if a client prefers to use default values ( <inbox/> element may be empty). However, the IQ type must be \"set\", even when the data form is missing. Limiting the query It can happen that the amount of inbox entries is too big for a given user, even after filtering by start and end as already available in mod_inbox . Hence, we need to set a fixed limit of the number of entries that are requested. For this, we can use a <max> attribute as defined in XEP-0059: #2.1 Limiting the Number of Items : 1 2 3 4 5 6 7 8 9 10 11 12 13 <iq type= 'set' id= '10bca' > <inbox xmlns= 'erlang-solutions.com:xmpp:inbox:0' queryid= 'b6' > <x xmlns= 'jabber:x:data' type= 'form' > <field type= 'hidden' var= 'FORM_TYPE' ><value> erlang-solutions.com:xmpp:inbox:0 </value></field> <field type= 'list-single' var= 'order' ><value> asc </value></field> <field type= 'text-single' var= 'hidden_read' ><value> true </value></field> <field type= 'boolean' var= 'archive' ><value> false </value></field> </x> <set xmlns= 'http://jabber.org/protocol/rsm' > <max> Max </max> </set> </inbox> </iq> where Max is a non-negative integer. Properties of an entry Given an entry, certain properties are defined for such an entry: Archived Clients usually have two different boxes for the inbox: the regular one, simply called the inbox (or the active inbox), and an archive box, where clients can manually throw conversations they don't want displayed in the default UI. It is expected that entries will reside in the archive until they're either manually moved back to the active box, or they receive a new message: in such case the entry should jump back to the active box automatically. Read Entries keep a count of unread messages that is incremented automatically upon receiving a new message, and (in the current implementation) set to zero upon receiving either a message by one-self, or an appropriate chat marker as defined in XEP-0333 (which markers reset the count is a matter of configuration, see doc ). This property can also be manually set to zero or to one using the appropriate requests as explained below. Muted Entries can be muted for given periods of time, and likewise, unmuted. This changes the UI representation, and also, means that the user won't get PNs (Push Notifications) for this entry, until the time set expires or the user sets otherwise. Knowledge of this is necessary to help build the UI. Expected times can be extended before the period has expired, without the need to first unmuting. When muting a conversation, the final timestamp will be calculated by the server as the current time plus the requested period, in seconds, to centralise knowledge of UTC clocks. When muting an already muted conversation, the timestamp is simply overridden following the previous specification. Other properties No more properties are expected, but one could envisage notions of flagging conversations with different colours, for example according to their urgency, or a client-specific category (work, personal, fitness, and whatnot), or pins to denote an entry should be always displayed (possibly in a special format, like on top of the box). The design of the protocol, and the implementation, aims to leave room for future extensions. Getting properties To fetch all supported properties, a classic Data Form is used. Upon the client sending an iq-get without a jid: 1 2 3 <iq id= 'some_unique_id' type= 'get' > <query xmlns= 'erlang-solutions.com:xmpp:inbox:0#conversation' /> </iq> The server would respond with: 1 2 3 4 5 6 7 8 9 10 <iq from= 'alice@localhost' to= 'alice@localhost/res1' id= 'some_unique_id' type= 'result' > <query xmlns= 'erlang-solutions.com:xmpp:inbox:0#conversation' > <x xmlns= 'jabber:x:data' type= 'form' > <field type= 'hidden' var= 'FORM_TYPE' ><value> erlang-solutions.com:xmpp:inbox:0 </value></field> <field var= 'archive' type= 'boolean' value= 'false' /> <field var= 'read' type= 'boolean' value= 'false' /> <field var= 'mute' type= 'text-single' value= '0' /> </x> </query> </iq> If the properties of a certain entry were to be fetched, it can easily be done with: 1 2 3 <iq id= 'some_unique_id' type= 'get' > <query xmlns= 'erlang-solutions.com:xmpp:inbox:0#conversation' jid= 'bob@localhost' /> </iq> To which the server will reply, just like before, with: 1 2 3 4 5 6 7 <iq id= 'some_unique_id' to= 'alice@localhost/res1' type= 'result' > <query xmlns= 'erlang-solutions.com:xmpp:inbox:0#conversation' > <archive> false </archive> <mute> 0 </mute> <read> true </read> </query> </iq> Setting properties Setting properties is done using the standard XMPP pattern of iq-query and iq-result , as below: 1 2 3 4 5 6 <iq id= 'some_unique_id' type= 'set' > <query xmlns= 'erlang-solutions.com:xmpp:inbox:0#conversation' jid= 'bob@localhost' > <Property> Value </Property> <!-- Possibly other properties --> </query> </iq> Where Property and Value are a list of key-value pairs as follows: - archive : true or false - mute : number of seconds to mute for. Choose 0 for unmuting. - read (adjective, not verb): true or false . Setting to true essentially sets the unread-count to 0 , false sets the unread-count to 1 (if it was equal to 0 , otherwise it lefts it unchanged). No other possibilities are offered, to reduce the risk of inconsistencies or problems induced by a faulty client. Note that resetting the inbox count will not be forwarded. While a chat marker will be forwarded to the interlocutor(s), (including the case of a big groupchat with thousands of participants), this reset stanza will not. If the query was successful, the server will answer with two stanzas, following the classic pattern of broadcasting state changes. First, it would send a message with a <x> children containing all new configuration, to the bare-jid of the user: this facilitates broadcasting to all online resources to successfully synchronise their interfaces. 1 2 3 4 5 6 7 <message from= 'alice@localhost' to= 'alice@localhost' id= 'some_unique_id' > <x xmlns= 'erlang-solutions.com:xmpp:inbox:0#conversation' jid= 'bob@localhost' > <archive> false </archive> <mute> 0 </mute> <read> true </read> </x> </message> where <mute> may contain either a zero, to denote unmuted, or a RFC3339 timestamp, as in 2021-02-25T08:44:14.323836Z . To the requesting resource, a simple iq-result would be then sent to notify of success, as required by the iq directives of the XMPP RFCs: 1 <iq id= 'some_unique_id' to= 'alice@localhost/res1' type= 'result' /> If the request was not successful, the server would then answer as in: 1 2 3 4 5 <iq to= 'alice@localhost/res1' type= 'error' > <error type= 'Type' > <Condition xmlns= 'urn:ietf:params:xml:ns:xmpp-stanzas' /> </error> </iq> Where Type will usually be modify or cancel , as explained in https://xmpp.org/rfcs/rfc6120.html#stanzas-error-syntax , and Condition is as explained in https://xmpp.org/rfcs/rfc6120.html#stanzas-error-conditions , bad-request being the most common. This final syntax for the protocol has been chosen as it allows for better pipelining of requests, and it remains consistent with how, for example, rooms are configured for MUC-Light. Examples: archiving an entry To archive an entry, the client can send: 1 2 3 4 5 <iq id= 'some_unique_id' type= 'set' > <query xmlns= 'erlang-solutions.com:xmpp:inbox:0#conversation' jid= 'bob@localhost' > <archive> true </archive> </query> </iq> On success, the server would return (considering the entry has no unread messages and is not muted): 1 2 3 4 5 6 7 <iq id= 'some_unique_id' to= 'alice@localhost/res1' type= 'result' > <query xmlns= 'erlang-solutions.com:xmpp:inbox:0#conversation' jid= 'bob@localhost' > <archive> true </archive> <mute> 0 </mute> <read> true </read> </query> </iq> If the client had sent an invalid number (negative, or NaN), the server would answer: 1 2 3 4 5 <iq to= 'alice@localhost/res1' type= 'error' > <error type= 'modify' > <bad-request xmlns= 'urn:ietf:params:xml:ns:xmpp-stanzas' /> </error> </iq> Examples: muting an entry To mute an entry for a full day (86400 seconds in a day, 604800 in a week, for example), a client can send: 1 2 3 4 5 <iq id= 'some_unique_id' type= 'set' > <query xmlns= 'erlang-solutions.com:xmpp:inbox:0#conversation' jid= 'bob@localhost' > <mute> 86400 </mute> </query> </iq> On success, the server would return (considering the server receives the timestamp on \"2021-02-26T09:11:05.634232Z\", and the entry is on the active box and completely read): 1 2 3 4 5 6 7 <iq id= 'some_unique_id' to= 'alice@localhost/res1' type= 'result' > <query xmlns= 'erlang-solutions.com:xmpp:inbox:0#conversation' jid= 'bob@localhost' > <archive> false </archive> <mute> 2021-02-27T09:11:05.634232Z </mute> <read> true </read> </query> </iq> If the client had sent an invalid number (negative, or NaN), the server would answer: 1 2 3 4 5 <iq to= 'alice@localhost/res1' type= 'error' > <error type= 'modify' > <bad-request xmlns= 'urn:ietf:params:xml:ns:xmpp-stanzas' /> </error> </iq> To unmute, similarly, the client can send: 1 2 3 4 5 <iq id= 'some_unique_id' type= 'set' > <query xmlns= 'erlang-solutions.com:xmpp:inbox:0#conversation' jid= 'bob@localhost' > <mute> 0 </mute> </query> </iq> And server responses will be similar. Examples: reading an entry To set an entry as read, the client can send: 1 2 3 4 5 <iq id= 'some_unique_id' type= 'set' > <query xmlns= 'erlang-solutions.com:xmpp:inbox:0#conversation' jid= 'bob@localhost' > <read> true </read> </query> </iq> On success, the server would return (considering the entry is not archived and not muted): 1 2 3 4 5 6 7 <iq id= 'some_unique_id' to= 'alice@localhost/res1' type= 'result' > <query xmlns= 'erlang-solutions.com:xmpp:inbox:0#conversation' jid= 'bob@localhost' > <archive> false </archive> <mute> 0 </mute> <read> true </read> </query> </iq> On error, as usual, the client would get: 1 2 3 4 5 <iq to= 'alice@localhost/res1' type= 'error' > <error type= 'modify' > <bad-request xmlns= 'urn:ietf:params:xml:ns:xmpp-stanzas' /> </error> </iq> And similarly, to set a conversation as unread: 1 2 3 4 5 <iq id= 'some_unique_id' type= 'set' > <query xmlns= 'erlang-solutions.com:xmpp:inbox:0#conversation' jid= 'bob@localhost' > <read> false </read> </query> </iq> Deprecated entry stanza: You can reset the inbox with the following stanza: 1 2 3 <iq type= 'set' > <reset xmlns= 'erlang-solutions.com:xmpp:inbox:0#conversation' jid= 'interlocutor_bare_jid' /> </iq> Here jid is the bare jid of the user whose inbox we want to reset. This action does not change the last message stored in inbox; meaning that neither this stanza nor anything given within will be stored; the only change is the inbox unread_count is set to zero. Example request 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 <!-- Alice sends: --> <message type= \"chat\" to= \"bob@localhost/res1\" id= \u201d123\u201d > <body> Hello </body> </message> <!-- Bob receives: --> <message from= \"alice@localhost/res1\" to= \"bob@localhost/res1\" id= \u201c123\u201d xml:lang= \"en\" type= \"chat\" > <body> Hello </body> </message> <!-- Alice sends: --> <iq type= \"set\" id= \"10bca\" > <inbox xmlns= \u201derlang-solutions.com:xmpp:inbox:0\u201d queryid= \"b6\" > <x xmlns= 'jabber:x:data' type= 'form' > <field type= 'hidden' var= 'FORM_TYPE' ><value> erlang-solutions.com:xmpp:inbox:0 </value></field> <field type= 'text-single' var= 'start' ><value> 2018-07-10T12:00:00Z </value></field> <field type= 'text-single' var= 'end' ><value> 2018-07-11T12:00:00Z </value></field> <field type= 'list-single' var= 'order' ><value> asc </value></field> </x> </inbox> </iq> <!-- Alice receives: --> <message from= \"alice@localhost\" to= \"alice@localhost\" id= \"9b759\" > <result xmlns= \"erlang-solutions.com:xmpp:inbox:0\" unread= \"0\" queryid= \"b6\" > <forwarded xmlns= \"urn:xmpp:forward:0\" > <delay xmlns= \"urn:xmpp:delay\" stamp= \"2018-07-10T23:08:25.123456Z\" /> <message xml:lang= \"en\" type= \"chat\" to= \"bob@localhost/res1\" from= \"alice@localhost/res1\" id= \u201d123\u201d > <body> Hello </body> </message> </forwarded> <archive> false </archive> <mute> 0 </mute> </result> </message> <iq from= \"alice@localhost\" to= \"alice@localhost/res1\" id= \"10bca\" type= \"result\" > <fin xmlns= 'erlang-solutions.com:xmpp:inbox:0' > <count> 1 </count> <unread-messages> 0 </unread-messages> <active-conversations> 0 </active-conversations> </fin> </iq> Example error response 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 <!--Alice sends request with invalid value of start field: --> <iq type= 'set' id= 'a78478f20103ff8354d7834d0ba2fdb2' > <inbox xmlns= 'erlang-solutions.com:xmpp:inbox:0' > <x xmlns= 'jabber:x:data' type= 'submit' > <field type= 'text-single' var= 'start' > <value> invalid </value> </field> </x> </inbox> </iq> <!--Alice receives an error with description of the first encountered invalid value: --> <iq from= 'alice@localhost' to= 'alice@localhost/res1' id= 'a78478f20103ff8354d7834d0ba2fdb2' type= 'error' > <error code= '400' type= 'modify' > <bad-rquest xmlns= 'urn:ietf:params:xml:ns:xmpp-stanzas' /> <text xmlns= 'urn:ietf:params:xml:ns:xmpp-stanzas' > Invalid inbox form field value, field=start, value=invalid </text> </error> </iq>","title":"Inbox"},{"location":"open-extensions/inbox/#terminology","text":"","title":"Terminology:"},{"location":"open-extensions/inbox/#the-inbox","text":"It is personal to a given user and represents the current status of the conversations of that user. It's the front-page of the chat feature.","title":"The Inbox"},{"location":"open-extensions/inbox/#inbox-entry","text":"It is a specific conversation, that the user can identify by the recipient jid, that is, the user jid in case of a one-to-one chat, or the room jid in case of a group-chat.","title":"Inbox entry"},{"location":"open-extensions/inbox/#box-also-referred-to-as-folder","text":"A category where entries can be classified. The default box is the active box, simply called inbox . There is a second box, called archive , where entries can be thrown into and not displayed by default. No more boxes are expected.","title":"Box (also referred to as \"folder\")"},{"location":"open-extensions/inbox/#entity-use-cases","text":"","title":"Entity Use Cases"},{"location":"open-extensions/inbox/#discovering-inbox-services","text":"An entity can discover the inbox service via a Features Discovery request: 1 2 3 4 5 6 7 8 9 10 11 12 <!-- Client --> <iq type= 'get' id= 'a96d4244760853af7b3ae84faa1a40fb' to= 'localhost' > <query xmlns= 'http://jabber.org/protocol/disco#info' /> </iq> <!-- Server --> <iq from= 'localhost' to= 'alice@localhost/res1' id= 'a96d4244760853af7b3ae84faa1a40fb' type= 'result' > <query xmlns= 'http://jabber.org/protocol/disco#info' > <identity category= 'server' type= 'im' name= 'MongooseIM' /> <feature var= 'erlang-solutions.com:xmpp:inbox:0' /> </query> </iq>","title":"Discovering Inbox Services"},{"location":"open-extensions/inbox/#fetching-the-inbox","text":"","title":"Fetching the inbox"},{"location":"open-extensions/inbox/#querying","text":"The inbox is fetched using regular XMPP Data Forms . To request the supported form, the client should send: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 <!-- Client --> <iq type= 'get' id= 'some_unique_id' > <query xmlns= 'erlang-solutions.com:xmpp:inbox:0' /> </iq> <!-- Server --> <iq from= 'alice@localhost' to= 'alice@localhost/res1' id= 'some_unique_id' type= 'result' > <query xmlns= 'erlang-solutions.com:xmpp:inbox:0' > <x xmlns= 'jabber:x:data' type= 'form' > <field type= 'hidden' var= 'FORM_TYPE' ><value> erlang-solutions.com:xmpp:inbox:0 </value></field> <field var= 'start' type= 'text-single' /> <field var= 'end' type= 'text-single' /> <field var= 'order' type= 'list-single' > <value> desc </value> <option label= 'Ascending by timestamp' ><value> asc </value></option> <option label= 'Descending by timestamp' ><value> desc </value></option> </field> <field var= 'hidden_read' type= 'text-single' value= 'false' /> <field var= 'archive' type= 'boolean' /> </x> </query> </iq> To fetch the inbox, the client should send: 1 2 3 <iq type= 'set' id= '10bca' > <inbox xmlns= 'erlang-solutions.com:xmpp:inbox:0' queryid= 'b6' /> </iq> Then the client should receive: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 <message from= \"alice@localhost\" to= \"alice@localhost/res1\" id= \"9b759\" > <result xmlns= \"erlang-solutions.com:xmpp:inbox:0\" unread= \"0\" queryid= \"b6\" > <forwarded xmlns= \"urn:xmpp:forward:0\" > <delay xmlns= \"urn:xmpp:delay\" stamp= \"2018-07-10T23:08:25.123456Z\" /> <message xml:lang= \"en\" type= \"chat\" to= \"bob@localhost/res1\" from= \"alice@localhost/res1\" id= \u201d123\u201d > <body> Hello </body> </message> </forwarded> <archive> false </archive> <mute> 0 </mute> </result> </message> <iq from= \"alice@localhost\" to= \"alice@localhost/res1\" id= \"b6\" type= \"result\" > <fin xmlns= 'erlang-solutions.com:xmpp:inbox:0' > <count> 1 </count> <unread-messages> 0 </unread-messages> <active-conversations> 0 </active-conversations> </fin> </iq> where none-or-many message stanzas are sent to the requesting resource describing each inbox entry, and a final iq-fin stanza marks the end of the inbox query, Inbox query result IQ stanza returns the following values: count : the total number of conversations (if hidden_read value was set to true, this value will be equal to active_conversations ) unread-messages : total number of unread messages from all conversations active-conversations : the number of conversations with unread message(s)","title":"Querying"},{"location":"open-extensions/inbox/#filtering-and-ordering","text":"Inbox query results may be filtered by time range and box, and sorted by timestamp. By default, mod_inbox returns all conversations, listing the ones updated most recently first. A client may specify the following parameters: variable start : Start date for the result set (value: ISO timestamp) variable end : End date for the result set (value: ISO timestamp) variable order : Order by timestamp (values: asc , desc ) variable hidden_read : Show only conversations with unread messages (values: true , false ) variable archive : whether to query the archive inbox. true means querying only the archive box, false means querying only the active box. If the flag is not set, it is assumed all entries are requested. They are encoded inside a standard XMPP Data Forms format. Dates must be formatted according to XMPP Date and Time Profiles . It is not mandatory to add an empty data form if a client prefers to use default values ( <inbox/> element may be empty). However, the IQ type must be \"set\", even when the data form is missing.","title":"Filtering and ordering"},{"location":"open-extensions/inbox/#limiting-the-query","text":"It can happen that the amount of inbox entries is too big for a given user, even after filtering by start and end as already available in mod_inbox . Hence, we need to set a fixed limit of the number of entries that are requested. For this, we can use a <max> attribute as defined in XEP-0059: #2.1 Limiting the Number of Items : 1 2 3 4 5 6 7 8 9 10 11 12 13 <iq type= 'set' id= '10bca' > <inbox xmlns= 'erlang-solutions.com:xmpp:inbox:0' queryid= 'b6' > <x xmlns= 'jabber:x:data' type= 'form' > <field type= 'hidden' var= 'FORM_TYPE' ><value> erlang-solutions.com:xmpp:inbox:0 </value></field> <field type= 'list-single' var= 'order' ><value> asc </value></field> <field type= 'text-single' var= 'hidden_read' ><value> true </value></field> <field type= 'boolean' var= 'archive' ><value> false </value></field> </x> <set xmlns= 'http://jabber.org/protocol/rsm' > <max> Max </max> </set> </inbox> </iq> where Max is a non-negative integer.","title":"Limiting the query"},{"location":"open-extensions/inbox/#properties-of-an-entry","text":"Given an entry, certain properties are defined for such an entry:","title":"Properties of an entry"},{"location":"open-extensions/inbox/#archived","text":"Clients usually have two different boxes for the inbox: the regular one, simply called the inbox (or the active inbox), and an archive box, where clients can manually throw conversations they don't want displayed in the default UI. It is expected that entries will reside in the archive until they're either manually moved back to the active box, or they receive a new message: in such case the entry should jump back to the active box automatically.","title":"Archived"},{"location":"open-extensions/inbox/#read","text":"Entries keep a count of unread messages that is incremented automatically upon receiving a new message, and (in the current implementation) set to zero upon receiving either a message by one-self, or an appropriate chat marker as defined in XEP-0333 (which markers reset the count is a matter of configuration, see doc ). This property can also be manually set to zero or to one using the appropriate requests as explained below.","title":"Read"},{"location":"open-extensions/inbox/#muted","text":"Entries can be muted for given periods of time, and likewise, unmuted. This changes the UI representation, and also, means that the user won't get PNs (Push Notifications) for this entry, until the time set expires or the user sets otherwise. Knowledge of this is necessary to help build the UI. Expected times can be extended before the period has expired, without the need to first unmuting. When muting a conversation, the final timestamp will be calculated by the server as the current time plus the requested period, in seconds, to centralise knowledge of UTC clocks. When muting an already muted conversation, the timestamp is simply overridden following the previous specification.","title":"Muted"},{"location":"open-extensions/inbox/#other-properties","text":"No more properties are expected, but one could envisage notions of flagging conversations with different colours, for example according to their urgency, or a client-specific category (work, personal, fitness, and whatnot), or pins to denote an entry should be always displayed (possibly in a special format, like on top of the box). The design of the protocol, and the implementation, aims to leave room for future extensions.","title":"Other properties"},{"location":"open-extensions/inbox/#getting-properties","text":"To fetch all supported properties, a classic Data Form is used. Upon the client sending an iq-get without a jid: 1 2 3 <iq id= 'some_unique_id' type= 'get' > <query xmlns= 'erlang-solutions.com:xmpp:inbox:0#conversation' /> </iq> The server would respond with: 1 2 3 4 5 6 7 8 9 10 <iq from= 'alice@localhost' to= 'alice@localhost/res1' id= 'some_unique_id' type= 'result' > <query xmlns= 'erlang-solutions.com:xmpp:inbox:0#conversation' > <x xmlns= 'jabber:x:data' type= 'form' > <field type= 'hidden' var= 'FORM_TYPE' ><value> erlang-solutions.com:xmpp:inbox:0 </value></field> <field var= 'archive' type= 'boolean' value= 'false' /> <field var= 'read' type= 'boolean' value= 'false' /> <field var= 'mute' type= 'text-single' value= '0' /> </x> </query> </iq> If the properties of a certain entry were to be fetched, it can easily be done with: 1 2 3 <iq id= 'some_unique_id' type= 'get' > <query xmlns= 'erlang-solutions.com:xmpp:inbox:0#conversation' jid= 'bob@localhost' /> </iq> To which the server will reply, just like before, with: 1 2 3 4 5 6 7 <iq id= 'some_unique_id' to= 'alice@localhost/res1' type= 'result' > <query xmlns= 'erlang-solutions.com:xmpp:inbox:0#conversation' > <archive> false </archive> <mute> 0 </mute> <read> true </read> </query> </iq>","title":"Getting properties"},{"location":"open-extensions/inbox/#setting-properties","text":"Setting properties is done using the standard XMPP pattern of iq-query and iq-result , as below: 1 2 3 4 5 6 <iq id= 'some_unique_id' type= 'set' > <query xmlns= 'erlang-solutions.com:xmpp:inbox:0#conversation' jid= 'bob@localhost' > <Property> Value </Property> <!-- Possibly other properties --> </query> </iq> Where Property and Value are a list of key-value pairs as follows: - archive : true or false - mute : number of seconds to mute for. Choose 0 for unmuting. - read (adjective, not verb): true or false . Setting to true essentially sets the unread-count to 0 , false sets the unread-count to 1 (if it was equal to 0 , otherwise it lefts it unchanged). No other possibilities are offered, to reduce the risk of inconsistencies or problems induced by a faulty client. Note that resetting the inbox count will not be forwarded. While a chat marker will be forwarded to the interlocutor(s), (including the case of a big groupchat with thousands of participants), this reset stanza will not. If the query was successful, the server will answer with two stanzas, following the classic pattern of broadcasting state changes. First, it would send a message with a <x> children containing all new configuration, to the bare-jid of the user: this facilitates broadcasting to all online resources to successfully synchronise their interfaces. 1 2 3 4 5 6 7 <message from= 'alice@localhost' to= 'alice@localhost' id= 'some_unique_id' > <x xmlns= 'erlang-solutions.com:xmpp:inbox:0#conversation' jid= 'bob@localhost' > <archive> false </archive> <mute> 0 </mute> <read> true </read> </x> </message> where <mute> may contain either a zero, to denote unmuted, or a RFC3339 timestamp, as in 2021-02-25T08:44:14.323836Z . To the requesting resource, a simple iq-result would be then sent to notify of success, as required by the iq directives of the XMPP RFCs: 1 <iq id= 'some_unique_id' to= 'alice@localhost/res1' type= 'result' /> If the request was not successful, the server would then answer as in: 1 2 3 4 5 <iq to= 'alice@localhost/res1' type= 'error' > <error type= 'Type' > <Condition xmlns= 'urn:ietf:params:xml:ns:xmpp-stanzas' /> </error> </iq> Where Type will usually be modify or cancel , as explained in https://xmpp.org/rfcs/rfc6120.html#stanzas-error-syntax , and Condition is as explained in https://xmpp.org/rfcs/rfc6120.html#stanzas-error-conditions , bad-request being the most common. This final syntax for the protocol has been chosen as it allows for better pipelining of requests, and it remains consistent with how, for example, rooms are configured for MUC-Light.","title":"Setting properties"},{"location":"open-extensions/inbox/#examples-archiving-an-entry","text":"To archive an entry, the client can send: 1 2 3 4 5 <iq id= 'some_unique_id' type= 'set' > <query xmlns= 'erlang-solutions.com:xmpp:inbox:0#conversation' jid= 'bob@localhost' > <archive> true </archive> </query> </iq> On success, the server would return (considering the entry has no unread messages and is not muted): 1 2 3 4 5 6 7 <iq id= 'some_unique_id' to= 'alice@localhost/res1' type= 'result' > <query xmlns= 'erlang-solutions.com:xmpp:inbox:0#conversation' jid= 'bob@localhost' > <archive> true </archive> <mute> 0 </mute> <read> true </read> </query> </iq> If the client had sent an invalid number (negative, or NaN), the server would answer: 1 2 3 4 5 <iq to= 'alice@localhost/res1' type= 'error' > <error type= 'modify' > <bad-request xmlns= 'urn:ietf:params:xml:ns:xmpp-stanzas' /> </error> </iq>","title":"Examples: archiving an entry"},{"location":"open-extensions/inbox/#examples-muting-an-entry","text":"To mute an entry for a full day (86400 seconds in a day, 604800 in a week, for example), a client can send: 1 2 3 4 5 <iq id= 'some_unique_id' type= 'set' > <query xmlns= 'erlang-solutions.com:xmpp:inbox:0#conversation' jid= 'bob@localhost' > <mute> 86400 </mute> </query> </iq> On success, the server would return (considering the server receives the timestamp on \"2021-02-26T09:11:05.634232Z\", and the entry is on the active box and completely read): 1 2 3 4 5 6 7 <iq id= 'some_unique_id' to= 'alice@localhost/res1' type= 'result' > <query xmlns= 'erlang-solutions.com:xmpp:inbox:0#conversation' jid= 'bob@localhost' > <archive> false </archive> <mute> 2021-02-27T09:11:05.634232Z </mute> <read> true </read> </query> </iq> If the client had sent an invalid number (negative, or NaN), the server would answer: 1 2 3 4 5 <iq to= 'alice@localhost/res1' type= 'error' > <error type= 'modify' > <bad-request xmlns= 'urn:ietf:params:xml:ns:xmpp-stanzas' /> </error> </iq> To unmute, similarly, the client can send: 1 2 3 4 5 <iq id= 'some_unique_id' type= 'set' > <query xmlns= 'erlang-solutions.com:xmpp:inbox:0#conversation' jid= 'bob@localhost' > <mute> 0 </mute> </query> </iq> And server responses will be similar.","title":"Examples: muting an entry"},{"location":"open-extensions/inbox/#examples-reading-an-entry","text":"To set an entry as read, the client can send: 1 2 3 4 5 <iq id= 'some_unique_id' type= 'set' > <query xmlns= 'erlang-solutions.com:xmpp:inbox:0#conversation' jid= 'bob@localhost' > <read> true </read> </query> </iq> On success, the server would return (considering the entry is not archived and not muted): 1 2 3 4 5 6 7 <iq id= 'some_unique_id' to= 'alice@localhost/res1' type= 'result' > <query xmlns= 'erlang-solutions.com:xmpp:inbox:0#conversation' jid= 'bob@localhost' > <archive> false </archive> <mute> 0 </mute> <read> true </read> </query> </iq> On error, as usual, the client would get: 1 2 3 4 5 <iq to= 'alice@localhost/res1' type= 'error' > <error type= 'modify' > <bad-request xmlns= 'urn:ietf:params:xml:ns:xmpp-stanzas' /> </error> </iq> And similarly, to set a conversation as unread: 1 2 3 4 5 <iq id= 'some_unique_id' type= 'set' > <query xmlns= 'erlang-solutions.com:xmpp:inbox:0#conversation' jid= 'bob@localhost' > <read> false </read> </query> </iq>","title":"Examples: reading an entry"},{"location":"open-extensions/inbox/#deprecated-entry-stanza","text":"You can reset the inbox with the following stanza: 1 2 3 <iq type= 'set' > <reset xmlns= 'erlang-solutions.com:xmpp:inbox:0#conversation' jid= 'interlocutor_bare_jid' /> </iq> Here jid is the bare jid of the user whose inbox we want to reset. This action does not change the last message stored in inbox; meaning that neither this stanza nor anything given within will be stored; the only change is the inbox unread_count is set to zero.","title":"Deprecated entry stanza:"},{"location":"open-extensions/inbox/#example-request","text":"1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 <!-- Alice sends: --> <message type= \"chat\" to= \"bob@localhost/res1\" id= \u201d123\u201d > <body> Hello </body> </message> <!-- Bob receives: --> <message from= \"alice@localhost/res1\" to= \"bob@localhost/res1\" id= \u201c123\u201d xml:lang= \"en\" type= \"chat\" > <body> Hello </body> </message> <!-- Alice sends: --> <iq type= \"set\" id= \"10bca\" > <inbox xmlns= \u201derlang-solutions.com:xmpp:inbox:0\u201d queryid= \"b6\" > <x xmlns= 'jabber:x:data' type= 'form' > <field type= 'hidden' var= 'FORM_TYPE' ><value> erlang-solutions.com:xmpp:inbox:0 </value></field> <field type= 'text-single' var= 'start' ><value> 2018-07-10T12:00:00Z </value></field> <field type= 'text-single' var= 'end' ><value> 2018-07-11T12:00:00Z </value></field> <field type= 'list-single' var= 'order' ><value> asc </value></field> </x> </inbox> </iq> <!-- Alice receives: --> <message from= \"alice@localhost\" to= \"alice@localhost\" id= \"9b759\" > <result xmlns= \"erlang-solutions.com:xmpp:inbox:0\" unread= \"0\" queryid= \"b6\" > <forwarded xmlns= \"urn:xmpp:forward:0\" > <delay xmlns= \"urn:xmpp:delay\" stamp= \"2018-07-10T23:08:25.123456Z\" /> <message xml:lang= \"en\" type= \"chat\" to= \"bob@localhost/res1\" from= \"alice@localhost/res1\" id= \u201d123\u201d > <body> Hello </body> </message> </forwarded> <archive> false </archive> <mute> 0 </mute> </result> </message> <iq from= \"alice@localhost\" to= \"alice@localhost/res1\" id= \"10bca\" type= \"result\" > <fin xmlns= 'erlang-solutions.com:xmpp:inbox:0' > <count> 1 </count> <unread-messages> 0 </unread-messages> <active-conversations> 0 </active-conversations> </fin> </iq>","title":"Example request"},{"location":"open-extensions/inbox/#example-error-response","text":"1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 <!--Alice sends request with invalid value of start field: --> <iq type= 'set' id= 'a78478f20103ff8354d7834d0ba2fdb2' > <inbox xmlns= 'erlang-solutions.com:xmpp:inbox:0' > <x xmlns= 'jabber:x:data' type= 'submit' > <field type= 'text-single' var= 'start' > <value> invalid </value> </field> </x> </inbox> </iq> <!--Alice receives an error with description of the first encountered invalid value: --> <iq from= 'alice@localhost' to= 'alice@localhost/res1' id= 'a78478f20103ff8354d7834d0ba2fdb2' type= 'error' > <error code= '400' type= 'modify' > <bad-rquest xmlns= 'urn:ietf:params:xml:ns:xmpp-stanzas' /> <text xmlns= 'urn:ietf:params:xml:ns:xmpp-stanzas' > Invalid inbox form field value, field=start, value=invalid </text> </error> </iq>","title":"Example error response"},{"location":"open-extensions/muc_light/","text":"1. Introduction Classic Multi-User chat, as described in XEP-0045, adds an IRC-like functionality to XMPP. It distinguishes between the affiliation list and the occupant list, where the latter is based on presences routed to the room from the client resource. While perfectly sufficient for desktop applications and relatively stable network connection, it does not exactly meet the challenges the mobile world it is facing. Modern mobile applications do not rely on presence information, as it can frequently change. The expected user experience not only differs from the IRC model, but also uses only a small subset of XEP-0045 features. The service described in this specification attempts to provide a complete solution for all common use cases of mobile groupchats. 2. Requirements Here are some high-level features required from a new variant of MUC The service allows any user to create a room for group communication. Users cannot join rooms on their own. They have to be added by the room owner or (if configured by service administrator) any other occupant. Only the owner can remove other occupants from the room. Every occupant can leave the room. A user may block the attempts of being added to the specific room or by specific user. The message sent in the room is always broadcasted to every occupant. The full occupant list is always available to all occupants. The occupant is always visible on the list, even if they do not have any resources online. Occupants can only have two affiliations: owner and member. There MUST be at most one owner in the room (the service can choose to treat all users equally). If the room becomes empty, it is destroyed. Occupants cannot hide behind nicks. Their real bare JID is always visible to everyone No exchange of any <presence/> stanza inside the room. The user MUST be able to retrieve the list of rooms they occupy. The owner can modify the room configuration at any time; members may also be allowed to set configuration. All occupants can get the full room configuration at any time. Room history is available only in Message Archive Management. 3. Entity Use Cases 3.1. Discovering a MUC Light Service An entity often discovers a MUC service by sending a Service Discovery items (\"disco#items\") request to its own server. Entity Queries the Server for Associated Services 1 2 3 4 5 6 <iq from= 'hag66@shakespeare.lit/pda' id= 'h7ns81g' to= 'shakespeare.lit' type= 'get' > <query xmlns= 'http://jabber.org/protocol/disco#items' /> </iq> The server then returns the services that are associated with it. Server Returns a Disco Items Result 1 2 3 4 5 6 7 8 <iq from= 'shakespeare.lit' id= 'h7ns81g' to= 'hag66@shakespeare.lit/pda' type= 'result' > <query xmlns= 'http://jabber.org/protocol/disco#items' > <item jid= 'muclight.shakespeare.lit' name= 'MUC Light Service' /> </query> </iq> 3.2. Discovering the Features Supported by a MUC Light Service An entity may wish to discover if a service implements the Multi-User Chat protocol; in order to do so, it sends a service discovery information (\"disco#info\") query to the MUC service's JID. Entity Queries Chat Service for MUC Light Support via Disco 1 2 3 4 5 <iq from= 'hag66@shakespeare.lit/pda' id= 'lx09df27' to= 'muclight.shakespeare.lit' type= 'get' > <query xmlns= 'http://jabber.org/protocol/disco#info' /> </iq> The service MUST return its identity and the features it supports. Service Returns a Disco Info Result 1 2 3 4 5 6 7 8 9 <iq from= 'muclight.shakespeare.lit' id= 'lx09df27' to= 'hag66@shakespeare.lit/pda' type= 'result' > <query xmlns= 'http://jabber.org/protocol/disco#info' > <identity category= 'conference' name= 'Shakespearean Chat Service' type= 'text' /> <feature var= 'urn:xmpp:muclight:0' /> </query> </iq> 3.3. Discovering Occupied Rooms The service discovery items (\"disco#items\") protocol enables an entity to query a service for a list of associated items, which in the case of a chat service would consist of the specific chat rooms the entity occupies. Entity Queries Chat Service for Rooms 1 2 3 4 5 6 <iq from= 'hag66@shakespeare.lit/pda' id= 'zb8q41f4' to= 'muclight.shakespeare.lit' type= 'get' > <query xmlns= 'http://jabber.org/protocol/disco#items' /> </iq> The service MUST return a full list of the rooms the entity occupies. The server SHOULD include room name and version in each item. Service Returns a Disco Items Result 1 2 3 4 5 6 7 8 9 10 11 12 13 <iq from= 'muclight.shakespeare.lit' id= 'zb8q41f4' to= 'hag66@shakespeare.lit/pda' type= 'result' > <query xmlns= 'http://jabber.org/protocol/disco#items' > <item jid= 'heath@muclight.shakespeare.lit' name= 'A Lonely Heath' version= '1' /> <item jid= 'coven@muclight.shakespeare.lit' name= 'A Dark Cave' version= '2' /> <item jid= 'forres@muclight.shakespeare.lit' name= 'The Palace' version= '3' /> <item jid= 'inverness@muclight.shakespeare.lit' name= 'Macbeth&apos;s Castle' version= '4' /> </query> </iq> If the full list of rooms is large (see XEP-0030 for details), the service MAY return only a partial list of rooms. If it does, it MUST include a <set/> element qualified by the 'http://jabber.org/protocol/rsm' namespace (as defined in Result Set Management (XEP-0059) [1]) to indicate that the list is not the full result set. Service Returns a Limited List of Disco Items Result 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 <iq from= 'muclight.shakespeare.lit' id= 'hx51v49s' to= 'hag66@shakespeare.lit/pda' type= 'result' > <query xmlns= 'http://jabber.org/protocol/disco#items' > <item jid= 'alls-well-that-ends-well@muclight.shakespeare.lit' name= 'Everybody dies' version= '1' /> <item jid= 'as-you-like-it@muclight.shakespeare.lit' name= 'As you like it' version= '2' /> <item jid= 'cleopatra@muclight.shakespeare.lit' name= 'Cleo fans' version= '3' /> <item jid= 'comedy-of-errors@muclight.shakespeare.lit' name= '404 Comedy not found' version= '4' /> <item jid= 'coriolanus@muclight.shakespeare.lit' name= 'What is Coriolanus?' version= '5' /> <item jid= 'cymbeline@muclight.shakespeare.lit' name= 'Music room' version= '6' /> <item jid= 'hamlet@muclight.shakespeare.lit' name= 'To chat or not to chat?' version= '7' /> <item jid= 'henry-the-fourth-one@muclight.shakespeare.lit' name= 'Royal Room 1' version= '8' /> <item jid= 'henry-the-fourth-two@muclight.shakespeare.lit' name= 'Royal Room 2' version= '9' /> <item jid= 'henry-the-fifth@muclight.shakespeare.lit' name= 'Royal Room Prime' version= '10' /> <set xmlns= 'http://jabber.org/protocol/rsm' > <first index= '0' > alls-well-that-ends-well@muclight.shakespeare.lit </first> <last> henry-the-fifth@muclight.shakespeare.lit </last> <count> 37 </count> </set> </query> </iq> 4. Occupant Use Cases 4.1. Sending a message to a room Every occupant in the room MAY broadcast messages to other occupants. In order to do so, the client MUST send a groupchat message to the room bare JID. The room automatically assumes that occupants' nicks are equal to their bare JIDs. MUC light is designed for applications where it is not important to hide behind nicknames. On the contrary - it is up to the client to replace pure JIDs with user-friendly names like phone numbers or full names if necessary. The room MUST route all messages of the 'groupchat' type. Client sends a message to the room 1 2 3 4 5 6 <message from= 'hag66@shakespeare.lit/pda' id= 'msg111' to= 'coven@muclight.shakespeare.lit' type= 'groupchat' > <body> Harpier cries: 'tis time, 'tis time. </body> </message> Server broadcasts a groupchat message 1 2 3 4 5 <message id= 'msg111' type= 'groupchat' from= 'coven@muclight.shakespeare.lit/hag66@shakespeare.lit' to= 'crone1@shakespeare.lit' > <body> Harpier cries: 'tis time, 'tis time. </body> </message> 1 2 3 4 5 <message id= 'msg111' type= 'groupchat' from= 'coven@muclight.shakespeare.lit/hag66@shakespeare.lit' to= 'crone2@shakespeare.lit' > <body> Harpier cries: 'tis time, 'tis time. </body> </message> Note the message is sent to all the room occupants including the original sender. 1 2 3 4 5 <message id= 'msg111' type= 'groupchat' from= 'coven@muclight.shakespeare.lit/hag66@shakespeare.lit' to= 'hag66@shakespeare.lit' > <body> Harpier cries: 'tis time, 'tis time. </body> </message> 4.2. Changing a room subject The service MAY allow room occupants to set the room subject by changing the \"subject\" configuration field. A standard configuration stanza is used in this case. Subject change is announced like an ordinary configuration change. Client sends a message to the room 1 2 3 4 5 6 7 8 <iq from= 'hag66@shakespeare.lit/pda' id= 'subject1' to= 'coven@muclight.shakespeare.lit' type= 'set' > <query xmlns= 'urn:xmpp:muclight:0#configuration' > <subject> To be or not to be? </subject> </query> </iq> 1 2 3 4 5 6 7 8 9 10 11 <message from= 'coven@muclight.shakespeare.lit' to= 'crone1@shakespeare.lit' type= 'groupchat' id= 'newsubject' > <x xmlns= 'urn:xmpp:muclight:0#configuration' > <prev-version> asdfghj000 </prev-version> <version> asdfghj </version> <subject> To be or not to be? </subject> </x> <body /> </message> 1 2 3 4 5 6 7 8 9 10 11 <message from= 'coven@muclight.shakespeare.lit' to= 'hag66@shakespeare.lit' type= 'groupchat' id= 'newsubject' > <x xmlns= 'urn:xmpp:muclight:0#configuration' > <prev-version> asdfghj000 </prev-version> <version> asdfghj </version> <subject> To be or not to be? </subject> </x> <body /> </message> 1 2 3 4 <iq to= 'hag66@shakespeare.lit/pda' id= 'subject1' from= 'coven@muclight.shakespeare.lit' type= 'result' /> 4.3. Requesting room information Room occupants may request room information (configuration and/or occupants list) by an information version. It is up to the service to define the version string, the only requirement for it, is to be unique per room. Please note there are no separate versions for configuration and occupant list alone. If the server side version does not match the one provided by the client (or if the client does not provide one, i.e. the 'version' element is empty), the service MUST respond with a current version string and full configuration and/or occupant list. If the version strings match, server MUST reply with an empty result. Only room occupants can get room information. Matching versions 1 2 3 4 5 6 7 8 <iq from= 'crone1@shakespeare.lit/desktop' id= 'config0' to= 'coven@muclight.shakespeare.lit' type= 'get' > <query xmlns= 'urn:xmpp:muclight:0#configuration' > <version> abcdefg </version> </query> </iq> 1 2 3 4 <iq from= 'coven@muclight.shakespeare.lit' id= 'config0' to= 'crone1@shakespeare.lit/desktop' type= 'result' /> 4.3.1. Getting the room configuration Client gets configuration from the server 1 2 3 4 5 6 7 8 <iq from= 'crone1@shakespeare.lit/desktop' id= 'getconfig1' to= 'coven@muclight.shakespeare.lit' type= 'get' > <query xmlns= 'urn:xmpp:muclight:0#configuration' > <version> abcdefg </version> </query> </iq> 1 2 3 4 5 6 7 8 9 <iq from= 'coven@muclight.shakespeare.lit' id= 'getconfig1' to= 'crone1@shakespeare.lit/desktop' type= 'result' > <query xmlns= 'urn:xmpp:muclight:0#configuration' > <version> 123456 </version> <roomname> A Dark Cave </roomname> </query> </iq> 4.3.2. Requesting a user list Client requests a user list 1 2 3 4 5 6 7 8 <iq from= 'crone1@shakespeare.lit/desktop' id= 'getmembers' to= 'coven@muclight.shakespeare.lit' type= 'get' > <query xmlns= 'urn:xmpp:muclight:0#affiliations' > <version> abcdefg </version> </query> </iq> 1 2 3 4 5 6 7 8 9 10 11 <iq from= 'coven@muclight.shakespeare.lit' id= 'getmembers' to= 'crone1@shakespeare.lit/desktop' type= 'result' > <query xmlns= 'urn:xmpp:muclight:0#affiliations' > <version> 123456 </version> <user affiliation= 'owner' > user1@shakespeare.lit </user> <user affiliation= 'member' > user2@shakespeare.lit </user> <user affiliation= 'member' > user3@shakespeare.lit </user> </query> </iq> 4.3.3. Requesting full room information Room occupants may request both lists (configuration + occupants) with a single request. Client requests room information 1 2 3 4 5 6 7 8 <iq from= 'crone1@shakespeare.lit/desktop' id= 'getinfo1' to= 'coven@muclight.shakespeare.lit' type= 'get' > <query xmlns= 'urn:xmpp:muclight:0#info' > <version> abcdefg </version> </query> </iq> 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 <iq from= 'coven@muclight.shakespeare.lit' id= 'getinfo1' to= 'crone1@shakespeare.lit/desktop' type= 'result' > <query xmlns= 'urn:xmpp:muclight:0#info' > <version> 123456 </version> <configuration> <roomname> A Dark Cave </roomname> </configuration> <occupants> <user affiliation= 'owner' > user1@shakespeare.lit </user> <user affiliation= 'member' > user2@shakespeare.lit </user> <user affiliation= 'member' > user3@shakespeare.lit </user> </occupants> </query> </iq> 4.4. Leaving the room Every occupant is allowed to leave the room at any time. It is done by modifying their own affiliation. Occupant leaves the room 1 2 3 4 5 6 7 8 <iq from= 'crone1@shakespeare.lit/desktop' id= 'leave1' to= 'coven@muclight.shakespeare.lit' type= 'set' > <query xmlns= 'urn:xmpp:muclight:0#affiliations' > <user affiliation= 'none' > crone1@shakespeare.lit </user> </query> </iq> 1 2 3 4 5 6 7 8 9 <message from= 'coven@muclight.shakespeare.lit' to= 'crone1@shakespeare.lit' type= 'groupchat' id= 'leave1' > <x xmlns= 'urn:xmpp:muclight:0#affiliations' > <user affiliation= 'none' > crone1@shakespeare.lit </user> </x> <body /> </message> 1 2 3 4 5 6 7 8 9 10 11 <message from= 'coven@muclight.shakespeare.lit' to= 'hag77@shakespeare.lit' type= 'groupchat' id= 'leave1' > <x xmlns= 'urn:xmpp:muclight:0#affiliations' > <prev-version> 1111111 </prev-version> <version> aaaaaaa </version> <user affiliation= 'none' > crone1@shakespeare.lit </user> </x> <body /> </message> 1 2 3 4 5 6 7 8 9 10 11 <message from= 'coven@muclight.shakespeare.lit' to= 'hag88@shakespeare.lit' type= 'groupchat' id= 'leave1' > <x xmlns= 'urn:xmpp:muclight:0#affiliations' > <prev-version> 1111111 </prev-version> <version> aaaaaaa </version> <user affiliation= 'none' > crone1@shakespeare.lit </user> </x> <body /> </message> 1 2 3 4 <iq to= 'crone1@shakespeare.lit/desktop' id= 'leave1' from= 'coven@muclight.shakespeare.lit' type= 'result' /> 4.5. Blocking functionality A user MAY choose to automatically deny being added to the room. All stanzas must be directed to MUC Light service. User MAY send more than one item in a single request and mix both 'user' and 'room' elements. If the occupant tries to add another user to the room, and this user has set a blocking policy, the server MUST ignore the attempt. No error is returned, this user is simply skipped when processing affiliation change query. Service denies adding blocking user 1 2 3 4 5 6 7 8 9 <iq from= 'crone2@shakespeare.lit/desktop' id= 'blocked1' to= 'coven@muclight.shakespeare.lit' type= 'set' > <query xmlns= 'urn:xmpp:muclight:0#affiliations' > <user affiliation= 'member' > crone1@shakespeare.lit </user> <user affiliation= 'member' > crone3@shakespeare.lit </user> </query> </iq> 1 2 3 4 5 6 7 8 9 <message from= 'coven@muclight.shakespeare.lit' to= 'crone2@shakespeare.lit' type= 'groupchat' id= 'blockedadd1' > <x xmlns= 'urn:xmpp:muclight:0#affiliations' > <user affiliation= 'member' > crone3@shakespeare.lit </user> </x> <body /> </message> 1 2 3 4 5 6 7 8 9 <message from= 'coven@muclight.shakespeare.lit' to= 'hag88@@shakespeare.lit' type= 'groupchat' id= 'blockedadd1' > <x xmlns= 'urn:xmpp:muclight:0#affiliations' > <user affiliation= 'member' > crone3@shakespeare.lit </user> </x> <body /> </message> 1 2 3 4 <iq to= 'crone2@shakespeare.lit/desktop' id= 'blocked1' from= 'coven@muclight.shakespeare.lit' type= 'result' /> 4.5.1. Requesting a blocking list In order to get the current blocking list in the MUC Light service, the client sends an empty IQ get query with a proper namespace. The list includes only items with a 'deny' action, since the 'allow' behaviour is default for MUC Light and is only used for the list modification. User retrieves a blocking list 1 2 3 4 5 6 7 <iq from= 'crone1@shakespeare.lit/desktop' id= 'getblock1' to= 'muclight.shakespeare.lit' type= 'get' > <query xmlns= 'urn:xmpp:muclight:0#blocking' > </query> </iq> 1 2 3 4 5 6 7 8 9 <iq type= 'result' id= 'getblock1' to= 'crone1@shakespeare.lit/desktop' from= 'muclight.shakespeare.lit' > <query xmlns= 'urn:xmpp:muclight:0#blocking' > <room action= 'deny' > coven@muclight.shakespeare.lit </room> <user action= 'deny' > hag77@shakespeare.lit </user> </query> </iq> 4.5.2. Blocking a room In order to block a room, a query must contain at least one 'room' item with a 'deny' action and a room bare JID in the content. User blocks a room 1 2 3 4 5 6 7 8 9 <iq from= 'crone1@shakespeare.lit/desktop' id= 'block1' to= 'muclight.shakespeare.lit' type= 'set' > <query xmlns= 'urn:xmpp:muclight:0#blocking' > <room action= 'deny' > coven@muclight.shakespeare.lit </room> <room action= 'deny' > chapel@shakespeare.lit </room> </query> </iq> 1 2 3 4 <iq type= 'result' id= 'block1' to= 'crone1@shakespeare.lit/desktop' from= 'muclight.shakespeare.lit' /> 4.5.3. Blocking a user In order to block a user, a query must contain at least one 'user' item with a 'deny' action and a user bare JID in the content. User blocks another user 1 2 3 4 5 6 7 8 9 <iq from= 'crone1@shakespeare.lit/desktop' id= 'block2' to= 'muclight.shakespeare.lit' type= 'set' > <query xmlns= 'urn:xmpp:muclight:0#blocking' > <user action= 'deny' > hag66@shakespeare.lit </user> <user action= 'deny' > hag77@shakespeare.lit </user> </query> </iq> 1 2 3 4 <iq type= 'result' id= 'block2' to= 'crone1@shakespeare.lit/desktop' from= 'muclight.shakespeare.lit' /> 4.5.4. Unblocking In order to cancel a blocking, a query must contain at least one 'room' or 'user' item with an 'allow' action and an appriopriate bare JID in the content. Unblocking a JID that is not blocked does not trigger any error. The server MUST return an empty IQ result in such case. User cancels blocking 1 2 3 4 5 6 7 8 9 <iq from= 'crone1@shakespeare.lit/desktop' id= 'unblock1' to= 'muclight.shakespeare.lit' type= 'set' > <query xmlns= 'urn:xmpp:muclight:0#blocking' > <room action= 'allow' > coven@muclight.shakespeare.lit </room> <user action= 'allow' > hag66@shakespeare.lit </user> </query> </iq> 1 2 3 4 <iq type= 'result' id= 'unblock1' to= 'crone1@shakespeare.lit/desktop' from= 'muclight.shakespeare.lit' /> 5. Owner Use Cases 5.1. Creating a new room A room is created by submitting a dedicated stanza. The client application should pick a random room node name, since a human-readable room name is in configuration. For rules that apply to the configuration options, please see \"Setting room configuration\" chapter. The client MAY include initial configuration and occupant list (the list MUST NOT include the creator). The server MAY allow sending an incomplete configuration form. In such case the server MUST use the default values for missing fields. The server MAY enforce a minimal occupant list length. The service MAY either give the creator the 'owner' or 'member' status. In the latter case all users are equal. Upon room creation success, the service MUST reply with an empty IQ result. The following rules (similar to the ones relevant to the affiliation change request) apply to the occupant list: 'none' affiliation cannot be used. All user bare JIDs must be unique At most one owner can be chosen. If none is chosen, the room creator will become \"just\" a 'member'. After the room is created (but before receiving IQ result), new occupants (including the creator) receive <message/> from the room with their affiliations (the stanza MUST include only recipient's affiliation) and the initial room version. <prev-version/> element MUST NOT be included. Client requests room creation 1 2 3 4 5 6 7 8 9 10 11 12 13 14 <iq from= 'crone1@shakespeare.lit/desktop' id= 'create1' to= 'coven@muclight.shakespeare.lit' type= 'set' > <query xmlns= 'urn:xmpp:muclight:0#create' > <configuration> <roomname> A Dark Cave </roomname> </configuration> <occupants> <user affiliation= 'member' > user1@shakespeare.lit </user> <user affiliation= 'member' > user2@shakespeare.lit </user> </occupants> </query> </iq> 1 2 3 4 5 6 7 8 9 10 <message from= 'coven@muclight.shakespeare.lit' to= 'crone1@shakespeare.lit' type= 'groupchat' id= 'createnotif' > <x xmlns= 'urn:xmpp:muclight:0#affiliations' > <version> aaaaaaa </version> <user affiliation= 'owner' > crone1@shakespeare.lit </user> </x> <body /> </message> 1 2 3 4 5 6 7 8 9 10 <message from= 'coven@muclight.shakespeare.lit' to= 'user1@shakespeare.lit' type= 'groupchat' id= 'createnotif' > <x xmlns= 'urn:xmpp:muclight:0#affiliations' > <version> aaaaaaa </version> <user affiliation= 'member' > user1@shakespeare.lit </user> </x> <body /> </message> 1 2 3 4 5 6 7 8 9 10 <message from= 'coven@muclight.shakespeare.lit' to= 'user2@shakespeare.lit' type= 'groupchat' id= 'createnotif' > <x xmlns= 'urn:xmpp:muclight:0#affiliations' > <version> aaaaaaa </version> <user affiliation= 'member' > user2@shakespeare.lit </user> </x> <body /> </message> 1 2 3 4 <iq to= 'crone1@shakespeare.lit/desktop' id= 'create1' from= 'coven@muclight.shakespeare.lit' type= 'result' /> 5.1.1. Requesting a new room with a unique name If a client would like to avoid a room JID conflict, it MAY request creating a new room with a server-side generated name, that is verfied to be unique. In order to do so, the client MUST send a creation request to service JID, not room bare JID. The IQ result will originate from the new room bare JID The messages with affiliation change notifications MUST have the same ID as IQ set and result. Client requests room creation 1 2 3 4 5 6 7 8 9 10 <iq from= 'crone1@shakespeare.lit/desktop' id= 'createrandom' to= 'muclight.shakespeare.lit' type= 'set' > <query xmlns= 'urn:xmpp:muclight:0#create' > <configuration> <roomname> Random Cave </roomname> </configuration> </query> </iq> 1 2 3 4 5 6 7 8 9 10 <message from= 'randomcave@muclight.shakespeare.lit' to= 'crone1@shakespeare.lit' type= 'groupchat' id= 'createrandom' > <x xmlns= 'urn:xmpp:muclight:0#affiliations' > <version> aaaaaaa </version> <user affiliation= 'owner' > crone1@shakespeare.lit </user> </x> <body /> </message> 1 2 3 4 <iq to= 'crone1@shakespeare.lit/desktop' id= 'createrandom' from= 'muclight.shakespeare.lit' type= 'result' /> 5.1.2. Room already exists If the chosen room name already exists, the service MUST return a 'conflict' error. Client requests room creation with existing name 1 2 3 4 5 6 7 8 9 10 <iq from= 'crone1@shakespeare.lit/desktop' id= 'conflict1' to= 'castle@muclight.shakespeare.lit' type= 'set' > <query xmlns= 'urn:xmpp:muclight:0#create' > <configuration> <roomname> A Dark Cave </roomname> </configuration> </query> </iq> 1 2 3 4 5 6 7 8 <iq to= 'crone1@shakespeare.lit/desktop' id= 'conflict1' from= 'castle@muclight.shakespeare.lit' type= 'error' > <error type= 'cancel' > <conflict xmlns= 'urn:ietf:params:xml:ns:xmpp-stanzas' /> </error> </iq> 5.2. Destroying a room A room is automatically destroyed when its occupant list becomes empty or the room owner explicitly sends an IQ with a room destroy request. Before sending an IQ result, every occupant is notified that its affiliation has changed to 'none'. These notifications include an <x/> element qualified with a \"urn:xmpp:muclight:0#destroy\" namespace. Only the room owner is allowed to destroy it. Room destruction notification SHOULD NOT contain version (or \"prev-version\" information). Client requests room destruction 1 2 3 4 5 6 <iq from= 'crone1@shakespeare.lit/desktop' id= 'destroy1' to= 'coven@muclight.shakespeare.lit' type= 'set' > <query xmlns= 'urn:xmpp:muclight:0#destroy' /> </iq> 1 2 3 4 5 6 7 8 9 10 <message from= 'coven@muclight.shakespeare.lit' to= 'crone1@shakespeare.lit' type= 'groupchat' id= 'destroynotif' > <x xmlns= 'urn:xmpp:muclight:0#affiliations' > <user affiliation= 'none' > crone1@shakespeare.lit </user> </x> <x xmlns= 'urn:xmpp:muclight:0#destroy' /> <body /> </message> 1 2 3 4 5 6 7 8 9 10 <message from= 'coven@muclight.shakespeare.lit' to= 'hag77@shakespeare.lit' type= 'groupchat' id= 'destroynotif' > <x xmlns= 'urn:xmpp:muclight:0#affiliations' > <user affiliation= 'none' > hag77@shakespeare.lit </user> </x> <x xmlns= 'urn:xmpp:muclight:0#destroy' /> <body /> </message> 1 2 3 4 5 6 7 8 9 10 <message from= 'coven@muclight.shakespeare.lit' to= 'hag88@shakespeare.lit' type= 'groupchat' id= 'destroynotif' > <x xmlns= 'urn:xmpp:muclight:0#affiliations' > <user affiliation= 'none' > hag88@shakespeare.lit </user> </x> <x xmlns= 'urn:xmpp:muclight:0#destroy' /> <body /> </message> 1 2 3 4 <iq to= 'crone1@shakespeare.lit/desktop' id= 'create1' from= 'coven@muclight.shakespeare.lit' type= 'result' /> 5.3. Setting room configuration Only room owners can modify the room configuration but the service MAY allow members to change it too. All room occupants MUST be notified about a configuration change and both the new and old room version string ( <version /> and <prev-version /> respectively). \"version\" and \"prev-version\" configuration field names are NOT ALLOWED - they are reserved for room versioning. The service MAY allow the client to set the configuration fields with any name but it is NOT RECOMMENDED. The Data Forms are not used for the configuration. Instead, the config fields are encoded in XML elements with names equal to the key and content equal to the value. Client configuration request to the server 1 2 3 4 5 6 7 8 <iq from= 'crone1@shakespeare.lit/desktop' id= 'conf2' to= 'coven@muclight.shakespeare.lit' type= 'set' > <query xmlns= 'urn:xmpp:muclight:0#configuration' > <roomname> A Darker Cave </roomname> </query> </iq> 1 2 3 4 5 6 7 8 9 10 11 <message from= 'coven@muclight.shakespeare.lit' to= 'crone1@shakespeare.lit' type= 'groupchat' id= 'configchange' > <x xmlns= 'urn:xmpp:muclight:0#configuration' > <prev-version> zaqwsx </prev-version> <version> zxcvbnm </version> <roomname> A Darker Cave </roomname> </x> <body /> </message> 1 2 3 4 5 6 7 8 9 10 11 <message from= 'coven@muclight.shakespeare.lit' to= 'hag66@shakespeare.lit' type= 'groupchat' id= 'configchange' > <x xmlns= 'urn:xmpp:muclight:0#configuration' > <prev-version> zaqwsx </prev-version> <version> zxcvbnm </version> <roomname> A Darker Cave </roomname> </x> <body /> </message> 1 2 3 4 <iq to= 'crone1@shakespeare.lit/desktop' id= 'conf2' from= 'coven@muclight.shakespeare.lit' type= 'result' /> The server SHOULD accept incomplete (i.e. delta) configuration forms. In such case, values of the missing fields SHOULD be preserved. 5.4. Changing the occupant list The occupant list is modified by a direct affiliation change. Following rules apply: There are only 3 affiliations. owner - can do everything in the room member - can send messages to the room and if the service allows it, can also change configuration or change others' affiliations none - not in the room; it's a keyword for marking a user for removal from a room Every occupant can change its own affiliation to none in order to leave the room. The only way to join the room is being added by other occupant. The owner can change affiliations at will. If the owner leaves, the server MAY use any strategy to choose a new one. The room can have at most one owner. Giving someone else the 'owner' status effectively causes the current one to lose it. The owner can choose a new owner when leaving by including both 'none' and 'owner' items in affiliation change request. Every user JID can be used in the request at most once. A single request MAY change multiple affiliations. All changes must be meaningful, e.g. setting member's affiliation to 'member' is considered a bad request. Server MAY allow members to add new members but they still cannot make anyone an 'owner' or remove other users from the room. On success the server will reply with a result IQ with all the changed items. BEFORE returning the IQ result, the service MUST route a message with the affiliation change to all relevant users. Newcomers, i.e. users that were not occupants before the change, SHOULD receive only their own affiliation and SHOULD NOT receive a <prev-version /> element. The notifications must include both the new and old room version ( <version /> and <prev-version /> respectively) string (except for the ones directed to users that have been removed from the room). The notifications contain a list of items. The item list may be different from the list in the IQ set, because some of the changes may require additional operations, e.g. choosing new owner when the old one leaves. Users, that are still in the room after the change, will receive the full change list. Users, that have been removed from the room with the request, will get only one item: themselves with affiliation 'none'. Affiliations change request Let's consider a room coven with following members: crone1 - owner hag77 - member hag88 - member hag66 is not in the room yet. User crone1 wants to add hag66 to the room, kick hag88 out and make hag77 the room owner. 1 2 3 4 5 6 7 8 9 10 <iq from= 'crone1@shakespeare.lit/desktop' id= 'member1' to= 'coven@muclight.shakespeare.lit' type= 'set' > <query xmlns= 'urn:xmpp:muclight:0#affiliations' > <user affiliation= 'member' > hag66@shakespeare.lit </user> <user affiliation= 'owner' > hag77@shakespeare.lit </user> <user affiliation= 'none' > hag88@shakespeare.lit </user> </query> </iq> Now each user will receive an update. As you can see, affiliations have changed accordingly to crone1 request. However, this request implies one more update. Since hag77 has been promoted to a new owner, crone1 is automatically degraded to member . 1 2 3 4 5 6 7 8 9 10 11 12 13 14 <message from= 'coven@muclight.shakespeare.lit' to= 'crone1@shakespeare.lit' type= 'groupchat' id= 'memberchange' > <x xmlns= 'urn:xmpp:muclight:0#affiliations' > <prev-version> njiokm </prev-version> <version> qwerty </version> <user affiliation= 'member' > crone1@shakespeare.lit </user> <user affiliation= 'member' > hag66@shakespeare.lit </user> <user affiliation= 'owner' > hag77@shakespeare.lit </user> <user affiliation= 'none' > hag88@shakespeare.lit </user> </x> <body></body> </message> Because hag66 was not a member of this room before, they only receive their own affiliation and no prev-version element. 1 2 3 4 5 6 7 8 9 10 <message from= 'coven@muclight.shakespeare.lit' to= 'hag66@shakespeare.lit' type= 'groupchat' id= 'memberchange' > <x xmlns= 'urn:xmpp:muclight:0#affiliations' > <version> qwerty </version> <user affiliation= 'member' > hag66@shakespeare.lit </user> </x> <body></body> </message> hag77 receives an ordinary update, just like crone1 . 1 2 3 4 5 6 7 8 9 10 11 12 13 14 <message from= 'coven@muclight.shakespeare.lit' to= 'hag77@shakespeare.lit' type= 'groupchat' id= 'memberchange' > <x xmlns= 'urn:xmpp:muclight:0#affiliations' > <prev-version> njiokm </prev-version> <version> qwerty </version> <user affiliation= 'member' > crone1@shakespeare.lit </user> <user affiliation= 'member' > hag66@shakespeare.lit </user> <user affiliation= 'owner' > hag77@shakespeare.lit </user> <user affiliation= 'none' > hag88@shakespeare.lit </user> </x> <body></body> </message> hag88 has been kicked out of the room and therefore gets only their own affiliation change of type 'none'. 1 2 3 4 5 6 7 8 9 <message from= 'coven@muclight.shakespeare.lit' to= 'hag88@shakespeare.lit' type= 'groupchat' id= 'memberchange' > <x xmlns= 'urn:xmpp:muclight:0#affiliations' > <user affiliation= 'none' > hag88@shakespeare.lit </user> </x> <body></body> </message> crone1 gets the result IQ after the change. 1 2 3 4 <iq to= 'crone1@shakespeare.lit/desktop' id= 'member1' from= 'coven@muclight.shakespeare.lit' type= 'result' /> 6. Interactions with RFCs and other XEPs 6.1. User rosters The service MAY add user's rooms to its roster. It allows the client to skip the separate Disco request to the service. Roster items with rooms MUST belong to the group \"urn:xmpp:muclight:0\" (MUC Light namespace) and include the <version/> element. Their subscription type MUST be 'to'. Entity requests the roster and receives a reply that includes a room item 1 2 3 <iq type= 'get' id= 'roster1' to= 'shakespeare.lit' > <query xmlns= 'jabber:iq:roster' /> </iq> 1 2 3 4 5 6 7 8 9 10 <iq id= 'roster1' to= 'hag66@shakespeare.lit/tablet' type= 'result' > <query xmlns= 'jabber:iq:roster' ver= 'ver7' > <item jid= 'hag77@shakespeare.lit' subscription= 'both' /> <item jid= 'hag88@shakespeare.lit' subscription= 'both' /> <item jid= 'coven@muclight.shakespeare.lit' name= 'The Coven' subscription= 'to' > <group> urn:xmpp:muclight:0 </group> <version> 1234345 </version> </item> </query> </iq> 6.2. XEP-0313 Message Archive Management This section defines the rules for archiving MUC Light events and messages. Stanzas described in the subsections below MUST be archived by the server. The stanzas not included here MUST NOT be archived. The <message/> element inside <forwarded/> MUST include a \"from\" attribute and MUST NOT include a \"to\" attribute. \"id\" SHOULD be archived as well. In case of regular groupchat messages, the \"from\" attribute MUST consist of a room full JID with a sender bare JID in the resource part. As for room notification, e.g. create event, \"from\" MUST be equal to room bare JID. Examples below use MAM v0.4 protocol. The archive can be fetched only from a specific room, the client MUST NOT query MUC Light service directly. 6.2.1. Groupchat message from occupant Message from a user MUST be archived with all child elements. Occupant queries MAM and receives regular groupchat message 1 2 3 <iq type= 'set' id= 'mamget1' to= 'coven@muclight.shakespeare.lit' > <query xmlns= 'urn:xmpp:mam:1' queryid= 'f27' /> </iq> 1 2 3 4 5 6 7 8 9 10 11 12 <message id= 'aeb213' to= 'hag66@shakespeare.lit/pda' > <result xmlns= 'urn:xmpp:mam:1' queryid= 'f27' id= '28482-98726-73623' > <forwarded xmlns= 'urn:xmpp:forward:0' > <delay xmlns= 'urn:xmpp:delay' stamp= '2010-07-10T23:08:25Z' /> <message from= \"coven@muclight.shakespeare.lit/hag77@shakespeare.lit\" id= \"msgid11\" > <body> Welcome! </body> <x xmlns= \"elixir:ingredient\" > bat-wing </x> </message> </forwarded> </result> </message> 1 <iq type= 'result' id= 'mamget1' from= 'coven@muclight.shakespeare.lit' /> 6.2.2. Affiliation change Every archived affiliation change notification MUST include the <version/> element and MUST NOT contain the <prev-version/> element. Occupant queries MAM and receives an affiliation change notification 1 2 3 <iq type= 'set' id= 'mamget2' to= 'muclight.shakespeare.lit' > <query xmlns= 'urn:xmpp:mam:1' queryid= 'f37' /> </iq> 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 <message id= 'aef2133' to= 'hag66@shakespeare.lit/pda' > <result xmlns= 'urn:xmpp:mam:1' queryid= 'f37' id= '21482-98726-71623' > <forwarded xmlns= 'urn:xmpp:forward:0' > <delay xmlns= 'urn:xmpp:delay' stamp= '2013-07-10T21:08:25Z' /> <message from= \"coven@muclight.shakespeare.lit\" id= \"notifid11\" > <x xmlns= 'urn:xmpp:muclight:0#affiliations' > <version> b9uf13h98f13 </version> <user affiliation= 'owner' > hag66@shakespeare.lit </user> <user affiliation= 'member' > user1@shakespeare.lit </user> <user affiliation= 'member' > user2@shakespeare.lit </user> </x> </message> </forwarded> </result> </message> 1 <iq type= 'result' id= 'mamget12' /> 6.2.3. Room creation Room creation is archived as an affiliation change that includes ALL initial occupants (including the room creator). 7. General Error Cases 7.1. Client sends an unauthorized stanza to a room If a client sends a stanza to the room, that it does not occupy, the service MUST reply with the 'item-not-found' error. Unauthorized IQ 1 2 3 4 5 6 7 8 <iq from= 'crone1@shakespeare.lit/desktop' id= 'member1' to= 'coven@muclight.shakespeare.lit' type= 'set' > <query xmlns= 'urn:xmpp:muclight:0#affiliations' > <user affiliation= 'member' > hag66@shakespeare.lit </user> </query> </iq> 1 2 3 4 5 6 7 8 <iq to= 'crone1@shakespeare.lit/desktop' id= 'member1' from= 'coven@muclight.shakespeare.lit' type= 'error' > <error type= 'cancel' > <item-not-found xmlns= 'urn:ietf:params:xml:ns:xmpp-stanzas' /> </error> </iq> Unauthorized message 1 2 3 4 5 6 <message from= 'hag66@shakespeare.lit/pda' id= 'unauth2' to= 'coven@muclight.shakespeare.lit' type= 'groupchat' > <body> Harpier cries: 'tis time, 'tis time. </body> </message> 1 2 3 4 5 6 7 8 <message to= 'hag66@shakespeare.lit/pda' id= 'unauth2' from= 'coven@muclight.shakespeare.lit' type= 'error' > <error type= 'cancel' > <item-not-found xmlns= 'urn:ietf:params:xml:ns:xmpp-stanzas' /> </error> </message> 7.2. Client sends a <presence/> stanza to the service The service MUST ignore all <presence/> stanzas sent by the client. 7.3. Client sends an invalid stanza to the service If service receives an invalid stanza it MUST reply with a 'bad-request' error. Invalid IQ 1 2 3 4 5 6 7 8 <iq from= 'crone1@shakespeare.lit/desktop' id= 'bad1' to= 'coven@muclight.shakespeare.lit' type= 'set' > <query xmlns= 'urn:xmpp:muclight:0#affiliations' > <item role= 'participant' > hag66@shakespeare.lit </item> </query> </iq> 1 2 3 4 5 6 7 8 <iq to= 'crone1@shakespeare.lit/desktop' id= 'bad1' from= 'coven@muclight.shakespeare.lit' type= 'error' > <error type= 'modify' > <bad-request xmlns= 'urn:ietf:params:xml:ns:xmpp-stanzas' /> </error> </iq> Invalid message 1 2 3 4 5 6 <message from= 'hag66@shakespeare.lit/pda' id= 'bad2' to= 'coven@muclight.shakespeare.lit' type= 'chat' > <body> Harpier cries: 'tis time, 'tis time. </body> </message> 1 2 3 4 5 6 7 8 <message to= 'hag66@shakespeare.lit/pda' id= 'bad2' from= 'coven@muclight.shakespeare.lit' type= 'error' > <error type= 'modify' > <bad-request xmlns= 'urn:ietf:params:xml:ns:xmpp-stanzas' /> </error> </message> 7.4. Request sender has insufficient privileges If the request sender does not have sufficient privileges (but is a room occupant), the service MUST reply with a 'not-allowed' error. It occurs in the following cases: A member tries to change the configuration but the service is not configured to allow it. It does not apply to the subject change, although it has to be performed by sending <message/> with <subject/> , not configuration <iq/> . A member tries to change anyone's affiliation to 'none' or 'owner'. A member tries to change someone's affiliation to 'member' but the service is not configured to allow it. Prohibited IQ 1 2 3 4 5 6 7 8 <iq from= 'minion@shakespeare.lit/desktop' id= 'privileges1' to= 'coven@muclight.shakespeare.lit' type= 'set' > <query xmlns= 'urn:xmpp:muclight:0#affiliations' > <user role= 'owner' > minion@shakespeare.lit </user> </query> </iq> 1 2 3 4 5 6 7 8 <iq to= 'minion@shakespeare.lit/desktop' id= 'privileges1' from= 'coven@muclight.shakespeare.lit' type= 'error' > <error type= 'cancel' > <not-allowed xmlns= 'urn:ietf:params:xml:ns:xmpp-stanzas' /> </error> </iq> 8. Implementation Notes 8.1. XEP-0045 mappings Some client-side developers might choose to use existing XEP-0045 Multi-User Chat implementations to interface with the new MUC Light. There may be various reasons to do so: using a familiar protocol, avoiding additional implementation, quick prototyping etc. This section provides suggestions of mappings between XEP-0045 stanzas and the new ones described in this document. Operations not described here SHOULD remain unmodified. 8.1.1. Discovering the Features Supported by a MUC Service A Disco result MAY either include a new <feature/> element with an \"http://jabber.org/protocol/muc\" namespace next to MUC Light one, or completely replace it, which is the RECOMMENDED behaviour. Returning a MUC namespace in Disco 1 2 3 4 5 6 <iq from= 'hag66@shakespeare.lit/pda' id= 'lx09df27' to= 'muclight.shakespeare.lit' type= 'get' > <query xmlns= 'http://jabber.org/protocol/disco#info' /> </iq> 1 2 3 4 5 6 7 8 9 10 11 <iq from= 'muclight.shakespeare.lit' id= 'lx09df27' to= 'hag66@shakespeare.lit/pda' type= 'result' > <query xmlns= 'http://jabber.org/protocol/disco#info' > <identity category= 'conference' name= 'Shakespearean Chat Service' type= 'text' /> <feature var= 'http://jabber.org/protocol/muc' /> </query> </iq> 8.1.2. Discovering Occupied Rooms The room list MUST NOT include room versions. Service Returns Disco Items Result 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 <iq from= 'muclight.shakespeare.lit' id= 'zb8q41f4' to= 'hag66@shakespeare.lit/pda' type= 'result' > <query xmlns= 'http://jabber.org/protocol/disco#items' > <item jid= 'heath@muclight.shakespeare.lit' name= 'A Lonely Heath' /> <item jid= 'coven@muclight.shakespeare.lit' name= 'A Dark Cave' /> <item jid= 'forres@muclight.shakespeare.lit' name= 'The Palace' /> <item jid= 'inverness@muclight.shakespeare.lit' name= 'Macbeth&apos;s Castle' /> </query> </iq> 8.1.3. Changing a room subject Instead of distributing the configuration change notifications, the room MUST route <message/> with a <subject/> like a classic MUC would. The client MUST send a classic message <subject/> as well. The room SHOULD save a new subject in the room configuration. New subject is routed as an ordinary message 1 2 3 4 5 6 <message from= 'hag66@shakespeare.lit/pda' id= 'compsubject' to= 'coven@muclight.shakespeare.lit' type= 'groupchat' > <subject> To be or not to be? </subject> </message> 1 2 3 4 5 6 <message from= 'coven@muclight.shakespeare.lit' to= 'crone1@shakespeare.lit' type= 'groupchat' id= 'compsubject' > <subject> To be or not to be? </subject> </message> 1 2 3 4 5 6 <message from= 'coven@muclight.shakespeare.lit' to= 'hag66@shakespeare.lit' type= 'groupchat' id= 'compsubject' > <subject> To be or not to be? </subject> </message> 8.1.4. Getting a room configuration Room configuration is encoded in a Data Form, that simulates the XEP-0045 config form. Getting the room configuration does not benefit from room versioning. Requesting room configuration 1 2 3 4 5 6 <iq from= 'crone1@shakespeare.lit/desktop' id= 'comp-config' to= 'coven@muclight.shakespeare.lit' type= 'get' > <query xmlns= 'http://jabber.org/protocol/muc#owner' /> </iq> 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 <iq from= 'coven@muclight.shakespeare.lit' id= 'comp-config' to= 'crone1@shakespeare.lit/desktop' type= 'result' > <query xmlns= 'http://jabber.org/protocol/muc#owner' > <x xmlns= 'jabber:x:data' type= 'form' > <title> Configuration for \"coven\" Room </title> <field type= 'hidden' var= 'FORM_TYPE' > <value> http://jabber.org/protocol/muc#roomconfig </value> </field> <field label= 'Natural-Language Room Name' type= 'text-single' var= 'muc#roomconfig_roomname' > <value> A Dark Cave </value> </field> <field label= 'Room subject' type= 'text-single' var= 'muc#roomconfig_subject' > <value> To be or not to be? </value> </field> </x> </query> </iq> 8.1.5. Requesting a user list A user list is retrieved with an affiliation IQ get. Requesting affiliation list 1 2 3 4 5 6 7 8 <iq from= 'crone1@shakespeare.lit/desktop' id= 'comp-getaff' to= 'coven@muclight.shakespeare.lit' type= 'get' > <query xmlns= 'http://jabber.org/protocol/muc#admin' > <item affiliation= 'owner' /> <item affiliation= 'member' /> </query> </iq> 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 <iq from= 'coven@muclight.shakespeare.lit' id= 'comp-getaff' to= 'crone1@shakespeare.lit/desktop' type= 'result' > <query xmlns= 'http://jabber.org/protocol/muc#admin' > <item affiliation= 'owner' jid= 'crone1@shakespeare.lit' nick= 'crone1@shakespeare.lit' role= 'moderator' /> <item affiliation= 'member' jid= 'hag66@shakespeare.lit' nick= 'hag66@shakespeare.lit' role= 'participant' /> </query> </iq> 8.1.6. Requesting room information There is no XEP-0045 equivalent for getting full room information. 8.1.7. Leaving the room Leaving the room is performed by setting the own affiliation to 'none'. The service uses <presence/> to notify all occupants (and former occupant) about the change. <presence/> to the leaving occupant MUST be of the type \"unavailable\" and MUST include a status code 321 (i.e. user leaving due to affiliation change). Leaving the room 1 2 3 4 5 6 7 8 <iq from= 'crone1@shakespeare.lit/desktop' id= 'comp-leave' to= 'coven@muclight.shakespeare.lit' type= 'set' > <query xmlns= 'http://jabber.org/protocol/muc#admin' > <item affiliation= 'none' jid= 'crone1@shakespeare.lit' /> </query> </iq> 1 2 3 4 5 6 7 8 <presence from= 'coven@muclight.shakespeare.lit/crone1@shakespeare.lit' to= 'crone1@shakespeare.lit' type= 'unavailable' > <x xmlns= 'http://jabber.org/protocol/muc#user' > <item affiliation= 'none' jid= 'crone1@shakespeare.lit/pda' role= 'none' /> <status code= '321' /> </x> </presence> 1 2 3 4 5 6 7 <presence from= 'coven@muclight.shakespeare.lit/crone1@shakespeare.lit' to= 'hag66@shakespeare.lit/desktop' > <x xmlns= 'http://jabber.org/protocol/muc#user' > <item affiliation= 'none' jid= 'crone1@shakespeare.lit/pda' role= 'none' /> <status code= '321' /> </x> </presence> 1 2 3 4 <iq from= 'coven@muclight.shakespeare.lit' id= 'comp-leave' to= 'crone1@shakespeare.lit/desktop' type= 'result' /> 8.1.8. Blocking functionality The blocking functionality uses a small subset of the Privacy Lists protocol. Stanzas MUST be addressed to the sender's bare JID (the to attribute may be skipped). The privacy list name MUST be equal to \"urn:xmpp:muclight:0\". Obviously, this method won't work properly in XMPP Server Federation, because privacy stanzas are handled by sender's server and the MUC Light Blocking functionality is handled by a MUC Light service server. As opposed to XEP-0016, it is allowed to send \"delta\" privacy lists. 8.1.8.1. Request blocking list Retrieving blocking list 1 2 3 4 5 <iq from= 'crone1@shakespeare.lit/desktop' type= 'get' id= 'comp-getlist' > <query xmlns= 'jabber:iq:privacy' > <list name= 'urn:xmpp:muclight:0' /> </query> </iq> 1 2 3 4 5 6 7 8 9 10 11 12 13 14 <iq type= 'result' id= 'comp-getlist' to= 'crone1@shakespeare.lit/desktop' > <query xmlns= 'jabber:iq:privacy' > <list name= 'urn:xmpp:muclight:0' > <item type= 'jid' value= 'coven@muclight.shakespeare.lit' action= 'deny' order= '1' /> <item type= 'jid' value= 'muclight.shakespeare.lit/hag66@shakespeare.lit' action= 'deny' order= '1' /> </list> </query> </iq> 8.1.8.2. Blocking a room In order to block a room, the client MUST deny a room bare JID in privacy list. Blocking a room 1 2 3 4 5 6 7 8 9 10 <iq from= 'crone1@shakespeare.lit/desktop' type= 'set' id= 'comp-blockroom' > <query xmlns= 'jabber:iq:privacy' > <list name= 'urn:xmpp:muclight:0' > <item type= 'jid' value= 'coven@muclight.shakespeare.lit' action= 'deny' order= '1' /> </list> </query> </iq> 1 <iq type= 'result' id= 'comp-blockroom' to= 'crone1@shakespeare.lit/desktop' /> 8.1.8.3. Blocking a user In order to block a room, the client MUST deny a service JID with user's bare JID in the resource. Blocking a user 1 2 3 4 5 6 7 8 9 10 <iq from= 'crone1@shakespeare.lit/desktop' type= 'set' id= 'comp-blockuser' > <query xmlns= 'jabber:iq:privacy' > <list name= 'urn:xmpp:muclight:0' > <item type= 'jid' value= 'muclight.shakespeare.lit/hag66@shakespeare.lit' action= 'deny' order= '1' /> </list> </query> </iq> 1 <iq type= 'result' id= 'comp-blockuser' to= 'crone1@shakespeare.lit/desktop' /> 8.1.8.4. Unblocking Unblocking 1 2 3 4 5 6 7 8 9 10 11 12 13 14 <iq from= 'crone1@shakespeare.lit/desktop' type= 'get' id= 'comp-getlist' > <query xmlns= 'jabber:iq:privacy' > <list name= 'urn:xmpp:muclight:0' > <item type= 'jid' value= 'coven@muclight.shakespeare.lit' action= 'allow' order= '1' /> <item type= 'jid' value= 'muclight.shakespeare.lit/hag66@shakespeare.lit' action= 'allow' order= '1' /> </list> </query> </iq> 1 <iq type= 'result' id= 'comp-getlist' to= 'crone1@shakespeare.lit/desktop' /> 8.1.9. Creating a room The room is created in a standard XEP-0045 way. Client MUST use a nick equal to their own bare JID. Compatibility mode MUST NOT support a unique room name generation. Creating a room 1 2 3 4 <presence from= 'crone1@shakespeare.lit/desktop' to= 'coven@muclight.shakespeare.lit/crone1@shakespeare.lit' > <x xmlns= 'http://jabber.org/protocol/muc' /> </presence> 1 2 3 4 5 6 7 8 <presence from= 'coven@chat.shakespeare.lit/crone1@shakespeare.lit' to= 'crone1@shakespeare.lit/desktop' > <x xmlns= 'http://jabber.org/protocol/muc#user' > <item affiliation= 'owner' role= 'moderator' /> <status code= '110' /> <status code= '201' /> </x> </presence> 8.1.9.1. Room already exists If the client attempts to create a room that is already used, it will receive an error <presence/> informing that registration is required (like in the case of members-only rooms in XEP-0045). Creating a room 1 2 3 4 5 6 7 8 <presence from= 'coven@muclight.shakespeare.lit/crone1@shakespeare.lit' to= 'crone1@shakespeare.lit/desktop' type= 'error' > <x xmlns= 'http://jabber.org/protocol/muc' /> <error by= 'coven@muclight.shakespeare.lit' type= 'auth' > <registration-required xmlns= 'urn:ietf:params:xml:ns:xmpp-stanzas' /> </error> </presence> 8.1.10. Destroying the room A classic XEP-0045 method is used but the service SHOULD NOT forward reason and alternate venue JID. Destroying the room 1 2 3 4 5 6 7 8 9 10 <iq from= 'crone1@shakespeare.lit/desktop' id= 'begone' to= 'heath@muclight.shakespeare.lit' type= 'set' > <query xmlns= 'http://jabber.org/protocol/muc#owner' > <destroy jid= 'coven@muclight.shakespare.lit' > <reason> Some reason. </reason> </destroy> </query> </iq> 1 2 3 4 5 6 7 <presence from= 'heath@chat.shakespeare.lit/crone1@shakespeare.lit' to= 'crone1@shakespeare.lit/desktop' type= 'unavailable' > <x xmlns= 'http://jabber.org/protocol/muc#user' > <item affiliation= 'none' role= 'none' /> <destroy /> </x> </presence> 1 2 3 4 5 6 7 8 <presence from= 'heath@chat.shakespeare.lit/wiccarocks@shakespeare.lit' to= 'wiccarocks@shakespeare.lit/laptop' type= 'unavailable' > <x xmlns= 'http://jabber.org/protocol/muc#user' > <item affiliation= 'none' role= 'none' /> <destroy /> </x> </presence> 1 2 3 4 5 6 7 8 9 <presence from= 'heath@chat.shakespeare.lit/hag66@shakespeare.lit' to= 'hag66@shakespeare.lit/pda' type= 'unavailable' > <x xmlns= 'http://jabber.org/protocol/muc#user' > <item affiliation= 'none' role= 'none' /> <destroy /> </x> </presence> 1 2 3 4 <iq from= 'heath@chat.shakespeare.lit' id= 'begone' to= 'crone1@shakespeare.lit/desktop' type= 'result' /> 8.1.11. Setting room configuration Room occupants can use a standard XEP-0045 configuration modification method. The service MUST broadcast only the notification about the configuration change with a status code 104, so every occupant can retrieve the new room configuration in a separate request. The client is allowed to send a config delta in a form. Setting room configuration 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 <iq to= 'coven@muclight.shakespeare.lit' id= 'comp-setconfig' from= 'crone1@shakespeare.lit/desktop' type= 'set' > <query xmlns= 'http://jabber.org/protocol/muc#owner' > <x xmlns= 'jabber:x:data' type= 'form' > <field type= 'hidden' var= 'FORM_TYPE' > <value> http://jabber.org/protocol/muc#roomconfig </value> </field> <field label= 'Natural-Language Room Name' type= 'text-single' var= 'muc#roomconfig_roomname' > <value> A Darker Cave </value> </field> <field label= 'Room subject' type= 'text-single' var= 'muc#roomconfig_subject' > <value> To be! </value> </field> </x> </query> </iq> 1 2 3 4 5 6 7 8 <message from= 'coven@muclight.shakespeare.lit' id= 'comp-confchange' to= 'crone1@shakespeare.lit/desktop' type= 'groupchat' > <x xmlns= 'http://jabber.org/protocol/muc#user' > <status code= '104' /> </x> </message> 1 2 3 4 5 6 7 8 <message from= 'coven@muclight.shakespeare.lit' id= 'comp-confchange' to= 'crone2@shakespeare.lit/desktop' type= 'groupchat' > <x xmlns= 'http://jabber.org/protocol/muc#user' > <status code= '104' /> </x> </message> 1 2 3 4 <iq from= 'coven@muclight.shakespeare.lit' id= 'comp-setconfig' to= 'crone1@shakespeare.lit/desktop' type= 'result' /> 8.1.12. Changing occupant list The service MUST send an affiliation change notification to all participants. Leaving users MUST NOT receive any information except for their own \"none\" affiliation. New users MUST receive an invitation message. Changing occupant list 1 2 3 4 5 6 7 8 9 <iq from= 'crone1@shakespeare.lit/desktop' id= 'comp-setaff' to= 'coven@muclight.shakespeare.lit' type= 'set' > <query xmlns= 'http://jabber.org/protocol/muc#admin' > <item affiliation= 'none' jid= 'hag66@shakespeare.lit' /> <item affiliation= 'member' jid= 'hecate@shakespeare.lit' /> </query> </iq> 1 2 3 4 5 6 7 8 <presence from= 'coven@chat.shakespeare.lit/hag66@shakespeare.lit' to= 'hag66@shakespeare.lit' type= 'unavailable' > <x xmlns= 'http://jabber.org/protocol/muc#user' > <item affiliation= 'none' jid= 'hag66@shakespeare.lit' role= 'none' /> <status code= '321' /> </x> </presence> 1 2 3 4 5 6 7 <message from= 'coven@muclight.shakespeare.lit' id= 'comp-invite0' to= 'hecate@shakespeare.lit' > <x xmlns= 'http://jabber.org/protocol/muc#user' > <invite from= 'crone1@shakespeare.lit' /> </x> </message> 1 2 3 4 5 6 7 8 <presence from= 'coven@chat.shakespeare.lit/hag66@shakespeare.lit' to= 'crone1@shakespeare.lit' type= 'unavailable' > <x xmlns= 'http://jabber.org/protocol/muc#user' > <item affiliation= 'none' jid= 'hag66@shakespeare.lit' role= 'none' /> <status code= '321' /> </x> </presence> 1 2 3 4 5 6 7 8 9 <presence from= 'coven@chat.shakespeare.lit/hecate@shakespeare.lit' to= 'crone1@shakespeare.lit' > <x xmlns= 'http://jabber.org/protocol/muc#user' > <item affiliation= 'member' jid= 'hecate@shakespeare.lit' role= 'participant' nick= 'hecate@shakespeare.lit' /> </x> </presence> 1 2 3 4 <iq from= 'coven@muclight.shakespeare.lit' id= 'comp-setaff' to= 'crone1@shakespeare.lit/desktop' type= 'result' /> 8.2. Service limits and configuration The MUC Light service may be abused by a malicious users, e.g. due to replicating a single message for every room occupant. The list below contains suggested configurable limits that SHOULD be implemented. The service features that might vary depending on a specific application are included as well. Maximum number of rooms the user occupies. Blocking feature enabled/disabled. XEP-0045 compatibility mode enabled/disabled. Room creator's initial affiliation: owner/member. Room configuration may be changed by owner/occupants. New members can be invited by owner/occupants. Maximal room size.","title":"MUC light"},{"location":"open-extensions/muc_light/#1-introduction","text":"Classic Multi-User chat, as described in XEP-0045, adds an IRC-like functionality to XMPP. It distinguishes between the affiliation list and the occupant list, where the latter is based on presences routed to the room from the client resource. While perfectly sufficient for desktop applications and relatively stable network connection, it does not exactly meet the challenges the mobile world it is facing. Modern mobile applications do not rely on presence information, as it can frequently change. The expected user experience not only differs from the IRC model, but also uses only a small subset of XEP-0045 features. The service described in this specification attempts to provide a complete solution for all common use cases of mobile groupchats.","title":"1. Introduction"},{"location":"open-extensions/muc_light/#2-requirements","text":"Here are some high-level features required from a new variant of MUC The service allows any user to create a room for group communication. Users cannot join rooms on their own. They have to be added by the room owner or (if configured by service administrator) any other occupant. Only the owner can remove other occupants from the room. Every occupant can leave the room. A user may block the attempts of being added to the specific room or by specific user. The message sent in the room is always broadcasted to every occupant. The full occupant list is always available to all occupants. The occupant is always visible on the list, even if they do not have any resources online. Occupants can only have two affiliations: owner and member. There MUST be at most one owner in the room (the service can choose to treat all users equally). If the room becomes empty, it is destroyed. Occupants cannot hide behind nicks. Their real bare JID is always visible to everyone No exchange of any <presence/> stanza inside the room. The user MUST be able to retrieve the list of rooms they occupy. The owner can modify the room configuration at any time; members may also be allowed to set configuration. All occupants can get the full room configuration at any time. Room history is available only in Message Archive Management.","title":"2. Requirements"},{"location":"open-extensions/muc_light/#3-entity-use-cases","text":"","title":"3. Entity Use Cases"},{"location":"open-extensions/muc_light/#31-discovering-a-muc-light-service","text":"An entity often discovers a MUC service by sending a Service Discovery items (\"disco#items\") request to its own server. Entity Queries the Server for Associated Services 1 2 3 4 5 6 <iq from= 'hag66@shakespeare.lit/pda' id= 'h7ns81g' to= 'shakespeare.lit' type= 'get' > <query xmlns= 'http://jabber.org/protocol/disco#items' /> </iq> The server then returns the services that are associated with it. Server Returns a Disco Items Result 1 2 3 4 5 6 7 8 <iq from= 'shakespeare.lit' id= 'h7ns81g' to= 'hag66@shakespeare.lit/pda' type= 'result' > <query xmlns= 'http://jabber.org/protocol/disco#items' > <item jid= 'muclight.shakespeare.lit' name= 'MUC Light Service' /> </query> </iq>","title":"3.1. Discovering a MUC Light Service"},{"location":"open-extensions/muc_light/#32-discovering-the-features-supported-by-a-muc-light-service","text":"An entity may wish to discover if a service implements the Multi-User Chat protocol; in order to do so, it sends a service discovery information (\"disco#info\") query to the MUC service's JID. Entity Queries Chat Service for MUC Light Support via Disco 1 2 3 4 5 <iq from= 'hag66@shakespeare.lit/pda' id= 'lx09df27' to= 'muclight.shakespeare.lit' type= 'get' > <query xmlns= 'http://jabber.org/protocol/disco#info' /> </iq> The service MUST return its identity and the features it supports. Service Returns a Disco Info Result 1 2 3 4 5 6 7 8 9 <iq from= 'muclight.shakespeare.lit' id= 'lx09df27' to= 'hag66@shakespeare.lit/pda' type= 'result' > <query xmlns= 'http://jabber.org/protocol/disco#info' > <identity category= 'conference' name= 'Shakespearean Chat Service' type= 'text' /> <feature var= 'urn:xmpp:muclight:0' /> </query> </iq>","title":"3.2. Discovering the Features Supported by a MUC Light Service"},{"location":"open-extensions/muc_light/#33-discovering-occupied-rooms","text":"The service discovery items (\"disco#items\") protocol enables an entity to query a service for a list of associated items, which in the case of a chat service would consist of the specific chat rooms the entity occupies. Entity Queries Chat Service for Rooms 1 2 3 4 5 6 <iq from= 'hag66@shakespeare.lit/pda' id= 'zb8q41f4' to= 'muclight.shakespeare.lit' type= 'get' > <query xmlns= 'http://jabber.org/protocol/disco#items' /> </iq> The service MUST return a full list of the rooms the entity occupies. The server SHOULD include room name and version in each item. Service Returns a Disco Items Result 1 2 3 4 5 6 7 8 9 10 11 12 13 <iq from= 'muclight.shakespeare.lit' id= 'zb8q41f4' to= 'hag66@shakespeare.lit/pda' type= 'result' > <query xmlns= 'http://jabber.org/protocol/disco#items' > <item jid= 'heath@muclight.shakespeare.lit' name= 'A Lonely Heath' version= '1' /> <item jid= 'coven@muclight.shakespeare.lit' name= 'A Dark Cave' version= '2' /> <item jid= 'forres@muclight.shakespeare.lit' name= 'The Palace' version= '3' /> <item jid= 'inverness@muclight.shakespeare.lit' name= 'Macbeth&apos;s Castle' version= '4' /> </query> </iq> If the full list of rooms is large (see XEP-0030 for details), the service MAY return only a partial list of rooms. If it does, it MUST include a <set/> element qualified by the 'http://jabber.org/protocol/rsm' namespace (as defined in Result Set Management (XEP-0059) [1]) to indicate that the list is not the full result set. Service Returns a Limited List of Disco Items Result 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 <iq from= 'muclight.shakespeare.lit' id= 'hx51v49s' to= 'hag66@shakespeare.lit/pda' type= 'result' > <query xmlns= 'http://jabber.org/protocol/disco#items' > <item jid= 'alls-well-that-ends-well@muclight.shakespeare.lit' name= 'Everybody dies' version= '1' /> <item jid= 'as-you-like-it@muclight.shakespeare.lit' name= 'As you like it' version= '2' /> <item jid= 'cleopatra@muclight.shakespeare.lit' name= 'Cleo fans' version= '3' /> <item jid= 'comedy-of-errors@muclight.shakespeare.lit' name= '404 Comedy not found' version= '4' /> <item jid= 'coriolanus@muclight.shakespeare.lit' name= 'What is Coriolanus?' version= '5' /> <item jid= 'cymbeline@muclight.shakespeare.lit' name= 'Music room' version= '6' /> <item jid= 'hamlet@muclight.shakespeare.lit' name= 'To chat or not to chat?' version= '7' /> <item jid= 'henry-the-fourth-one@muclight.shakespeare.lit' name= 'Royal Room 1' version= '8' /> <item jid= 'henry-the-fourth-two@muclight.shakespeare.lit' name= 'Royal Room 2' version= '9' /> <item jid= 'henry-the-fifth@muclight.shakespeare.lit' name= 'Royal Room Prime' version= '10' /> <set xmlns= 'http://jabber.org/protocol/rsm' > <first index= '0' > alls-well-that-ends-well@muclight.shakespeare.lit </first> <last> henry-the-fifth@muclight.shakespeare.lit </last> <count> 37 </count> </set> </query> </iq>","title":"3.3. Discovering Occupied Rooms"},{"location":"open-extensions/muc_light/#4-occupant-use-cases","text":"","title":"4. Occupant Use Cases"},{"location":"open-extensions/muc_light/#41-sending-a-message-to-a-room","text":"Every occupant in the room MAY broadcast messages to other occupants. In order to do so, the client MUST send a groupchat message to the room bare JID. The room automatically assumes that occupants' nicks are equal to their bare JIDs. MUC light is designed for applications where it is not important to hide behind nicknames. On the contrary - it is up to the client to replace pure JIDs with user-friendly names like phone numbers or full names if necessary. The room MUST route all messages of the 'groupchat' type. Client sends a message to the room 1 2 3 4 5 6 <message from= 'hag66@shakespeare.lit/pda' id= 'msg111' to= 'coven@muclight.shakespeare.lit' type= 'groupchat' > <body> Harpier cries: 'tis time, 'tis time. </body> </message> Server broadcasts a groupchat message 1 2 3 4 5 <message id= 'msg111' type= 'groupchat' from= 'coven@muclight.shakespeare.lit/hag66@shakespeare.lit' to= 'crone1@shakespeare.lit' > <body> Harpier cries: 'tis time, 'tis time. </body> </message> 1 2 3 4 5 <message id= 'msg111' type= 'groupchat' from= 'coven@muclight.shakespeare.lit/hag66@shakespeare.lit' to= 'crone2@shakespeare.lit' > <body> Harpier cries: 'tis time, 'tis time. </body> </message> Note the message is sent to all the room occupants including the original sender. 1 2 3 4 5 <message id= 'msg111' type= 'groupchat' from= 'coven@muclight.shakespeare.lit/hag66@shakespeare.lit' to= 'hag66@shakespeare.lit' > <body> Harpier cries: 'tis time, 'tis time. </body> </message>","title":"4.1. Sending a message to a room"},{"location":"open-extensions/muc_light/#42-changing-a-room-subject","text":"The service MAY allow room occupants to set the room subject by changing the \"subject\" configuration field. A standard configuration stanza is used in this case. Subject change is announced like an ordinary configuration change. Client sends a message to the room 1 2 3 4 5 6 7 8 <iq from= 'hag66@shakespeare.lit/pda' id= 'subject1' to= 'coven@muclight.shakespeare.lit' type= 'set' > <query xmlns= 'urn:xmpp:muclight:0#configuration' > <subject> To be or not to be? </subject> </query> </iq> 1 2 3 4 5 6 7 8 9 10 11 <message from= 'coven@muclight.shakespeare.lit' to= 'crone1@shakespeare.lit' type= 'groupchat' id= 'newsubject' > <x xmlns= 'urn:xmpp:muclight:0#configuration' > <prev-version> asdfghj000 </prev-version> <version> asdfghj </version> <subject> To be or not to be? </subject> </x> <body /> </message> 1 2 3 4 5 6 7 8 9 10 11 <message from= 'coven@muclight.shakespeare.lit' to= 'hag66@shakespeare.lit' type= 'groupchat' id= 'newsubject' > <x xmlns= 'urn:xmpp:muclight:0#configuration' > <prev-version> asdfghj000 </prev-version> <version> asdfghj </version> <subject> To be or not to be? </subject> </x> <body /> </message> 1 2 3 4 <iq to= 'hag66@shakespeare.lit/pda' id= 'subject1' from= 'coven@muclight.shakespeare.lit' type= 'result' />","title":"4.2. Changing a room subject"},{"location":"open-extensions/muc_light/#43-requesting-room-information","text":"Room occupants may request room information (configuration and/or occupants list) by an information version. It is up to the service to define the version string, the only requirement for it, is to be unique per room. Please note there are no separate versions for configuration and occupant list alone. If the server side version does not match the one provided by the client (or if the client does not provide one, i.e. the 'version' element is empty), the service MUST respond with a current version string and full configuration and/or occupant list. If the version strings match, server MUST reply with an empty result. Only room occupants can get room information. Matching versions 1 2 3 4 5 6 7 8 <iq from= 'crone1@shakespeare.lit/desktop' id= 'config0' to= 'coven@muclight.shakespeare.lit' type= 'get' > <query xmlns= 'urn:xmpp:muclight:0#configuration' > <version> abcdefg </version> </query> </iq> 1 2 3 4 <iq from= 'coven@muclight.shakespeare.lit' id= 'config0' to= 'crone1@shakespeare.lit/desktop' type= 'result' />","title":"4.3. Requesting room information"},{"location":"open-extensions/muc_light/#431-getting-the-room-configuration","text":"Client gets configuration from the server 1 2 3 4 5 6 7 8 <iq from= 'crone1@shakespeare.lit/desktop' id= 'getconfig1' to= 'coven@muclight.shakespeare.lit' type= 'get' > <query xmlns= 'urn:xmpp:muclight:0#configuration' > <version> abcdefg </version> </query> </iq> 1 2 3 4 5 6 7 8 9 <iq from= 'coven@muclight.shakespeare.lit' id= 'getconfig1' to= 'crone1@shakespeare.lit/desktop' type= 'result' > <query xmlns= 'urn:xmpp:muclight:0#configuration' > <version> 123456 </version> <roomname> A Dark Cave </roomname> </query> </iq>","title":"4.3.1. Getting the room configuration"},{"location":"open-extensions/muc_light/#432-requesting-a-user-list","text":"Client requests a user list 1 2 3 4 5 6 7 8 <iq from= 'crone1@shakespeare.lit/desktop' id= 'getmembers' to= 'coven@muclight.shakespeare.lit' type= 'get' > <query xmlns= 'urn:xmpp:muclight:0#affiliations' > <version> abcdefg </version> </query> </iq> 1 2 3 4 5 6 7 8 9 10 11 <iq from= 'coven@muclight.shakespeare.lit' id= 'getmembers' to= 'crone1@shakespeare.lit/desktop' type= 'result' > <query xmlns= 'urn:xmpp:muclight:0#affiliations' > <version> 123456 </version> <user affiliation= 'owner' > user1@shakespeare.lit </user> <user affiliation= 'member' > user2@shakespeare.lit </user> <user affiliation= 'member' > user3@shakespeare.lit </user> </query> </iq>","title":"4.3.2. Requesting a user list"},{"location":"open-extensions/muc_light/#433-requesting-full-room-information","text":"Room occupants may request both lists (configuration + occupants) with a single request. Client requests room information 1 2 3 4 5 6 7 8 <iq from= 'crone1@shakespeare.lit/desktop' id= 'getinfo1' to= 'coven@muclight.shakespeare.lit' type= 'get' > <query xmlns= 'urn:xmpp:muclight:0#info' > <version> abcdefg </version> </query> </iq> 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 <iq from= 'coven@muclight.shakespeare.lit' id= 'getinfo1' to= 'crone1@shakespeare.lit/desktop' type= 'result' > <query xmlns= 'urn:xmpp:muclight:0#info' > <version> 123456 </version> <configuration> <roomname> A Dark Cave </roomname> </configuration> <occupants> <user affiliation= 'owner' > user1@shakespeare.lit </user> <user affiliation= 'member' > user2@shakespeare.lit </user> <user affiliation= 'member' > user3@shakespeare.lit </user> </occupants> </query> </iq>","title":"4.3.3. Requesting full room information"},{"location":"open-extensions/muc_light/#44-leaving-the-room","text":"Every occupant is allowed to leave the room at any time. It is done by modifying their own affiliation. Occupant leaves the room 1 2 3 4 5 6 7 8 <iq from= 'crone1@shakespeare.lit/desktop' id= 'leave1' to= 'coven@muclight.shakespeare.lit' type= 'set' > <query xmlns= 'urn:xmpp:muclight:0#affiliations' > <user affiliation= 'none' > crone1@shakespeare.lit </user> </query> </iq> 1 2 3 4 5 6 7 8 9 <message from= 'coven@muclight.shakespeare.lit' to= 'crone1@shakespeare.lit' type= 'groupchat' id= 'leave1' > <x xmlns= 'urn:xmpp:muclight:0#affiliations' > <user affiliation= 'none' > crone1@shakespeare.lit </user> </x> <body /> </message> 1 2 3 4 5 6 7 8 9 10 11 <message from= 'coven@muclight.shakespeare.lit' to= 'hag77@shakespeare.lit' type= 'groupchat' id= 'leave1' > <x xmlns= 'urn:xmpp:muclight:0#affiliations' > <prev-version> 1111111 </prev-version> <version> aaaaaaa </version> <user affiliation= 'none' > crone1@shakespeare.lit </user> </x> <body /> </message> 1 2 3 4 5 6 7 8 9 10 11 <message from= 'coven@muclight.shakespeare.lit' to= 'hag88@shakespeare.lit' type= 'groupchat' id= 'leave1' > <x xmlns= 'urn:xmpp:muclight:0#affiliations' > <prev-version> 1111111 </prev-version> <version> aaaaaaa </version> <user affiliation= 'none' > crone1@shakespeare.lit </user> </x> <body /> </message> 1 2 3 4 <iq to= 'crone1@shakespeare.lit/desktop' id= 'leave1' from= 'coven@muclight.shakespeare.lit' type= 'result' />","title":"4.4. Leaving the room"},{"location":"open-extensions/muc_light/#45-blocking-functionality","text":"A user MAY choose to automatically deny being added to the room. All stanzas must be directed to MUC Light service. User MAY send more than one item in a single request and mix both 'user' and 'room' elements. If the occupant tries to add another user to the room, and this user has set a blocking policy, the server MUST ignore the attempt. No error is returned, this user is simply skipped when processing affiliation change query. Service denies adding blocking user 1 2 3 4 5 6 7 8 9 <iq from= 'crone2@shakespeare.lit/desktop' id= 'blocked1' to= 'coven@muclight.shakespeare.lit' type= 'set' > <query xmlns= 'urn:xmpp:muclight:0#affiliations' > <user affiliation= 'member' > crone1@shakespeare.lit </user> <user affiliation= 'member' > crone3@shakespeare.lit </user> </query> </iq> 1 2 3 4 5 6 7 8 9 <message from= 'coven@muclight.shakespeare.lit' to= 'crone2@shakespeare.lit' type= 'groupchat' id= 'blockedadd1' > <x xmlns= 'urn:xmpp:muclight:0#affiliations' > <user affiliation= 'member' > crone3@shakespeare.lit </user> </x> <body /> </message> 1 2 3 4 5 6 7 8 9 <message from= 'coven@muclight.shakespeare.lit' to= 'hag88@@shakespeare.lit' type= 'groupchat' id= 'blockedadd1' > <x xmlns= 'urn:xmpp:muclight:0#affiliations' > <user affiliation= 'member' > crone3@shakespeare.lit </user> </x> <body /> </message> 1 2 3 4 <iq to= 'crone2@shakespeare.lit/desktop' id= 'blocked1' from= 'coven@muclight.shakespeare.lit' type= 'result' />","title":"4.5. Blocking functionality"},{"location":"open-extensions/muc_light/#451-requesting-a-blocking-list","text":"In order to get the current blocking list in the MUC Light service, the client sends an empty IQ get query with a proper namespace. The list includes only items with a 'deny' action, since the 'allow' behaviour is default for MUC Light and is only used for the list modification. User retrieves a blocking list 1 2 3 4 5 6 7 <iq from= 'crone1@shakespeare.lit/desktop' id= 'getblock1' to= 'muclight.shakespeare.lit' type= 'get' > <query xmlns= 'urn:xmpp:muclight:0#blocking' > </query> </iq> 1 2 3 4 5 6 7 8 9 <iq type= 'result' id= 'getblock1' to= 'crone1@shakespeare.lit/desktop' from= 'muclight.shakespeare.lit' > <query xmlns= 'urn:xmpp:muclight:0#blocking' > <room action= 'deny' > coven@muclight.shakespeare.lit </room> <user action= 'deny' > hag77@shakespeare.lit </user> </query> </iq>","title":"4.5.1. Requesting a blocking list"},{"location":"open-extensions/muc_light/#452-blocking-a-room","text":"In order to block a room, a query must contain at least one 'room' item with a 'deny' action and a room bare JID in the content. User blocks a room 1 2 3 4 5 6 7 8 9 <iq from= 'crone1@shakespeare.lit/desktop' id= 'block1' to= 'muclight.shakespeare.lit' type= 'set' > <query xmlns= 'urn:xmpp:muclight:0#blocking' > <room action= 'deny' > coven@muclight.shakespeare.lit </room> <room action= 'deny' > chapel@shakespeare.lit </room> </query> </iq> 1 2 3 4 <iq type= 'result' id= 'block1' to= 'crone1@shakespeare.lit/desktop' from= 'muclight.shakespeare.lit' />","title":"4.5.2. Blocking a room"},{"location":"open-extensions/muc_light/#453-blocking-a-user","text":"In order to block a user, a query must contain at least one 'user' item with a 'deny' action and a user bare JID in the content. User blocks another user 1 2 3 4 5 6 7 8 9 <iq from= 'crone1@shakespeare.lit/desktop' id= 'block2' to= 'muclight.shakespeare.lit' type= 'set' > <query xmlns= 'urn:xmpp:muclight:0#blocking' > <user action= 'deny' > hag66@shakespeare.lit </user> <user action= 'deny' > hag77@shakespeare.lit </user> </query> </iq> 1 2 3 4 <iq type= 'result' id= 'block2' to= 'crone1@shakespeare.lit/desktop' from= 'muclight.shakespeare.lit' />","title":"4.5.3. Blocking a user"},{"location":"open-extensions/muc_light/#454-unblocking","text":"In order to cancel a blocking, a query must contain at least one 'room' or 'user' item with an 'allow' action and an appriopriate bare JID in the content. Unblocking a JID that is not blocked does not trigger any error. The server MUST return an empty IQ result in such case. User cancels blocking 1 2 3 4 5 6 7 8 9 <iq from= 'crone1@shakespeare.lit/desktop' id= 'unblock1' to= 'muclight.shakespeare.lit' type= 'set' > <query xmlns= 'urn:xmpp:muclight:0#blocking' > <room action= 'allow' > coven@muclight.shakespeare.lit </room> <user action= 'allow' > hag66@shakespeare.lit </user> </query> </iq> 1 2 3 4 <iq type= 'result' id= 'unblock1' to= 'crone1@shakespeare.lit/desktop' from= 'muclight.shakespeare.lit' />","title":"4.5.4. Unblocking"},{"location":"open-extensions/muc_light/#5-owner-use-cases","text":"","title":"5. Owner Use Cases"},{"location":"open-extensions/muc_light/#51-creating-a-new-room","text":"A room is created by submitting a dedicated stanza. The client application should pick a random room node name, since a human-readable room name is in configuration. For rules that apply to the configuration options, please see \"Setting room configuration\" chapter. The client MAY include initial configuration and occupant list (the list MUST NOT include the creator). The server MAY allow sending an incomplete configuration form. In such case the server MUST use the default values for missing fields. The server MAY enforce a minimal occupant list length. The service MAY either give the creator the 'owner' or 'member' status. In the latter case all users are equal. Upon room creation success, the service MUST reply with an empty IQ result. The following rules (similar to the ones relevant to the affiliation change request) apply to the occupant list: 'none' affiliation cannot be used. All user bare JIDs must be unique At most one owner can be chosen. If none is chosen, the room creator will become \"just\" a 'member'. After the room is created (but before receiving IQ result), new occupants (including the creator) receive <message/> from the room with their affiliations (the stanza MUST include only recipient's affiliation) and the initial room version. <prev-version/> element MUST NOT be included. Client requests room creation 1 2 3 4 5 6 7 8 9 10 11 12 13 14 <iq from= 'crone1@shakespeare.lit/desktop' id= 'create1' to= 'coven@muclight.shakespeare.lit' type= 'set' > <query xmlns= 'urn:xmpp:muclight:0#create' > <configuration> <roomname> A Dark Cave </roomname> </configuration> <occupants> <user affiliation= 'member' > user1@shakespeare.lit </user> <user affiliation= 'member' > user2@shakespeare.lit </user> </occupants> </query> </iq> 1 2 3 4 5 6 7 8 9 10 <message from= 'coven@muclight.shakespeare.lit' to= 'crone1@shakespeare.lit' type= 'groupchat' id= 'createnotif' > <x xmlns= 'urn:xmpp:muclight:0#affiliations' > <version> aaaaaaa </version> <user affiliation= 'owner' > crone1@shakespeare.lit </user> </x> <body /> </message> 1 2 3 4 5 6 7 8 9 10 <message from= 'coven@muclight.shakespeare.lit' to= 'user1@shakespeare.lit' type= 'groupchat' id= 'createnotif' > <x xmlns= 'urn:xmpp:muclight:0#affiliations' > <version> aaaaaaa </version> <user affiliation= 'member' > user1@shakespeare.lit </user> </x> <body /> </message> 1 2 3 4 5 6 7 8 9 10 <message from= 'coven@muclight.shakespeare.lit' to= 'user2@shakespeare.lit' type= 'groupchat' id= 'createnotif' > <x xmlns= 'urn:xmpp:muclight:0#affiliations' > <version> aaaaaaa </version> <user affiliation= 'member' > user2@shakespeare.lit </user> </x> <body /> </message> 1 2 3 4 <iq to= 'crone1@shakespeare.lit/desktop' id= 'create1' from= 'coven@muclight.shakespeare.lit' type= 'result' />","title":"5.1. Creating a new room"},{"location":"open-extensions/muc_light/#511-requesting-a-new-room-with-a-unique-name","text":"If a client would like to avoid a room JID conflict, it MAY request creating a new room with a server-side generated name, that is verfied to be unique. In order to do so, the client MUST send a creation request to service JID, not room bare JID. The IQ result will originate from the new room bare JID The messages with affiliation change notifications MUST have the same ID as IQ set and result. Client requests room creation 1 2 3 4 5 6 7 8 9 10 <iq from= 'crone1@shakespeare.lit/desktop' id= 'createrandom' to= 'muclight.shakespeare.lit' type= 'set' > <query xmlns= 'urn:xmpp:muclight:0#create' > <configuration> <roomname> Random Cave </roomname> </configuration> </query> </iq> 1 2 3 4 5 6 7 8 9 10 <message from= 'randomcave@muclight.shakespeare.lit' to= 'crone1@shakespeare.lit' type= 'groupchat' id= 'createrandom' > <x xmlns= 'urn:xmpp:muclight:0#affiliations' > <version> aaaaaaa </version> <user affiliation= 'owner' > crone1@shakespeare.lit </user> </x> <body /> </message> 1 2 3 4 <iq to= 'crone1@shakespeare.lit/desktop' id= 'createrandom' from= 'muclight.shakespeare.lit' type= 'result' />","title":"5.1.1. Requesting a new room with a unique name"},{"location":"open-extensions/muc_light/#512-room-already-exists","text":"If the chosen room name already exists, the service MUST return a 'conflict' error. Client requests room creation with existing name 1 2 3 4 5 6 7 8 9 10 <iq from= 'crone1@shakespeare.lit/desktop' id= 'conflict1' to= 'castle@muclight.shakespeare.lit' type= 'set' > <query xmlns= 'urn:xmpp:muclight:0#create' > <configuration> <roomname> A Dark Cave </roomname> </configuration> </query> </iq> 1 2 3 4 5 6 7 8 <iq to= 'crone1@shakespeare.lit/desktop' id= 'conflict1' from= 'castle@muclight.shakespeare.lit' type= 'error' > <error type= 'cancel' > <conflict xmlns= 'urn:ietf:params:xml:ns:xmpp-stanzas' /> </error> </iq>","title":"5.1.2. Room already exists"},{"location":"open-extensions/muc_light/#52-destroying-a-room","text":"A room is automatically destroyed when its occupant list becomes empty or the room owner explicitly sends an IQ with a room destroy request. Before sending an IQ result, every occupant is notified that its affiliation has changed to 'none'. These notifications include an <x/> element qualified with a \"urn:xmpp:muclight:0#destroy\" namespace. Only the room owner is allowed to destroy it. Room destruction notification SHOULD NOT contain version (or \"prev-version\" information). Client requests room destruction 1 2 3 4 5 6 <iq from= 'crone1@shakespeare.lit/desktop' id= 'destroy1' to= 'coven@muclight.shakespeare.lit' type= 'set' > <query xmlns= 'urn:xmpp:muclight:0#destroy' /> </iq> 1 2 3 4 5 6 7 8 9 10 <message from= 'coven@muclight.shakespeare.lit' to= 'crone1@shakespeare.lit' type= 'groupchat' id= 'destroynotif' > <x xmlns= 'urn:xmpp:muclight:0#affiliations' > <user affiliation= 'none' > crone1@shakespeare.lit </user> </x> <x xmlns= 'urn:xmpp:muclight:0#destroy' /> <body /> </message> 1 2 3 4 5 6 7 8 9 10 <message from= 'coven@muclight.shakespeare.lit' to= 'hag77@shakespeare.lit' type= 'groupchat' id= 'destroynotif' > <x xmlns= 'urn:xmpp:muclight:0#affiliations' > <user affiliation= 'none' > hag77@shakespeare.lit </user> </x> <x xmlns= 'urn:xmpp:muclight:0#destroy' /> <body /> </message> 1 2 3 4 5 6 7 8 9 10 <message from= 'coven@muclight.shakespeare.lit' to= 'hag88@shakespeare.lit' type= 'groupchat' id= 'destroynotif' > <x xmlns= 'urn:xmpp:muclight:0#affiliations' > <user affiliation= 'none' > hag88@shakespeare.lit </user> </x> <x xmlns= 'urn:xmpp:muclight:0#destroy' /> <body /> </message> 1 2 3 4 <iq to= 'crone1@shakespeare.lit/desktop' id= 'create1' from= 'coven@muclight.shakespeare.lit' type= 'result' />","title":"5.2. Destroying a room"},{"location":"open-extensions/muc_light/#53-setting-room-configuration","text":"Only room owners can modify the room configuration but the service MAY allow members to change it too. All room occupants MUST be notified about a configuration change and both the new and old room version string ( <version /> and <prev-version /> respectively). \"version\" and \"prev-version\" configuration field names are NOT ALLOWED - they are reserved for room versioning. The service MAY allow the client to set the configuration fields with any name but it is NOT RECOMMENDED. The Data Forms are not used for the configuration. Instead, the config fields are encoded in XML elements with names equal to the key and content equal to the value. Client configuration request to the server 1 2 3 4 5 6 7 8 <iq from= 'crone1@shakespeare.lit/desktop' id= 'conf2' to= 'coven@muclight.shakespeare.lit' type= 'set' > <query xmlns= 'urn:xmpp:muclight:0#configuration' > <roomname> A Darker Cave </roomname> </query> </iq> 1 2 3 4 5 6 7 8 9 10 11 <message from= 'coven@muclight.shakespeare.lit' to= 'crone1@shakespeare.lit' type= 'groupchat' id= 'configchange' > <x xmlns= 'urn:xmpp:muclight:0#configuration' > <prev-version> zaqwsx </prev-version> <version> zxcvbnm </version> <roomname> A Darker Cave </roomname> </x> <body /> </message> 1 2 3 4 5 6 7 8 9 10 11 <message from= 'coven@muclight.shakespeare.lit' to= 'hag66@shakespeare.lit' type= 'groupchat' id= 'configchange' > <x xmlns= 'urn:xmpp:muclight:0#configuration' > <prev-version> zaqwsx </prev-version> <version> zxcvbnm </version> <roomname> A Darker Cave </roomname> </x> <body /> </message> 1 2 3 4 <iq to= 'crone1@shakespeare.lit/desktop' id= 'conf2' from= 'coven@muclight.shakespeare.lit' type= 'result' /> The server SHOULD accept incomplete (i.e. delta) configuration forms. In such case, values of the missing fields SHOULD be preserved.","title":"5.3. Setting room configuration"},{"location":"open-extensions/muc_light/#54-changing-the-occupant-list","text":"The occupant list is modified by a direct affiliation change. Following rules apply: There are only 3 affiliations. owner - can do everything in the room member - can send messages to the room and if the service allows it, can also change configuration or change others' affiliations none - not in the room; it's a keyword for marking a user for removal from a room Every occupant can change its own affiliation to none in order to leave the room. The only way to join the room is being added by other occupant. The owner can change affiliations at will. If the owner leaves, the server MAY use any strategy to choose a new one. The room can have at most one owner. Giving someone else the 'owner' status effectively causes the current one to lose it. The owner can choose a new owner when leaving by including both 'none' and 'owner' items in affiliation change request. Every user JID can be used in the request at most once. A single request MAY change multiple affiliations. All changes must be meaningful, e.g. setting member's affiliation to 'member' is considered a bad request. Server MAY allow members to add new members but they still cannot make anyone an 'owner' or remove other users from the room. On success the server will reply with a result IQ with all the changed items. BEFORE returning the IQ result, the service MUST route a message with the affiliation change to all relevant users. Newcomers, i.e. users that were not occupants before the change, SHOULD receive only their own affiliation and SHOULD NOT receive a <prev-version /> element. The notifications must include both the new and old room version ( <version /> and <prev-version /> respectively) string (except for the ones directed to users that have been removed from the room). The notifications contain a list of items. The item list may be different from the list in the IQ set, because some of the changes may require additional operations, e.g. choosing new owner when the old one leaves. Users, that are still in the room after the change, will receive the full change list. Users, that have been removed from the room with the request, will get only one item: themselves with affiliation 'none'. Affiliations change request Let's consider a room coven with following members: crone1 - owner hag77 - member hag88 - member hag66 is not in the room yet. User crone1 wants to add hag66 to the room, kick hag88 out and make hag77 the room owner. 1 2 3 4 5 6 7 8 9 10 <iq from= 'crone1@shakespeare.lit/desktop' id= 'member1' to= 'coven@muclight.shakespeare.lit' type= 'set' > <query xmlns= 'urn:xmpp:muclight:0#affiliations' > <user affiliation= 'member' > hag66@shakespeare.lit </user> <user affiliation= 'owner' > hag77@shakespeare.lit </user> <user affiliation= 'none' > hag88@shakespeare.lit </user> </query> </iq> Now each user will receive an update. As you can see, affiliations have changed accordingly to crone1 request. However, this request implies one more update. Since hag77 has been promoted to a new owner, crone1 is automatically degraded to member . 1 2 3 4 5 6 7 8 9 10 11 12 13 14 <message from= 'coven@muclight.shakespeare.lit' to= 'crone1@shakespeare.lit' type= 'groupchat' id= 'memberchange' > <x xmlns= 'urn:xmpp:muclight:0#affiliations' > <prev-version> njiokm </prev-version> <version> qwerty </version> <user affiliation= 'member' > crone1@shakespeare.lit </user> <user affiliation= 'member' > hag66@shakespeare.lit </user> <user affiliation= 'owner' > hag77@shakespeare.lit </user> <user affiliation= 'none' > hag88@shakespeare.lit </user> </x> <body></body> </message> Because hag66 was not a member of this room before, they only receive their own affiliation and no prev-version element. 1 2 3 4 5 6 7 8 9 10 <message from= 'coven@muclight.shakespeare.lit' to= 'hag66@shakespeare.lit' type= 'groupchat' id= 'memberchange' > <x xmlns= 'urn:xmpp:muclight:0#affiliations' > <version> qwerty </version> <user affiliation= 'member' > hag66@shakespeare.lit </user> </x> <body></body> </message> hag77 receives an ordinary update, just like crone1 . 1 2 3 4 5 6 7 8 9 10 11 12 13 14 <message from= 'coven@muclight.shakespeare.lit' to= 'hag77@shakespeare.lit' type= 'groupchat' id= 'memberchange' > <x xmlns= 'urn:xmpp:muclight:0#affiliations' > <prev-version> njiokm </prev-version> <version> qwerty </version> <user affiliation= 'member' > crone1@shakespeare.lit </user> <user affiliation= 'member' > hag66@shakespeare.lit </user> <user affiliation= 'owner' > hag77@shakespeare.lit </user> <user affiliation= 'none' > hag88@shakespeare.lit </user> </x> <body></body> </message> hag88 has been kicked out of the room and therefore gets only their own affiliation change of type 'none'. 1 2 3 4 5 6 7 8 9 <message from= 'coven@muclight.shakespeare.lit' to= 'hag88@shakespeare.lit' type= 'groupchat' id= 'memberchange' > <x xmlns= 'urn:xmpp:muclight:0#affiliations' > <user affiliation= 'none' > hag88@shakespeare.lit </user> </x> <body></body> </message> crone1 gets the result IQ after the change. 1 2 3 4 <iq to= 'crone1@shakespeare.lit/desktop' id= 'member1' from= 'coven@muclight.shakespeare.lit' type= 'result' />","title":"5.4. Changing the occupant list"},{"location":"open-extensions/muc_light/#6-interactions-with-rfcs-and-other-xeps","text":"","title":"6. Interactions with RFCs and other XEPs"},{"location":"open-extensions/muc_light/#61-user-rosters","text":"The service MAY add user's rooms to its roster. It allows the client to skip the separate Disco request to the service. Roster items with rooms MUST belong to the group \"urn:xmpp:muclight:0\" (MUC Light namespace) and include the <version/> element. Their subscription type MUST be 'to'. Entity requests the roster and receives a reply that includes a room item 1 2 3 <iq type= 'get' id= 'roster1' to= 'shakespeare.lit' > <query xmlns= 'jabber:iq:roster' /> </iq> 1 2 3 4 5 6 7 8 9 10 <iq id= 'roster1' to= 'hag66@shakespeare.lit/tablet' type= 'result' > <query xmlns= 'jabber:iq:roster' ver= 'ver7' > <item jid= 'hag77@shakespeare.lit' subscription= 'both' /> <item jid= 'hag88@shakespeare.lit' subscription= 'both' /> <item jid= 'coven@muclight.shakespeare.lit' name= 'The Coven' subscription= 'to' > <group> urn:xmpp:muclight:0 </group> <version> 1234345 </version> </item> </query> </iq>","title":"6.1. User rosters"},{"location":"open-extensions/muc_light/#62-xep-0313-message-archive-management","text":"This section defines the rules for archiving MUC Light events and messages. Stanzas described in the subsections below MUST be archived by the server. The stanzas not included here MUST NOT be archived. The <message/> element inside <forwarded/> MUST include a \"from\" attribute and MUST NOT include a \"to\" attribute. \"id\" SHOULD be archived as well. In case of regular groupchat messages, the \"from\" attribute MUST consist of a room full JID with a sender bare JID in the resource part. As for room notification, e.g. create event, \"from\" MUST be equal to room bare JID. Examples below use MAM v0.4 protocol. The archive can be fetched only from a specific room, the client MUST NOT query MUC Light service directly.","title":"6.2. XEP-0313 Message Archive Management"},{"location":"open-extensions/muc_light/#621-groupchat-message-from-occupant","text":"Message from a user MUST be archived with all child elements. Occupant queries MAM and receives regular groupchat message 1 2 3 <iq type= 'set' id= 'mamget1' to= 'coven@muclight.shakespeare.lit' > <query xmlns= 'urn:xmpp:mam:1' queryid= 'f27' /> </iq> 1 2 3 4 5 6 7 8 9 10 11 12 <message id= 'aeb213' to= 'hag66@shakespeare.lit/pda' > <result xmlns= 'urn:xmpp:mam:1' queryid= 'f27' id= '28482-98726-73623' > <forwarded xmlns= 'urn:xmpp:forward:0' > <delay xmlns= 'urn:xmpp:delay' stamp= '2010-07-10T23:08:25Z' /> <message from= \"coven@muclight.shakespeare.lit/hag77@shakespeare.lit\" id= \"msgid11\" > <body> Welcome! </body> <x xmlns= \"elixir:ingredient\" > bat-wing </x> </message> </forwarded> </result> </message> 1 <iq type= 'result' id= 'mamget1' from= 'coven@muclight.shakespeare.lit' />","title":"6.2.1. Groupchat message from occupant"},{"location":"open-extensions/muc_light/#622-affiliation-change","text":"Every archived affiliation change notification MUST include the <version/> element and MUST NOT contain the <prev-version/> element. Occupant queries MAM and receives an affiliation change notification 1 2 3 <iq type= 'set' id= 'mamget2' to= 'muclight.shakespeare.lit' > <query xmlns= 'urn:xmpp:mam:1' queryid= 'f37' /> </iq> 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 <message id= 'aef2133' to= 'hag66@shakespeare.lit/pda' > <result xmlns= 'urn:xmpp:mam:1' queryid= 'f37' id= '21482-98726-71623' > <forwarded xmlns= 'urn:xmpp:forward:0' > <delay xmlns= 'urn:xmpp:delay' stamp= '2013-07-10T21:08:25Z' /> <message from= \"coven@muclight.shakespeare.lit\" id= \"notifid11\" > <x xmlns= 'urn:xmpp:muclight:0#affiliations' > <version> b9uf13h98f13 </version> <user affiliation= 'owner' > hag66@shakespeare.lit </user> <user affiliation= 'member' > user1@shakespeare.lit </user> <user affiliation= 'member' > user2@shakespeare.lit </user> </x> </message> </forwarded> </result> </message> 1 <iq type= 'result' id= 'mamget12' />","title":"6.2.2. Affiliation change"},{"location":"open-extensions/muc_light/#623-room-creation","text":"Room creation is archived as an affiliation change that includes ALL initial occupants (including the room creator).","title":"6.2.3. Room creation"},{"location":"open-extensions/muc_light/#7-general-error-cases","text":"","title":"7. General Error Cases"},{"location":"open-extensions/muc_light/#71-client-sends-an-unauthorized-stanza-to-a-room","text":"If a client sends a stanza to the room, that it does not occupy, the service MUST reply with the 'item-not-found' error. Unauthorized IQ 1 2 3 4 5 6 7 8 <iq from= 'crone1@shakespeare.lit/desktop' id= 'member1' to= 'coven@muclight.shakespeare.lit' type= 'set' > <query xmlns= 'urn:xmpp:muclight:0#affiliations' > <user affiliation= 'member' > hag66@shakespeare.lit </user> </query> </iq> 1 2 3 4 5 6 7 8 <iq to= 'crone1@shakespeare.lit/desktop' id= 'member1' from= 'coven@muclight.shakespeare.lit' type= 'error' > <error type= 'cancel' > <item-not-found xmlns= 'urn:ietf:params:xml:ns:xmpp-stanzas' /> </error> </iq> Unauthorized message 1 2 3 4 5 6 <message from= 'hag66@shakespeare.lit/pda' id= 'unauth2' to= 'coven@muclight.shakespeare.lit' type= 'groupchat' > <body> Harpier cries: 'tis time, 'tis time. </body> </message> 1 2 3 4 5 6 7 8 <message to= 'hag66@shakespeare.lit/pda' id= 'unauth2' from= 'coven@muclight.shakespeare.lit' type= 'error' > <error type= 'cancel' > <item-not-found xmlns= 'urn:ietf:params:xml:ns:xmpp-stanzas' /> </error> </message>","title":"7.1. Client sends an unauthorized stanza to a room"},{"location":"open-extensions/muc_light/#72-client-sends-a-presence-stanza-to-the-service","text":"The service MUST ignore all <presence/> stanzas sent by the client.","title":"7.2. Client sends a &lt;presence/&gt; stanza to the service"},{"location":"open-extensions/muc_light/#73-client-sends-an-invalid-stanza-to-the-service","text":"If service receives an invalid stanza it MUST reply with a 'bad-request' error. Invalid IQ 1 2 3 4 5 6 7 8 <iq from= 'crone1@shakespeare.lit/desktop' id= 'bad1' to= 'coven@muclight.shakespeare.lit' type= 'set' > <query xmlns= 'urn:xmpp:muclight:0#affiliations' > <item role= 'participant' > hag66@shakespeare.lit </item> </query> </iq> 1 2 3 4 5 6 7 8 <iq to= 'crone1@shakespeare.lit/desktop' id= 'bad1' from= 'coven@muclight.shakespeare.lit' type= 'error' > <error type= 'modify' > <bad-request xmlns= 'urn:ietf:params:xml:ns:xmpp-stanzas' /> </error> </iq> Invalid message 1 2 3 4 5 6 <message from= 'hag66@shakespeare.lit/pda' id= 'bad2' to= 'coven@muclight.shakespeare.lit' type= 'chat' > <body> Harpier cries: 'tis time, 'tis time. </body> </message> 1 2 3 4 5 6 7 8 <message to= 'hag66@shakespeare.lit/pda' id= 'bad2' from= 'coven@muclight.shakespeare.lit' type= 'error' > <error type= 'modify' > <bad-request xmlns= 'urn:ietf:params:xml:ns:xmpp-stanzas' /> </error> </message>","title":"7.3. Client sends an invalid stanza to the service"},{"location":"open-extensions/muc_light/#74-request-sender-has-insufficient-privileges","text":"If the request sender does not have sufficient privileges (but is a room occupant), the service MUST reply with a 'not-allowed' error. It occurs in the following cases: A member tries to change the configuration but the service is not configured to allow it. It does not apply to the subject change, although it has to be performed by sending <message/> with <subject/> , not configuration <iq/> . A member tries to change anyone's affiliation to 'none' or 'owner'. A member tries to change someone's affiliation to 'member' but the service is not configured to allow it. Prohibited IQ 1 2 3 4 5 6 7 8 <iq from= 'minion@shakespeare.lit/desktop' id= 'privileges1' to= 'coven@muclight.shakespeare.lit' type= 'set' > <query xmlns= 'urn:xmpp:muclight:0#affiliations' > <user role= 'owner' > minion@shakespeare.lit </user> </query> </iq> 1 2 3 4 5 6 7 8 <iq to= 'minion@shakespeare.lit/desktop' id= 'privileges1' from= 'coven@muclight.shakespeare.lit' type= 'error' > <error type= 'cancel' > <not-allowed xmlns= 'urn:ietf:params:xml:ns:xmpp-stanzas' /> </error> </iq>","title":"7.4. Request sender has insufficient privileges"},{"location":"open-extensions/muc_light/#8-implementation-notes","text":"","title":"8. Implementation Notes"},{"location":"open-extensions/muc_light/#81-xep-0045-mappings","text":"Some client-side developers might choose to use existing XEP-0045 Multi-User Chat implementations to interface with the new MUC Light. There may be various reasons to do so: using a familiar protocol, avoiding additional implementation, quick prototyping etc. This section provides suggestions of mappings between XEP-0045 stanzas and the new ones described in this document. Operations not described here SHOULD remain unmodified.","title":"8.1. XEP-0045 mappings"},{"location":"open-extensions/muc_light/#811-discovering-the-features-supported-by-a-muc-service","text":"A Disco result MAY either include a new <feature/> element with an \"http://jabber.org/protocol/muc\" namespace next to MUC Light one, or completely replace it, which is the RECOMMENDED behaviour. Returning a MUC namespace in Disco 1 2 3 4 5 6 <iq from= 'hag66@shakespeare.lit/pda' id= 'lx09df27' to= 'muclight.shakespeare.lit' type= 'get' > <query xmlns= 'http://jabber.org/protocol/disco#info' /> </iq> 1 2 3 4 5 6 7 8 9 10 11 <iq from= 'muclight.shakespeare.lit' id= 'lx09df27' to= 'hag66@shakespeare.lit/pda' type= 'result' > <query xmlns= 'http://jabber.org/protocol/disco#info' > <identity category= 'conference' name= 'Shakespearean Chat Service' type= 'text' /> <feature var= 'http://jabber.org/protocol/muc' /> </query> </iq>","title":"8.1.1. Discovering the Features Supported by a MUC Service"},{"location":"open-extensions/muc_light/#812-discovering-occupied-rooms","text":"The room list MUST NOT include room versions. Service Returns Disco Items Result 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 <iq from= 'muclight.shakespeare.lit' id= 'zb8q41f4' to= 'hag66@shakespeare.lit/pda' type= 'result' > <query xmlns= 'http://jabber.org/protocol/disco#items' > <item jid= 'heath@muclight.shakespeare.lit' name= 'A Lonely Heath' /> <item jid= 'coven@muclight.shakespeare.lit' name= 'A Dark Cave' /> <item jid= 'forres@muclight.shakespeare.lit' name= 'The Palace' /> <item jid= 'inverness@muclight.shakespeare.lit' name= 'Macbeth&apos;s Castle' /> </query> </iq>","title":"8.1.2. Discovering Occupied Rooms"},{"location":"open-extensions/muc_light/#813-changing-a-room-subject","text":"Instead of distributing the configuration change notifications, the room MUST route <message/> with a <subject/> like a classic MUC would. The client MUST send a classic message <subject/> as well. The room SHOULD save a new subject in the room configuration. New subject is routed as an ordinary message 1 2 3 4 5 6 <message from= 'hag66@shakespeare.lit/pda' id= 'compsubject' to= 'coven@muclight.shakespeare.lit' type= 'groupchat' > <subject> To be or not to be? </subject> </message> 1 2 3 4 5 6 <message from= 'coven@muclight.shakespeare.lit' to= 'crone1@shakespeare.lit' type= 'groupchat' id= 'compsubject' > <subject> To be or not to be? </subject> </message> 1 2 3 4 5 6 <message from= 'coven@muclight.shakespeare.lit' to= 'hag66@shakespeare.lit' type= 'groupchat' id= 'compsubject' > <subject> To be or not to be? </subject> </message>","title":"8.1.3. Changing a room subject"},{"location":"open-extensions/muc_light/#814-getting-a-room-configuration","text":"Room configuration is encoded in a Data Form, that simulates the XEP-0045 config form. Getting the room configuration does not benefit from room versioning. Requesting room configuration 1 2 3 4 5 6 <iq from= 'crone1@shakespeare.lit/desktop' id= 'comp-config' to= 'coven@muclight.shakespeare.lit' type= 'get' > <query xmlns= 'http://jabber.org/protocol/muc#owner' /> </iq> 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 <iq from= 'coven@muclight.shakespeare.lit' id= 'comp-config' to= 'crone1@shakespeare.lit/desktop' type= 'result' > <query xmlns= 'http://jabber.org/protocol/muc#owner' > <x xmlns= 'jabber:x:data' type= 'form' > <title> Configuration for \"coven\" Room </title> <field type= 'hidden' var= 'FORM_TYPE' > <value> http://jabber.org/protocol/muc#roomconfig </value> </field> <field label= 'Natural-Language Room Name' type= 'text-single' var= 'muc#roomconfig_roomname' > <value> A Dark Cave </value> </field> <field label= 'Room subject' type= 'text-single' var= 'muc#roomconfig_subject' > <value> To be or not to be? </value> </field> </x> </query> </iq>","title":"8.1.4. Getting a room configuration"},{"location":"open-extensions/muc_light/#815-requesting-a-user-list","text":"A user list is retrieved with an affiliation IQ get. Requesting affiliation list 1 2 3 4 5 6 7 8 <iq from= 'crone1@shakespeare.lit/desktop' id= 'comp-getaff' to= 'coven@muclight.shakespeare.lit' type= 'get' > <query xmlns= 'http://jabber.org/protocol/muc#admin' > <item affiliation= 'owner' /> <item affiliation= 'member' /> </query> </iq> 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 <iq from= 'coven@muclight.shakespeare.lit' id= 'comp-getaff' to= 'crone1@shakespeare.lit/desktop' type= 'result' > <query xmlns= 'http://jabber.org/protocol/muc#admin' > <item affiliation= 'owner' jid= 'crone1@shakespeare.lit' nick= 'crone1@shakespeare.lit' role= 'moderator' /> <item affiliation= 'member' jid= 'hag66@shakespeare.lit' nick= 'hag66@shakespeare.lit' role= 'participant' /> </query> </iq>","title":"8.1.5. Requesting a user list"},{"location":"open-extensions/muc_light/#816-requesting-room-information","text":"There is no XEP-0045 equivalent for getting full room information.","title":"8.1.6. Requesting room information"},{"location":"open-extensions/muc_light/#817-leaving-the-room","text":"Leaving the room is performed by setting the own affiliation to 'none'. The service uses <presence/> to notify all occupants (and former occupant) about the change. <presence/> to the leaving occupant MUST be of the type \"unavailable\" and MUST include a status code 321 (i.e. user leaving due to affiliation change). Leaving the room 1 2 3 4 5 6 7 8 <iq from= 'crone1@shakespeare.lit/desktop' id= 'comp-leave' to= 'coven@muclight.shakespeare.lit' type= 'set' > <query xmlns= 'http://jabber.org/protocol/muc#admin' > <item affiliation= 'none' jid= 'crone1@shakespeare.lit' /> </query> </iq> 1 2 3 4 5 6 7 8 <presence from= 'coven@muclight.shakespeare.lit/crone1@shakespeare.lit' to= 'crone1@shakespeare.lit' type= 'unavailable' > <x xmlns= 'http://jabber.org/protocol/muc#user' > <item affiliation= 'none' jid= 'crone1@shakespeare.lit/pda' role= 'none' /> <status code= '321' /> </x> </presence> 1 2 3 4 5 6 7 <presence from= 'coven@muclight.shakespeare.lit/crone1@shakespeare.lit' to= 'hag66@shakespeare.lit/desktop' > <x xmlns= 'http://jabber.org/protocol/muc#user' > <item affiliation= 'none' jid= 'crone1@shakespeare.lit/pda' role= 'none' /> <status code= '321' /> </x> </presence> 1 2 3 4 <iq from= 'coven@muclight.shakespeare.lit' id= 'comp-leave' to= 'crone1@shakespeare.lit/desktop' type= 'result' />","title":"8.1.7. Leaving the room"},{"location":"open-extensions/muc_light/#818-blocking-functionality","text":"The blocking functionality uses a small subset of the Privacy Lists protocol. Stanzas MUST be addressed to the sender's bare JID (the to attribute may be skipped). The privacy list name MUST be equal to \"urn:xmpp:muclight:0\". Obviously, this method won't work properly in XMPP Server Federation, because privacy stanzas are handled by sender's server and the MUC Light Blocking functionality is handled by a MUC Light service server. As opposed to XEP-0016, it is allowed to send \"delta\" privacy lists.","title":"8.1.8. Blocking functionality"},{"location":"open-extensions/muc_light/#8181-request-blocking-list","text":"Retrieving blocking list 1 2 3 4 5 <iq from= 'crone1@shakespeare.lit/desktop' type= 'get' id= 'comp-getlist' > <query xmlns= 'jabber:iq:privacy' > <list name= 'urn:xmpp:muclight:0' /> </query> </iq> 1 2 3 4 5 6 7 8 9 10 11 12 13 14 <iq type= 'result' id= 'comp-getlist' to= 'crone1@shakespeare.lit/desktop' > <query xmlns= 'jabber:iq:privacy' > <list name= 'urn:xmpp:muclight:0' > <item type= 'jid' value= 'coven@muclight.shakespeare.lit' action= 'deny' order= '1' /> <item type= 'jid' value= 'muclight.shakespeare.lit/hag66@shakespeare.lit' action= 'deny' order= '1' /> </list> </query> </iq>","title":"8.1.8.1. Request blocking list"},{"location":"open-extensions/muc_light/#8182-blocking-a-room","text":"In order to block a room, the client MUST deny a room bare JID in privacy list. Blocking a room 1 2 3 4 5 6 7 8 9 10 <iq from= 'crone1@shakespeare.lit/desktop' type= 'set' id= 'comp-blockroom' > <query xmlns= 'jabber:iq:privacy' > <list name= 'urn:xmpp:muclight:0' > <item type= 'jid' value= 'coven@muclight.shakespeare.lit' action= 'deny' order= '1' /> </list> </query> </iq> 1 <iq type= 'result' id= 'comp-blockroom' to= 'crone1@shakespeare.lit/desktop' />","title":"8.1.8.2. Blocking a room"},{"location":"open-extensions/muc_light/#8183-blocking-a-user","text":"In order to block a room, the client MUST deny a service JID with user's bare JID in the resource. Blocking a user 1 2 3 4 5 6 7 8 9 10 <iq from= 'crone1@shakespeare.lit/desktop' type= 'set' id= 'comp-blockuser' > <query xmlns= 'jabber:iq:privacy' > <list name= 'urn:xmpp:muclight:0' > <item type= 'jid' value= 'muclight.shakespeare.lit/hag66@shakespeare.lit' action= 'deny' order= '1' /> </list> </query> </iq> 1 <iq type= 'result' id= 'comp-blockuser' to= 'crone1@shakespeare.lit/desktop' />","title":"8.1.8.3. Blocking a user"},{"location":"open-extensions/muc_light/#8184-unblocking","text":"Unblocking 1 2 3 4 5 6 7 8 9 10 11 12 13 14 <iq from= 'crone1@shakespeare.lit/desktop' type= 'get' id= 'comp-getlist' > <query xmlns= 'jabber:iq:privacy' > <list name= 'urn:xmpp:muclight:0' > <item type= 'jid' value= 'coven@muclight.shakespeare.lit' action= 'allow' order= '1' /> <item type= 'jid' value= 'muclight.shakespeare.lit/hag66@shakespeare.lit' action= 'allow' order= '1' /> </list> </query> </iq> 1 <iq type= 'result' id= 'comp-getlist' to= 'crone1@shakespeare.lit/desktop' />","title":"8.1.8.4. Unblocking"},{"location":"open-extensions/muc_light/#819-creating-a-room","text":"The room is created in a standard XEP-0045 way. Client MUST use a nick equal to their own bare JID. Compatibility mode MUST NOT support a unique room name generation. Creating a room 1 2 3 4 <presence from= 'crone1@shakespeare.lit/desktop' to= 'coven@muclight.shakespeare.lit/crone1@shakespeare.lit' > <x xmlns= 'http://jabber.org/protocol/muc' /> </presence> 1 2 3 4 5 6 7 8 <presence from= 'coven@chat.shakespeare.lit/crone1@shakespeare.lit' to= 'crone1@shakespeare.lit/desktop' > <x xmlns= 'http://jabber.org/protocol/muc#user' > <item affiliation= 'owner' role= 'moderator' /> <status code= '110' /> <status code= '201' /> </x> </presence>","title":"8.1.9. Creating a room"},{"location":"open-extensions/muc_light/#8191-room-already-exists","text":"If the client attempts to create a room that is already used, it will receive an error <presence/> informing that registration is required (like in the case of members-only rooms in XEP-0045). Creating a room 1 2 3 4 5 6 7 8 <presence from= 'coven@muclight.shakespeare.lit/crone1@shakespeare.lit' to= 'crone1@shakespeare.lit/desktop' type= 'error' > <x xmlns= 'http://jabber.org/protocol/muc' /> <error by= 'coven@muclight.shakespeare.lit' type= 'auth' > <registration-required xmlns= 'urn:ietf:params:xml:ns:xmpp-stanzas' /> </error> </presence>","title":"8.1.9.1. Room already exists"},{"location":"open-extensions/muc_light/#8110-destroying-the-room","text":"A classic XEP-0045 method is used but the service SHOULD NOT forward reason and alternate venue JID. Destroying the room 1 2 3 4 5 6 7 8 9 10 <iq from= 'crone1@shakespeare.lit/desktop' id= 'begone' to= 'heath@muclight.shakespeare.lit' type= 'set' > <query xmlns= 'http://jabber.org/protocol/muc#owner' > <destroy jid= 'coven@muclight.shakespare.lit' > <reason> Some reason. </reason> </destroy> </query> </iq> 1 2 3 4 5 6 7 <presence from= 'heath@chat.shakespeare.lit/crone1@shakespeare.lit' to= 'crone1@shakespeare.lit/desktop' type= 'unavailable' > <x xmlns= 'http://jabber.org/protocol/muc#user' > <item affiliation= 'none' role= 'none' /> <destroy /> </x> </presence> 1 2 3 4 5 6 7 8 <presence from= 'heath@chat.shakespeare.lit/wiccarocks@shakespeare.lit' to= 'wiccarocks@shakespeare.lit/laptop' type= 'unavailable' > <x xmlns= 'http://jabber.org/protocol/muc#user' > <item affiliation= 'none' role= 'none' /> <destroy /> </x> </presence> 1 2 3 4 5 6 7 8 9 <presence from= 'heath@chat.shakespeare.lit/hag66@shakespeare.lit' to= 'hag66@shakespeare.lit/pda' type= 'unavailable' > <x xmlns= 'http://jabber.org/protocol/muc#user' > <item affiliation= 'none' role= 'none' /> <destroy /> </x> </presence> 1 2 3 4 <iq from= 'heath@chat.shakespeare.lit' id= 'begone' to= 'crone1@shakespeare.lit/desktop' type= 'result' />","title":"8.1.10. Destroying the room"},{"location":"open-extensions/muc_light/#8111-setting-room-configuration","text":"Room occupants can use a standard XEP-0045 configuration modification method. The service MUST broadcast only the notification about the configuration change with a status code 104, so every occupant can retrieve the new room configuration in a separate request. The client is allowed to send a config delta in a form. Setting room configuration 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 <iq to= 'coven@muclight.shakespeare.lit' id= 'comp-setconfig' from= 'crone1@shakespeare.lit/desktop' type= 'set' > <query xmlns= 'http://jabber.org/protocol/muc#owner' > <x xmlns= 'jabber:x:data' type= 'form' > <field type= 'hidden' var= 'FORM_TYPE' > <value> http://jabber.org/protocol/muc#roomconfig </value> </field> <field label= 'Natural-Language Room Name' type= 'text-single' var= 'muc#roomconfig_roomname' > <value> A Darker Cave </value> </field> <field label= 'Room subject' type= 'text-single' var= 'muc#roomconfig_subject' > <value> To be! </value> </field> </x> </query> </iq> 1 2 3 4 5 6 7 8 <message from= 'coven@muclight.shakespeare.lit' id= 'comp-confchange' to= 'crone1@shakespeare.lit/desktop' type= 'groupchat' > <x xmlns= 'http://jabber.org/protocol/muc#user' > <status code= '104' /> </x> </message> 1 2 3 4 5 6 7 8 <message from= 'coven@muclight.shakespeare.lit' id= 'comp-confchange' to= 'crone2@shakespeare.lit/desktop' type= 'groupchat' > <x xmlns= 'http://jabber.org/protocol/muc#user' > <status code= '104' /> </x> </message> 1 2 3 4 <iq from= 'coven@muclight.shakespeare.lit' id= 'comp-setconfig' to= 'crone1@shakespeare.lit/desktop' type= 'result' />","title":"8.1.11. Setting room configuration"},{"location":"open-extensions/muc_light/#8112-changing-occupant-list","text":"The service MUST send an affiliation change notification to all participants. Leaving users MUST NOT receive any information except for their own \"none\" affiliation. New users MUST receive an invitation message. Changing occupant list 1 2 3 4 5 6 7 8 9 <iq from= 'crone1@shakespeare.lit/desktop' id= 'comp-setaff' to= 'coven@muclight.shakespeare.lit' type= 'set' > <query xmlns= 'http://jabber.org/protocol/muc#admin' > <item affiliation= 'none' jid= 'hag66@shakespeare.lit' /> <item affiliation= 'member' jid= 'hecate@shakespeare.lit' /> </query> </iq> 1 2 3 4 5 6 7 8 <presence from= 'coven@chat.shakespeare.lit/hag66@shakespeare.lit' to= 'hag66@shakespeare.lit' type= 'unavailable' > <x xmlns= 'http://jabber.org/protocol/muc#user' > <item affiliation= 'none' jid= 'hag66@shakespeare.lit' role= 'none' /> <status code= '321' /> </x> </presence> 1 2 3 4 5 6 7 <message from= 'coven@muclight.shakespeare.lit' id= 'comp-invite0' to= 'hecate@shakespeare.lit' > <x xmlns= 'http://jabber.org/protocol/muc#user' > <invite from= 'crone1@shakespeare.lit' /> </x> </message> 1 2 3 4 5 6 7 8 <presence from= 'coven@chat.shakespeare.lit/hag66@shakespeare.lit' to= 'crone1@shakespeare.lit' type= 'unavailable' > <x xmlns= 'http://jabber.org/protocol/muc#user' > <item affiliation= 'none' jid= 'hag66@shakespeare.lit' role= 'none' /> <status code= '321' /> </x> </presence> 1 2 3 4 5 6 7 8 9 <presence from= 'coven@chat.shakespeare.lit/hecate@shakespeare.lit' to= 'crone1@shakespeare.lit' > <x xmlns= 'http://jabber.org/protocol/muc#user' > <item affiliation= 'member' jid= 'hecate@shakespeare.lit' role= 'participant' nick= 'hecate@shakespeare.lit' /> </x> </presence> 1 2 3 4 <iq from= 'coven@muclight.shakespeare.lit' id= 'comp-setaff' to= 'crone1@shakespeare.lit/desktop' type= 'result' />","title":"8.1.12. Changing occupant list"},{"location":"open-extensions/muc_light/#82-service-limits-and-configuration","text":"The MUC Light service may be abused by a malicious users, e.g. due to replicating a single message for every room occupant. The list below contains suggested configurable limits that SHOULD be implemented. The service features that might vary depending on a specific application are included as well. Maximum number of rooms the user occupies. Blocking feature enabled/disabled. XEP-0045 compatibility mode enabled/disabled. Room creator's initial affiliation: owner/member. Room configuration may be changed by owner/occupants. New members can be invited by owner/occupants. Maximal room size.","title":"8.2. Service limits and configuration"},{"location":"open-extensions/token-reconnection/","text":"Introduction Automatic reconnection after spurious disconnection is a must-have feature in modern IM applications. One way of providing this feature is storing the user login information on the disk. Here you need to balance two values - security and convienience for the end-user. To put it simply: storing passowords in plaintext is inherently insecure while protecting the XMPP password with a master-password is damages the user experience. With a token-based authentication mechanism, the user has to provide login information only once, for the initial connection to the XMPP server, and can later rely on the application's automatic use of tokens for subsequent reconnections. Reconnecting to the XMPP server, usually means that the client has to go through the same long process of SASL challenge-response exchange which may cause noticable lags, especially while using SCRAM-based mechanisms. Providing a token to the XMPP server is secure and doesn't require multiple challenge-response roundtrips, therefore might significantly speed up reconnection times. Requirements This extension requires the client application to authenticate to the XMPP server using a regular XMPP authentication mechanism like SCRAM-SHA-1 at least once. After that, the following authentications may be done using X-OAUTH SASL mechanism with a token obtained from the server. To enable the feature, modules mod_auth_token and mod_keystore have to be enabled on the server. For more details regarding the configuration see mod_auth_token documentation and mod_keystore . Token types Token Type Description Access token These are short lived tokens whose grants aren't tracked by the server (i.e. there's no need to store anything in a database). Access tokens can be used as a payload for the X-OAUTH authentication mechanism and grant access to the system. Access tokens can't be revoked. An access token is valid only until its expiry date is reached. Refresh token These are longer lived tokens which are tracked by the server, and therefore require persistent storage. Refresh tokens can be used as a payload for the X-OAUTH authentication mechanism and grant access to the system, as well as result in a new set of tokens being returned upon successful authentication. Refresh tokens can be revoked. A refresh token is valid until it has expired, unless it has been revoked. On revocation, it immediately becomes invalid. As the server stores information about granted tokens, it can also persistently mark them as revoked. While only two token types have been described above, implementations might use other token types for specific purposes. For example, a particular token type could limit the access privileges of a user logged into the system or denote an affiliation with a Multi User Chat room. None of such capability grants are a subject of this specification though. Use cases Obtaining a token After authenticating with some other mechanism like SCRAM-SHA-1, a client may request a token from the server by sending the following iq get to its own bare JID: Client requests tokens 1 2 3 <iq type= 'get' to= 'alice@wonderland.com' id= '123' > <query xmlns= 'erlang-solutions.com:xmpp:token-auth:0' /> </iq> Server responds with a tokens 1 2 3 4 5 6 <iq from= \"alice@wonderland.com\" type= \"result\" to= \"alice@wonderland.com/resource\" id= \"123\" > <items xmlns= \"erlang-solutions.com:xmpp:token-auth:0\" > <access_token> YWNjZXNzAGFsaWNlQHdvbmRlcmxhbmQuY29tL01pY2hhbC1QaW90cm93c2tpcy1NYWNCb29rLVBybwA2MzYyMTg4Mzc2NAA4M2QwNzNiZjBkOGJlYzVjZmNkODgyY2ZlMzkyZWM5NGIzZjA4ODNlNDI4ZjQzYjc5MGYxOWViM2I2ZWJlNDc0ODc3MDkxZTIyN2RhOGMwYTk2ZTc5ODBhNjM5NjE1Zjk= </access_token> <refresh_token> cmVmcmVzaABhbGljZUB3b25kZXJsYW5kLmNvbS9NaWNoYWwtUGlvdHJvd3NraXMtTWFjQm9vay1Qcm8ANjM2MjMwMDYxODQAMQAwZGQxOGJjODhkMGQ0N2MzNTBkYzAwYjcxZjMyZDVmOWIwOTljMmI1ODU5MmNhN2QxZGFmNWFkNGM0NDQ2ZGU2MWYxYzdhNTJjNDUyMGI5YmIxNGIxNTMwMTE4YTM1NTc= </refresh_token> </items> </iq> Authentication with an access token Client authenticates with an access token 1 2 3 <auth xmlns= \"urn:ietf:params:xml:ns:xmpp-sasl\" mechanism= \"X-OAUTH\" > YWNjZXNzAGFsaWNlQHdvbmRlcmxhbmQuY29tL01pY2hhbC1QaW90cm93c2tpcy1NYWNCb29rLVBybwA2MzYyMTg4Mzc2NAA4M2QwNzNiZjBkOGJlYzVjZmNkODgyY2ZlMzkyZWM5NGIzZjA4ODNlNDI4ZjQzYjc5MGYxOWViM2I2ZWJlNDc0ODc3MDkxZTIyN2RhOGMwYTk2ZTc5ODBhNjM5NjE1Zjk= </auth> Server responds with a success 1 <success xmlns= \"urn:ietf:params:xml:ns:xmpp-sasl\" /> Authentication with a refresh token In this situation server will respond with a new refresh token which SHOULD be used in future authentication. Client authenticates with a refresh token 1 2 3 <auth xmlns= \"urn:ietf:params:xml:ns:xmpp-sasl\" mechanism= \"X-OAUTH\" > cmVmcmVzaABhbGljZUB3b25kZXJsYW5kLmNvbS9NaWNoYWwtUGlvdHJvd3NraXMtTWFjQm9vay1Qcm8ANjM2MjMwMDYxODQAMQAwZGQxOGJjODhkMGQ0N2MzNTBkYzAwYjcxZjMyZDVmOWIwOTljMmI1ODU5MmNhN2QxZGFmNWFkNGM0NDQ2ZGU2MWYxYzdhNTJjNDUyMGI5YmIxNGIxNTMwMTE4YTM1NTc= </auth> Server responds with a success and a new refresh token 1 2 3 <success xmlns= \"urn:ietf:params:xml:ns:xmpp-sasl\" > cmVmcmVzaABhbGljZUB3b25kZXJsYW5kLmNvbS9NaWNoYWwtUGlvdHJvd3NraXMtTWFjQm9vay1Qcm8ANjM2MjMwMDYxODQAMgAwZGQxOGJjODhkMGQ0N2MzNTBkYzAwYjcxZjMyZDVmOWIwOTljMmI1ODU5MmNhN2QxZGFmNWFkNGM0NDQ2ZGU2MWYxYzdhNTJjNDUyMGI5YmIxNGIxNTMwMTE4YTM1NTc= </success> Token format All tokens are exchanged as Base64 encoded binary data. Serialization format of the token before encoding with Base64 is dependent on its type. Common parts in every token are BARE_JID and EXPIRES_AT . EXPIRES_AT is a timestamp saying when a given token will expire. \\0 stands for the ASCII null character (i.e. byte 0). Text in single quotes ('example') is literal. ALL_CAPS denote parameters. Access token format 1 2 BASE64_encode ('access', \\0, BARE_JID, \\0, EXPIRES_AT, \\0, DATA) Example (please note the line break was added only for readability): 1 2 'access' \\0 Q8@wonderland.com \\0 64875466454 \\0 0acd0a66d06934791d046060cf9f1ad3c2abb3274cc7e7d7b2bc7e2ac4453ed774b6c6813b40ebec2bbc3774d59d4087 Refresh token format 1 2 BASE64_encode ('refresh', \\0, BARE_JID, \\0, EXPIRES_AT, \\0, SEQUENCE_NO, \\0, DATA) Example (please note the line break was added only for readability): 1 2 'refresh' \\0 qp@wonderland.com \\0 64875466457 \\0 6 \\0 8f57cb019cd6dc6e7779be165b9558611baf71ee4a40d03e77b78b069f482f96c9d23b1ac1ef69f64c1a1db3d36a96ad","title":"Token-based reconnection"},{"location":"open-extensions/token-reconnection/#introduction","text":"Automatic reconnection after spurious disconnection is a must-have feature in modern IM applications. One way of providing this feature is storing the user login information on the disk. Here you need to balance two values - security and convienience for the end-user. To put it simply: storing passowords in plaintext is inherently insecure while protecting the XMPP password with a master-password is damages the user experience. With a token-based authentication mechanism, the user has to provide login information only once, for the initial connection to the XMPP server, and can later rely on the application's automatic use of tokens for subsequent reconnections. Reconnecting to the XMPP server, usually means that the client has to go through the same long process of SASL challenge-response exchange which may cause noticable lags, especially while using SCRAM-based mechanisms. Providing a token to the XMPP server is secure and doesn't require multiple challenge-response roundtrips, therefore might significantly speed up reconnection times.","title":"Introduction"},{"location":"open-extensions/token-reconnection/#requirements","text":"This extension requires the client application to authenticate to the XMPP server using a regular XMPP authentication mechanism like SCRAM-SHA-1 at least once. After that, the following authentications may be done using X-OAUTH SASL mechanism with a token obtained from the server. To enable the feature, modules mod_auth_token and mod_keystore have to be enabled on the server. For more details regarding the configuration see mod_auth_token documentation and mod_keystore .","title":"Requirements"},{"location":"open-extensions/token-reconnection/#token-types","text":"Token Type Description Access token These are short lived tokens whose grants aren't tracked by the server (i.e. there's no need to store anything in a database). Access tokens can be used as a payload for the X-OAUTH authentication mechanism and grant access to the system. Access tokens can't be revoked. An access token is valid only until its expiry date is reached. Refresh token These are longer lived tokens which are tracked by the server, and therefore require persistent storage. Refresh tokens can be used as a payload for the X-OAUTH authentication mechanism and grant access to the system, as well as result in a new set of tokens being returned upon successful authentication. Refresh tokens can be revoked. A refresh token is valid until it has expired, unless it has been revoked. On revocation, it immediately becomes invalid. As the server stores information about granted tokens, it can also persistently mark them as revoked. While only two token types have been described above, implementations might use other token types for specific purposes. For example, a particular token type could limit the access privileges of a user logged into the system or denote an affiliation with a Multi User Chat room. None of such capability grants are a subject of this specification though.","title":"Token types"},{"location":"open-extensions/token-reconnection/#use-cases","text":"","title":"Use cases"},{"location":"open-extensions/token-reconnection/#obtaining-a-token","text":"After authenticating with some other mechanism like SCRAM-SHA-1, a client may request a token from the server by sending the following iq get to its own bare JID: Client requests tokens 1 2 3 <iq type= 'get' to= 'alice@wonderland.com' id= '123' > <query xmlns= 'erlang-solutions.com:xmpp:token-auth:0' /> </iq> Server responds with a tokens 1 2 3 4 5 6 <iq from= \"alice@wonderland.com\" type= \"result\" to= \"alice@wonderland.com/resource\" id= \"123\" > <items xmlns= \"erlang-solutions.com:xmpp:token-auth:0\" > <access_token> YWNjZXNzAGFsaWNlQHdvbmRlcmxhbmQuY29tL01pY2hhbC1QaW90cm93c2tpcy1NYWNCb29rLVBybwA2MzYyMTg4Mzc2NAA4M2QwNzNiZjBkOGJlYzVjZmNkODgyY2ZlMzkyZWM5NGIzZjA4ODNlNDI4ZjQzYjc5MGYxOWViM2I2ZWJlNDc0ODc3MDkxZTIyN2RhOGMwYTk2ZTc5ODBhNjM5NjE1Zjk= </access_token> <refresh_token> cmVmcmVzaABhbGljZUB3b25kZXJsYW5kLmNvbS9NaWNoYWwtUGlvdHJvd3NraXMtTWFjQm9vay1Qcm8ANjM2MjMwMDYxODQAMQAwZGQxOGJjODhkMGQ0N2MzNTBkYzAwYjcxZjMyZDVmOWIwOTljMmI1ODU5MmNhN2QxZGFmNWFkNGM0NDQ2ZGU2MWYxYzdhNTJjNDUyMGI5YmIxNGIxNTMwMTE4YTM1NTc= </refresh_token> </items> </iq>","title":"Obtaining a token"},{"location":"open-extensions/token-reconnection/#authentication-with-an-access-token","text":"Client authenticates with an access token 1 2 3 <auth xmlns= \"urn:ietf:params:xml:ns:xmpp-sasl\" mechanism= \"X-OAUTH\" > YWNjZXNzAGFsaWNlQHdvbmRlcmxhbmQuY29tL01pY2hhbC1QaW90cm93c2tpcy1NYWNCb29rLVBybwA2MzYyMTg4Mzc2NAA4M2QwNzNiZjBkOGJlYzVjZmNkODgyY2ZlMzkyZWM5NGIzZjA4ODNlNDI4ZjQzYjc5MGYxOWViM2I2ZWJlNDc0ODc3MDkxZTIyN2RhOGMwYTk2ZTc5ODBhNjM5NjE1Zjk= </auth> Server responds with a success 1 <success xmlns= \"urn:ietf:params:xml:ns:xmpp-sasl\" />","title":"Authentication with an access token"},{"location":"open-extensions/token-reconnection/#authentication-with-a-refresh-token","text":"In this situation server will respond with a new refresh token which SHOULD be used in future authentication. Client authenticates with a refresh token 1 2 3 <auth xmlns= \"urn:ietf:params:xml:ns:xmpp-sasl\" mechanism= \"X-OAUTH\" > cmVmcmVzaABhbGljZUB3b25kZXJsYW5kLmNvbS9NaWNoYWwtUGlvdHJvd3NraXMtTWFjQm9vay1Qcm8ANjM2MjMwMDYxODQAMQAwZGQxOGJjODhkMGQ0N2MzNTBkYzAwYjcxZjMyZDVmOWIwOTljMmI1ODU5MmNhN2QxZGFmNWFkNGM0NDQ2ZGU2MWYxYzdhNTJjNDUyMGI5YmIxNGIxNTMwMTE4YTM1NTc= </auth> Server responds with a success and a new refresh token 1 2 3 <success xmlns= \"urn:ietf:params:xml:ns:xmpp-sasl\" > cmVmcmVzaABhbGljZUB3b25kZXJsYW5kLmNvbS9NaWNoYWwtUGlvdHJvd3NraXMtTWFjQm9vay1Qcm8ANjM2MjMwMDYxODQAMgAwZGQxOGJjODhkMGQ0N2MzNTBkYzAwYjcxZjMyZDVmOWIwOTljMmI1ODU5MmNhN2QxZGFmNWFkNGM0NDQ2ZGU2MWYxYzdhNTJjNDUyMGI5YmIxNGIxNTMwMTE4YTM1NTc= </success>","title":"Authentication with a refresh token"},{"location":"open-extensions/token-reconnection/#token-format","text":"All tokens are exchanged as Base64 encoded binary data. Serialization format of the token before encoding with Base64 is dependent on its type. Common parts in every token are BARE_JID and EXPIRES_AT . EXPIRES_AT is a timestamp saying when a given token will expire. \\0 stands for the ASCII null character (i.e. byte 0). Text in single quotes ('example') is literal. ALL_CAPS denote parameters.","title":"Token format"},{"location":"open-extensions/token-reconnection/#access-token-format","text":"1 2 BASE64_encode ('access', \\0, BARE_JID, \\0, EXPIRES_AT, \\0, DATA) Example (please note the line break was added only for readability): 1 2 'access' \\0 Q8@wonderland.com \\0 64875466454 \\0 0acd0a66d06934791d046060cf9f1ad3c2abb3274cc7e7d7b2bc7e2ac4453ed774b6c6813b40ebec2bbc3774d59d4087","title":"Access token format"},{"location":"open-extensions/token-reconnection/#refresh-token-format","text":"1 2 BASE64_encode ('refresh', \\0, BARE_JID, \\0, EXPIRES_AT, \\0, SEQUENCE_NO, \\0, DATA) Example (please note the line break was added only for readability): 1 2 'refresh' \\0 qp@wonderland.com \\0 64875466457 \\0 6 \\0 8f57cb019cd6dc6e7779be165b9558611baf71ee4a40d03e77b78b069f482f96c9d23b1ac1ef69f64c1a1db3d36a96ad","title":"Refresh token format"},{"location":"operation-and-maintenance/Cluster-configuration-and-node-management/","text":"Environment configuration File descriptors To handle large traffic, some of the system variables need to be tuned. Number one on that list is the maximum number of file descriptors which often is set to 1024. Each MongooseIM connection consumes ~1 file descriptor, so the default value will not suffice for larger installations - when it is exceeded, emfile errors will appear in logs. To check the current limit execute: ulimit -n . To list all limits execute: ulimit -a . In the example below we set limits for a mongooseim user. To increase the limit the following entries should be added in /etc/security/limits.conf : 1 2 mongooseim soft nofile 1000000 mongooseim hard nofile 1000000 If you are using Ubuntu , all /etc/pam.d/common-session* files should include session required pam_limits.so . vm.args file This file contains Erlang options used when starting the VM. It is located in REL_ROOT/etc/vm.args where REL_ROOT is the path to a MongooseIM release (ie. _build/prod/rel/mongooseim if you build MongooseIM from source). When using an SSL/TLS connection we advise to increase ERL_MAX_PORTS to 350000 . This value specifies how many ports (files, drivers, sockets etc) can be used by the Erlang VM. Be cautious - it preallocates some structures inside the VM and will have impact on the memory usage. We suggest 350000 for 100 k users when using an SSL/TLS connection or 250000 in other cases. To check how memory consumption changes depending on ERL_MAX_PORTS , use the following command: 1 env ERL_MAX_PORTS =[ given value ] erl -noinput -eval 'io:format(\"~p~n\",[erlang:memory(system)]).' -s erlang halt Another change you need to make when building a MongooseIM cluster is setting the -sname . To do it, just set the -sname option in vm.args with node's hostname, which must be resolvable on other nodes in the cluster. Port range To connect to other nodes, a freshly started node uses a port from the range inet_dist_listen_min to inet_dist_listen_max . To enable this, add the following line to the vm.args file: 1 -kernel inet_dist_listen_min 50000 inet_dist_listen_max 50010 Make sure that the range you set provides enough ports for all the nodes in the cluster. Remember to keep an epmd port open (port 4369) if any firewall restrictions are required. Epmd keeps track of which Erlang node is using which ports on the local machine. Connecting nodes Checklist: working directory rel/mongooseim (root of a MongooseIM release or installation) the same cookie across all nodes ( vm.args -setcookie parameter) each node should be able to ping other nodes using its sname (ex. net_adm:ping('mongoose@localhost') ) Initial node There is no action required on the initial node. Just start MongooseIM using mongooseim start or mongooseim live . New node - joining cluster 1 2 3 mongooseimctl start mongooseimctl started #waits until MongooseIM starts mongooseimctl join_cluster ClusterMember ClusterMember is the name of a running node set in vm.args file, for example mongooseim@localhost . This node has to be part of the cluster we'd like to join. First, MongooseIM will display a warning and a question if the operation should proceed: 1 Warning. This will drop all current connections and will discard all persistent data from Mnesia. Do you want to continue? (yes/no) If you type yes MongooseIM will start joining the cluster. Successful output may look like the following: 1 You have successfully joined the node mongooseim2@localhost to the cluster with node member mongooseim@localhost In order to skip the question you can add option -f which will perform the action without displaying the warning and waiting for the confirmation. Leaving cluster To leave a running node from the cluster, call: 1 mongooseimctl leave_cluster It only makes sense to use it if the node is the part of a cluster, e.g join_cluster was called from that node before. Similarly to join_cluster a warning and a question will be displayed unless the option -f is added to the command. The successful output from the above command may look like the following: 1 The node mongooseim2@localhost has successfully left the cluster Removing a node from the cluster To remove another node from the cluster, call the following command from one of the cluster members: 1 mongooseimctl remove_from_cluster RemoteNodeName where RemoteNodeName is a name of the node that we'd like to remove from our cluster. This command could be useful when the node is dead and not responding and we'd like to remove it remotely. The successful output from the above command may look like the following: 1 The node mongooseim2@localhost has been removed from the cluster Cluster status You can use the following commands on any of the running nodes to examine the cluster or to see if a newly added node is properly clustered: 1 mongooseimctl mnesia info | grep \"running db nodes\" This command shows all running nodes. A healthy cluster should contain all nodes here. For example: 1 running db nodes = [ mongooseim@node1, mongooseim@node2 ] To see stopped or misbehaving nodes following command can be useful: 1 mongooseimctl mnesia info | grep \"stopped db nodes\" This command shows which nodes are considered stopped. This does not necessarily indicate that they are down but might be a symptom of a communication problem. Load Balancing Elastic Load Balancer (ELB) When using ELB please be advised that some warm-up time may be needed before the load balancer works efficiently for a big load. Software load balancer A good example of load balancing on the application layer are HAProxy and Nginx. DNS-based load balancing Load balancing can be performed on a DNS level. A DNS response can have a number of IP addresses that can be returned to the client side in a random order. On the AWS stack this type of balancing is provided by Route53. The description of their service can be found in the Route53 Developer's Guide . Other The approaches described above can be mixed - we can use DNS load balancing to pick a software load balancer which will select one of the nodes.","title":"Cluster configuration and node management"},{"location":"operation-and-maintenance/Cluster-configuration-and-node-management/#environment-configuration","text":"","title":"Environment configuration"},{"location":"operation-and-maintenance/Cluster-configuration-and-node-management/#file-descriptors","text":"To handle large traffic, some of the system variables need to be tuned. Number one on that list is the maximum number of file descriptors which often is set to 1024. Each MongooseIM connection consumes ~1 file descriptor, so the default value will not suffice for larger installations - when it is exceeded, emfile errors will appear in logs. To check the current limit execute: ulimit -n . To list all limits execute: ulimit -a . In the example below we set limits for a mongooseim user. To increase the limit the following entries should be added in /etc/security/limits.conf : 1 2 mongooseim soft nofile 1000000 mongooseim hard nofile 1000000 If you are using Ubuntu , all /etc/pam.d/common-session* files should include session required pam_limits.so .","title":"File descriptors"},{"location":"operation-and-maintenance/Cluster-configuration-and-node-management/#vmargs-file","text":"This file contains Erlang options used when starting the VM. It is located in REL_ROOT/etc/vm.args where REL_ROOT is the path to a MongooseIM release (ie. _build/prod/rel/mongooseim if you build MongooseIM from source). When using an SSL/TLS connection we advise to increase ERL_MAX_PORTS to 350000 . This value specifies how many ports (files, drivers, sockets etc) can be used by the Erlang VM. Be cautious - it preallocates some structures inside the VM and will have impact on the memory usage. We suggest 350000 for 100 k users when using an SSL/TLS connection or 250000 in other cases. To check how memory consumption changes depending on ERL_MAX_PORTS , use the following command: 1 env ERL_MAX_PORTS =[ given value ] erl -noinput -eval 'io:format(\"~p~n\",[erlang:memory(system)]).' -s erlang halt Another change you need to make when building a MongooseIM cluster is setting the -sname . To do it, just set the -sname option in vm.args with node's hostname, which must be resolvable on other nodes in the cluster.","title":"vm.args file"},{"location":"operation-and-maintenance/Cluster-configuration-and-node-management/#port-range","text":"To connect to other nodes, a freshly started node uses a port from the range inet_dist_listen_min to inet_dist_listen_max . To enable this, add the following line to the vm.args file: 1 -kernel inet_dist_listen_min 50000 inet_dist_listen_max 50010 Make sure that the range you set provides enough ports for all the nodes in the cluster. Remember to keep an epmd port open (port 4369) if any firewall restrictions are required. Epmd keeps track of which Erlang node is using which ports on the local machine.","title":"Port range"},{"location":"operation-and-maintenance/Cluster-configuration-and-node-management/#connecting-nodes","text":"Checklist: working directory rel/mongooseim (root of a MongooseIM release or installation) the same cookie across all nodes ( vm.args -setcookie parameter) each node should be able to ping other nodes using its sname (ex. net_adm:ping('mongoose@localhost') )","title":"Connecting nodes"},{"location":"operation-and-maintenance/Cluster-configuration-and-node-management/#initial-node","text":"There is no action required on the initial node. Just start MongooseIM using mongooseim start or mongooseim live .","title":"Initial node"},{"location":"operation-and-maintenance/Cluster-configuration-and-node-management/#new-node-joining-cluster","text":"1 2 3 mongooseimctl start mongooseimctl started #waits until MongooseIM starts mongooseimctl join_cluster ClusterMember ClusterMember is the name of a running node set in vm.args file, for example mongooseim@localhost . This node has to be part of the cluster we'd like to join. First, MongooseIM will display a warning and a question if the operation should proceed: 1 Warning. This will drop all current connections and will discard all persistent data from Mnesia. Do you want to continue? (yes/no) If you type yes MongooseIM will start joining the cluster. Successful output may look like the following: 1 You have successfully joined the node mongooseim2@localhost to the cluster with node member mongooseim@localhost In order to skip the question you can add option -f which will perform the action without displaying the warning and waiting for the confirmation.","title":"New node - joining cluster"},{"location":"operation-and-maintenance/Cluster-configuration-and-node-management/#leaving-cluster","text":"To leave a running node from the cluster, call: 1 mongooseimctl leave_cluster It only makes sense to use it if the node is the part of a cluster, e.g join_cluster was called from that node before. Similarly to join_cluster a warning and a question will be displayed unless the option -f is added to the command. The successful output from the above command may look like the following: 1 The node mongooseim2@localhost has successfully left the cluster","title":"Leaving cluster"},{"location":"operation-and-maintenance/Cluster-configuration-and-node-management/#removing-a-node-from-the-cluster","text":"To remove another node from the cluster, call the following command from one of the cluster members: 1 mongooseimctl remove_from_cluster RemoteNodeName where RemoteNodeName is a name of the node that we'd like to remove from our cluster. This command could be useful when the node is dead and not responding and we'd like to remove it remotely. The successful output from the above command may look like the following: 1 The node mongooseim2@localhost has been removed from the cluster","title":"Removing a node from the cluster"},{"location":"operation-and-maintenance/Cluster-configuration-and-node-management/#cluster-status","text":"You can use the following commands on any of the running nodes to examine the cluster or to see if a newly added node is properly clustered: 1 mongooseimctl mnesia info | grep \"running db nodes\" This command shows all running nodes. A healthy cluster should contain all nodes here. For example: 1 running db nodes = [ mongooseim@node1, mongooseim@node2 ] To see stopped or misbehaving nodes following command can be useful: 1 mongooseimctl mnesia info | grep \"stopped db nodes\" This command shows which nodes are considered stopped. This does not necessarily indicate that they are down but might be a symptom of a communication problem.","title":"Cluster status"},{"location":"operation-and-maintenance/Cluster-configuration-and-node-management/#load-balancing","text":"","title":"Load Balancing"},{"location":"operation-and-maintenance/Cluster-configuration-and-node-management/#elastic-load-balancer-elb","text":"When using ELB please be advised that some warm-up time may be needed before the load balancer works efficiently for a big load.","title":"Elastic Load Balancer (ELB)"},{"location":"operation-and-maintenance/Cluster-configuration-and-node-management/#software-load-balancer","text":"A good example of load balancing on the application layer are HAProxy and Nginx.","title":"Software load balancer"},{"location":"operation-and-maintenance/Cluster-configuration-and-node-management/#dns-based-load-balancing","text":"Load balancing can be performed on a DNS level. A DNS response can have a number of IP addresses that can be returned to the client side in a random order. On the AWS stack this type of balancing is provided by Route53. The description of their service can be found in the Route53 Developer's Guide .","title":"DNS-based load balancing"},{"location":"operation-and-maintenance/Cluster-configuration-and-node-management/#other","text":"The approaches described above can be mixed - we can use DNS load balancing to pick a software load balancer which will select one of the nodes.","title":"Other"},{"location":"operation-and-maintenance/Cluster-management-considerations/","text":"These apply to bare metal, virtualization, hypervisor, containers and other technologies. Single-node MongooseIM With a single-node MongooseIM, one can set up a vertically scalable system, that is a function of the server resources. MongooseIM can scale from hundreds to tens of thousands of concurrent users. Note that in a single-node MongooseIM, there is no load distribution, and no fallback or failover in case of a failure. This architecture is suitable for low-scale deployments, such as testing and development environments on embedded devices, personal computers, or servers. Dual-node MongooseIM With a dual-node MongooseIM, one can set up a vertically scalable system, that is a function of the servers' resources. We recommend that servers with the same power are used. Both nodes can handle different sets of services, given that these non-MongooseIM services consume roughly the same resources on both servers. In this setup, MongooseIM can scale up to hundred of thousands of concurrent users. In a dual-node MongooseIM, there is a 50-50 load distribution - there is a possible fallback or failover in case of a node failure. Please keep in mind that to avoid degrading the service the remaining node should be able to handle the full load when necessary. This setup is applicable to low to mid-scale deployments used f.e. for functional and load testing. We recommend using real dedicated servers, although MongooseIM could run in a cluster mode with low-power machines, such as embedded devices. This setup provides better fault tolerance and robustness than the single-node but it's not recommended for production environments. The minimum recommended production setup is 3 nodes. Multi-node MongooseIM With a multi-node MongooseIM, one can set up a system that is highly scalable both vertically and horizontally and that is still a function of the servers' resources. We recommend that servers with the same power are used. We also recommend that all the nodes handle the same set of services. In this setup, MongooseIM can scale up to tens of millions of concurrent users. In a multi-node MongooseIM, with n nodes, there is a 1/n load distribution - there is a possible fallback or failover in case of a node failure. To avoid degrading the service the remaining nodes should be able to handle 1/(n-1) load when necessary. This setup fits mid and large-scale deployments, such as production environments. We recommend using real dedicated, powerful servers. Multi-datacenter MongooseIM With a multi-datacenter MongooseIM, one can set up a system that is highly scalable both vertically and horizontally. The MongooseIM clusters are simply distributed across continents for local, low-lag client connections, and the clusters are interconnected via high-speed links. In this setup, MongooseIM can scale up to hundreds of millions of concurrent users. This applies to large and very large-scale deployments. We advise contacting us in case of such a big deployment. Summary table Setup : reflects the number of nodes in your cluster. Purpose : is the goal and use of this cluster. Low-end : number of concurrent users on low-power machines, such as laptops, embedded devices, entry-level cloud or bare metal. High-end : number of concurrent users on powerful machines, with lots of memory, multi-core CPU, whether in cloud or bare metal. Setup Purpose Low-end High-end Single-node Functional testing, development 100 to 10k 100k to 500k Dual-node Low-end system, load testing 1k to 100k 1M to 3M Multi-node High-end production system 10k to 1M 2M to 10M Multi-datacenter Very large scale production system 100k to 10M 10M to 100M Important notes Scalability highly depends on variables such as: machine's power, such as memory, CPU, I/O the type of concurrent users: most iOS apps are not connected in the background, they use APNS to push info to the device web clients use websockets, with fallback on BOSH (HTTP long-polling) client-side and backend-side REST API how much archiving is needed and the latency for storage and querying, which depends a lot on storage backend architecture message throughput: one-to-one MUC MUC light PubSub Presences HTTP notifications (may include queuing systems such as RabbitMQ or Kafka) latency of messaging, both real-time and archived messages OS configuration To achieve high scalability you have to adjust the configuration of your operating system. First, set some network related parameters - this is what we use for load testing: Parameter Value net.ipv4.ip_local_port_range 1024 65535 net.ipv4.tcp_mem 16777216 16777216 16777216 net.ipv4.tcp_wmem 4096 87380 16777216 net.ipv4.tcp_rmem 4096 87380 16777216 Then, you have to increase the number of file descriptors allowed for the user running your MongooseIM server process. In Linux, this is most commonly done in /etc/security/limits.conf . You should remember, though, that there is a limit to it \u2014 you can't increase it above an upper bound which is set by the fs.file-max kernel parameter. And there is a limit to a possible increase in fs.file-max as well \u2014 you can't increase it beyond 1048576, which is 2^20 and is set by another kernel parameter, fs.nr_open . Once you increase that one, you are good to go.","title":"Cluster management considerations"},{"location":"operation-and-maintenance/Cluster-management-considerations/#single-node-mongooseim","text":"With a single-node MongooseIM, one can set up a vertically scalable system, that is a function of the server resources. MongooseIM can scale from hundreds to tens of thousands of concurrent users. Note that in a single-node MongooseIM, there is no load distribution, and no fallback or failover in case of a failure. This architecture is suitable for low-scale deployments, such as testing and development environments on embedded devices, personal computers, or servers.","title":"Single-node MongooseIM"},{"location":"operation-and-maintenance/Cluster-management-considerations/#dual-node-mongooseim","text":"With a dual-node MongooseIM, one can set up a vertically scalable system, that is a function of the servers' resources. We recommend that servers with the same power are used. Both nodes can handle different sets of services, given that these non-MongooseIM services consume roughly the same resources on both servers. In this setup, MongooseIM can scale up to hundred of thousands of concurrent users. In a dual-node MongooseIM, there is a 50-50 load distribution - there is a possible fallback or failover in case of a node failure. Please keep in mind that to avoid degrading the service the remaining node should be able to handle the full load when necessary. This setup is applicable to low to mid-scale deployments used f.e. for functional and load testing. We recommend using real dedicated servers, although MongooseIM could run in a cluster mode with low-power machines, such as embedded devices. This setup provides better fault tolerance and robustness than the single-node but it's not recommended for production environments. The minimum recommended production setup is 3 nodes.","title":"Dual-node MongooseIM"},{"location":"operation-and-maintenance/Cluster-management-considerations/#multi-node-mongooseim","text":"With a multi-node MongooseIM, one can set up a system that is highly scalable both vertically and horizontally and that is still a function of the servers' resources. We recommend that servers with the same power are used. We also recommend that all the nodes handle the same set of services. In this setup, MongooseIM can scale up to tens of millions of concurrent users. In a multi-node MongooseIM, with n nodes, there is a 1/n load distribution - there is a possible fallback or failover in case of a node failure. To avoid degrading the service the remaining nodes should be able to handle 1/(n-1) load when necessary. This setup fits mid and large-scale deployments, such as production environments. We recommend using real dedicated, powerful servers.","title":"Multi-node MongooseIM"},{"location":"operation-and-maintenance/Cluster-management-considerations/#multi-datacenter-mongooseim","text":"With a multi-datacenter MongooseIM, one can set up a system that is highly scalable both vertically and horizontally. The MongooseIM clusters are simply distributed across continents for local, low-lag client connections, and the clusters are interconnected via high-speed links. In this setup, MongooseIM can scale up to hundreds of millions of concurrent users. This applies to large and very large-scale deployments. We advise contacting us in case of such a big deployment.","title":"Multi-datacenter MongooseIM"},{"location":"operation-and-maintenance/Cluster-management-considerations/#summary-table","text":"Setup : reflects the number of nodes in your cluster. Purpose : is the goal and use of this cluster. Low-end : number of concurrent users on low-power machines, such as laptops, embedded devices, entry-level cloud or bare metal. High-end : number of concurrent users on powerful machines, with lots of memory, multi-core CPU, whether in cloud or bare metal. Setup Purpose Low-end High-end Single-node Functional testing, development 100 to 10k 100k to 500k Dual-node Low-end system, load testing 1k to 100k 1M to 3M Multi-node High-end production system 10k to 1M 2M to 10M Multi-datacenter Very large scale production system 100k to 10M 10M to 100M","title":"Summary table"},{"location":"operation-and-maintenance/Cluster-management-considerations/#important-notes","text":"Scalability highly depends on variables such as: machine's power, such as memory, CPU, I/O the type of concurrent users: most iOS apps are not connected in the background, they use APNS to push info to the device web clients use websockets, with fallback on BOSH (HTTP long-polling) client-side and backend-side REST API how much archiving is needed and the latency for storage and querying, which depends a lot on storage backend architecture message throughput: one-to-one MUC MUC light PubSub Presences HTTP notifications (may include queuing systems such as RabbitMQ or Kafka) latency of messaging, both real-time and archived messages","title":"Important notes"},{"location":"operation-and-maintenance/Cluster-management-considerations/#os-configuration","text":"To achieve high scalability you have to adjust the configuration of your operating system. First, set some network related parameters - this is what we use for load testing: Parameter Value net.ipv4.ip_local_port_range 1024 65535 net.ipv4.tcp_mem 16777216 16777216 16777216 net.ipv4.tcp_wmem 4096 87380 16777216 net.ipv4.tcp_rmem 4096 87380 16777216 Then, you have to increase the number of file descriptors allowed for the user running your MongooseIM server process. In Linux, this is most commonly done in /etc/security/limits.conf . You should remember, though, that there is a limit to it \u2014 you can't increase it above an upper bound which is set by the fs.file-max kernel parameter. And there is a limit to a possible increase in fs.file-max as well \u2014 you can't increase it beyond 1048576, which is 2^20 and is set by another kernel parameter, fs.nr_open . Once you increase that one, you are good to go.","title":"OS configuration"},{"location":"operation-and-maintenance/Cluster-restart/","text":"When you are using a MongooseIM cluster that is using Mnesia backend for any extensions, there could occur an issue related to the distributed Mnesia nodes. How to restart a cluster: Having Node A and Node B, the cluster restart procedure should occur in the following way: Start the nodes in the opposite order to the one in which they were stopped. The first node you restart should be the last one to go down. For cluster with 3 nodes, after stopping the nodes ABC , they should be started in CBA order. How NOT to restart a cluster: Having Node A and Node B. When the nodes are stopped in AB order, starting the node A first can result in issues related to the distributed Mnesia nodes and not bring up a node that is fully operational. Changing the order of the restarted nodes can cause issues with distributed Mnesia. Make sure to follow the recommendations if you are using Mnesia backend for any of the extensions. Please note that for some of the extensions, the Mnesia backend is set by default without having that configured explicitly in the configuration file. For more information related to the cluster configuration and maintenance, please see Cluster configuration and node management section.","title":"Cluster restart"},{"location":"operation-and-maintenance/Cluster-restart/#how-to-restart-a-cluster","text":"Having Node A and Node B, the cluster restart procedure should occur in the following way: Start the nodes in the opposite order to the one in which they were stopped. The first node you restart should be the last one to go down. For cluster with 3 nodes, after stopping the nodes ABC , they should be started in CBA order.","title":"How to restart a cluster:"},{"location":"operation-and-maintenance/Cluster-restart/#how-not-to-restart-a-cluster","text":"Having Node A and Node B. When the nodes are stopped in AB order, starting the node A first can result in issues related to the distributed Mnesia nodes and not bring up a node that is fully operational. Changing the order of the restarted nodes can cause issues with distributed Mnesia. Make sure to follow the recommendations if you are using Mnesia backend for any of the extensions. Please note that for some of the extensions, the Mnesia backend is set by default without having that configured explicitly in the configuration file. For more information related to the cluster configuration and maintenance, please see Cluster configuration and node management section.","title":"How NOT to restart a cluster:"},{"location":"operation-and-maintenance/Humio/","text":"Humio and MongooseIM Getting Humio's ingest token Visit this url to create a new sandbox's ingest token. The URL is: 1 https://cloud.humio.com/YOUR_REPOSITORY_NAME_HERE/settings/ingest-tokens Configure Filebeat Configure Filebeat, using this config file priv/filebeat.mongooseim.humio.yml . We recommend to use the Filebeat docker container. You have to use an open-source version of Filebeat, which has the oss suffix. This example mounts a log directory $(pwd)/_build/mim1/rel/mongooseim/log as a volume for Filebeat. It also mounts a configuration file $(pwd)/priv/filebeat.mongooseim.humio.yml . Most likely these paths would be different on your machine. Pass your Humio ingest token as a password argument. Or uncomment and change it inside the filebeat.mongooseim.humio.yml file. 1 2 3 4 5 6 docker run -d \\ --name mongooseim-filebeat \\ -v \" $( pwd ) /_build/mim1/rel/mongooseim/log:/usr/lib/mongooseim/log\" \\ -v \" $( pwd ) /priv/filebeat.mongooseim.humio.yml:/usr/share/filebeat/filebeat.yml:ro\" \\ docker.elastic.co/beats/filebeat-oss:7.9.2 \\ filebeat -e -E output.elasticsearch.password = \"abc12345-xxxx-yyyy-zzzz-123456789abc\" Argument -e enables debugging information for Filebeat that can be visible using the docker logs mongooseim-filebeat command. Viewing logs Navigate to https://cloud.humio.com/sandbox/search to see the Sandbox's dashboard. A list of log messages: Structured log message:","title":"Logging with Humio"},{"location":"operation-and-maintenance/Humio/#humio-and-mongooseim","text":"","title":"Humio and MongooseIM"},{"location":"operation-and-maintenance/Humio/#getting-humios-ingest-token","text":"Visit this url to create a new sandbox's ingest token. The URL is: 1 https://cloud.humio.com/YOUR_REPOSITORY_NAME_HERE/settings/ingest-tokens","title":"Getting Humio's ingest token"},{"location":"operation-and-maintenance/Humio/#configure-filebeat","text":"Configure Filebeat, using this config file priv/filebeat.mongooseim.humio.yml . We recommend to use the Filebeat docker container. You have to use an open-source version of Filebeat, which has the oss suffix. This example mounts a log directory $(pwd)/_build/mim1/rel/mongooseim/log as a volume for Filebeat. It also mounts a configuration file $(pwd)/priv/filebeat.mongooseim.humio.yml . Most likely these paths would be different on your machine. Pass your Humio ingest token as a password argument. Or uncomment and change it inside the filebeat.mongooseim.humio.yml file. 1 2 3 4 5 6 docker run -d \\ --name mongooseim-filebeat \\ -v \" $( pwd ) /_build/mim1/rel/mongooseim/log:/usr/lib/mongooseim/log\" \\ -v \" $( pwd ) /priv/filebeat.mongooseim.humio.yml:/usr/share/filebeat/filebeat.yml:ro\" \\ docker.elastic.co/beats/filebeat-oss:7.9.2 \\ filebeat -e -E output.elasticsearch.password = \"abc12345-xxxx-yyyy-zzzz-123456789abc\" Argument -e enables debugging information for Filebeat that can be visible using the docker logs mongooseim-filebeat command.","title":"Configure Filebeat"},{"location":"operation-and-maintenance/Humio/#viewing-logs","text":"Navigate to https://cloud.humio.com/sandbox/search to see the Sandbox's dashboard. A list of log messages: Structured log message:","title":"Viewing logs"},{"location":"operation-and-maintenance/Logging-%26-monitoring/","text":"Logs We strongly recommend storing logs in one centralized place when working in a clustered environment. MongooseIM uses the standard OTP logging framework: Logger . Its handlers can be replaced and customised, according to Logger's documentation. Syslog integration MongooseIM uses syslogger as a Logger handler for syslog. To activate it you have to add syslogger to the applications section in src/mongooseim/app.src : 1 %% syslogger, % uncomment to enable a logger handler for syslog You also need to edit rel/files/app.config and uncomment the lines: 1 2 3 4 5 6 7 8 % Uncomment these lines to enable logging to syslog. % Remember to add syslogger as a dependency in mongooseim.app.src. %% {syslogger, [ %% {ident, \"mongooseim\"}, %% {logger, [ %% {handler, sys_log, syslogger, %% #{formatter => {logger_formatter, #{single_line => true}}}}]}] %% }, You can provide different parameters to change the handler's behaviour as described in the syslogger's GitHub page : ident - a string to tag all the syslog messages with. The default is mongooseim . facility - the facility to log to (see the syslog documentation). log_opts - see the syslog documentation for the description. Depending on the system you use, remember to also add the appropriate line in the syslog config file. For example, if the facility local0 is set: 1 local0.info /var/log/mongooseim.log All the logs of level info should be passed to the /var/log/mongooseim.log file. Example log (e.g tail -f /var/log/mongooseim.log ): 1 Apr 1 12:36:49 User.local mongooseim[6068]: [info] <0.7.0> Application mnesia started on node mongooseim@localhost Further / multiserver integration For more advanced processing and analysis of logs, including gathering logs from multiple machines, you can use one of the many available systems (e.g. logstash/elasticsearch/kibana, graylog, splunk), by redirecting mongoose logs to such service with an appropriate Logger 's handler. Check Logging for more information. Monitoring WombatOAM WombatOAM is an operations and maintenance framework for Erlang based systems. Its Web Dashboard displays this data in an aggregated manner. Additionally, WombatOAM provides interfaces to feed the data to other OAM tools such as Graphite, Nagios or Zabbix. For more information see: WombatOAM . graphite-collectd To monitor MongooseIM during load testing, we recommend the following open source applications: Grafana is used for data presentation. Graphite is a server used for metrics storage. collectd is a daemon running on the monitored nodes capturing data related to CPU and Memory usage, IO etc. Plug-in Exometer reporters MongooseIM uses a fork of Exometer library for collecting metrics. Exometer has many plug-in reporters that can send metrics to external services. We maintain exometer_report_graphite and exometer_report_statsd for Graphite and StatsD respectively. It is possible to enable them in MongooseIM via the app.config file. The file sits next to the mongooseim.toml file in the rel/files and _REL_DIR_/etc directories. Below you can find a sample configuration. It shows setting up a reporter connecting to graphite running on localhost. You can see an additional option not listed in the Exometer docs - mongooseim_report_interval , which sets the metrics' resolution, i.e. how often Exometer gathers and sends metrics through reporters. By default, the resolution is set to 60 seconds. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 ... { exometer_core , [ { mongooseim_report_interval , 60000 }, %% 60 seconds { report , [ { reporters , [ { exometer_report_graphite , [ { prefix , \"mongooseim\" }, { connect_timeout , 5000 }, { host , \"127.0.0.1\" }, { port , 2003 }, { api_key , \"\" } ]} ]} ]} ]} ... Run Graphite & Grafana in Docker - quick start The following commands will download the latest version of kamon/grafana_graphite docker image that contains both Grafana and Graphite, and start them while mounting the local directory ./docker-grafana-graphite-master/data for metric persistence: 1 2 curl -SL https://github.com/kamon-io/docker-grafana-graphite/archive/master.tar.gz | tar -xzf - make -C docker-grafana-graphite-master up Go to http://localhost:80 to view the Grafana dashboard that's already set up to use metrics from Graphite. Add metrics to Grafana dashboard We recommend the following metrics as a baseline for tracking your MongooseIM installation. For time-based metrics, you can choose to display multiple calculated values for a reporting period - we recommend tracking at least max , median and mean . 1 2 3 4 5 6 7 8 9 10 11 12 13 Session count: <prefix>.global.totalSessionCount.value XMPP messages received: <prefix>.<domain>.xmppMessageReceived.one XMPP messages sent: <prefix>.<domain>.xmppMessageSent.one Successful logins: <prefix>.<domain>.sessionSuccessfulLogins.one Logouts: <prefix>.<domain>.sessionLogouts.one Authorization time: <prefix>.<domain>.backends.auth.authorize.<value-type> RDBMS \"simple\" query time: <prefix>.<domain>.backends.mongoose_rdbms.query.<value-type> RDBMS prepared query time: <prefix>.<domain>.backends.mongoose_rdbms.execute.<value-type> MAM lookups: <prefix>.<domain>.mam_lookup_messages.one MAM archivization time: <prefix>.<domain>.backends.mod_mam.archive.<value-type> MAM lookup time: <prefix>.<domain>.backends.mod_mam.lookup.<value-type> MAM private messages flush time: <prefix>.<domain>.mod_mam_rdbms_async_pool_writer.flush_time.<value-type> MAM MUC messages flush time: <prefix>.<domain>.mod_mam_muc_rdbms_async_pool_writer.flush_time.<value-type> Note that RDBMS metrics are only relevant if MongooseIM is configured with an RDBMS backend , MAM metrics when mod_mam is enabled and MAM flush times when MAM is configured with an RDBMS backend with async_writer option (default). Example graph in Grafana This screenshot shows a graph plotting the RDBMS simple query time metric mentioned above. The graph is plotted for three nodes with each node having a different prefix: mongoose.node1 , mongoose.node2 and mongoose.node3 . The queries take metrics for all nodes and all domains ( ** is a wildcard for multiple parts of the metric name) and group them per-node and per-value-type (respectively 1 st and -1 st part of the metric's name). Parts of the names are indexed from 0 . Time-based metrics in MongooseIM are given in microseconds , so to display human-readable values in graph's legend, the Y-axis unit has to be edited on the Axes tab.","title":"Logging & monitoring"},{"location":"operation-and-maintenance/Logging-%26-monitoring/#logs","text":"We strongly recommend storing logs in one centralized place when working in a clustered environment. MongooseIM uses the standard OTP logging framework: Logger . Its handlers can be replaced and customised, according to Logger's documentation.","title":"Logs"},{"location":"operation-and-maintenance/Logging-%26-monitoring/#syslog-integration","text":"MongooseIM uses syslogger as a Logger handler for syslog. To activate it you have to add syslogger to the applications section in src/mongooseim/app.src : 1 %% syslogger, % uncomment to enable a logger handler for syslog You also need to edit rel/files/app.config and uncomment the lines: 1 2 3 4 5 6 7 8 % Uncomment these lines to enable logging to syslog. % Remember to add syslogger as a dependency in mongooseim.app.src. %% {syslogger, [ %% {ident, \"mongooseim\"}, %% {logger, [ %% {handler, sys_log, syslogger, %% #{formatter => {logger_formatter, #{single_line => true}}}}]}] %% }, You can provide different parameters to change the handler's behaviour as described in the syslogger's GitHub page : ident - a string to tag all the syslog messages with. The default is mongooseim . facility - the facility to log to (see the syslog documentation). log_opts - see the syslog documentation for the description. Depending on the system you use, remember to also add the appropriate line in the syslog config file. For example, if the facility local0 is set: 1 local0.info /var/log/mongooseim.log All the logs of level info should be passed to the /var/log/mongooseim.log file. Example log (e.g tail -f /var/log/mongooseim.log ): 1 Apr 1 12:36:49 User.local mongooseim[6068]: [info] <0.7.0> Application mnesia started on node mongooseim@localhost","title":"Syslog integration"},{"location":"operation-and-maintenance/Logging-%26-monitoring/#further-multiserver-integration","text":"For more advanced processing and analysis of logs, including gathering logs from multiple machines, you can use one of the many available systems (e.g. logstash/elasticsearch/kibana, graylog, splunk), by redirecting mongoose logs to such service with an appropriate Logger 's handler. Check Logging for more information.","title":"Further / multiserver integration"},{"location":"operation-and-maintenance/Logging-%26-monitoring/#monitoring","text":"","title":"Monitoring"},{"location":"operation-and-maintenance/Logging-%26-monitoring/#wombatoam","text":"WombatOAM is an operations and maintenance framework for Erlang based systems. Its Web Dashboard displays this data in an aggregated manner. Additionally, WombatOAM provides interfaces to feed the data to other OAM tools such as Graphite, Nagios or Zabbix. For more information see: WombatOAM .","title":"WombatOAM"},{"location":"operation-and-maintenance/Logging-%26-monitoring/#graphite-collectd","text":"To monitor MongooseIM during load testing, we recommend the following open source applications: Grafana is used for data presentation. Graphite is a server used for metrics storage. collectd is a daemon running on the monitored nodes capturing data related to CPU and Memory usage, IO etc.","title":"graphite-collectd"},{"location":"operation-and-maintenance/Logging-%26-monitoring/#plug-in-exometer-reporters","text":"MongooseIM uses a fork of Exometer library for collecting metrics. Exometer has many plug-in reporters that can send metrics to external services. We maintain exometer_report_graphite and exometer_report_statsd for Graphite and StatsD respectively. It is possible to enable them in MongooseIM via the app.config file. The file sits next to the mongooseim.toml file in the rel/files and _REL_DIR_/etc directories. Below you can find a sample configuration. It shows setting up a reporter connecting to graphite running on localhost. You can see an additional option not listed in the Exometer docs - mongooseim_report_interval , which sets the metrics' resolution, i.e. how often Exometer gathers and sends metrics through reporters. By default, the resolution is set to 60 seconds. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 ... { exometer_core , [ { mongooseim_report_interval , 60000 }, %% 60 seconds { report , [ { reporters , [ { exometer_report_graphite , [ { prefix , \"mongooseim\" }, { connect_timeout , 5000 }, { host , \"127.0.0.1\" }, { port , 2003 }, { api_key , \"\" } ]} ]} ]} ]} ...","title":"Plug-in Exometer reporters"},{"location":"operation-and-maintenance/Logging-%26-monitoring/#run-graphite-grafana-in-docker-quick-start","text":"The following commands will download the latest version of kamon/grafana_graphite docker image that contains both Grafana and Graphite, and start them while mounting the local directory ./docker-grafana-graphite-master/data for metric persistence: 1 2 curl -SL https://github.com/kamon-io/docker-grafana-graphite/archive/master.tar.gz | tar -xzf - make -C docker-grafana-graphite-master up Go to http://localhost:80 to view the Grafana dashboard that's already set up to use metrics from Graphite.","title":"Run Graphite &amp; Grafana in Docker - quick start"},{"location":"operation-and-maintenance/Logging-%26-monitoring/#add-metrics-to-grafana-dashboard","text":"We recommend the following metrics as a baseline for tracking your MongooseIM installation. For time-based metrics, you can choose to display multiple calculated values for a reporting period - we recommend tracking at least max , median and mean . 1 2 3 4 5 6 7 8 9 10 11 12 13 Session count: <prefix>.global.totalSessionCount.value XMPP messages received: <prefix>.<domain>.xmppMessageReceived.one XMPP messages sent: <prefix>.<domain>.xmppMessageSent.one Successful logins: <prefix>.<domain>.sessionSuccessfulLogins.one Logouts: <prefix>.<domain>.sessionLogouts.one Authorization time: <prefix>.<domain>.backends.auth.authorize.<value-type> RDBMS \"simple\" query time: <prefix>.<domain>.backends.mongoose_rdbms.query.<value-type> RDBMS prepared query time: <prefix>.<domain>.backends.mongoose_rdbms.execute.<value-type> MAM lookups: <prefix>.<domain>.mam_lookup_messages.one MAM archivization time: <prefix>.<domain>.backends.mod_mam.archive.<value-type> MAM lookup time: <prefix>.<domain>.backends.mod_mam.lookup.<value-type> MAM private messages flush time: <prefix>.<domain>.mod_mam_rdbms_async_pool_writer.flush_time.<value-type> MAM MUC messages flush time: <prefix>.<domain>.mod_mam_muc_rdbms_async_pool_writer.flush_time.<value-type> Note that RDBMS metrics are only relevant if MongooseIM is configured with an RDBMS backend , MAM metrics when mod_mam is enabled and MAM flush times when MAM is configured with an RDBMS backend with async_writer option (default).","title":"Add metrics to Grafana dashboard"},{"location":"operation-and-maintenance/Logging-%26-monitoring/#example-graph-in-grafana","text":"This screenshot shows a graph plotting the RDBMS simple query time metric mentioned above. The graph is plotted for three nodes with each node having a different prefix: mongoose.node1 , mongoose.node2 and mongoose.node3 . The queries take metrics for all nodes and all domains ( ** is a wildcard for multiple parts of the metric name) and group them per-node and per-value-type (respectively 1 st and -1 st part of the metric's name). Parts of the names are indexed from 0 . Time-based metrics in MongooseIM are given in microseconds , so to display human-readable values in graph's legend, the Y-axis unit has to be edited on the Axes tab.","title":"Example graph in Grafana"},{"location":"operation-and-maintenance/Logging-fields/","text":"Fields reason , class , stacktrace : standard error catching fields. module , function , line , timestamp , node , when , pid : reserved fields (could be used by logger itself). When logging IQs, adding the acc field should be enough. If acc not available, iq can be used. If iq is not available, sub_el could be logged as a last option. what : why we are logging. We often use the function name as the what field. Suffixes : If something goes wrong, use a _failed suffix (instead of unable_to and _error ). The most common suffixes are _starting , _started , _stopping , _stopped , and _result . Prefixes : We sometimes add prefixes to what to signal where we are logging from. Such prefixes should be short. Please, don't prefix with the complete module name. Some examples for prefixes are: mam_ , sm_ , muc_ , auth_ , s2s_ , pool_ . When checking the final event name, remove duplicates from it. Bad event names Good event names Why s2s_dns_error s2s_dns_lookup_failed Not _failed prefix s2s_dns_error s2s_dns_lookup_timeout More specific failure reason mod_mam_starting mam_starting Use mam_ prefix for MAM modules mongoose_wpool_mgr_pool_starting pool_starting Too long and repetitive Logger defaults Timestamp should be ordered first when possible, so that sorting is automatic. Name Type Description Examples timestamp atom The timestamp (with timezone information) 2018-07-11T13:41:10+00:00 at string Where in code the call or log line was emitted module:function:line level enum log level according to RFC 5424 warning Generally required Name Type Description Examples Notes what atom Event (or issue) name remove_user_failed text binary Human readable description <<\"MAM failed to contact MySQL\">> result binary Explanation of the what key failed Optional tags [atom] The subcomponent taking action and logging data. [c2s, presence], [mam, rdbms] This category should be chosen based on filtering needs, and may represent the domain of concern for some operations HTTP requests Name Type Description Examples Notes path binary HTTP path <<\"/api/add_user\">> code integer HTTP code 200 ip tuple IP address inet:ip_address() port integer TCP/UDP port number 5222 peer tuple peer() :: {inet:ip_address(), inet:port_number()} {{127,0,0,1},5222} req map Cowboy request Provide when available reply_body binary Body reply <<\"ok\">> XMPP Name Type Description Examples Notes acc map mongoose_acc, used to extract fields #{...} user binary Local Username <<\"alice\">> Use #jid.luser when available server binary Local Server (host) name <<\"localhost\">> Use #jid.lserver when available sub_host binary Subhost when MUC or pubsub are used <<\"muc.localhost\">> It's not the same as server remote_user binary Remote Username (usually who makes IQ requests) <<\"alice\">> Use #jid.luser when available remote_server binary Remote Server (usually who makes IQ requests) <<\"otherhost\">> Use #jid.lserver when available iq record MongooseIM IQ record #iq{} Provide when available (but it could be acc instead) sub_el record IQ sub element #xmlel{} Provide ONLY if iq not available c2s_state record C2S process state, that would be used by formatter #state{} from_jid binary Accumulator's from_jid <<\"alice@localhost\">> to_jid binary Accumulator's to_jid <<\"to@localhost\">> packet binary Accumulator's element <<\"<message>...\">> Encoded as XML, not erlang records exml_packet record Same as packet, but in #xmlel{} format #xmlel{} Record, formatted in formatter Other requests Name Type Description Examples Notes duration integer Duration of some operation in milliseconds 5000 Don't use it for microseconds state_name atom State name in gen_fsm wait_for_stream state term gen_server state #state{} Consider adding a formatter call_from tuple From argument in gen_server's handle_call {Pid, Tag} When logging exceptions what key should contain en _exception suffix. Following keys should be present: Name Type Description Examples Notes class enum catch Class:Reason:Stacktrace error reason term catch Class:Reason:Stacktrace http_timeout stacktrace term catch Class:Reason:Stacktrace [...] Formatted by formatter Macros for logging unexpected requests gen_server processes sometimes receive messages they couldn't process. We use macros to log such events (just because you would need them in each gen_server module). We don't need to log state or state names for such events. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 %% We don't always handle unexpected calls. handle_call ( Request , From , State ) -> ? UNEXPECTED_CALL ( Request , From ), { reply , { error , unexpected_call }, State }. %% We don't always handle unexpected casts. handle_cast ( Msg , State ) -> ? UNEXPECTED_CAST ( Msg ), { noreply , State }. %% We SHOULD ignore all unexpected messages, because they could arrive in case %% of gen_server call timeouts. handle_info ( Msg , State ) -> ? UNEXPECTED_INFO ( Msg ), { noreply , State }. These macros translate into warning logs with the following keys, respectively: 1 2 3 #{ what => unexpected_cast , msg => Msg }. #{ what => unexpected_info , msg => Msg }. #{ what => unexpected_call , msg => Msg , call_from => From }.","title":"Logging fields"},{"location":"operation-and-maintenance/Logging-fields/#fields","text":"reason , class , stacktrace : standard error catching fields. module , function , line , timestamp , node , when , pid : reserved fields (could be used by logger itself). When logging IQs, adding the acc field should be enough. If acc not available, iq can be used. If iq is not available, sub_el could be logged as a last option. what : why we are logging. We often use the function name as the what field. Suffixes : If something goes wrong, use a _failed suffix (instead of unable_to and _error ). The most common suffixes are _starting , _started , _stopping , _stopped , and _result . Prefixes : We sometimes add prefixes to what to signal where we are logging from. Such prefixes should be short. Please, don't prefix with the complete module name. Some examples for prefixes are: mam_ , sm_ , muc_ , auth_ , s2s_ , pool_ . When checking the final event name, remove duplicates from it. Bad event names Good event names Why s2s_dns_error s2s_dns_lookup_failed Not _failed prefix s2s_dns_error s2s_dns_lookup_timeout More specific failure reason mod_mam_starting mam_starting Use mam_ prefix for MAM modules mongoose_wpool_mgr_pool_starting pool_starting Too long and repetitive","title":"Fields"},{"location":"operation-and-maintenance/Logging-fields/#logger-defaults","text":"Timestamp should be ordered first when possible, so that sorting is automatic. Name Type Description Examples timestamp atom The timestamp (with timezone information) 2018-07-11T13:41:10+00:00 at string Where in code the call or log line was emitted module:function:line level enum log level according to RFC 5424 warning","title":"Logger defaults"},{"location":"operation-and-maintenance/Logging-fields/#generally-required","text":"Name Type Description Examples Notes what atom Event (or issue) name remove_user_failed text binary Human readable description <<\"MAM failed to contact MySQL\">> result binary Explanation of the what key failed Optional tags [atom] The subcomponent taking action and logging data. [c2s, presence], [mam, rdbms] This category should be chosen based on filtering needs, and may represent the domain of concern for some operations","title":"Generally required"},{"location":"operation-and-maintenance/Logging-fields/#http-requests","text":"Name Type Description Examples Notes path binary HTTP path <<\"/api/add_user\">> code integer HTTP code 200 ip tuple IP address inet:ip_address() port integer TCP/UDP port number 5222 peer tuple peer() :: {inet:ip_address(), inet:port_number()} {{127,0,0,1},5222} req map Cowboy request Provide when available reply_body binary Body reply <<\"ok\">>","title":"HTTP requests"},{"location":"operation-and-maintenance/Logging-fields/#xmpp","text":"Name Type Description Examples Notes acc map mongoose_acc, used to extract fields #{...} user binary Local Username <<\"alice\">> Use #jid.luser when available server binary Local Server (host) name <<\"localhost\">> Use #jid.lserver when available sub_host binary Subhost when MUC or pubsub are used <<\"muc.localhost\">> It's not the same as server remote_user binary Remote Username (usually who makes IQ requests) <<\"alice\">> Use #jid.luser when available remote_server binary Remote Server (usually who makes IQ requests) <<\"otherhost\">> Use #jid.lserver when available iq record MongooseIM IQ record #iq{} Provide when available (but it could be acc instead) sub_el record IQ sub element #xmlel{} Provide ONLY if iq not available c2s_state record C2S process state, that would be used by formatter #state{} from_jid binary Accumulator's from_jid <<\"alice@localhost\">> to_jid binary Accumulator's to_jid <<\"to@localhost\">> packet binary Accumulator's element <<\"<message>...\">> Encoded as XML, not erlang records exml_packet record Same as packet, but in #xmlel{} format #xmlel{} Record, formatted in formatter","title":"XMPP"},{"location":"operation-and-maintenance/Logging-fields/#other-requests","text":"Name Type Description Examples Notes duration integer Duration of some operation in milliseconds 5000 Don't use it for microseconds state_name atom State name in gen_fsm wait_for_stream state term gen_server state #state{} Consider adding a formatter call_from tuple From argument in gen_server's handle_call {Pid, Tag}","title":"Other requests"},{"location":"operation-and-maintenance/Logging-fields/#when-logging-exceptions","text":"what key should contain en _exception suffix. Following keys should be present: Name Type Description Examples Notes class enum catch Class:Reason:Stacktrace error reason term catch Class:Reason:Stacktrace http_timeout stacktrace term catch Class:Reason:Stacktrace [...] Formatted by formatter","title":"When logging exceptions"},{"location":"operation-and-maintenance/Logging-fields/#macros-for-logging-unexpected-requests","text":"gen_server processes sometimes receive messages they couldn't process. We use macros to log such events (just because you would need them in each gen_server module). We don't need to log state or state names for such events. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 %% We don't always handle unexpected calls. handle_call ( Request , From , State ) -> ? UNEXPECTED_CALL ( Request , From ), { reply , { error , unexpected_call }, State }. %% We don't always handle unexpected casts. handle_cast ( Msg , State ) -> ? UNEXPECTED_CAST ( Msg ), { noreply , State }. %% We SHOULD ignore all unexpected messages, because they could arrive in case %% of gen_server call timeouts. handle_info ( Msg , State ) -> ? UNEXPECTED_INFO ( Msg ), { noreply , State }. These macros translate into warning logs with the following keys, respectively: 1 2 3 #{ what => unexpected_cast , msg => Msg }. #{ what => unexpected_info , msg => Msg }. #{ what => unexpected_call , msg => Msg , call_from => From }.","title":"Macros for logging unexpected requests"},{"location":"operation-and-maintenance/Logging/","text":"Configuring logging The main configuration for logging is in the Application Config file. You can find it in mongooseim/etc/app.config in the release directory. Primary log level Primary log level sets maximum log level in the system. This check is applied for any event in the system before the event is passed to any handler. Primary log level, that is used before MongooseIM config is loaded: 1 2 3 4 5 [ { kernel , [ { logger_level , notice } ]} ]. Once MongooseIM config is loaded, the loglevel option from mongooseim.toml is used instead. Primary filters Functions from the filters section are applied for any message once it passes the primary log level check. Keep that configuration block as it is, unless you are planning to extend the filtering logic. 1 2 3 4 5 6 7 8 9 10 11 12 13 [{ kernel , [ { logger , [ %% Default filters applied to all events before passing them to handlers: { filters , log , [ %% If we want to see complete accumulator in logs % {preserve_acc_filter, {fun mongoose_log_filter:preserve_acc_filter/2, no_state}}, { format_packet_filter , { fun mongoose_log_filter : format_packet_filter / 2 , no_state }}, { format_acc_filter , { fun mongoose_log_filter : format_acc_filter / 2 , no_state }}, { format_c2s_state_filter , { fun mongoose_log_filter : format_c2s_state_filter / 2 , no_state }}, { format_stacktrace_filter , { fun mongoose_log_filter : format_stacktrace_filter / 2 , no_state }} ]}, .... }}]. preserve_acc_filter filter is disabled by default, but could be enabled, if you are interested in debugging the accumulator logic (see the mongoose_acc module). Shell log handler Controls what MongooseIM prints to the standard output. Erlang OTP docs for logger_std_h 1 2 3 4 5 6 7 8 9 { handler , shell_log , logger_std_h , #{ %% Default log level for handlers is to log everything, that %% passes primary log level and module log levels level => all , formatter => { mongoose_flatlog_formatter , #{ map_depth => 3 , term_depth => 50 }} }}, File log handler Controls what and how MongooseIM prints into files. Erlang OTP docs for logger_disk_log_h You can have several file handlers. File handlers should have different handler IDs (i.e. disk_log , disk_json_log ) There are two file log handlers defined by default: one that formats in JSON and one that formats in Logfmt format ( key=value pairs). Both JSON and Logfmt handlers are enabled by default . We recommend to disable handlers, that you are not using. This could improve performance greatly. To disable them, just remove them from app.config . Check information below about log formatters. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 { handler , disk_log , logger_disk_log_h , #{ level => all , config => #{ file => \"{{mongooseim_log_dir}}/mongooseim.log\" , type => wrap , max_no_files => 5 , max_no_bytes => 2097152 , sync_mode_qlen => 2000 , % If sync_mode_qlen is set to the same value as drop_mode_qlen, drop_mode_qlen => 2000 , % synchronous mode is disabled. That is, the handler always runs flush_qlen => 5000 , % in asynchronous mode, unless dropping or flushing is invoked. overload_kill_enable => true % Documentation about Overload protection, together with default values, can be found here: % http://erlang.org/doc/apps/kernel/logger_chapter.html#protecting-the-handler-from-overload }, formatter => ... }}, Logfmt file log handler Wrapper around the flatlog library with custom template options configured by default. Options: map_depth - the maximum depth to format maps. map_depth => 3 means that the map #{one => #{two => #{three => #{four => key}}}} would be printed as one_two_three_four=... . While the map #{one => #{two => #{three => key}}} would be still printed as one_two_three=key . term_depth - the maximum depth to which terms are printed. Anything below this depth is replaced with ... . unlimited by default. 1 2 3 4 formatter => { mongoose_flatlog_formatter , #{ map_depth => 3 , term_depth => 50 }} JSON file log handler JSON formatted file. It could be used to store messages in ELK, in Humio or in Splunk. Check this tutorial to configure MongooseIM with Humio. Check below information to configure MongooseIM with ELK. You can use Filebeat to send messages from the file into ELK. Options: format_depth - the maximum depth to which terms are printed. Anything below this depth is replaced with ... . unlimited by default. format_chars_limit - A soft limit on the number of characters when printing terms. When the number of characters is reached, remaining structures are replaced by \"...\". format_chars_limit defaults to unlimited , which means no limit on the number of characters returned. depth - the maximum depth for json properties. Default is unlimited . Options deeper than the depth are replaced with the ... string. 1 2 3 4 5 formatter => { mongoose_json_formatter , #{ format_depth => 10 , format_chars_limit => 3000 , depth => 10 }} Different log level for a specific module Motivation: Sometimes we are interested in debug messages from a particular module. Useful to debug new or experimental modules. This example: Changes log level for one particular module. Forwards the log messages to any enabled handler. Changes: Enable module log level for ejabberd_c2s . 1 2 %% Module log level { module_level , debug , [ ejabberd_c2s ]}, Separate log for module debugging Motivation: Sometimes we are only interested in log messages from one particular module. Useful for debugging and development. Does not affect overload protection in other handlers. This example: Forwards all logging from a module ejabberd_c2s to a separate file. Keeps the other handlers intact. Changes: Modify any existing handler to explicitly set log level. Enable module log level for ejabberd_c2s . Add a new custom handler into kernel.logger options. Issues: This would also disable module log level logic for other handlers. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 %% Existing handlers { handler , shell_log , logger_std_h , #{ level => notice , %% was level => all ... }, { handler , disk_log , logger_disk_log_h , #{ level => notice , ... }, ... %% Module log level { module_level , debug , [ ejabberd_c2s ]}, %% New handler { handler , disk_log_c2s , logger_disk_log_h , #{ level => debug , config => #{ %% Choose destination: file => \"{{mongooseim_log_dir}}/ejabberd_c2s.log\" , %% Common options: type => wrap , max_no_files => 5 , max_no_bytes => 2097152 , sync_mode_qlen => 2000 , drop_mode_qlen => 2000 , flush_qlen => 5000 , overload_kill_enable => true }, formatter => { mongoose_flatlog_formatter , #{ map_depth => 3 , term_depth => 50 }}, filters => [ %% That filter matches messages from ejabberd_c2s module { module_filter , { fun mongoose_log_filter : filter_module / 2 , [ ejabberd_c2s ]}} ] }} Setting up Kibana This example sets up ElasticSearch and Kibana for development purposes. Create a network, so filebeat can find ELK: 1 docker network create logging Run ELK (consult with the container docs for more options): 1 docker run -d -p 5601 :5601 -p 9200 :9200 -p 5044 :5044 --network logging --name elk sebp/elk:oss-792 Create a volume for logs: 1 docker volume create mongooseim-logs Run MongooseIM daemon: 1 2 docker run -d -t -h mongooseim -v mongooseim-logs:/usr/lib/mongooseim/log \\ --network logging --name mongooseim -p 5222 :5222 mongooseim/mongooseim:latest The next part is based on Filebeat's docs . Setup filebeat (should be called once, that creates indexes in Elasticsearch): 1 2 3 4 docker run --network logging --rm \\ docker.elastic.co/beats/filebeat-oss:7.9.2 \\ setup -E setup.kibana.host = elk:5601 \\ -E output.elasticsearch.hosts = '[\"elk:9200\"]' Create filebeat.mongooseim.yml config file: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 filebeat.inputs : - paths : - /usr/lib/mongooseim/log/mongooseim.json.1 input_type : log json.keys_under_root : true json.add_error_key : true json.overwrite_keys : true processors : # Keep the original \"when\" field too, because of microseconds precision - timestamp : field : when layouts : # Date '2006-01-02T15:04:05.999Z' in mongoose format - '2006-01-02T15:04:05.999+00:00' test : - '2020-09-29T11:25:51.925316+00:00' Create a volume for persistent Filebeat data (so, it would not insert log duplicates, if mongooseim-filebeat container is recreated): 1 docker volume create filebeat-data Actually run the Filebeat daemon: 1 2 3 4 5 6 7 8 docker run -d \\ --network logging \\ --name mongooseim-filebeat \\ -v mongooseim-logs:/usr/lib/mongooseim/log \\ -v filebeat-data:/usr/share/filebeat/data \\ -v = \" $( pwd ) /filebeat.mongooseim.yml:/usr/share/filebeat/filebeat.yml:ro\" \\ docker.elastic.co/beats/filebeat-oss:7.9.2 \\ filebeat -e -E output.elasticsearch.hosts = '[\"elk:9200\"]' In case you want to store and view logs from a dev server in Elasticsearch: 1 2 3 4 5 6 7 docker run -d \\ --network logging \\ --name mongooseim-filebeat \\ -v \" $( pwd ) /_build/mim1/rel/mongooseim/log:/usr/lib/mongooseim/log\" \\ -v = \" $( pwd ) /priv/filebeat.mongooseim.yml:/usr/share/filebeat/filebeat.yml:ro\" \\ docker.elastic.co/beats/filebeat-oss:7.9.2 \\ filebeat -e -E output.elasticsearch.hosts = '[\"elk:9200\"]'","title":"Logging configuration"},{"location":"operation-and-maintenance/Logging/#configuring-logging","text":"The main configuration for logging is in the Application Config file. You can find it in mongooseim/etc/app.config in the release directory.","title":"Configuring logging"},{"location":"operation-and-maintenance/Logging/#primary-log-level","text":"Primary log level sets maximum log level in the system. This check is applied for any event in the system before the event is passed to any handler. Primary log level, that is used before MongooseIM config is loaded: 1 2 3 4 5 [ { kernel , [ { logger_level , notice } ]} ]. Once MongooseIM config is loaded, the loglevel option from mongooseim.toml is used instead.","title":"Primary log level"},{"location":"operation-and-maintenance/Logging/#primary-filters","text":"Functions from the filters section are applied for any message once it passes the primary log level check. Keep that configuration block as it is, unless you are planning to extend the filtering logic. 1 2 3 4 5 6 7 8 9 10 11 12 13 [{ kernel , [ { logger , [ %% Default filters applied to all events before passing them to handlers: { filters , log , [ %% If we want to see complete accumulator in logs % {preserve_acc_filter, {fun mongoose_log_filter:preserve_acc_filter/2, no_state}}, { format_packet_filter , { fun mongoose_log_filter : format_packet_filter / 2 , no_state }}, { format_acc_filter , { fun mongoose_log_filter : format_acc_filter / 2 , no_state }}, { format_c2s_state_filter , { fun mongoose_log_filter : format_c2s_state_filter / 2 , no_state }}, { format_stacktrace_filter , { fun mongoose_log_filter : format_stacktrace_filter / 2 , no_state }} ]}, .... }}]. preserve_acc_filter filter is disabled by default, but could be enabled, if you are interested in debugging the accumulator logic (see the mongoose_acc module).","title":"Primary filters"},{"location":"operation-and-maintenance/Logging/#shell-log-handler","text":"Controls what MongooseIM prints to the standard output. Erlang OTP docs for logger_std_h 1 2 3 4 5 6 7 8 9 { handler , shell_log , logger_std_h , #{ %% Default log level for handlers is to log everything, that %% passes primary log level and module log levels level => all , formatter => { mongoose_flatlog_formatter , #{ map_depth => 3 , term_depth => 50 }} }},","title":"Shell log handler"},{"location":"operation-and-maintenance/Logging/#file-log-handler","text":"Controls what and how MongooseIM prints into files. Erlang OTP docs for logger_disk_log_h You can have several file handlers. File handlers should have different handler IDs (i.e. disk_log , disk_json_log ) There are two file log handlers defined by default: one that formats in JSON and one that formats in Logfmt format ( key=value pairs). Both JSON and Logfmt handlers are enabled by default . We recommend to disable handlers, that you are not using. This could improve performance greatly. To disable them, just remove them from app.config . Check information below about log formatters. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 { handler , disk_log , logger_disk_log_h , #{ level => all , config => #{ file => \"{{mongooseim_log_dir}}/mongooseim.log\" , type => wrap , max_no_files => 5 , max_no_bytes => 2097152 , sync_mode_qlen => 2000 , % If sync_mode_qlen is set to the same value as drop_mode_qlen, drop_mode_qlen => 2000 , % synchronous mode is disabled. That is, the handler always runs flush_qlen => 5000 , % in asynchronous mode, unless dropping or flushing is invoked. overload_kill_enable => true % Documentation about Overload protection, together with default values, can be found here: % http://erlang.org/doc/apps/kernel/logger_chapter.html#protecting-the-handler-from-overload }, formatter => ... }},","title":"File log handler"},{"location":"operation-and-maintenance/Logging/#logfmt-file-log-handler","text":"Wrapper around the flatlog library with custom template options configured by default. Options: map_depth - the maximum depth to format maps. map_depth => 3 means that the map #{one => #{two => #{three => #{four => key}}}} would be printed as one_two_three_four=... . While the map #{one => #{two => #{three => key}}} would be still printed as one_two_three=key . term_depth - the maximum depth to which terms are printed. Anything below this depth is replaced with ... . unlimited by default. 1 2 3 4 formatter => { mongoose_flatlog_formatter , #{ map_depth => 3 , term_depth => 50 }}","title":"Logfmt file log handler"},{"location":"operation-and-maintenance/Logging/#json-file-log-handler","text":"JSON formatted file. It could be used to store messages in ELK, in Humio or in Splunk. Check this tutorial to configure MongooseIM with Humio. Check below information to configure MongooseIM with ELK. You can use Filebeat to send messages from the file into ELK. Options: format_depth - the maximum depth to which terms are printed. Anything below this depth is replaced with ... . unlimited by default. format_chars_limit - A soft limit on the number of characters when printing terms. When the number of characters is reached, remaining structures are replaced by \"...\". format_chars_limit defaults to unlimited , which means no limit on the number of characters returned. depth - the maximum depth for json properties. Default is unlimited . Options deeper than the depth are replaced with the ... string. 1 2 3 4 5 formatter => { mongoose_json_formatter , #{ format_depth => 10 , format_chars_limit => 3000 , depth => 10 }}","title":"JSON file log handler"},{"location":"operation-and-maintenance/Logging/#different-log-level-for-a-specific-module","text":"Motivation: Sometimes we are interested in debug messages from a particular module. Useful to debug new or experimental modules. This example: Changes log level for one particular module. Forwards the log messages to any enabled handler. Changes: Enable module log level for ejabberd_c2s . 1 2 %% Module log level { module_level , debug , [ ejabberd_c2s ]},","title":"Different log level for a specific module"},{"location":"operation-and-maintenance/Logging/#separate-log-for-module-debugging","text":"Motivation: Sometimes we are only interested in log messages from one particular module. Useful for debugging and development. Does not affect overload protection in other handlers. This example: Forwards all logging from a module ejabberd_c2s to a separate file. Keeps the other handlers intact. Changes: Modify any existing handler to explicitly set log level. Enable module log level for ejabberd_c2s . Add a new custom handler into kernel.logger options. Issues: This would also disable module log level logic for other handlers. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 %% Existing handlers { handler , shell_log , logger_std_h , #{ level => notice , %% was level => all ... }, { handler , disk_log , logger_disk_log_h , #{ level => notice , ... }, ... %% Module log level { module_level , debug , [ ejabberd_c2s ]}, %% New handler { handler , disk_log_c2s , logger_disk_log_h , #{ level => debug , config => #{ %% Choose destination: file => \"{{mongooseim_log_dir}}/ejabberd_c2s.log\" , %% Common options: type => wrap , max_no_files => 5 , max_no_bytes => 2097152 , sync_mode_qlen => 2000 , drop_mode_qlen => 2000 , flush_qlen => 5000 , overload_kill_enable => true }, formatter => { mongoose_flatlog_formatter , #{ map_depth => 3 , term_depth => 50 }}, filters => [ %% That filter matches messages from ejabberd_c2s module { module_filter , { fun mongoose_log_filter : filter_module / 2 , [ ejabberd_c2s ]}} ] }}","title":"Separate log for module debugging"},{"location":"operation-and-maintenance/Logging/#setting-up-kibana","text":"This example sets up ElasticSearch and Kibana for development purposes. Create a network, so filebeat can find ELK: 1 docker network create logging Run ELK (consult with the container docs for more options): 1 docker run -d -p 5601 :5601 -p 9200 :9200 -p 5044 :5044 --network logging --name elk sebp/elk:oss-792 Create a volume for logs: 1 docker volume create mongooseim-logs Run MongooseIM daemon: 1 2 docker run -d -t -h mongooseim -v mongooseim-logs:/usr/lib/mongooseim/log \\ --network logging --name mongooseim -p 5222 :5222 mongooseim/mongooseim:latest The next part is based on Filebeat's docs . Setup filebeat (should be called once, that creates indexes in Elasticsearch): 1 2 3 4 docker run --network logging --rm \\ docker.elastic.co/beats/filebeat-oss:7.9.2 \\ setup -E setup.kibana.host = elk:5601 \\ -E output.elasticsearch.hosts = '[\"elk:9200\"]' Create filebeat.mongooseim.yml config file: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 filebeat.inputs : - paths : - /usr/lib/mongooseim/log/mongooseim.json.1 input_type : log json.keys_under_root : true json.add_error_key : true json.overwrite_keys : true processors : # Keep the original \"when\" field too, because of microseconds precision - timestamp : field : when layouts : # Date '2006-01-02T15:04:05.999Z' in mongoose format - '2006-01-02T15:04:05.999+00:00' test : - '2020-09-29T11:25:51.925316+00:00' Create a volume for persistent Filebeat data (so, it would not insert log duplicates, if mongooseim-filebeat container is recreated): 1 docker volume create filebeat-data Actually run the Filebeat daemon: 1 2 3 4 5 6 7 8 docker run -d \\ --network logging \\ --name mongooseim-filebeat \\ -v mongooseim-logs:/usr/lib/mongooseim/log \\ -v filebeat-data:/usr/share/filebeat/data \\ -v = \" $( pwd ) /filebeat.mongooseim.yml:/usr/share/filebeat/filebeat.yml:ro\" \\ docker.elastic.co/beats/filebeat-oss:7.9.2 \\ filebeat -e -E output.elasticsearch.hosts = '[\"elk:9200\"]' In case you want to store and view logs from a dev server in Elasticsearch: 1 2 3 4 5 6 7 docker run -d \\ --network logging \\ --name mongooseim-filebeat \\ -v \" $( pwd ) /_build/mim1/rel/mongooseim/log:/usr/lib/mongooseim/log\" \\ -v = \" $( pwd ) /priv/filebeat.mongooseim.yml:/usr/share/filebeat/filebeat.yml:ro\" \\ docker.elastic.co/beats/filebeat-oss:7.9.2 \\ filebeat -e -E output.elasticsearch.hosts = '[\"elk:9200\"]'","title":"Setting up Kibana"},{"location":"operation-and-maintenance/MongooseIM-metrics/","text":"MongooseIM metrics MongooseIM by default collects many metrics showing the user behaviour and general system statistics. They are managed by exometer . MongooseIM uses ESL's fork of this project . All metrics are divided into the following groups: Per host type metrics: Gathered separately for every host type supported by the cluster. Warning: If a cluster supports many (thousands or more) host types, performance issues might occur. To avoid this, use global equivalents of the metrics with all_metrics_are_global config option. Hook metrics. They are created for every hook and incremented on every call to it. Global metrics: Metrics common for all host types. Data metrics. These are misc. metrics related to data transfers (e.g. sent and received stanza size statistics). VM metrics. Basic Erlang VM statistics. Backend metrics: Histograms with timings of calls to various backends. Metrics types spiral This kind of metric provides 2 values: total event count (e.g. stanzas processed) and a value in 60s window ( one value). Dividing one value by 60 provides an average per-second value over last minute. Example: [{total, 1000}, {one, 20}] value A simple value. It is actually a one-element proplist: [{value, N}] . Example: [{value, 256}] gauge It is similar to a value type but consists of two properties: value ms_since_reset - Time in milliseconds elapsed from the last metric update. Example: [{value, 12}, {ms_since_reset, 91761}] proplist A metric which is a nonstandard proplist. You can find the lists of keys in metrics descriptions. Example: [{total,295941736}, {processes_used,263766824}, {atom_used,640435}, {binary,1513152}, {ets,3942592}, {system,32182072}] histogram A histogram collects values over a sliding window of 60s and exposes the following stats: n - A number of samples. mean - An arithmetic mean. min max median 50 , 75 , 90 , 95 , 99 , 999 - 50th, 75th, 90th, 95th, 99th and 99.9th percentile Per host type metrics Hook metrics There are more hook metrics than what is listed in this table, because they are automatically created for every new hook. As a result it makes more sense to maintain a list of the most relevant or useful items, rather than keeping this table fully in sync with the code. Name Type Description (when it gets incremented) [HostType, anonymous_purge_hook] spiral An anonymous user disconnects. [HostType, c2s_unauthenticated_iq] spiral An IQ sent from a user to a server without authentication. [HostType, disco_info] spiral An information about the server has been requested via Disco protocol. [HostType, disco_local_features] spiral A list of server features is gathered. [HostType, disco_local_identity] spiral A list of server identities is gathered. [HostType, disco_local_items] spiral A list of server's items (e.g. services) is gathered. [HostType, disco_sm_features] spiral A list of user's features is gathered. [HostType, disco_sm_identity] spiral A list of user's identities is gathered. [HostType, disco_sm_items] spiral A list of user's items is gathered. [HostType, mam_lookup_messages] spiral An archive lookup is performed. [HostType, offline_message_hook] spiral A message was sent to an offline user. (Except for \"error\", \"headline\" and \"groupchat\" message types.) [HostType, offline_groupchat_message_hook] spiral A groupchat message was sent to an offline user. [HostType, privacy_updated_list] spiral User's privacy list is updated. [HostType, resend_offline_messages_hook] spiral A list of offline messages is gathered for delivery to a user's new connection. [HostType, roster_get_subscription_lists] spiral Presence subscription lists (based on which presence updates are broadcasted) are gathered. [HostType, roster_in_subscription] spiral A presence with subscription update is processed. [HostType, roster_out_subscription] spiral A presence with subscription update is received from a client. [HostType, sm_broadcast] spiral A stanza is broadcasted to all of user's resources. [HostType, unset_presence_hook] spiral A user disconnects or sends an unavailable presence. Presences & rosters Name Type Description (when it gets incremented) [HostType, modPresenceSubscriptions] spiral Presence subscription is processed. [HostType, modPresenceUnsubscriptions] spiral Presence unsubscription is processed. [HostType, modRosterGets] spiral User's roster is fetched. [HostType, modRosterPush] spiral A roster update is pushed to a single session. [HostType, modRosterSets] spiral User's roster is updated. Privacy lists Name Type Description (when it gets incremented) [HostType, modPrivacyGets] spiral IQ privacy get is processed. [HostType, modPrivacyPush] spiral Privacy list update is sent to a single session. [HostType, modPrivacySets] spiral IQ privacy set is processed. [HostType, modPrivacySetsActive] spiral Active privacy list is changed. [HostType, modPrivacySetsDefault] spiral Default privacy list is changed. [HostType, modPrivacyStanzaAll] spiral A packet is checked against the privacy list. [HostType, modPrivacyStanzaDenied] spiral Privacy list check resulted in deny . [HostType, modPrivacyStanzaBlocked] spiral Privacy list check resulted in block . Other Name Type Description (when it gets incremented) [HostType, sessionAuthFails] spiral A client failed to authenticate. [HostType, sessionCount] counter Number of active sessions. [HostType, sessionLogouts] spiral A client session is closed. [HostType, sessionSuccessfulLogins] spiral A client session is opened. [HostType, xmppErrorIq] spiral An error IQ is sent to a client. [HostType, xmppErrorMessage] spiral An error message is sent to a client. [HostType, xmppErrorPresence] spiral An error presence is sent to a client. [HostType, xmppErrorTotal] spiral A stanza with error type is routed. [HostType, xmppMessageBounced] spiral A service-unavailable error is sent, because the message recipient if offline. [HostType, xmppIqSent] spiral An IQ is sent by a client. [HostType, xmppMessageSent] spiral A message is sent by a client [HostType, xmppPresenceSent] spiral A presence is sent by a client. [HostType, xmppStanzaSent] spiral A stanza is sent by a client. [HostType, xmppIqReceived] spiral An IQ is sent to a client. [HostType, xmppMessageReceived] spiral A message is sent to a client. [HostType, xmppPresenceReceived] spiral A presence is sent to a client. [HostType, xmppStanzaReceived] spiral A stanza is sent to a client. [HostType, xmppStanzaCount] spiral A stanza is sent to a client. [HostType, xmppStanzaDropped] spiral A stanza is dropped due to an AMP rule or a filter_packet processing flow. Extension-specific metrics Metrics specific to an extension, e.g. Message Archive Management, are described in respective module documentation pages. Global metrics Name Type Description (when it gets incremented) [global, routingErrors] spiral It is not possible to route a stanza (all routing handlers failed). [global, nodeSessionCount] value A number of sessions connected to a given MongooseIM node. [global, totalSessionCount] value A number of sessions connected to a MongooseIM cluster. [global, uniqueSessionCount] value A number of unique users connected to a MongooseIM cluster (e.g. 3 sessions of the same user will be counted as 1 in this metric). [global, cache, unique_sessions_number] gauge A cached value of uniqueSessionCount . It is automatically updated when a unique session count is calculated. [global, nodeUpTime] value Node uptime. [global, clusterSize] value A number of nodes in a MongooseIM cluster seen by a given MongooseIM node. [global, tcpPortsUsed] value A number of open tcp connections. This should relate to the number of connected sessions and databases, as well as federations and http requests, in order to detect connection leaks. [global, processQueueLengths] probe The number of queued messages in the internal message queue of every erlang process, and the internal queue of every fsm (ejabberd_c2s). This is sampled every 30 seconds asynchronously. It is a good indicator of an overloaded system: if too many messages are queued at the same time, the system is not able to process the data at the rate it was designed for. Data metrics Metric name Type Description [global, data, xmpp, received, xml_stanza_size] histogram A size (in bytes) of a received stanza after decompression and decryption. [global, data, xmpp, sent, xml_stanza_size] histogram A size (in bytes) of a stanza sent to a client socket. [global, data, xmpp, received, compressed_size] histogram A size (in bytes) of a received stanza before decompression. [global, data, xmpp, sent, compressed_size] histogram A size (in bytes) of a stanza after compression. [global, data, xmpp, received, encrypted_size] histogram A size (in bytes) of a received stanza before decryption. [global, data, xmpp, sent, encrypted_size] histogram A size (in bytes) of a stanza after encryption. [global, data, dist] proplist Network stats for an Erlang distributed communication. A proplist with values: recv_oct , recv_cnt , recv_max , send_oct , send_max , send_cnt , send_pend , connections [global, data, rdbms, PoolName] proplist For every RDBMS pool defined, an instance of this metric is available. It is a proplist with values workers , recv_oct , recv_cnt , recv_max , send_oct , send_max , send_cnt , send_pend . VM metrics Metric name Type Description [global, erlang, memory] proplist A proplist with total , processes_used , atom_used , binary , ets and system memory stats. [global, erlang, system_info] proplist A proplist with port_count , port_limit , process_count , process_limit , ets_limit stats. Backend metrics Some extension modules expose histograms with timings of calls made to their backends. Please check the documentation of modules that are enabled in your config file, in order to learn if they provide them. All module backend metrics names use the following convention: [global, backends, Module, BackendAction] and [global, backends, Module, BackendAction, count] . The former is a histogram of operation times. However, the time is not recorded if a backend operation exits with an exception. The latter is a number of calls (spiral metric), incremented for every call (even a failed one). Besides these, following authentication metrics are always available: [HostType, backends, auth, authorize] [HostType, backends, auth, check_password] [HostType, backends, auth, try_register] [HostType, backends, auth, does_user_exist] These are total times of respective operations. One operation usually requires only a single call to an auth backend but sometimes with e.g. 3 backends configured, the operation may fail for first 2 backends. In such case, these metrics will be updated with combined time of 2 failed and 1 successful request. Additionally, the RDBMS layer in MongooseIM exposes two more metrics, if RDBMS is configured: [global, backends, mongoose_rdbms, query] - Execution time of a \"simple\" (not prepared) query by a DB driver. [global, backends, mongoose_rdbms, execute] - Execution time of a prepared query by a DB driver.","title":"Metrics"},{"location":"operation-and-maintenance/MongooseIM-metrics/#mongooseim-metrics","text":"MongooseIM by default collects many metrics showing the user behaviour and general system statistics. They are managed by exometer . MongooseIM uses ESL's fork of this project . All metrics are divided into the following groups: Per host type metrics: Gathered separately for every host type supported by the cluster. Warning: If a cluster supports many (thousands or more) host types, performance issues might occur. To avoid this, use global equivalents of the metrics with all_metrics_are_global config option. Hook metrics. They are created for every hook and incremented on every call to it. Global metrics: Metrics common for all host types. Data metrics. These are misc. metrics related to data transfers (e.g. sent and received stanza size statistics). VM metrics. Basic Erlang VM statistics. Backend metrics: Histograms with timings of calls to various backends.","title":"MongooseIM metrics"},{"location":"operation-and-maintenance/MongooseIM-metrics/#metrics-types","text":"","title":"Metrics types"},{"location":"operation-and-maintenance/MongooseIM-metrics/#spiral","text":"This kind of metric provides 2 values: total event count (e.g. stanzas processed) and a value in 60s window ( one value). Dividing one value by 60 provides an average per-second value over last minute. Example: [{total, 1000}, {one, 20}]","title":"spiral"},{"location":"operation-and-maintenance/MongooseIM-metrics/#value","text":"A simple value. It is actually a one-element proplist: [{value, N}] . Example: [{value, 256}]","title":"value"},{"location":"operation-and-maintenance/MongooseIM-metrics/#gauge","text":"It is similar to a value type but consists of two properties: value ms_since_reset - Time in milliseconds elapsed from the last metric update. Example: [{value, 12}, {ms_since_reset, 91761}]","title":"gauge"},{"location":"operation-and-maintenance/MongooseIM-metrics/#proplist","text":"A metric which is a nonstandard proplist. You can find the lists of keys in metrics descriptions. Example: [{total,295941736}, {processes_used,263766824}, {atom_used,640435}, {binary,1513152}, {ets,3942592}, {system,32182072}]","title":"proplist"},{"location":"operation-and-maintenance/MongooseIM-metrics/#histogram","text":"A histogram collects values over a sliding window of 60s and exposes the following stats: n - A number of samples. mean - An arithmetic mean. min max median 50 , 75 , 90 , 95 , 99 , 999 - 50th, 75th, 90th, 95th, 99th and 99.9th percentile","title":"histogram"},{"location":"operation-and-maintenance/MongooseIM-metrics/#per-host-type-metrics","text":"","title":"Per host type metrics"},{"location":"operation-and-maintenance/MongooseIM-metrics/#hook-metrics","text":"There are more hook metrics than what is listed in this table, because they are automatically created for every new hook. As a result it makes more sense to maintain a list of the most relevant or useful items, rather than keeping this table fully in sync with the code. Name Type Description (when it gets incremented) [HostType, anonymous_purge_hook] spiral An anonymous user disconnects. [HostType, c2s_unauthenticated_iq] spiral An IQ sent from a user to a server without authentication. [HostType, disco_info] spiral An information about the server has been requested via Disco protocol. [HostType, disco_local_features] spiral A list of server features is gathered. [HostType, disco_local_identity] spiral A list of server identities is gathered. [HostType, disco_local_items] spiral A list of server's items (e.g. services) is gathered. [HostType, disco_sm_features] spiral A list of user's features is gathered. [HostType, disco_sm_identity] spiral A list of user's identities is gathered. [HostType, disco_sm_items] spiral A list of user's items is gathered. [HostType, mam_lookup_messages] spiral An archive lookup is performed. [HostType, offline_message_hook] spiral A message was sent to an offline user. (Except for \"error\", \"headline\" and \"groupchat\" message types.) [HostType, offline_groupchat_message_hook] spiral A groupchat message was sent to an offline user. [HostType, privacy_updated_list] spiral User's privacy list is updated. [HostType, resend_offline_messages_hook] spiral A list of offline messages is gathered for delivery to a user's new connection. [HostType, roster_get_subscription_lists] spiral Presence subscription lists (based on which presence updates are broadcasted) are gathered. [HostType, roster_in_subscription] spiral A presence with subscription update is processed. [HostType, roster_out_subscription] spiral A presence with subscription update is received from a client. [HostType, sm_broadcast] spiral A stanza is broadcasted to all of user's resources. [HostType, unset_presence_hook] spiral A user disconnects or sends an unavailable presence.","title":"Hook metrics"},{"location":"operation-and-maintenance/MongooseIM-metrics/#presences-rosters","text":"Name Type Description (when it gets incremented) [HostType, modPresenceSubscriptions] spiral Presence subscription is processed. [HostType, modPresenceUnsubscriptions] spiral Presence unsubscription is processed. [HostType, modRosterGets] spiral User's roster is fetched. [HostType, modRosterPush] spiral A roster update is pushed to a single session. [HostType, modRosterSets] spiral User's roster is updated.","title":"Presences &amp; rosters"},{"location":"operation-and-maintenance/MongooseIM-metrics/#privacy-lists","text":"Name Type Description (when it gets incremented) [HostType, modPrivacyGets] spiral IQ privacy get is processed. [HostType, modPrivacyPush] spiral Privacy list update is sent to a single session. [HostType, modPrivacySets] spiral IQ privacy set is processed. [HostType, modPrivacySetsActive] spiral Active privacy list is changed. [HostType, modPrivacySetsDefault] spiral Default privacy list is changed. [HostType, modPrivacyStanzaAll] spiral A packet is checked against the privacy list. [HostType, modPrivacyStanzaDenied] spiral Privacy list check resulted in deny . [HostType, modPrivacyStanzaBlocked] spiral Privacy list check resulted in block .","title":"Privacy lists"},{"location":"operation-and-maintenance/MongooseIM-metrics/#other","text":"Name Type Description (when it gets incremented) [HostType, sessionAuthFails] spiral A client failed to authenticate. [HostType, sessionCount] counter Number of active sessions. [HostType, sessionLogouts] spiral A client session is closed. [HostType, sessionSuccessfulLogins] spiral A client session is opened. [HostType, xmppErrorIq] spiral An error IQ is sent to a client. [HostType, xmppErrorMessage] spiral An error message is sent to a client. [HostType, xmppErrorPresence] spiral An error presence is sent to a client. [HostType, xmppErrorTotal] spiral A stanza with error type is routed. [HostType, xmppMessageBounced] spiral A service-unavailable error is sent, because the message recipient if offline. [HostType, xmppIqSent] spiral An IQ is sent by a client. [HostType, xmppMessageSent] spiral A message is sent by a client [HostType, xmppPresenceSent] spiral A presence is sent by a client. [HostType, xmppStanzaSent] spiral A stanza is sent by a client. [HostType, xmppIqReceived] spiral An IQ is sent to a client. [HostType, xmppMessageReceived] spiral A message is sent to a client. [HostType, xmppPresenceReceived] spiral A presence is sent to a client. [HostType, xmppStanzaReceived] spiral A stanza is sent to a client. [HostType, xmppStanzaCount] spiral A stanza is sent to a client. [HostType, xmppStanzaDropped] spiral A stanza is dropped due to an AMP rule or a filter_packet processing flow.","title":"Other"},{"location":"operation-and-maintenance/MongooseIM-metrics/#extension-specific-metrics","text":"Metrics specific to an extension, e.g. Message Archive Management, are described in respective module documentation pages.","title":"Extension-specific metrics"},{"location":"operation-and-maintenance/MongooseIM-metrics/#global-metrics","text":"Name Type Description (when it gets incremented) [global, routingErrors] spiral It is not possible to route a stanza (all routing handlers failed). [global, nodeSessionCount] value A number of sessions connected to a given MongooseIM node. [global, totalSessionCount] value A number of sessions connected to a MongooseIM cluster. [global, uniqueSessionCount] value A number of unique users connected to a MongooseIM cluster (e.g. 3 sessions of the same user will be counted as 1 in this metric). [global, cache, unique_sessions_number] gauge A cached value of uniqueSessionCount . It is automatically updated when a unique session count is calculated. [global, nodeUpTime] value Node uptime. [global, clusterSize] value A number of nodes in a MongooseIM cluster seen by a given MongooseIM node. [global, tcpPortsUsed] value A number of open tcp connections. This should relate to the number of connected sessions and databases, as well as federations and http requests, in order to detect connection leaks. [global, processQueueLengths] probe The number of queued messages in the internal message queue of every erlang process, and the internal queue of every fsm (ejabberd_c2s). This is sampled every 30 seconds asynchronously. It is a good indicator of an overloaded system: if too many messages are queued at the same time, the system is not able to process the data at the rate it was designed for.","title":"Global metrics"},{"location":"operation-and-maintenance/MongooseIM-metrics/#data-metrics","text":"Metric name Type Description [global, data, xmpp, received, xml_stanza_size] histogram A size (in bytes) of a received stanza after decompression and decryption. [global, data, xmpp, sent, xml_stanza_size] histogram A size (in bytes) of a stanza sent to a client socket. [global, data, xmpp, received, compressed_size] histogram A size (in bytes) of a received stanza before decompression. [global, data, xmpp, sent, compressed_size] histogram A size (in bytes) of a stanza after compression. [global, data, xmpp, received, encrypted_size] histogram A size (in bytes) of a received stanza before decryption. [global, data, xmpp, sent, encrypted_size] histogram A size (in bytes) of a stanza after encryption. [global, data, dist] proplist Network stats for an Erlang distributed communication. A proplist with values: recv_oct , recv_cnt , recv_max , send_oct , send_max , send_cnt , send_pend , connections [global, data, rdbms, PoolName] proplist For every RDBMS pool defined, an instance of this metric is available. It is a proplist with values workers , recv_oct , recv_cnt , recv_max , send_oct , send_max , send_cnt , send_pend .","title":"Data metrics"},{"location":"operation-and-maintenance/MongooseIM-metrics/#vm-metrics","text":"Metric name Type Description [global, erlang, memory] proplist A proplist with total , processes_used , atom_used , binary , ets and system memory stats. [global, erlang, system_info] proplist A proplist with port_count , port_limit , process_count , process_limit , ets_limit stats.","title":"VM metrics"},{"location":"operation-and-maintenance/MongooseIM-metrics/#backend-metrics","text":"Some extension modules expose histograms with timings of calls made to their backends. Please check the documentation of modules that are enabled in your config file, in order to learn if they provide them. All module backend metrics names use the following convention: [global, backends, Module, BackendAction] and [global, backends, Module, BackendAction, count] . The former is a histogram of operation times. However, the time is not recorded if a backend operation exits with an exception. The latter is a number of calls (spiral metric), incremented for every call (even a failed one). Besides these, following authentication metrics are always available: [HostType, backends, auth, authorize] [HostType, backends, auth, check_password] [HostType, backends, auth, try_register] [HostType, backends, auth, does_user_exist] These are total times of respective operations. One operation usually requires only a single call to an auth backend but sometimes with e.g. 3 backends configured, the operation may fail for first 2 backends. In such case, these metrics will be updated with combined time of 2 failed and 1 successful request. Additionally, the RDBMS layer in MongooseIM exposes two more metrics, if RDBMS is configured: [global, backends, mongoose_rdbms, query] - Execution time of a \"simple\" (not prepared) query by a DB driver. [global, backends, mongoose_rdbms, execute] - Execution time of a prepared query by a DB driver.","title":"Backend metrics"},{"location":"operation-and-maintenance/Rolling-upgrade/","text":"Rolling upgrade For all MongooseIM production deployments we recommend running multiple server nodes connected in a cluster behind a load-balancer. Rolling upgrade is a process of upgrading MongooseIM cluster, one node at a time. Make sure you have at least the number of nodes able to handle your traffic plus one before the rolling upgrade to guarantee the availability and minimise the downtime. Running different MongooseIM versions at the same time beyond the duration of the upgrade is not recommended and not supported. Rolling upgrade procedure is recommended over configuration reload which is not supported since version 4.1. Please note that more complex upgrades that involve schema updates, customisations or have functional changes might require more specific and specially crafted migration procedure. If you want just to make the changes to the configuration file, please follow steps 1, 3, 4, 6, 7, 8. This type of change can also be done one node at a time. It would require you to check the cluster status, modify the configuration file and restart the node. The usual MongooseIM cluster upgrade can be achieved with the following steps: 1. Check the cluster status. Use the following command on the running nodes and examine the status of the cluster: 1 2 3 mongooseimctl mnesia info | grep \"running db nodes\" running db nodes = [ mongooseim@node1, mongooseim@node2 ] This command shows all running nodes. A healthy cluster should list all nodes that are part of the cluster. Should you have any issues related to node clustering, please refer to Cluster configuration and node management section. 2. Copy the configuration file. Make a copy of the configuration file before the upgrade, as some package managers might override your custom configuration with the default one. Please note that since version 4.1 *.cfg MongooseIM configuration format is no longer supported and needs to be rewritten in the new *.toml format. 3. Apply the changes from the migration guide. All modifications of the configuration file or updates of the database schema, that are required to perform version upgrade, can be found in the Migration Guide section. When upgrading more than one version, please make sure to go over all consecutive migration guides. For example, when migrating from MongooseIM 3.7 to 4.1, please familiarize yourself with and apply all necessary changes described in the following pages of the Migration Guide section. 3.7.0 to 4.0.0 4.0.0 to 4.0.1 4.0.1 to 4.1.0 4. Stop the running node. Use the following command to stop the MognooseIM node: 1 mongooseimctl stop 5. Install new MongooseIM version. You can get the new version of MongooseIM by either building MongooseIM from source code or downloading and upgrading from package . 6. Start the node. Use the following command to start and check the status of the MognooseIM node and the cluster: 1 2 3 4 mongooseimctl start mongooseimctl status mongooseimctl mnesia info | grep \"running db nodes\" 7. Test the cluster. Please verify that the nodes are running and part of the same cluster. If the cluster is working as expected, the migration of the node is complete. 8. Upgrade the remaining nodes. Once all the prior steps are completed successfully, repeat the process for all nodes that are part of the MongooseIM cluster. Further cluster upgrade considerations Another way to perform a cluster upgrade with minimising possible downtime would be to setup a parallel MongooseIM cluster running newer version. You can redirect the incoming traffic to the new cluster with use of a load-balancer. Once no connections are handled by the old cluster, it can by safely stopped and the migration is complete. We highly recommend testing new software release in staging environment before it is deployed on production. Should you need any help with the upgrade, deployments or load testing of your MongooseIM cluster, please reach out to us. MongooseIM consultancy and support is part of our commercial offering .","title":"Rolling upgrade"},{"location":"operation-and-maintenance/Rolling-upgrade/#rolling-upgrade","text":"For all MongooseIM production deployments we recommend running multiple server nodes connected in a cluster behind a load-balancer. Rolling upgrade is a process of upgrading MongooseIM cluster, one node at a time. Make sure you have at least the number of nodes able to handle your traffic plus one before the rolling upgrade to guarantee the availability and minimise the downtime. Running different MongooseIM versions at the same time beyond the duration of the upgrade is not recommended and not supported. Rolling upgrade procedure is recommended over configuration reload which is not supported since version 4.1. Please note that more complex upgrades that involve schema updates, customisations or have functional changes might require more specific and specially crafted migration procedure. If you want just to make the changes to the configuration file, please follow steps 1, 3, 4, 6, 7, 8. This type of change can also be done one node at a time. It would require you to check the cluster status, modify the configuration file and restart the node. The usual MongooseIM cluster upgrade can be achieved with the following steps:","title":"Rolling upgrade"},{"location":"operation-and-maintenance/Rolling-upgrade/#1-check-the-cluster-status","text":"Use the following command on the running nodes and examine the status of the cluster: 1 2 3 mongooseimctl mnesia info | grep \"running db nodes\" running db nodes = [ mongooseim@node1, mongooseim@node2 ] This command shows all running nodes. A healthy cluster should list all nodes that are part of the cluster. Should you have any issues related to node clustering, please refer to Cluster configuration and node management section.","title":"1. Check the cluster status."},{"location":"operation-and-maintenance/Rolling-upgrade/#2-copy-the-configuration-file","text":"Make a copy of the configuration file before the upgrade, as some package managers might override your custom configuration with the default one. Please note that since version 4.1 *.cfg MongooseIM configuration format is no longer supported and needs to be rewritten in the new *.toml format.","title":"2. Copy the configuration file."},{"location":"operation-and-maintenance/Rolling-upgrade/#3-apply-the-changes-from-the-migration-guide","text":"All modifications of the configuration file or updates of the database schema, that are required to perform version upgrade, can be found in the Migration Guide section. When upgrading more than one version, please make sure to go over all consecutive migration guides. For example, when migrating from MongooseIM 3.7 to 4.1, please familiarize yourself with and apply all necessary changes described in the following pages of the Migration Guide section. 3.7.0 to 4.0.0 4.0.0 to 4.0.1 4.0.1 to 4.1.0","title":"3. Apply the changes from the migration guide."},{"location":"operation-and-maintenance/Rolling-upgrade/#4-stop-the-running-node","text":"Use the following command to stop the MognooseIM node: 1 mongooseimctl stop","title":"4. Stop the running node."},{"location":"operation-and-maintenance/Rolling-upgrade/#5-install-new-mongooseim-version","text":"You can get the new version of MongooseIM by either building MongooseIM from source code or downloading and upgrading from package .","title":"5. Install new MongooseIM version."},{"location":"operation-and-maintenance/Rolling-upgrade/#6-start-the-node","text":"Use the following command to start and check the status of the MognooseIM node and the cluster: 1 2 3 4 mongooseimctl start mongooseimctl status mongooseimctl mnesia info | grep \"running db nodes\"","title":"6. Start the node."},{"location":"operation-and-maintenance/Rolling-upgrade/#7-test-the-cluster","text":"Please verify that the nodes are running and part of the same cluster. If the cluster is working as expected, the migration of the node is complete.","title":"7. Test the cluster."},{"location":"operation-and-maintenance/Rolling-upgrade/#8-upgrade-the-remaining-nodes","text":"Once all the prior steps are completed successfully, repeat the process for all nodes that are part of the MongooseIM cluster.","title":"8. Upgrade the remaining nodes."},{"location":"operation-and-maintenance/Rolling-upgrade/#further-cluster-upgrade-considerations","text":"Another way to perform a cluster upgrade with minimising possible downtime would be to setup a parallel MongooseIM cluster running newer version. You can redirect the incoming traffic to the new cluster with use of a load-balancer. Once no connections are handled by the old cluster, it can by safely stopped and the migration is complete. We highly recommend testing new software release in staging environment before it is deployed on production. Should you need any help with the upgrade, deployments or load testing of your MongooseIM cluster, please reach out to us. MongooseIM consultancy and support is part of our commercial offering .","title":"Further cluster upgrade considerations"},{"location":"operation-and-maintenance/System-Metrics-Privacy-Policy/","text":"Introduction MongooseIM system metrics are gathered to analyse the trends and needs of our users, improve MongooseIM, and let us know where to focus our efforts. This section is devoted to explaining how to customise, read, enable and disable collecting of the system metrics. Consent To ensure transparency, a log message is generated on every MongooseIM node start (unless the metrics service is configured with the report option) to show that the functionality is enabled. The user is being notified that the metrics are gathered and has the right to withdraw the consent at any time without limiting the functionality of the product. For more information on how to disable this feature, please see the Services section. What information is being gathered? When introducing this feature, it is crucial for us to be fully transparent as to what information is being gathered. In general, we capture information on how MongooseIM is being used, its version and the chosen feature set. We only report the names of known modules and APIs that are part of the opensource product. All additional customisations are simply counted without disclosing any specific details. The user can view all the information that is shared in two different ways. The log file system_metrics_report.json contains the most recent report that was sent. Additionally, the user can configure the Tracking ID to use their own Google Analytics account and have a view of their MongooseIM status in that dashboard. For more information on how to set up the Tracking ID, please see How to configure additional and private Tracking ID in Google Analytics . The full list of information that is being gathered can be seen below: MongooseIM node uptime. MongooseIM version. Number of nodes that are part of the MongooseIM cluster. Generic modules that are part of the opensource project and are in use. Some modules report what database they use as a backend, e.g. Sample report . Number of custom modules - without disclosing any details, we are just curious to see if there are any. Number of connected external XMPP components. List of configured REST APIs that are part of the opensource project. XMPP transport mechanisms like, TCP/TLS, WebSockets or BOSH. Geographical Data - Google Analytics is providing several geographical dimensions, such as City, Country, Continent. These values are derived from the IP address the data was sent from. See About Geographical Data for more details. How is the information being used? The information collected is automatically anonymised before it is being processed any further. Each MongooseIM is randomly generating a Client ID that is being attached to the reports. The collected data has only statistical relevance and aims to help us understand the needs of our users. Knowing how our product is used will allow us to identify the core value it brings to the users. It will point out the direction in which to expand it and show us how to target our further efforts developing it. How does a report look like? A sample report showing metrics for the mod_vcard backends from Google Analytics can be found below. Based on such report we can see the frequency of different backends being used with mod_vcard. How often are the metrics reported? Metrics are reported first shortly after the system startup and later at regular intervals. These timers are configurable using the initial_report and periodic_report parameters. The default values are 5 minutes for the initial report and 3 hours for the periodic one. These reporting intervals can be changed depending on the configuration parameters. How to configure this service? This functionality is provided as a \"service\". For more details regarding service configuration, please see the Services section. How to configure additional and private Tracking ID in Google Analytics? The data is gathered and forwarded to Google Analytics. The user can add custom Google Analytics Tracking ID in the MongooseIM configuration and see all incoming events that are related to their own system metrics. For more details on how to create or sign in to the Google Analytics account, please see Get Started with Analytics. Tracking ID is a property identification code that all collected data is associated with. It is determining the destination where the collected data is sent. To create a new Tracking ID, please follow the steps below: Go to the Admin tab of your user dashboard. Create a new account with + Create Account . Add new property with + Create Property . Within the new property go to Tracking Info > Tracking Code . Tracking ID can be found in the top left corner of the section and has following format UA-XXXX-Y. Example configuration New Tracking ID can be added to the list of options 1 2 3 4 [services.service_mongoose_system_metrics] initial_report = 300 _000 periodic_report = 10 _800_000 tracking_id = \"UA-XXXX-Y\" For more details regarding service configuration, please see Services section. Data Sharing Policy For more information on how Google Analytics collects and processes data, please see Google Privacy & Terms . Google Analytics is being used due to the ease of host and display reporting information. We will not share any user specific information with further third parties not mentioned in this document. Some insight into the statistical significance regarding our findings from the bulk data collected, has been shared as a blog post on our website.","title":"System Metrics Privacy Policy"},{"location":"operation-and-maintenance/System-Metrics-Privacy-Policy/#introduction","text":"MongooseIM system metrics are gathered to analyse the trends and needs of our users, improve MongooseIM, and let us know where to focus our efforts. This section is devoted to explaining how to customise, read, enable and disable collecting of the system metrics.","title":"Introduction"},{"location":"operation-and-maintenance/System-Metrics-Privacy-Policy/#consent","text":"To ensure transparency, a log message is generated on every MongooseIM node start (unless the metrics service is configured with the report option) to show that the functionality is enabled. The user is being notified that the metrics are gathered and has the right to withdraw the consent at any time without limiting the functionality of the product. For more information on how to disable this feature, please see the Services section.","title":"Consent"},{"location":"operation-and-maintenance/System-Metrics-Privacy-Policy/#what-information-is-being-gathered","text":"When introducing this feature, it is crucial for us to be fully transparent as to what information is being gathered. In general, we capture information on how MongooseIM is being used, its version and the chosen feature set. We only report the names of known modules and APIs that are part of the opensource product. All additional customisations are simply counted without disclosing any specific details. The user can view all the information that is shared in two different ways. The log file system_metrics_report.json contains the most recent report that was sent. Additionally, the user can configure the Tracking ID to use their own Google Analytics account and have a view of their MongooseIM status in that dashboard. For more information on how to set up the Tracking ID, please see How to configure additional and private Tracking ID in Google Analytics . The full list of information that is being gathered can be seen below: MongooseIM node uptime. MongooseIM version. Number of nodes that are part of the MongooseIM cluster. Generic modules that are part of the opensource project and are in use. Some modules report what database they use as a backend, e.g. Sample report . Number of custom modules - without disclosing any details, we are just curious to see if there are any. Number of connected external XMPP components. List of configured REST APIs that are part of the opensource project. XMPP transport mechanisms like, TCP/TLS, WebSockets or BOSH. Geographical Data - Google Analytics is providing several geographical dimensions, such as City, Country, Continent. These values are derived from the IP address the data was sent from. See About Geographical Data for more details.","title":"What information is being gathered?"},{"location":"operation-and-maintenance/System-Metrics-Privacy-Policy/#how-is-the-information-being-used","text":"The information collected is automatically anonymised before it is being processed any further. Each MongooseIM is randomly generating a Client ID that is being attached to the reports. The collected data has only statistical relevance and aims to help us understand the needs of our users. Knowing how our product is used will allow us to identify the core value it brings to the users. It will point out the direction in which to expand it and show us how to target our further efforts developing it.","title":"How is the information being used?"},{"location":"operation-and-maintenance/System-Metrics-Privacy-Policy/#how-does-a-report-look-like","text":"A sample report showing metrics for the mod_vcard backends from Google Analytics can be found below. Based on such report we can see the frequency of different backends being used with mod_vcard.","title":"How does a report look like?"},{"location":"operation-and-maintenance/System-Metrics-Privacy-Policy/#how-often-are-the-metrics-reported","text":"Metrics are reported first shortly after the system startup and later at regular intervals. These timers are configurable using the initial_report and periodic_report parameters. The default values are 5 minutes for the initial report and 3 hours for the periodic one. These reporting intervals can be changed depending on the configuration parameters.","title":"How often are the metrics reported?"},{"location":"operation-and-maintenance/System-Metrics-Privacy-Policy/#how-to-configure-this-service","text":"This functionality is provided as a \"service\". For more details regarding service configuration, please see the Services section.","title":"How to configure this service?"},{"location":"operation-and-maintenance/System-Metrics-Privacy-Policy/#how-to-configure-additional-and-private-tracking-id-in-google-analytics","text":"The data is gathered and forwarded to Google Analytics. The user can add custom Google Analytics Tracking ID in the MongooseIM configuration and see all incoming events that are related to their own system metrics. For more details on how to create or sign in to the Google Analytics account, please see Get Started with Analytics. Tracking ID is a property identification code that all collected data is associated with. It is determining the destination where the collected data is sent. To create a new Tracking ID, please follow the steps below: Go to the Admin tab of your user dashboard. Create a new account with + Create Account . Add new property with + Create Property . Within the new property go to Tracking Info > Tracking Code . Tracking ID can be found in the top left corner of the section and has following format UA-XXXX-Y.","title":"How to configure additional and private Tracking ID in Google Analytics?"},{"location":"operation-and-maintenance/System-Metrics-Privacy-Policy/#example-configuration","text":"New Tracking ID can be added to the list of options 1 2 3 4 [services.service_mongoose_system_metrics] initial_report = 300 _000 periodic_report = 10 _800_000 tracking_id = \"UA-XXXX-Y\" For more details regarding service configuration, please see Services section.","title":"Example configuration"},{"location":"operation-and-maintenance/System-Metrics-Privacy-Policy/#data-sharing-policy","text":"For more information on how Google Analytics collects and processes data, please see Google Privacy & Terms . Google Analytics is being used due to the ease of host and display reporting information. We will not share any user specific information with further third parties not mentioned in this document. Some insight into the statistical significance regarding our findings from the bulk data collected, has been shared as a blog post on our website.","title":"Data Sharing Policy"},{"location":"operation-and-maintenance/gdpr-considerations/","text":"GDPR considerations This page describes what GDPR implies in terms of server management. Data affected by GDPR commands inbox - All entries in the subject's inbox. If their messages are stored in other users' inbox, they will not be removed. message archive - Same as above for 1-1 messages. In case of group chat messages, they are retrieved as personal data but not removed. offline storage - All messages stored for delivery. roster - All entries in the subject's roster. Other users' rosters are NOT affected, even if they include the subject's JID or other data. vCard - The entire content of the subject's vCard. private XML storage - All items stored by the subject will be removed. publish-subscribe retrieval: all subject's subscriptions and nodes (with their payloads included). removal: subject's subscriptions, push and PEP nodes (with their data included). GDPR CLI commands All CLI commands are accessible via the mongooseimctl command, located in the bin/ directory inside the MIM release. Personal data retrieval requires service_admin_extra with gdpr group enabled. Creating a GDPR-safe user account mongooseimctl register <domain> <password> This command will create an anonymised JID with a random username part. It ensures that no personal information will be leaked via logs or database entries, which include the user's JID. Example 1 2 $ mongooseimctl register localhost abc123 User 1567 -420657-155810-C1CEC31F5C993258@localhost successfully registered Retrieval of Personal Data mongooseimctl retrieve_personal_data <username> <domain> <filepath for the output as a zip> It retrieves personal data accessible to the server (see \"Technical limitations\" section below). The directory where the zip file will be created must already exist. After the execution is complete, a zip file will appear in the specified folder with personal information in CSV files grouped by type. Example 1 mongooseimctl retrieve_personal_data 1567 -420657-155810-C1CEC31F5C993258 localhost /home/mongooseim/gdpr/1567-420657-155810-C1CEC31F5C993258.zip Removal of Personal Data mongooseimctl unregister <username> <domain> It removes the user's account along with all associated personal data accessible to the server (see \"Technical limitations\" section below). Example 1 mongooseimctl unregister 1567 -420657-155810-C1CEC31F5C993258 localhost Technical limitations of GDPR retrieval and removal Both GDPR retrieval and removal will process the data available via configured extensions and database(s). If a part of personal information is managed by an extension that is e.g. temporarily disabled, it won't be retrieved/deleted. If any MIM extension you had enabled on production is now disabled or you've switched one of them (or e.g. auth module) to another database, it is possible that some personal data will not be retrieved or removed as expected. In such case, please consider starting a separate MIM instance that is configured to access all places, where personal data may be stored. You may also extract the missing pieces of information on your own, however we won't cover the details of this method in this guide. Please also visit Known issues page to learn about a mod_mam_muc issue that may manifest in some environments.","title":"GDPR considerations"},{"location":"operation-and-maintenance/gdpr-considerations/#gdpr-considerations","text":"This page describes what GDPR implies in terms of server management.","title":"GDPR considerations"},{"location":"operation-and-maintenance/gdpr-considerations/#data-affected-by-gdpr-commands","text":"inbox - All entries in the subject's inbox. If their messages are stored in other users' inbox, they will not be removed. message archive - Same as above for 1-1 messages. In case of group chat messages, they are retrieved as personal data but not removed. offline storage - All messages stored for delivery. roster - All entries in the subject's roster. Other users' rosters are NOT affected, even if they include the subject's JID or other data. vCard - The entire content of the subject's vCard. private XML storage - All items stored by the subject will be removed. publish-subscribe retrieval: all subject's subscriptions and nodes (with their payloads included). removal: subject's subscriptions, push and PEP nodes (with their data included).","title":"Data affected by GDPR commands"},{"location":"operation-and-maintenance/gdpr-considerations/#gdpr-cli-commands","text":"All CLI commands are accessible via the mongooseimctl command, located in the bin/ directory inside the MIM release. Personal data retrieval requires service_admin_extra with gdpr group enabled.","title":"GDPR CLI commands"},{"location":"operation-and-maintenance/gdpr-considerations/#creating-a-gdpr-safe-user-account","text":"mongooseimctl register <domain> <password> This command will create an anonymised JID with a random username part. It ensures that no personal information will be leaked via logs or database entries, which include the user's JID.","title":"Creating a GDPR-safe user account"},{"location":"operation-and-maintenance/gdpr-considerations/#example","text":"1 2 $ mongooseimctl register localhost abc123 User 1567 -420657-155810-C1CEC31F5C993258@localhost successfully registered","title":"Example"},{"location":"operation-and-maintenance/gdpr-considerations/#retrieval-of-personal-data","text":"mongooseimctl retrieve_personal_data <username> <domain> <filepath for the output as a zip> It retrieves personal data accessible to the server (see \"Technical limitations\" section below). The directory where the zip file will be created must already exist. After the execution is complete, a zip file will appear in the specified folder with personal information in CSV files grouped by type.","title":"Retrieval of Personal Data"},{"location":"operation-and-maintenance/gdpr-considerations/#example_1","text":"1 mongooseimctl retrieve_personal_data 1567 -420657-155810-C1CEC31F5C993258 localhost /home/mongooseim/gdpr/1567-420657-155810-C1CEC31F5C993258.zip","title":"Example"},{"location":"operation-and-maintenance/gdpr-considerations/#removal-of-personal-data","text":"mongooseimctl unregister <username> <domain> It removes the user's account along with all associated personal data accessible to the server (see \"Technical limitations\" section below).","title":"Removal of Personal Data"},{"location":"operation-and-maintenance/gdpr-considerations/#example_2","text":"1 mongooseimctl unregister 1567 -420657-155810-C1CEC31F5C993258 localhost","title":"Example"},{"location":"operation-and-maintenance/gdpr-considerations/#technical-limitations-of-gdpr-retrieval-and-removal","text":"Both GDPR retrieval and removal will process the data available via configured extensions and database(s). If a part of personal information is managed by an extension that is e.g. temporarily disabled, it won't be retrieved/deleted. If any MIM extension you had enabled on production is now disabled or you've switched one of them (or e.g. auth module) to another database, it is possible that some personal data will not be retrieved or removed as expected. In such case, please consider starting a separate MIM instance that is configured to access all places, where personal data may be stored. You may also extract the missing pieces of information on your own, however we won't cover the details of this method in this guide. Please also visit Known issues page to learn about a mod_mam_muc issue that may manifest in some environments.","title":"Technical limitations of GDPR retrieval and removal"},{"location":"operation-and-maintenance/known-issues/","text":"This document provides a list of all known issues with MongooseIM operation and configuration. You may also find proposed workarounds if any are available. Missing MUC Light room config fields with RDBMS backend Before MongooseIM 3.5.x (incl.) new MUC Light rooms could be created with some config fields absent in the RDBMS table. These options couldn't be re-added later by changing the room config via requests from the clients. It happened when the default config was a subset of the schema, and the client hasn't provided these values when a room was created. Please note that this issue was resolved from MIM 3.6.0 onwards as the default_config option was deleted. How to fix this? You have to iterate over all rooms in the DB ( muc_light_rooms table) and add missing entries to the muc_light_config table. Every option is inserted as a separate row and is stored as plain text, so it should be straightforward. Let's say you were using the following config in mongooseim.cfg : 1 2 3 4 5 6 7 8 9 10 { config_schema , [ \"roomname\" , \"subject\" , \"background\" , \"notification_sound\" ]}, { default_config , [ { \"roomname\" , \"The room\" }, { \"subject\" , \"Chit-chat\" } ]} Your client application has created some rooms without the background option by mistake. For every id in the muc_light_rooms table, you need to execute: 1 INSERT INTO muc_light_config ( room_id , opt , val ) VALUES ( 'put id here' , 'background' , 'new default value' ); MSSQL connectivity via ODBC We have observed some issues with he ODBC driver used by MongooseIM in the past. The problems should now be resolved, and MSSQL is verified to work on Ubuntu 20.04.2 LTS. GDPR retrieval for MAM MUC limitation When the personal data retrieval is executed for a user in a specific domain, Message Archive Management for groupchats must be running for this particular domain. This is the case for most configurations, but the problem manifests when a MongooseIM operator configures mod_mam_muc / mod_mam_meta to start only for a subset of domains supported by the cluster ( host_config option). In such case, personal data stored by MAM MUC will not be retrieved for this user. Proposed workaround Start a dedicated MongooseIM instance with a slightly different config, which enables Message Archive Management for the user's domain. This instance doesn't have to be clustered with other nodes and doesn't have to be accessible for actual users. After a successful retrieval, this instance may be terminated and deleted if necessary.","title":"Known issues"},{"location":"operation-and-maintenance/known-issues/#missing-muc-light-room-config-fields-with-rdbms-backend","text":"Before MongooseIM 3.5.x (incl.) new MUC Light rooms could be created with some config fields absent in the RDBMS table. These options couldn't be re-added later by changing the room config via requests from the clients. It happened when the default config was a subset of the schema, and the client hasn't provided these values when a room was created. Please note that this issue was resolved from MIM 3.6.0 onwards as the default_config option was deleted.","title":"Missing MUC Light room config fields with RDBMS backend"},{"location":"operation-and-maintenance/known-issues/#how-to-fix-this","text":"You have to iterate over all rooms in the DB ( muc_light_rooms table) and add missing entries to the muc_light_config table. Every option is inserted as a separate row and is stored as plain text, so it should be straightforward. Let's say you were using the following config in mongooseim.cfg : 1 2 3 4 5 6 7 8 9 10 { config_schema , [ \"roomname\" , \"subject\" , \"background\" , \"notification_sound\" ]}, { default_config , [ { \"roomname\" , \"The room\" }, { \"subject\" , \"Chit-chat\" } ]} Your client application has created some rooms without the background option by mistake. For every id in the muc_light_rooms table, you need to execute: 1 INSERT INTO muc_light_config ( room_id , opt , val ) VALUES ( 'put id here' , 'background' , 'new default value' );","title":"How to fix this?"},{"location":"operation-and-maintenance/known-issues/#mssql-connectivity-via-odbc","text":"We have observed some issues with he ODBC driver used by MongooseIM in the past. The problems should now be resolved, and MSSQL is verified to work on Ubuntu 20.04.2 LTS.","title":"MSSQL connectivity via ODBC"},{"location":"operation-and-maintenance/known-issues/#gdpr-retrieval-for-mam-muc-limitation","text":"When the personal data retrieval is executed for a user in a specific domain, Message Archive Management for groupchats must be running for this particular domain. This is the case for most configurations, but the problem manifests when a MongooseIM operator configures mod_mam_muc / mod_mam_meta to start only for a subset of domains supported by the cluster ( host_config option). In such case, personal data stored by MAM MUC will not be retrieved for this user.","title":"GDPR retrieval for MAM MUC limitation"},{"location":"operation-and-maintenance/known-issues/#proposed-workaround","text":"Start a dedicated MongooseIM instance with a slightly different config, which enables Message Archive Management for the user's domain. This instance doesn't have to be clustered with other nodes and doesn't have to be accessible for actual users. After a successful retrieval, this instance may be terminated and deleted if necessary.","title":"Proposed workaround"},{"location":"operation-and-maintenance/tls-distribution/","text":"Distribution over TLS It's possible to use TLS for communication between MongooseIM cluster nodes. To enable it, find the directory of your release, below it look for etc/vm.dist.args and, inside the file, the section about the distribution protocol: 1 2 3 4 5 6 7 8 9 10 11 ## Use TLS for connections between Erlang cluster members. ## Don't forget to override the paths to point to your certificate(s) and key(s)! ## Once a connection is established, Erlang doesn't differentiate between ## a client and a server - the same certs/keys can be used on both sides. #-proto_dist inet_tls #-ssl_dist_opt server_certfile /Users/erszcz/work/esl/mongooseim/_build/mim1/rel/mongooseim/priv/ssl/fake_cert.pem client_certfile /Users/erszcz/work/esl/mongooseim/_build/mim1/rel/mongooseim/priv/ssl/fake_cert.pem # server_keyfile /Users/erszcz/work/esl/mongooseim/_build/mim1/rel/mongooseim/priv/ssl/fake_key.pem client_keyfile /Users/erszcz/work/esl/mongooseim/_build/mim1/rel/mongooseim/priv/ssl/fake_key.pem # server_cacertfile /Users/erszcz/work/esl/mongooseim/_build/mim1/rel/mongooseim/priv/ssl/cacert.pem client_cacertfile /Users/erszcz/work/esl/mongooseim/_build/mim1/rel/mongooseim/priv/ssl/cacert.pem # client_verify verify_peer # server_verify verify_peer # server_fail_if_no_peer_cert true By default, the proto_dist as well as the following options for configuring the cluster member are commented out. Enable them and provide the correct paths to your CA certificate, server certificate and server key. There's a number of caveats to remember about when running Erlang distribution over TLS : TLS-enabled and non-TLS Erlang nodes can't communicate with one another. Remember about it when trying to run erl -[s]name ... and communicating with the server. Establishing a TLS connection will fail if a certificate isn't found in the specified location. You might receive a log message indicating that when nodes try to connect: 1 2017-03-10 16:16:03.844 [warning] <0.4218.2> global: mongooseim@localhost failed to connect to fed1@localhost If the pointed-at certificate/key/CA-certificate file doesn't exist, it won't be reported before trying to connect. Look for (grep) the log message on all cluster nodes, as the message doesn't have to appear on all nodes if a connection fails. You can switch a cluster from running non-TLS distribution, to TLS distribution by shutting down a node, enabling TLS on it, starting it up again, and repeating the steps for each remaining node. Again, nodes with and without TLS enabled won't be able to communicate with one another. It's possible to fortify an Erlang cluster further than the Mongoose's preconfigured vm.dist.args does. This includes: checking certificate revocation status against a CA's Certificate Revocation List, securing/disabling EPMD (Erlang Port Mapper Daemon), using custom certificate verification functions. For details on these steps please refer to Erlang Distribution over TLS and Erlang (and Elixir) distribution without epmd .","title":"Distribution over TLS"},{"location":"operation-and-maintenance/tls-distribution/#distribution-over-tls","text":"It's possible to use TLS for communication between MongooseIM cluster nodes. To enable it, find the directory of your release, below it look for etc/vm.dist.args and, inside the file, the section about the distribution protocol: 1 2 3 4 5 6 7 8 9 10 11 ## Use TLS for connections between Erlang cluster members. ## Don't forget to override the paths to point to your certificate(s) and key(s)! ## Once a connection is established, Erlang doesn't differentiate between ## a client and a server - the same certs/keys can be used on both sides. #-proto_dist inet_tls #-ssl_dist_opt server_certfile /Users/erszcz/work/esl/mongooseim/_build/mim1/rel/mongooseim/priv/ssl/fake_cert.pem client_certfile /Users/erszcz/work/esl/mongooseim/_build/mim1/rel/mongooseim/priv/ssl/fake_cert.pem # server_keyfile /Users/erszcz/work/esl/mongooseim/_build/mim1/rel/mongooseim/priv/ssl/fake_key.pem client_keyfile /Users/erszcz/work/esl/mongooseim/_build/mim1/rel/mongooseim/priv/ssl/fake_key.pem # server_cacertfile /Users/erszcz/work/esl/mongooseim/_build/mim1/rel/mongooseim/priv/ssl/cacert.pem client_cacertfile /Users/erszcz/work/esl/mongooseim/_build/mim1/rel/mongooseim/priv/ssl/cacert.pem # client_verify verify_peer # server_verify verify_peer # server_fail_if_no_peer_cert true By default, the proto_dist as well as the following options for configuring the cluster member are commented out. Enable them and provide the correct paths to your CA certificate, server certificate and server key. There's a number of caveats to remember about when running Erlang distribution over TLS : TLS-enabled and non-TLS Erlang nodes can't communicate with one another. Remember about it when trying to run erl -[s]name ... and communicating with the server. Establishing a TLS connection will fail if a certificate isn't found in the specified location. You might receive a log message indicating that when nodes try to connect: 1 2017-03-10 16:16:03.844 [warning] <0.4218.2> global: mongooseim@localhost failed to connect to fed1@localhost If the pointed-at certificate/key/CA-certificate file doesn't exist, it won't be reported before trying to connect. Look for (grep) the log message on all cluster nodes, as the message doesn't have to appear on all nodes if a connection fails. You can switch a cluster from running non-TLS distribution, to TLS distribution by shutting down a node, enabling TLS on it, starting it up again, and repeating the steps for each remaining node. Again, nodes with and without TLS enabled won't be able to communicate with one another. It's possible to fortify an Erlang cluster further than the Mongoose's preconfigured vm.dist.args does. This includes: checking certificate revocation status against a CA's Certificate Revocation List, securing/disabling EPMD (Erlang Port Mapper Daemon), using custom certificate verification functions. For details on these steps please refer to Erlang Distribution over TLS and Erlang (and Elixir) distribution without epmd .","title":"Distribution over TLS"},{"location":"rest-api/Administration-backend/","text":"MongooseIM's REST API for backend administration Configuration Commands used by the REST API are provided by modules: mod_commands - provides general purpose commands: both user-like (e.g. sending a message and retrieving messages from the archive) and administration-like (e.g. create/delete a user and change the password). mod_muc_commands - commands related to Multi-user Chat rooms: create a room, invite users, send a message etc. mod_muc_light_commands - same but for rooms based on the muc-light protocol. To activate those commands, put the modules you need into the mongooseim.toml file: 1 2 3 4 5 [modules.mod_commands] [modules.mod_muc_commands] [modules.mod_muc_light_commands] You also have to hook the mongoose_api_admin module to an HTTP endpoint as described in the admin REST API handlers configuration section of the listeners documentation. OpenAPI specifications Read the beautiful Swagger documentation for more information. $(document).ready(function() { if (window.location.host.match(\"github\")){ path = window.location.pathname.match(\"(.*)/rest-api/Administration-backend\")[1] url = window.location.protocol + \"//\" + window.location.hostname finalURL = url + path + \"/swagger/index.html\" $('a[href$=\"swagger/index.html\"]').attr('href', finalURL) $('#swagger-ui-iframe').attr('src', finalURL) } })","title":"Administration backend"},{"location":"rest-api/Administration-backend/#mongooseims-rest-api-for-backend-administration","text":"","title":"MongooseIM's REST API for backend administration"},{"location":"rest-api/Administration-backend/#configuration","text":"Commands used by the REST API are provided by modules: mod_commands - provides general purpose commands: both user-like (e.g. sending a message and retrieving messages from the archive) and administration-like (e.g. create/delete a user and change the password). mod_muc_commands - commands related to Multi-user Chat rooms: create a room, invite users, send a message etc. mod_muc_light_commands - same but for rooms based on the muc-light protocol. To activate those commands, put the modules you need into the mongooseim.toml file: 1 2 3 4 5 [modules.mod_commands] [modules.mod_muc_commands] [modules.mod_muc_light_commands] You also have to hook the mongoose_api_admin module to an HTTP endpoint as described in the admin REST API handlers configuration section of the listeners documentation.","title":"Configuration"},{"location":"rest-api/Administration-backend/#openapi-specifications","text":"Read the beautiful Swagger documentation for more information. $(document).ready(function() { if (window.location.host.match(\"github\")){ path = window.location.pathname.match(\"(.*)/rest-api/Administration-backend\")[1] url = window.location.protocol + \"//\" + window.location.hostname finalURL = url + path + \"/swagger/index.html\" $('a[href$=\"swagger/index.html\"]').attr('href', finalURL) $('#swagger-ui-iframe').attr('src', finalURL) } })","title":"OpenAPI specifications"},{"location":"rest-api/Client-frontend/","text":"MongooseIM's REST API for frontend or client In addition to the regular XMPP connection methods such as TCP (with TLS/STARTTLS), WebSockets and BOSH, MongooseIM provides parts of its functionality over a REST API. Assumptions Every request has to be authenticated. Please see the Authentication section for more details. We strongly advise that this API is served over HTTPS. User registration has to be done via other methods (f.e. using the REST API for backend services ). The relevant endpoint has to be configured on the server side. See the configuration section . A list of provided actions is documented with Swagger. See the beautiful specification . Authentication MongooseIM uses Basic Authentication as an authentication method for the REST API. Basic authentication is a simple authentication scheme built into the HTTP protocol. Each HTTP request to the client REST API has to contain the Authorization header with the word Basic followed by a space and a base64-encoded string username@host:password , where: username@host is the user's bare JID , password is the password used to register the user's account. For example, to authorize as alice@localhost with the password secret , the client would send a header: 1 Authorization: Basic YWxpY2VAbG9jYWxob3N0OnNlY3JldA== Configuration Handlers have to be configured as shown in the REST API configuration example to enable REST API. In order to get the client REST API up and running simply copy the provided example. For more details about possible configuration parameters please see the relevant documentation of the listeners , in particular the client REST API handlers section. Smack library support REST API can fetch messages for Smack Stanza Properties. For example if we have properties in the stanza like: 1 2 3 4 5 6 7 8 9 10 11 12 13 <message xml:lang= 'en' to= 'alice@localhost' id= '123' type= 'chat' > <body xml:lang= 'en_US' > Hi! </body> <properties xmlns= \"http://www.jivesoftware.com/xmlns/xmpp/properties\" <property > <name> some_number </name> <value type= 'integer' > 123 </value> <property> <property> <name> some_string </name> <value type= 'string' > abc </value> <property> </properties> </message> then in the final json message these properties will be converted to json map without tag names and all types will be taken as string: 1 2 3 4 5 6 7 8 9 10 { \"to\" : \"alice@localhost\" , \"timestamp\" : 1531329049949 , \"id\" : \"123\" , \"from\" : \"bob@localhost\" , \"body\" : \"Hi!\" , \"properties\" :{ \"some_number\" : \"123\" , \"some_string\" : \"abc\" } } OpenAPI specifications See the beautiful Swagger documentation for more information. $(document).ready(function() { if (window.location.host.match(\"github\")){ path = window.location.pathname.match(\"(.*)/REST-API/\")[1] url = window.location.protocol + \"//\" + window.location.hostname finalURL = url + path + \"/swagger/index.html?client=true\" $('a[href$=\"swagger/index.html?client=true\"]').attr('href', finalURL) $('#swagger-ui-iframe').attr('src', finalURL) } })","title":"Client/frontend"},{"location":"rest-api/Client-frontend/#mongooseims-rest-api-for-frontend-or-client","text":"In addition to the regular XMPP connection methods such as TCP (with TLS/STARTTLS), WebSockets and BOSH, MongooseIM provides parts of its functionality over a REST API.","title":"MongooseIM's REST API for frontend or client"},{"location":"rest-api/Client-frontend/#assumptions","text":"Every request has to be authenticated. Please see the Authentication section for more details. We strongly advise that this API is served over HTTPS. User registration has to be done via other methods (f.e. using the REST API for backend services ). The relevant endpoint has to be configured on the server side. See the configuration section . A list of provided actions is documented with Swagger. See the beautiful specification .","title":"Assumptions"},{"location":"rest-api/Client-frontend/#authentication","text":"MongooseIM uses Basic Authentication as an authentication method for the REST API. Basic authentication is a simple authentication scheme built into the HTTP protocol. Each HTTP request to the client REST API has to contain the Authorization header with the word Basic followed by a space and a base64-encoded string username@host:password , where: username@host is the user's bare JID , password is the password used to register the user's account. For example, to authorize as alice@localhost with the password secret , the client would send a header: 1 Authorization: Basic YWxpY2VAbG9jYWxob3N0OnNlY3JldA==","title":"Authentication"},{"location":"rest-api/Client-frontend/#configuration","text":"Handlers have to be configured as shown in the REST API configuration example to enable REST API. In order to get the client REST API up and running simply copy the provided example. For more details about possible configuration parameters please see the relevant documentation of the listeners , in particular the client REST API handlers section.","title":"Configuration"},{"location":"rest-api/Client-frontend/#smack-library-support","text":"REST API can fetch messages for Smack Stanza Properties. For example if we have properties in the stanza like: 1 2 3 4 5 6 7 8 9 10 11 12 13 <message xml:lang= 'en' to= 'alice@localhost' id= '123' type= 'chat' > <body xml:lang= 'en_US' > Hi! </body> <properties xmlns= \"http://www.jivesoftware.com/xmlns/xmpp/properties\" <property > <name> some_number </name> <value type= 'integer' > 123 </value> <property> <property> <name> some_string </name> <value type= 'string' > abc </value> <property> </properties> </message> then in the final json message these properties will be converted to json map without tag names and all types will be taken as string: 1 2 3 4 5 6 7 8 9 10 { \"to\" : \"alice@localhost\" , \"timestamp\" : 1531329049949 , \"id\" : \"123\" , \"from\" : \"bob@localhost\" , \"body\" : \"Hi!\" , \"properties\" :{ \"some_number\" : \"123\" , \"some_string\" : \"abc\" } }","title":"Smack library support"},{"location":"rest-api/Client-frontend/#openapi-specifications","text":"See the beautiful Swagger documentation for more information. $(document).ready(function() { if (window.location.host.match(\"github\")){ path = window.location.pathname.match(\"(.*)/REST-API/\")[1] url = window.location.protocol + \"//\" + window.location.hostname finalURL = url + path + \"/swagger/index.html?client=true\" $('a[href$=\"swagger/index.html?client=true\"]').attr('href', finalURL) $('#swagger-ui-iframe').attr('src', finalURL) } })","title":"OpenAPI specifications"},{"location":"rest-api/Metrics-backend/","text":"Introduction Warning: This API is considered obsolete. Please use WombatOAM for monitoring or one of the exometer reporters and your favourite statistics service. To expose MongooseIM metrics, an adequate endpoint must be included in the listen section of mongooseim.toml . The specific configuration options are described in the metrics API handlers section. An example configuration: 1 2 3 4 5 6 7 8 9 [[listen.http]] port = 5288 transport . num_acceptors = 5 transport . max_connections = 10 [[listen.http.handlers.mongoose_api]] host = \"localhost\" path = \"/api\" handlers = [\"mongoose_api_metrics\"] If you'd like to learn more about metrics in MongooseIM, please visit MongooseIM metrics page. Security notice An auth mechanism is available only for the new administration API. That's why we recommend to expose this API only using a private interface or a port hidden behind a firewall to limit the access to the API. The above configuration starts the API only on a loopback interface. Response format The responses are composed in a JSON format with a root element containing one or more attributes as response elements. Example response: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 { \"hosts\" : [ \"localhost\" ], \"metrics\" : [ \"xmppErrorIq\" , \"xmppPresenceReceived\" , \"xmppMessageBounced\" , (...) ], \"global\" : [ \"nodeSessionCount\" , \"totalSessionCount\" , \"uniqueSessionCount\" , (...) ] } Services GET /api/metrics Returns 200 OK and two elements: host_types - A list of host type names available on the server. metrics - A list of per-host metrics. global - A list of global metrics. GET /api/metrics/all Returns 200 OK and an element: metrics - A list of aggregated (sum of all domains) per host type metrics with their values. GET /api/metrics/all/:metric On success returns 200 OK and an element: metric - An aggregated (sum of all domains) per host type metric. Returns 404 Not Found when metric :metric doesn't exist. GET /api/metrics/host_type/:host_type On success returns 200 OK and an element: metrics - A list of per host type metrics and their values for host_type :host_type . Returns 404 Not Found when host_type :host_type doesn't exist. GET /api/metrics/host_type/:host_type/:metric On success returns 200 OK and an element: metric - A per host type metric :metric and its value for host_type :host_type . Returns 404 Not Found when the pair (host_type :host_type , metric :metric ) doesn't exist. GET /api/metrics/global On success returns 200 OK and an element: metrics - A list of all global metrics and their values. GET /api/metrics/global/:metric On success returns 200 OK and an element: metric - A global metric :metric and its value. Returns 404 Not Found when metric :metric doesn't exist. collectd integration The interface is compatible with the collectd curl_json plugin. Data fetched by collectd may be later visualized by tools like Graphite. Here's an example of a collectd configuration entry that will fetch all available metrics for a given host: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 LoadPlugi n curl_jso n ... <Plugi n curl_jso n > <URL \"http://<MONGOOSEIM HOST>:<MONGOOSEIM HTTP LISTENER PORT>/api/metrics/host/<XMPP HOST>\" > I nstan ce \"mongooseim\" <Key \"metrics/sessionCount/value\" > Type \"absolute\" </Key> <Key \"metrics/*/count\" > Type \"absolute\" </Key> <Key \"metrics/*/one\" > Type \"absolute\" </Key> </URL> </Plugi n >","title":"Metrics backend"},{"location":"rest-api/Metrics-backend/#introduction","text":"Warning: This API is considered obsolete. Please use WombatOAM for monitoring or one of the exometer reporters and your favourite statistics service. To expose MongooseIM metrics, an adequate endpoint must be included in the listen section of mongooseim.toml . The specific configuration options are described in the metrics API handlers section. An example configuration: 1 2 3 4 5 6 7 8 9 [[listen.http]] port = 5288 transport . num_acceptors = 5 transport . max_connections = 10 [[listen.http.handlers.mongoose_api]] host = \"localhost\" path = \"/api\" handlers = [\"mongoose_api_metrics\"] If you'd like to learn more about metrics in MongooseIM, please visit MongooseIM metrics page.","title":"Introduction"},{"location":"rest-api/Metrics-backend/#security-notice","text":"An auth mechanism is available only for the new administration API. That's why we recommend to expose this API only using a private interface or a port hidden behind a firewall to limit the access to the API. The above configuration starts the API only on a loopback interface.","title":"Security notice"},{"location":"rest-api/Metrics-backend/#response-format","text":"The responses are composed in a JSON format with a root element containing one or more attributes as response elements. Example response: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 { \"hosts\" : [ \"localhost\" ], \"metrics\" : [ \"xmppErrorIq\" , \"xmppPresenceReceived\" , \"xmppMessageBounced\" , (...) ], \"global\" : [ \"nodeSessionCount\" , \"totalSessionCount\" , \"uniqueSessionCount\" , (...) ] }","title":"Response format"},{"location":"rest-api/Metrics-backend/#services","text":"","title":"Services"},{"location":"rest-api/Metrics-backend/#get-apimetrics","text":"Returns 200 OK and two elements: host_types - A list of host type names available on the server. metrics - A list of per-host metrics. global - A list of global metrics.","title":"GET /api/metrics"},{"location":"rest-api/Metrics-backend/#get-apimetricsall","text":"Returns 200 OK and an element: metrics - A list of aggregated (sum of all domains) per host type metrics with their values.","title":"GET /api/metrics/all"},{"location":"rest-api/Metrics-backend/#get-apimetricsallmetric","text":"On success returns 200 OK and an element: metric - An aggregated (sum of all domains) per host type metric. Returns 404 Not Found when metric :metric doesn't exist.","title":"GET /api/metrics/all/:metric"},{"location":"rest-api/Metrics-backend/#get-apimetricshost_typehost_type","text":"On success returns 200 OK and an element: metrics - A list of per host type metrics and their values for host_type :host_type . Returns 404 Not Found when host_type :host_type doesn't exist.","title":"GET /api/metrics/host_type/:host_type"},{"location":"rest-api/Metrics-backend/#get-apimetricshost_typehost_typemetric","text":"On success returns 200 OK and an element: metric - A per host type metric :metric and its value for host_type :host_type . Returns 404 Not Found when the pair (host_type :host_type , metric :metric ) doesn't exist.","title":"GET /api/metrics/host_type/:host_type/:metric"},{"location":"rest-api/Metrics-backend/#get-apimetricsglobal","text":"On success returns 200 OK and an element: metrics - A list of all global metrics and their values.","title":"GET /api/metrics/global"},{"location":"rest-api/Metrics-backend/#get-apimetricsglobalmetric","text":"On success returns 200 OK and an element: metric - A global metric :metric and its value. Returns 404 Not Found when metric :metric doesn't exist.","title":"GET /api/metrics/global/:metric"},{"location":"rest-api/Metrics-backend/#collectd-integration","text":"The interface is compatible with the collectd curl_json plugin. Data fetched by collectd may be later visualized by tools like Graphite. Here's an example of a collectd configuration entry that will fetch all available metrics for a given host: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 LoadPlugi n curl_jso n ... <Plugi n curl_jso n > <URL \"http://<MONGOOSEIM HOST>:<MONGOOSEIM HTTP LISTENER PORT>/api/metrics/host/<XMPP HOST>\" > I nstan ce \"mongooseim\" <Key \"metrics/sessionCount/value\" > Type \"absolute\" </Key> <Key \"metrics/*/count\" > Type \"absolute\" </Key> <Key \"metrics/*/one\" > Type \"absolute\" </Key> </URL> </Plugi n >","title":"collectd integration"},{"location":"user-guide/ABCs-of-MongooseIM/","text":"Overview MongooseIM is Erlang Solutions' robust, scalable and efficient XMPP server, aimed at large installations. Specifically designed for enterprise purposes, it is fault-tolerant, can utilise the resources of multiple clustered machines, and easily scale when more capacity is required by just adding nodes (new hardware boxes or VMs). It provides support for WebSockets and reimplemented BOSH (HTTP long-polling). Architecture MongooseIM brings configurability, scalability and fault-tolerance to the core feature of XMPP \u2013 routing messages. Its architecture is based on a set of pluggable modules that enable different features, including: Websockets: long-lived connections in the browser BOSH: HTTP long-polling MUC (Multi-User Chat): group chat Rosters: contact list, and subscriptions to users' presences MAM: Message Archive Management Message Carbons: for multi-device, real-time copies of all messages Last activity Metrics Offline messages Privacy settings vCards: user profiles This modular architecture allows high customisability and easy access to the required features. MongooseIM enables authenticating users using external or internal databases (Mnesia, RDBMS, NOSQL), LDAP or external scripts. It also allows connecting anonymous users, when required. For storing persistent data, MongooseIM uses Mnesia (the distributed internal Erlang database) and also MySQL and PostgreSQL (RDBMS databases), and Riak KV (NOSQL). If necessary, MongooseIM can be customised to work with a database chosen by the customer. Basic MongooseIM session storage is handled in Mnesia, but using Redis is also possible. Deployment and management MongooseIM can be deployed for a number of scenarios fitting customer needs. The default installation setup consists of a single MongooseIM node using Mnesia, so it does not require any additional services. This primary system is sufficient for fast deployment and connecting XMPP clients. A more scalable solution would be deploying MongooseIM with an external database for persistent data. Such a setup requires a cluster of MongooseIM nodes, an external database, and a load balancer to manage the traffic from the client applications. A single MongooseIM node can handle as many as 2.5 million online users. Based on our load tests, for deployments with multiple nodes, we are confident that 10 million online users is well within reach. Please note that such scalability numbers depend on the selected feature set that your MongooseIM installation is running. For more details please see our blogpost: Scaling a Mongoose: How scalable is the MongooseIM XMPP server? If the service requires a cluster of more than 10 nodes, we recommend using Redis instead of Mnesia for session storage. To avoid a single point of failure, a master-slave Redis setup is advisable. MongooseIM allows connecting different clusters as parts of larger systems. This feature is used in geo-localised services handling massive traffic from all over the world. MongooseIM gathers over 50 different XMPP-related metrics, allowing close monitoring of what happens inside the nodes. To manage the users, rosters, messages and general settings, we provide a command-line tool, mongooseimctl . Erlang Solutions also provides WombatOAM , an erlang VM monitoring solution, that enables ops and devs to better understand what going on in a MongooseIM cluster. For load testing consider Tide , another Erlang Solutions' tool that enables devs and ops to validate their scalability, given the clients scenarios. Client side In order to build client applications, the MoongooseIM team recommends the following libraries: XMPP REST API iOS XMPPframework , Objective-C Jayme , Swift Android Smack , Java Retrofit , Java Web Stanza.io / Strophe.js , JavaScript General knowledge of Erlang and XMPP allows complete control over the system and its components.","title":"ABCs of MongooseIM"},{"location":"user-guide/ABCs-of-MongooseIM/#overview","text":"MongooseIM is Erlang Solutions' robust, scalable and efficient XMPP server, aimed at large installations. Specifically designed for enterprise purposes, it is fault-tolerant, can utilise the resources of multiple clustered machines, and easily scale when more capacity is required by just adding nodes (new hardware boxes or VMs). It provides support for WebSockets and reimplemented BOSH (HTTP long-polling).","title":"Overview"},{"location":"user-guide/ABCs-of-MongooseIM/#architecture","text":"MongooseIM brings configurability, scalability and fault-tolerance to the core feature of XMPP \u2013 routing messages. Its architecture is based on a set of pluggable modules that enable different features, including: Websockets: long-lived connections in the browser BOSH: HTTP long-polling MUC (Multi-User Chat): group chat Rosters: contact list, and subscriptions to users' presences MAM: Message Archive Management Message Carbons: for multi-device, real-time copies of all messages Last activity Metrics Offline messages Privacy settings vCards: user profiles This modular architecture allows high customisability and easy access to the required features. MongooseIM enables authenticating users using external or internal databases (Mnesia, RDBMS, NOSQL), LDAP or external scripts. It also allows connecting anonymous users, when required. For storing persistent data, MongooseIM uses Mnesia (the distributed internal Erlang database) and also MySQL and PostgreSQL (RDBMS databases), and Riak KV (NOSQL). If necessary, MongooseIM can be customised to work with a database chosen by the customer. Basic MongooseIM session storage is handled in Mnesia, but using Redis is also possible.","title":"Architecture"},{"location":"user-guide/ABCs-of-MongooseIM/#deployment-and-management","text":"MongooseIM can be deployed for a number of scenarios fitting customer needs. The default installation setup consists of a single MongooseIM node using Mnesia, so it does not require any additional services. This primary system is sufficient for fast deployment and connecting XMPP clients. A more scalable solution would be deploying MongooseIM with an external database for persistent data. Such a setup requires a cluster of MongooseIM nodes, an external database, and a load balancer to manage the traffic from the client applications. A single MongooseIM node can handle as many as 2.5 million online users. Based on our load tests, for deployments with multiple nodes, we are confident that 10 million online users is well within reach. Please note that such scalability numbers depend on the selected feature set that your MongooseIM installation is running. For more details please see our blogpost: Scaling a Mongoose: How scalable is the MongooseIM XMPP server? If the service requires a cluster of more than 10 nodes, we recommend using Redis instead of Mnesia for session storage. To avoid a single point of failure, a master-slave Redis setup is advisable. MongooseIM allows connecting different clusters as parts of larger systems. This feature is used in geo-localised services handling massive traffic from all over the world. MongooseIM gathers over 50 different XMPP-related metrics, allowing close monitoring of what happens inside the nodes. To manage the users, rosters, messages and general settings, we provide a command-line tool, mongooseimctl . Erlang Solutions also provides WombatOAM , an erlang VM monitoring solution, that enables ops and devs to better understand what going on in a MongooseIM cluster. For load testing consider Tide , another Erlang Solutions' tool that enables devs and ops to validate their scalability, given the clients scenarios.","title":"Deployment and management"},{"location":"user-guide/ABCs-of-MongooseIM/#client-side","text":"In order to build client applications, the MoongooseIM team recommends the following libraries: XMPP REST API iOS XMPPframework , Objective-C Jayme , Swift Android Smack , Java Retrofit , Java Web Stanza.io / Strophe.js , JavaScript General knowledge of Erlang and XMPP allows complete control over the system and its components.","title":"Client side"},{"location":"user-guide/Bootstrap-Scripts/","text":"Bootstrap scripts The scripts are located in the rel/files/scripts/ directory in the MongooseIM repository. By default the bootstrap command executes bootstrap01-hello.sh , which just prints the information below: 1 2 3 4 5 ./_build/prod/rel/mongooseim/bin/mongooseimctl bootstrap Execute /Users/mikhailuvarov/erlang/esl/MongooseIM/_build/prod/rel/mongooseim/scripts/bootstrap01-hello.sh Hello from /Users/mikhailuvarov/erlang/esl/MongooseIM/_build/prod/rel/mongooseim/scripts/bootstrap01-hello.sh script. MongooseIM is installed into /Users/mikhailuvarov/erlang/esl/MongooseIM/_build/prod/rel/mongooseim Execution of scripts stops with an error, if any of scripts fail. Environment variables, available from scripts: ERTS_PATH - path to Erlang Runtime System, used by MongooseIM. MIM_DIR - MongooseIM release installation directory. Templating bootstrap script The script bootstrap20-template.escript renders files from the templates/ directory and writes result files into the etc/ directory. If you need the result files in a separate directory, create another script bootstrap30-template.sh , that moves files into a proper location. The etc/templates.ini file contains default template variables. A template config example: 1 2 3 [options] demo_session_lifetime = 600 demo_tls_versions = 'tlsv1.2', 'tlsv1.3' Only lowercase variables are allowed in templates.ini . You can redeclare options using environment variables when executing the bootstrap script: 1 MIM_DEMO_SESSION_LIFETIME = 700 mongooseimctl bootstrap Environment variables should have a MIM_ prefix. The variable names are case-insensitive (but we suggest to use the uppercase variable names for consistency). Demo template A demo template is located in rel/files/templates/demo.config . It is copied into the /templates directory inside your release directory. Testing templating scripts Templating script source code: rel/files/scripts/bootstrap20-template.escript . Testing script code: 1 2 tools/pkg/scripts/smoke_test.sh tools/pkg/scripts/smoke_templates.escript Testing command: 1 PRESET = pkg pkg_PLATFORM = centos_7 ESL_ERLANG_PKG_VER = 22 .1.8-2 ./tools/travis-test.sh","title":"Bootstrap scripts"},{"location":"user-guide/Bootstrap-Scripts/#bootstrap-scripts","text":"The scripts are located in the rel/files/scripts/ directory in the MongooseIM repository. By default the bootstrap command executes bootstrap01-hello.sh , which just prints the information below: 1 2 3 4 5 ./_build/prod/rel/mongooseim/bin/mongooseimctl bootstrap Execute /Users/mikhailuvarov/erlang/esl/MongooseIM/_build/prod/rel/mongooseim/scripts/bootstrap01-hello.sh Hello from /Users/mikhailuvarov/erlang/esl/MongooseIM/_build/prod/rel/mongooseim/scripts/bootstrap01-hello.sh script. MongooseIM is installed into /Users/mikhailuvarov/erlang/esl/MongooseIM/_build/prod/rel/mongooseim Execution of scripts stops with an error, if any of scripts fail. Environment variables, available from scripts: ERTS_PATH - path to Erlang Runtime System, used by MongooseIM. MIM_DIR - MongooseIM release installation directory.","title":"Bootstrap scripts"},{"location":"user-guide/Bootstrap-Scripts/#templating-bootstrap-script","text":"The script bootstrap20-template.escript renders files from the templates/ directory and writes result files into the etc/ directory. If you need the result files in a separate directory, create another script bootstrap30-template.sh , that moves files into a proper location. The etc/templates.ini file contains default template variables. A template config example: 1 2 3 [options] demo_session_lifetime = 600 demo_tls_versions = 'tlsv1.2', 'tlsv1.3' Only lowercase variables are allowed in templates.ini . You can redeclare options using environment variables when executing the bootstrap script: 1 MIM_DEMO_SESSION_LIFETIME = 700 mongooseimctl bootstrap Environment variables should have a MIM_ prefix. The variable names are case-insensitive (but we suggest to use the uppercase variable names for consistency).","title":"Templating bootstrap script"},{"location":"user-guide/Bootstrap-Scripts/#demo-template","text":"A demo template is located in rel/files/templates/demo.config . It is copied into the /templates directory inside your release directory.","title":"Demo template"},{"location":"user-guide/Bootstrap-Scripts/#testing-templating-scripts","text":"Templating script source code: rel/files/scripts/bootstrap20-template.escript . Testing script code: 1 2 tools/pkg/scripts/smoke_test.sh tools/pkg/scripts/smoke_templates.escript Testing command: 1 PRESET = pkg pkg_PLATFORM = centos_7 ESL_ERLANG_PKG_VER = 22 .1.8-2 ./tools/travis-test.sh","title":"Testing templating scripts"},{"location":"user-guide/Features-and-supported-standards/","text":"Features and supported standards XMPP Core: RFC 3920 , RFC 6120 Note: In RFC 6120 there are 3 different strategies defined in case of a session conflict (same full JID). They are described in 7.7.2.2. Conflict . MongooseIM always uses the 3rd option. It terminates the older session with a <conflict/> stream error. XMPP Instant Messaging and Presence: RFC 3921 , RFC 6121 Client connections: over TCP (with TLS/STARTTLS available) as defined in RFC 6120 over WebSockets as defined in RFC 7395 over HTTP(S) long-polling (BOSH) as defined in XEP-0124: Bidirectional-streams Over Synchronous HTTP (BOSH) and XEP-0206: XMPP Over BOSH REST API Server/backend connections: REST API Configurable database backends: Transient: Mnesia Redis Persistent: RDBMS: MySQL, PostgreSQL, generic ODBC NOSQL: Riak KV, Cassandra Integration with third-party services Amazon Simple Notification Service Supported XEPs XEP Number Name Module 0004 Data Forms 0012 Last Activity mod_last 0016 Privacy Lists mod_privacy 0018 Invisible Presence 0022 Message Events mod_offline 0023 Message Expiration mod_offline 0030 Service Discovery mod_disco 0045 Multi-User Chat mod_muc 0049 Private XML Storage mod_private 0050 Ad-Hoc Commands mod_adhoc 0054 vcard-temp mod_vcard 0055 Jabber Search mod_vcard 0059 Result Set Management 0060 Publish-Subscribe mod_pubsub 0068 Field Standardization for Data Forms 0073 Basic IM Protocol Suite 0077 In-Band Registration mod_register 0079 Advanced Message Processing mod_amp (partial support) 0082 XMPP Date and Time Profiles 0085 Chat State Notifications 0086 Error Condition Mappings 0106 JID Escaping 0114 Jabber Component Protocol ejabberd_service 0115 Entity Capabilities mod_caps 0124 Bidirectional-streams Over Synchronous HTTP (BOSH) mod_bosh 0126 Invisibility mod_privacy 0138 Stream Compression 0153 vCard-Based Avatars mod_vcard 0157 Contact Addresses for XMPP Services mod_disco 0160 Best Practices for Handling Offline Messages mod_offline 0163 Personal Eventing Protocol mod_pubsub 0170 Recommended Order of Stream Feature Negotiation 0175 Best Practices for Use of SASL ANONYMOUS 0185 Dialback Key Generation and Validation 0191 Blocking Command mod_blocking 0198 Stream Management mod_stream_management 0199 XMPP Ping mod_ping 0202 Entity Time 0203 Delayed Delivery 0206 XMPP Over BOSH mod_bosh 0215 External Service Discovery mod_extdisco 0237 Roster Versioning mod_roster 0270 XMPP Advanced Server 2010 0279 Server IP Check mod_sic 0280 Message Carbons mod_carboncopy 0313 Message Archive Management mod_mam 0352 Client State Indication mod_csi 0357 Push Notifications mod_event_pusher_push 0363 HTTP File Upload mod_http_upload 0384 OMEMO Encryption (MongooseIM supports PEP, which is required by this extension) 0387 XMPP Compliance Suites 2018 - all suites, Advanced Server level 0424 Message Retraction mod_mam Supported Open Extensions Name Module MUC Light mod_muc_light Inbox mod_inbox Token-based reconnection mod_auth_token , mod_keystore Integration with other platform components MongoosePUSH MongooseIM can be integrated with MongoosePush . For more details visit the push notification user guide . MongooseICE You can also connect Mongoose with MongooseICE . To get started, we recommend going through this tutorial .","title":"Features and supported standards"},{"location":"user-guide/Features-and-supported-standards/#features-and-supported-standards","text":"XMPP Core: RFC 3920 , RFC 6120 Note: In RFC 6120 there are 3 different strategies defined in case of a session conflict (same full JID). They are described in 7.7.2.2. Conflict . MongooseIM always uses the 3rd option. It terminates the older session with a <conflict/> stream error. XMPP Instant Messaging and Presence: RFC 3921 , RFC 6121 Client connections: over TCP (with TLS/STARTTLS available) as defined in RFC 6120 over WebSockets as defined in RFC 7395 over HTTP(S) long-polling (BOSH) as defined in XEP-0124: Bidirectional-streams Over Synchronous HTTP (BOSH) and XEP-0206: XMPP Over BOSH REST API Server/backend connections: REST API Configurable database backends: Transient: Mnesia Redis Persistent: RDBMS: MySQL, PostgreSQL, generic ODBC NOSQL: Riak KV, Cassandra Integration with third-party services Amazon Simple Notification Service","title":"Features and supported standards"},{"location":"user-guide/Features-and-supported-standards/#supported-xeps","text":"XEP Number Name Module 0004 Data Forms 0012 Last Activity mod_last 0016 Privacy Lists mod_privacy 0018 Invisible Presence 0022 Message Events mod_offline 0023 Message Expiration mod_offline 0030 Service Discovery mod_disco 0045 Multi-User Chat mod_muc 0049 Private XML Storage mod_private 0050 Ad-Hoc Commands mod_adhoc 0054 vcard-temp mod_vcard 0055 Jabber Search mod_vcard 0059 Result Set Management 0060 Publish-Subscribe mod_pubsub 0068 Field Standardization for Data Forms 0073 Basic IM Protocol Suite 0077 In-Band Registration mod_register 0079 Advanced Message Processing mod_amp (partial support) 0082 XMPP Date and Time Profiles 0085 Chat State Notifications 0086 Error Condition Mappings 0106 JID Escaping 0114 Jabber Component Protocol ejabberd_service 0115 Entity Capabilities mod_caps 0124 Bidirectional-streams Over Synchronous HTTP (BOSH) mod_bosh 0126 Invisibility mod_privacy 0138 Stream Compression 0153 vCard-Based Avatars mod_vcard 0157 Contact Addresses for XMPP Services mod_disco 0160 Best Practices for Handling Offline Messages mod_offline 0163 Personal Eventing Protocol mod_pubsub 0170 Recommended Order of Stream Feature Negotiation 0175 Best Practices for Use of SASL ANONYMOUS 0185 Dialback Key Generation and Validation 0191 Blocking Command mod_blocking 0198 Stream Management mod_stream_management 0199 XMPP Ping mod_ping 0202 Entity Time 0203 Delayed Delivery 0206 XMPP Over BOSH mod_bosh 0215 External Service Discovery mod_extdisco 0237 Roster Versioning mod_roster 0270 XMPP Advanced Server 2010 0279 Server IP Check mod_sic 0280 Message Carbons mod_carboncopy 0313 Message Archive Management mod_mam 0352 Client State Indication mod_csi 0357 Push Notifications mod_event_pusher_push 0363 HTTP File Upload mod_http_upload 0384 OMEMO Encryption (MongooseIM supports PEP, which is required by this extension) 0387 XMPP Compliance Suites 2018 - all suites, Advanced Server level 0424 Message Retraction mod_mam","title":"Supported XEPs"},{"location":"user-guide/Features-and-supported-standards/#supported-open-extensions","text":"Name Module MUC Light mod_muc_light Inbox mod_inbox Token-based reconnection mod_auth_token , mod_keystore","title":"Supported Open Extensions"},{"location":"user-guide/Features-and-supported-standards/#integration-with-other-platform-components","text":"","title":"Integration with other platform components"},{"location":"user-guide/Features-and-supported-standards/#mongoosepush","text":"MongooseIM can be integrated with MongoosePush . For more details visit the push notification user guide .","title":"MongoosePUSH"},{"location":"user-guide/Features-and-supported-standards/#mongooseice","text":"You can also connect Mongoose with MongooseICE . To get started, we recommend going through this tutorial .","title":"MongooseICE"},{"location":"user-guide/Getting-started/","text":"In this short guide we will set MongooseIM up and get users chatting right away. The goal is to get to know MongooseIM, set it up, go through basic operations and validation. Warning: This setup is not intended for production. Note: This procedure has been tested on an Ubuntu 18.04.x LTS. Installation We recommend, you install mongooseIM binaries from a package Erlang Solutions delivers. Alternatively, check out our tutorial on How to build MongooseIM from source code for an introduction to compiling, building and testing MongooseIM. Download a package Go to the downloads section of the Erlang Solutions website, and choose the version of MongooseIM you want. The following sections describe the installation process for different operating systems. Ubuntu and Debian Once the deb file is downloaded, open a terminal window and navigate to the directory containing the package. Use the following command to unpack and install MongooseIM: 1 sudo dpkg -i mongooseim_ [ version here ] .deb CentOS An ODBC (RDBMS) driver must be installed on your machine to unpack and install from RPM packages. Enter the following command in a terminal window to install the latest unixODBC driver: 1 sudo yum install unixODBC Once the RPM file is downloaded, open a terminal window and navigate to the directory containing the package. Use the following command to unpack and install MongooseIM: 1 sudo rpm -i mongooseim_ [ version here ] .rpm Running MongooseIM Warning: MongooseIM will use its default database - Mnesia, which is faster and simpler to setup, but not intended for production purposes when it comes to persistent data. Note: It is possible at anytime to use external databases. For more information see the end of this guide. The following command will start the MongooseIM server: 1 mongooseimctl start When you change the config file and want to restart the MongooseIM server: 1 mongooseimctl restart Use the following command to stop the MongooseIM server: 1 mongooseimctl stop This takes a few seconds. At any given time, the following command shows the status of a MongooseIM server: 1 mongooseimctl status If the command replies nodedown then MongooseIM is not running. Else it will show its status starting , started , or stopping , and its version. When needed, you can also launch the server in the interactive mode: 1 mongooseimctl live This will allow you to better detect and understand the errors in the configuration. When MongooseIM is properly running, the Erlang shell/console is then shown. Just type Control-C twice to exit, the server will then be shut down. For running MongooseIM in a non-interactive way within a supervision system (e.g. systemd), it is recommended to use the foreground mode: 1 mongooseimctl foreground Typing Control-C will stop the server. You can check server loglevel: 1 mongooseimctl get_loglevel Run bootstrap scripts for initial configuration: 1 mongooseimctl bootstrap It executes scripts inside the scripts/ directory with a bootstrap prefix in alphabetical order. More information Execute Hello from the scripts/bootstrap01-hello.sh script that you can find in the release directory $REPO_DIR/_build/prod/rel/mongooseim . Chat users Registering (creating) users The default XMPP domain served by MongooseIM right after installation is localhost . You can register (create) users with the mongooseimctl utility. This command registers the user user@domain using password password . 1 mongooseimctl register_identified user domain password Examples: 1 2 3 4 mongooseimctl register_identified alice localhost qwerty mongooseimctl register_identified bob localhost 12345678 mongooseimctl register_identified carol localhost abc123 mongooseimctl register_identified dan localhost dan Warning: The password is entered manually in the command line and history is accessible to the command line users. This method is not recommended for production use, you may prefer for example LDAP. You can check that it has correctly been created: 1 mongooseimctl check_account user host Example: 1 2 3 4 mongooseimctl check_account alice localhost mongooseimctl check_account bob localhost mongooseimctl check_account carol localhost mongooseimctl check_account dan localhost Now you can list all registered users in your host: 1 mongooseimctl registered_users host Example: 1 mongooseimctl registered_users localhost If you want delete users in your host: 1 mongooseimctl unregister user host Example: 1 mongooseimctl unregister dan localhost Populate the contact lists (rosters) For a given user ( localuser and localserver ), add a contact ( user and server ): 1 mongooseimctl add_rosteritem localuser localserver user server nick group subs Examples: 1 2 mongooseimctl add_rosteritem alice localhost bob localhost bob friends both mongooseimctl add_rosteritem bob localhost alice localhost alice friends both Note: The subs parameter is the \"subscription\" to a user's presence. Possible values are: none , from , to , or both . A subscription in both direction means each user will receive each other's presence. Verify the contact list: 1 mongooseimctl get_roster user host Examples: 1 2 3 mongooseimctl get_roster alice localhost mongooseimctl get_roster bob localhost mongooseimctl get_roster carol localhost Basic MongooseIM configuration You can edit the mongooseim.toml file: 1 /etc/mongooseim/mongooseim.toml Warning: We recommend you do not touch the advanced settings at this stage. For each change, edit the configuration file using the right Linux/Unix user. Save (and optionally backup, archive, or version) the configuration file and restart the MongooseIM server. Logging Set your own loglevel in the configuration file: 1 2 [general] loglevel = \"notice\" Save and exit your editor, restart MongooseIM and check your loglevel from the command line: 1 mongooseimctl get_loglevel Read the mongooseim.log file: 1 /var/log/mongooseim/mongooseim.log You can use commands such cat , more or less , even head or tail . In order to see live logs: 1 tail -f /var/log/mongooseim/mongooseim.log Type Ctrl+C to exit. MUC (Multi-User Chat) for groupchats Enable MUC, or Multi-User Chat, for groupchats/channels in the mongooseim.toml file: 1 2 3 4 [modules.mod_muc] host = \"muc.@HOST@\" access = \"muc\" access_create = \"muc_create\" Roster versioning For faster contact list downloads at each client/app (re)connection, edit the configuration file: 1 2 3 [modules.mod_roster] versioning = true store_current_id = true Review configuration If MongooseIM does not start because the configuration file is broken in some way: 1 mongooseimctl live Using an XMPP/Jabber client/app The following steps use the registered users on the MongooseIM server, done above. Users that are registered on your server can now add their accounts in a chat application like Gajim (specifying either the server\u2019s IP address or domain name), and start chatting! Note about session conflicts If you're going to connect several clients with the same username and domain (for example a phone and a laptop), please make sure they are using different resource names (a kind of device/client identifier). This should be configurable in the account settings of every XMPP client. Otherwise, the clients will keep disconnecting each other, because MongooseIM always terminates the older session in case of a conflict. Connect Gajim Gajim is available on Ubuntu, CentOS & Windows. Warning: Gajim has an obsolete UX. However, it is still well maintained, and has a console that is extremely useful for debugging and testing/validation purposes at the XMPP protocol level. Launch Gajim. Ignore the window with Plugin updates. Go to Edit -> Accounts. Click Add in the left part of the window and select I already have an account I want to use , click Forward Enter the user , domain and password for the accounts registered previously on the command line Click Forward and then Finish Ignore the TLS/SSL error/warning and continue Close the Account window. Add your three created users: alice , bob , and carol . Check what users are currently connected: 1 mongooseimctl connected_users_info Chat with another person Use alice 's account to send messages directly to bob and use bob 's account to reply directly to alice . From the MongooseIM command line: 1 mongooseimctl send_message_chat from to body Examples: 1 2 mongooseimctl send_message_chat carol@localhost alice@localhost hello mongooseimctl send_message_chat carol@localhost bob@localhost hi Group chats Use alice 's account to create a groupchat channel on your muc.localhost service, and configure it by making it persistent. Invite bob and carol . From bob 's' and carol 's accounts, accept the invitation and join the channel groupchat. All three users exchange messages. Contact lists Use carol 's account to add alice and bob to her contact list. Use alice 's and bob 's accounts accept those additions. Verify on the MongooseIM server: 1 mongooseimctl get_roster user host Examples: 1 2 3 mongooseimctl get_roster alice localhost mongooseimctl get_roster bob localhost mongooseimctl get_roster carol localhost Profile (vCard) Edit alice 's profile (vCard) in Gajim: Modify Account... , then Profile , just set her Name to Alice . Verify on the MongooseIM server: 1 mongooseimctl get_vcard alice localhost FN Summary Now you have the minimum knowledge: you know how to deploy MongooseIM, configure some basic features, check/verify a few useful items, validate it both on the client and server side, and utilize a few good practices. Summary: command line You know mongooseimctl , with commands such as: start , restart , stop , status , live , foreground get_loglevel register_identified , check_account , registered_users , unregister add_rosteritem , get_roster You can even run mongooseimctl without arguments for a list of available commands. Summary: files You know basic entries in the files: /etc/mongooseim/mongooseim.toml /var/log/mongooseim/mongooseim.log Summary: client/app In an app, you know how to: connect chat with another user create/join groupchats manage contact lists (roster) edit profile (vCard) Go further For the next steps, we now encourage you to: Deploy it as a single node, on a publicly accessible server, with a real routable domain name with its certificate Add an RDBMS for persistent data, and LDAP for user directory Enable message history with MAM (Message Archive Management) Enable file exchange with HTTP file upload, with an S3-compatible object storage server Use a mobile app for users to chat","title":"Getting started"},{"location":"user-guide/Getting-started/#installation","text":"We recommend, you install mongooseIM binaries from a package Erlang Solutions delivers. Alternatively, check out our tutorial on How to build MongooseIM from source code for an introduction to compiling, building and testing MongooseIM.","title":"Installation"},{"location":"user-guide/Getting-started/#download-a-package","text":"Go to the downloads section of the Erlang Solutions website, and choose the version of MongooseIM you want. The following sections describe the installation process for different operating systems.","title":"Download a package"},{"location":"user-guide/Getting-started/#ubuntu-and-debian","text":"Once the deb file is downloaded, open a terminal window and navigate to the directory containing the package. Use the following command to unpack and install MongooseIM: 1 sudo dpkg -i mongooseim_ [ version here ] .deb","title":"Ubuntu and Debian"},{"location":"user-guide/Getting-started/#centos","text":"An ODBC (RDBMS) driver must be installed on your machine to unpack and install from RPM packages. Enter the following command in a terminal window to install the latest unixODBC driver: 1 sudo yum install unixODBC Once the RPM file is downloaded, open a terminal window and navigate to the directory containing the package. Use the following command to unpack and install MongooseIM: 1 sudo rpm -i mongooseim_ [ version here ] .rpm","title":"CentOS"},{"location":"user-guide/Getting-started/#running-mongooseim","text":"Warning: MongooseIM will use its default database - Mnesia, which is faster and simpler to setup, but not intended for production purposes when it comes to persistent data. Note: It is possible at anytime to use external databases. For more information see the end of this guide. The following command will start the MongooseIM server: 1 mongooseimctl start When you change the config file and want to restart the MongooseIM server: 1 mongooseimctl restart Use the following command to stop the MongooseIM server: 1 mongooseimctl stop This takes a few seconds. At any given time, the following command shows the status of a MongooseIM server: 1 mongooseimctl status If the command replies nodedown then MongooseIM is not running. Else it will show its status starting , started , or stopping , and its version. When needed, you can also launch the server in the interactive mode: 1 mongooseimctl live This will allow you to better detect and understand the errors in the configuration. When MongooseIM is properly running, the Erlang shell/console is then shown. Just type Control-C twice to exit, the server will then be shut down. For running MongooseIM in a non-interactive way within a supervision system (e.g. systemd), it is recommended to use the foreground mode: 1 mongooseimctl foreground Typing Control-C will stop the server. You can check server loglevel: 1 mongooseimctl get_loglevel Run bootstrap scripts for initial configuration: 1 mongooseimctl bootstrap It executes scripts inside the scripts/ directory with a bootstrap prefix in alphabetical order. More information Execute Hello from the scripts/bootstrap01-hello.sh script that you can find in the release directory $REPO_DIR/_build/prod/rel/mongooseim .","title":"Running MongooseIM"},{"location":"user-guide/Getting-started/#chat-users","text":"","title":"Chat users"},{"location":"user-guide/Getting-started/#registering-creating-users","text":"The default XMPP domain served by MongooseIM right after installation is localhost . You can register (create) users with the mongooseimctl utility. This command registers the user user@domain using password password . 1 mongooseimctl register_identified user domain password Examples: 1 2 3 4 mongooseimctl register_identified alice localhost qwerty mongooseimctl register_identified bob localhost 12345678 mongooseimctl register_identified carol localhost abc123 mongooseimctl register_identified dan localhost dan Warning: The password is entered manually in the command line and history is accessible to the command line users. This method is not recommended for production use, you may prefer for example LDAP. You can check that it has correctly been created: 1 mongooseimctl check_account user host Example: 1 2 3 4 mongooseimctl check_account alice localhost mongooseimctl check_account bob localhost mongooseimctl check_account carol localhost mongooseimctl check_account dan localhost Now you can list all registered users in your host: 1 mongooseimctl registered_users host Example: 1 mongooseimctl registered_users localhost If you want delete users in your host: 1 mongooseimctl unregister user host Example: 1 mongooseimctl unregister dan localhost","title":"Registering (creating) users"},{"location":"user-guide/Getting-started/#populate-the-contact-lists-rosters","text":"For a given user ( localuser and localserver ), add a contact ( user and server ): 1 mongooseimctl add_rosteritem localuser localserver user server nick group subs Examples: 1 2 mongooseimctl add_rosteritem alice localhost bob localhost bob friends both mongooseimctl add_rosteritem bob localhost alice localhost alice friends both Note: The subs parameter is the \"subscription\" to a user's presence. Possible values are: none , from , to , or both . A subscription in both direction means each user will receive each other's presence. Verify the contact list: 1 mongooseimctl get_roster user host Examples: 1 2 3 mongooseimctl get_roster alice localhost mongooseimctl get_roster bob localhost mongooseimctl get_roster carol localhost","title":"Populate the contact lists (rosters)"},{"location":"user-guide/Getting-started/#basic-mongooseim-configuration","text":"You can edit the mongooseim.toml file: 1 /etc/mongooseim/mongooseim.toml Warning: We recommend you do not touch the advanced settings at this stage. For each change, edit the configuration file using the right Linux/Unix user. Save (and optionally backup, archive, or version) the configuration file and restart the MongooseIM server.","title":"Basic MongooseIM configuration"},{"location":"user-guide/Getting-started/#logging","text":"Set your own loglevel in the configuration file: 1 2 [general] loglevel = \"notice\" Save and exit your editor, restart MongooseIM and check your loglevel from the command line: 1 mongooseimctl get_loglevel Read the mongooseim.log file: 1 /var/log/mongooseim/mongooseim.log You can use commands such cat , more or less , even head or tail . In order to see live logs: 1 tail -f /var/log/mongooseim/mongooseim.log Type Ctrl+C to exit.","title":"Logging"},{"location":"user-guide/Getting-started/#muc-multi-user-chat-for-groupchats","text":"Enable MUC, or Multi-User Chat, for groupchats/channels in the mongooseim.toml file: 1 2 3 4 [modules.mod_muc] host = \"muc.@HOST@\" access = \"muc\" access_create = \"muc_create\"","title":"MUC (Multi-User Chat) for groupchats"},{"location":"user-guide/Getting-started/#roster-versioning","text":"For faster contact list downloads at each client/app (re)connection, edit the configuration file: 1 2 3 [modules.mod_roster] versioning = true store_current_id = true","title":"Roster versioning"},{"location":"user-guide/Getting-started/#review-configuration","text":"If MongooseIM does not start because the configuration file is broken in some way: 1 mongooseimctl live","title":"Review configuration"},{"location":"user-guide/Getting-started/#using-an-xmppjabber-clientapp","text":"The following steps use the registered users on the MongooseIM server, done above. Users that are registered on your server can now add their accounts in a chat application like Gajim (specifying either the server\u2019s IP address or domain name), and start chatting!","title":"Using an XMPP/Jabber client/app"},{"location":"user-guide/Getting-started/#note-about-session-conflicts","text":"If you're going to connect several clients with the same username and domain (for example a phone and a laptop), please make sure they are using different resource names (a kind of device/client identifier). This should be configurable in the account settings of every XMPP client. Otherwise, the clients will keep disconnecting each other, because MongooseIM always terminates the older session in case of a conflict.","title":"Note about session conflicts"},{"location":"user-guide/Getting-started/#connect-gajim","text":"Gajim is available on Ubuntu, CentOS & Windows. Warning: Gajim has an obsolete UX. However, it is still well maintained, and has a console that is extremely useful for debugging and testing/validation purposes at the XMPP protocol level. Launch Gajim. Ignore the window with Plugin updates. Go to Edit -> Accounts. Click Add in the left part of the window and select I already have an account I want to use , click Forward Enter the user , domain and password for the accounts registered previously on the command line Click Forward and then Finish Ignore the TLS/SSL error/warning and continue Close the Account window. Add your three created users: alice , bob , and carol . Check what users are currently connected: 1 mongooseimctl connected_users_info","title":"Connect Gajim"},{"location":"user-guide/Getting-started/#chat-with-another-person","text":"Use alice 's account to send messages directly to bob and use bob 's account to reply directly to alice . From the MongooseIM command line: 1 mongooseimctl send_message_chat from to body Examples: 1 2 mongooseimctl send_message_chat carol@localhost alice@localhost hello mongooseimctl send_message_chat carol@localhost bob@localhost hi","title":"Chat with another person"},{"location":"user-guide/Getting-started/#group-chats","text":"Use alice 's account to create a groupchat channel on your muc.localhost service, and configure it by making it persistent. Invite bob and carol . From bob 's' and carol 's accounts, accept the invitation and join the channel groupchat. All three users exchange messages.","title":"Group chats"},{"location":"user-guide/Getting-started/#contact-lists","text":"Use carol 's account to add alice and bob to her contact list. Use alice 's and bob 's accounts accept those additions. Verify on the MongooseIM server: 1 mongooseimctl get_roster user host Examples: 1 2 3 mongooseimctl get_roster alice localhost mongooseimctl get_roster bob localhost mongooseimctl get_roster carol localhost","title":"Contact lists"},{"location":"user-guide/Getting-started/#profile-vcard","text":"Edit alice 's profile (vCard) in Gajim: Modify Account... , then Profile , just set her Name to Alice . Verify on the MongooseIM server: 1 mongooseimctl get_vcard alice localhost FN","title":"Profile (vCard)"},{"location":"user-guide/Getting-started/#summary","text":"Now you have the minimum knowledge: you know how to deploy MongooseIM, configure some basic features, check/verify a few useful items, validate it both on the client and server side, and utilize a few good practices.","title":"Summary"},{"location":"user-guide/Getting-started/#summary-command-line","text":"You know mongooseimctl , with commands such as: start , restart , stop , status , live , foreground get_loglevel register_identified , check_account , registered_users , unregister add_rosteritem , get_roster You can even run mongooseimctl without arguments for a list of available commands.","title":"Summary: command line"},{"location":"user-guide/Getting-started/#summary-files","text":"You know basic entries in the files: /etc/mongooseim/mongooseim.toml /var/log/mongooseim/mongooseim.log","title":"Summary: files"},{"location":"user-guide/Getting-started/#summary-clientapp","text":"In an app, you know how to: connect chat with another user create/join groupchats manage contact lists (roster) edit profile (vCard)","title":"Summary: client/app"},{"location":"user-guide/Getting-started/#go-further","text":"For the next steps, we now encourage you to: Deploy it as a single node, on a publicly accessible server, with a real routable domain name with its certificate Add an RDBMS for persistent data, and LDAP for user directory Enable message history with MAM (Message Archive Management) Enable file exchange with HTTP file upload, with an S3-compatible object storage server Use a mobile app for users to chat","title":"Go further"},{"location":"user-guide/How-to-build/","text":"How to build MongooseIM Instructions provided in this page are verified for: CentOS 7 Ubuntu 16.04 LTS (Xenial) Ubuntu 18.04 LTS (Bionic) macOS 10.14 (Mojave) For any other OS versions, the instructions should still work, however, some steps or file paths may be different. Requirements To compile MongooseIM you need: Make CentOS: make Ubuntu: make Mac: Xcode Command Line Tools C and C++ compiler CentOS: gcc , gcc-c++ Ubuntu: gcc , g++ Mac: Xcode Command Line Tools Erlang/OTP 21.2 or higher; CentOS: erlang Ubuntu: erlang Mac (Homebrew): erlang Alternative for CentOS and Ubuntu: esl-erlang from Erlang Solutions website Alternative for all OS: kerl OpenSSL 0.9.8 or higher, for STARTTLS, SASL and SSL encryption CentOS: openssl and openssl-devel Ubuntu: libssl-dev Mac (Homebrew): openssl ODBC library CentOS: unixODBC-devel Ubuntu: unixodbc-dev Mac (Homebrew): unixodbc Zlib 1.2.3 or higher CentOS: zlib-devel Ubuntu: zlib1g-dev Mac: built-in Preparing macOS environment Step 1 Install Homebrew to manage packages on your Mac. You may use a different package manager but you'll need to figure out the package names and file paths on your own. Step 2 Install Xcode Command Line Tools. 1 xcode-select --install # install compilation tools Step 3 Install dependencies with Brew. 1 brew install erlang openssl unixodbc Step 4 Add OpenSSL paths to the compiler and linker environment variables: 1 2 export LDFLAGS = \"-L/usr/local/opt/openssl/lib\" export CFLAGS = \"-I/usr/local/opt/openssl/include\" Now, please proceed to the \"Building\" section. Preparing CentOS environment Please install the required dependencies: 1 sudo yum install git make zlib-devel openssl openssl-devel unixODBC-devel gcc gcc-c++ erlang Now, please proceed to the \"Building\" section. Preparing Ubuntu environment Please install the required dependencies: 1 sudo apt install git make zlib1g-dev libssl-dev unixodbc-dev gcc g++ erlang Now, please proceed to the \"Building\" section. Building To compile MongooseIM, navigate to the main repo directory (referenced as $REPO in this guide) and execute: 1 make [ rel ] rel is optional as it is the default target. This will download all dependencies, compile everything and build a prod release. If a more advanced release is required (with only specific DB support, e.g. mysql or pgsql) or you want to set the prefix or user for the installation script please refer to the release configuration page in our documentation. The make rel commands will generate a self-contained OTP system structure in the project's _build/prod/rel/mongooseim subdirectory. The contents of that directory are as follows: bin - startup/administration scripts, etc - configuration files, lib - MongooseIM binary, header and runtime files, var - spool directory, log - log file directory, releases - release files directory. Running MongooseIM To run MongooseIM from the project tree after compiling it, change to $REPO/_build/prod/rel/mongooseim . There you can use the mongooseim command line administration script to start and stop MongooseIM. For example, this command will start the server: 1 bin/mongooseim start You can also run the server in interactive mode (drop into an Erlang shell): 1 bin/mongooseim live There's also a tool called mongooseimctl to perform some operations on a running instance, e.g.: 1 2 3 4 5 6 7 8 9 10 $ bin/mongooseimctl status MongooseIM node mongooseim@localhost: operating system pid: 3105 Erlang VM status: started (of: starting | started | stopping) boot script status: started version: 3.4.0-7-gaec944c92 (as mongooseim) uptime: 0 days 00:00:12 distribution protocol: inet_tcp logs: log/mongooseim.log Building the testing target and running tests For testing purposes there's a different make target available: 1 make devrel which will generate releases mim1 , mim2 , mim3 , fed1 , reg1 in $REPO/_build/ and prepare them for testing and generating coverage reports. In order to learn how to execute tests, please consult Testing MongooseIM page .","title":"How to Build MongooseIM from source code"},{"location":"user-guide/How-to-build/#how-to-build-mongooseim","text":"Instructions provided in this page are verified for: CentOS 7 Ubuntu 16.04 LTS (Xenial) Ubuntu 18.04 LTS (Bionic) macOS 10.14 (Mojave) For any other OS versions, the instructions should still work, however, some steps or file paths may be different.","title":"How to build MongooseIM"},{"location":"user-guide/How-to-build/#requirements","text":"To compile MongooseIM you need: Make CentOS: make Ubuntu: make Mac: Xcode Command Line Tools C and C++ compiler CentOS: gcc , gcc-c++ Ubuntu: gcc , g++ Mac: Xcode Command Line Tools Erlang/OTP 21.2 or higher; CentOS: erlang Ubuntu: erlang Mac (Homebrew): erlang Alternative for CentOS and Ubuntu: esl-erlang from Erlang Solutions website Alternative for all OS: kerl OpenSSL 0.9.8 or higher, for STARTTLS, SASL and SSL encryption CentOS: openssl and openssl-devel Ubuntu: libssl-dev Mac (Homebrew): openssl ODBC library CentOS: unixODBC-devel Ubuntu: unixodbc-dev Mac (Homebrew): unixodbc Zlib 1.2.3 or higher CentOS: zlib-devel Ubuntu: zlib1g-dev Mac: built-in","title":"Requirements"},{"location":"user-guide/How-to-build/#preparing-macos-environment","text":"","title":"Preparing macOS environment"},{"location":"user-guide/How-to-build/#step-1","text":"Install Homebrew to manage packages on your Mac. You may use a different package manager but you'll need to figure out the package names and file paths on your own.","title":"Step 1"},{"location":"user-guide/How-to-build/#step-2","text":"Install Xcode Command Line Tools. 1 xcode-select --install # install compilation tools","title":"Step 2"},{"location":"user-guide/How-to-build/#step-3","text":"Install dependencies with Brew. 1 brew install erlang openssl unixodbc","title":"Step 3"},{"location":"user-guide/How-to-build/#step-4","text":"Add OpenSSL paths to the compiler and linker environment variables: 1 2 export LDFLAGS = \"-L/usr/local/opt/openssl/lib\" export CFLAGS = \"-I/usr/local/opt/openssl/include\" Now, please proceed to the \"Building\" section.","title":"Step 4"},{"location":"user-guide/How-to-build/#preparing-centos-environment","text":"Please install the required dependencies: 1 sudo yum install git make zlib-devel openssl openssl-devel unixODBC-devel gcc gcc-c++ erlang Now, please proceed to the \"Building\" section.","title":"Preparing CentOS environment"},{"location":"user-guide/How-to-build/#preparing-ubuntu-environment","text":"Please install the required dependencies: 1 sudo apt install git make zlib1g-dev libssl-dev unixodbc-dev gcc g++ erlang Now, please proceed to the \"Building\" section.","title":"Preparing Ubuntu environment"},{"location":"user-guide/How-to-build/#building","text":"To compile MongooseIM, navigate to the main repo directory (referenced as $REPO in this guide) and execute: 1 make [ rel ] rel is optional as it is the default target. This will download all dependencies, compile everything and build a prod release. If a more advanced release is required (with only specific DB support, e.g. mysql or pgsql) or you want to set the prefix or user for the installation script please refer to the release configuration page in our documentation. The make rel commands will generate a self-contained OTP system structure in the project's _build/prod/rel/mongooseim subdirectory. The contents of that directory are as follows: bin - startup/administration scripts, etc - configuration files, lib - MongooseIM binary, header and runtime files, var - spool directory, log - log file directory, releases - release files directory.","title":"Building"},{"location":"user-guide/How-to-build/#running-mongooseim","text":"To run MongooseIM from the project tree after compiling it, change to $REPO/_build/prod/rel/mongooseim . There you can use the mongooseim command line administration script to start and stop MongooseIM. For example, this command will start the server: 1 bin/mongooseim start You can also run the server in interactive mode (drop into an Erlang shell): 1 bin/mongooseim live There's also a tool called mongooseimctl to perform some operations on a running instance, e.g.: 1 2 3 4 5 6 7 8 9 10 $ bin/mongooseimctl status MongooseIM node mongooseim@localhost: operating system pid: 3105 Erlang VM status: started (of: starting | started | stopping) boot script status: started version: 3.4.0-7-gaec944c92 (as mongooseim) uptime: 0 days 00:00:12 distribution protocol: inet_tcp logs: log/mongooseim.log","title":"Running MongooseIM"},{"location":"user-guide/How-to-build/#building-the-testing-target-and-running-tests","text":"For testing purposes there's a different make target available: 1 make devrel which will generate releases mim1 , mim2 , mim3 , fed1 , reg1 in $REPO/_build/ and prepare them for testing and generating coverage reports. In order to learn how to execute tests, please consult Testing MongooseIM page .","title":"Building the testing target and running tests"},{"location":"user-guide/ICE_tutorial/","text":"How to set up MongooseICE (ICE/TURN/STUN server) Introduction Who is this document for? This tutorial presents our TURN/STUN server in action. You get to see how to set up and configure MongooseICE and examine a system utilising its many talents. Are you in need of an application requiring NAT traversal? Want to see how a TURN and STUN server would handle it? Or maybe you just like to tinker with interesting technologies and experience setting them up first hand? If that's the case, this tutorial is for you. What is the end result of this tutorial? At the end of the tutorial you will have a working environment with two peers, one sending a live video to another. The peer-to-peer communication will not be obstructed by any NATs that may occur in the background. The live video stream is only an example here - there are many possible use cases for peer-to-peer communication with NAT traversal. We chose to build an example application that shows video streaming, because it's vivid, catchy and fun. What do I need to begin? Before you begin you have to prepare an environment for setting up the components used in this tutorial. Here's a list of things you'll need: * One Android phone (or at least an Android emulator). The video player in this tutorial is available only as an Android application. * RaspberryPi or any other device that is able to run Elixir code . Oh, and also has ffmpeg installed. We are going to use use RaspberryPi 3, to give this tutorial a hint of IoT. * At least one machine with a public IPv4 address. It is necessary, because both MongooseIM and MongooseICE servers need to be accessible by all devices that are used in this demo system. You could use a private, local IP address, but then you would need to ensure that your phone and the RaspberryPi are behind some kind of a NAT relative to this IP address. Note: the demo will probably work without the NAT, but then there is no point in setting up a TURN server. We are going to use 2 VPS (Virtual Private Server) that are located somewhere far far away, both having public IPv4 address. Let's say MongooseICE is bound to 1.1.1.1 , and MongooseIM to 2.2.2.2 . General architecture of the environment built with this tutorial This is the architecture of the system we are building: As we know by now, MongooseIM is bound to 2.2.2.2 / myxmpp.com and MongooseICE to 1.1.1.1 . We also have a RaspberryPi that is connected to a private network (so is behind some NAT) and an Android phone that is connected to an LTE network and also is behind the carrier's NAT. ICE notes The end result of this tutorial not only uses MongooseICE and MongooseIM servers but also uses custom version of Mangosta-Android and [DemoStreamerICE]. Both projects are custom modified and custom made respectively in order to showcase the video streaming using the data relay capabilities provided by MongooseICE . The streaming itself, along with the signalling protocol, were prepared only for the case of this demo and are not a part of the platform . Those components exist only to visualize what can be achieved with MongooseICE and what can be built on top of it. Setting up MongooseIM (signalling) The ICE is nothing without signalling. The signalling protocol itself can be designed specifically for the application that is being deployed or can be implemented based on some standards, e.g. Jingle . Here, we chose to implement the simplest signalling possible, i.e. sending relay addresses via XMPP messages. No matter if we decide to go with this approach or with Jingle , we can use the MongooseIM XMPP server as a transport layer for the signalling. In order to enable signalling we need an instance of MongooseIM running with the simplest configuration, since the only thing we need from it is to provide us with means to communicate between two peers. Configuration You can find MongooseIM installation instructions on this page . Once you have cloned the repository and compiled the project, you need to modify the mongooseim.toml config file (you can find this file at $REPO/_build/prod/rel/mongooseim/etc/mongooseim.toml , where $REPO is a top-level directory of the cloned repo). 1 2 [general] hosts = [\"localhost\", \"myxmpp.com\"] This sets the virtual hostname of the XMPP server, so that you can register users in this domain. After that, you can start MongooseIM with 1 $REPO /_build/prod/rel/mongooseim/bin/mongooseimctl start Users After we finish setting up MongooseIM , we need to register some users. For this demo we need two users: movie@myxmpp.com and phone@myxmpp.com , for RaspberryPi and the Android phone respectively. In order to do that, type: 1 2 $REPO /_build/prod/rel/mongooseim/bin/mongooseimctl register_identified phone myxmpp.com xmpp_password $REPO /_build/prod/rel/mongooseim/bin/mongooseimctl register_identified movie myxmpp.com xmpp_password on the machine that has MongooseIM installed. As you can see here, we have created those two users, both with the password xmpp_password for simplicity. Setting up MongooseICE (TURN/STUN server) Now, since MongooseIM handles the signalling, we need the TURN relay and the STUN server to send peer-to-peer data. For that we are going to use the star of this tutorial - MongooseICE . How to get and configure The whole documentation that describes all options and deployment methods, can be found on the project's github page . Let's get to it! (this command assumes that we are on the server for MongooseICE and that it has Docker installed): 1 docker run -it --net = host -e \"MONGOOSEICE_UDP_RELAY_IP=1.1.1.1\" -e \"MONGOOSEICE_STUN_SECRET=secret\" -e \"MONGOOSEICE_UDP_REALM=myrelay\" mongooseim/mongooseice:0.4.0 This command starts the MongooseICE server in the Docker container, attaching its virtual network interface to the network interface of the host machine the Docker deamon is running on. There are three important configuration options we have to set via environment variables: MONGOOSEICE_UDP_RELAY_IP - This is the IP address that MongooseICE provides data relay on. This should be set to public IPv4 address. MONGOOSEICE_STUN_SECRET - This is a secret password that TURN clients need to provide to connect to this server. MONGOOSEICE_UDP_REALM - This is just a name for your TURN relay. And that's it! MongooseICE is now ready to roll! Setting up Mangosta-Android How to get and install The source code of the video-stream-demo-enabled Mangosta-Android can be found on the ice_demo_kt branch. If you want to tinker with it and compile it yourself, you can do that. All you need is Android Studio 2.3+ . The compilation is pretty straightforward, so I'm not going to explain it here. If you are interested in how it works, most of the code is in the inaka.com.mangosta.videostream package. If you don't want to compile this application from source, you can just install this .apk on your phone and that's it. How to configure Right after you start Mangosta-Android for the first time, you will need to login to your XMPP server. In order to do that, just enter the JID you have created for the phone ( phone@myxmpp.com ), the password ( xmpp_password ) and the server address ( 2.2.2.2 or myxmpp.com if you've set up the domain to actually point to this IP address), and then confirm by clicking \"Enter\". After we log in, we can start setting up the connection to the MongooseICE server we set up before. The process is shown on the screenshots below. On the \" Configure ICE \" screen we have to set 5 fields up: TURN server address - IPv4 address of our MongooseICE TURN Server port - since we did not set the port while configuring MongooseICE it uses a default one - 3478 TURN Realm - Realm name we have set via MONGOOSEICE_UDP_REALM variable. In our case it's \" myrelay \". TURN username - Current version of MongooseICE ignores this, so you may leave it as is. TURN password - The password that we have set via MONGOOSEICE_STUN_SECRET variable. In our case it's \" secret \" And that would be all. Now you can click \" TEST CONNECTION \" to, well..., test the connection. If everything works, you can \" SAVE \" the settings. Now your Mangosta-Android is ready to play streamed video, but we still need the source... Setting up RaspberryPi Let's configure the video source now. In our case it will be a RaspberryPi with Elixir and ffmpeg installed running our ICE demo application . The software For this demo we provide a simple XMPP client that also is able to send live video stream using ffmpeg whenever other peer asks for it via XMPP. This client is written in Elixir , so we can run it from source quite easily. How to get and configure You can get the client's sources here . For now we only need to run it, so let's get to it (on our RaspberryPi): 1 2 3 4 git clone https://github.com/esl/ice_demo.git cd ice_demo mix deps.get iex -S mix After a while we should get into Elixir shell. In order to enable the streamer, we need to start it, providing some configuration options (in the Elixir shell): 1 2 3 4 5 6 7 8 9 10 opts = [ jid : \"movie@myxmpp.com\" , password : \"xmpp_password\" , host : \"myxmpp.com\" , turn_addr : \"1.1.1.1:3784\" turn_username : \"username\" , turn_secret : \"secret\" , video_file : \"/home/pi/sintel.h264\" ] ICEDemo . start_movie ( opts ) The first 3 options are all about connecting to the XMPP server - we use \" movie@myxmpp.com \" user that we created earlier. Next 3 options are about connecting to the MongooseICE server. Those are similar to ones we set in Mangosta-Android . The last one points to the video file that will be streamed on request. This file has to be raw, H.264-encoded, video-only file. If you are not sure how to get one, you can just use this one (pre-rendered Sintel, OpenBlender project ). With this configuration, our RaspberryPi is ready to stream! The end result Playing the video Now we finally can get out phone and start streaming the video! In order to do that, we have to click the \" New video stream \" button as shown on the screenshots below, enter the JID of the RaspberryPi and confirm with the \" Stream! \" button. Hopefully, now you can see the video on your own mobile device.","title":"How to Set up MongooseICE"},{"location":"user-guide/ICE_tutorial/#how-to-set-up-mongooseice-iceturnstun-server","text":"","title":"How to set up MongooseICE (ICE/TURN/STUN server)"},{"location":"user-guide/ICE_tutorial/#introduction","text":"","title":"Introduction"},{"location":"user-guide/ICE_tutorial/#who-is-this-document-for","text":"This tutorial presents our TURN/STUN server in action. You get to see how to set up and configure MongooseICE and examine a system utilising its many talents. Are you in need of an application requiring NAT traversal? Want to see how a TURN and STUN server would handle it? Or maybe you just like to tinker with interesting technologies and experience setting them up first hand? If that's the case, this tutorial is for you.","title":"Who is this document for?"},{"location":"user-guide/ICE_tutorial/#what-is-the-end-result-of-this-tutorial","text":"At the end of the tutorial you will have a working environment with two peers, one sending a live video to another. The peer-to-peer communication will not be obstructed by any NATs that may occur in the background. The live video stream is only an example here - there are many possible use cases for peer-to-peer communication with NAT traversal. We chose to build an example application that shows video streaming, because it's vivid, catchy and fun.","title":"What is the end result of this tutorial?"},{"location":"user-guide/ICE_tutorial/#what-do-i-need-to-begin","text":"Before you begin you have to prepare an environment for setting up the components used in this tutorial. Here's a list of things you'll need: * One Android phone (or at least an Android emulator). The video player in this tutorial is available only as an Android application. * RaspberryPi or any other device that is able to run Elixir code . Oh, and also has ffmpeg installed. We are going to use use RaspberryPi 3, to give this tutorial a hint of IoT. * At least one machine with a public IPv4 address. It is necessary, because both MongooseIM and MongooseICE servers need to be accessible by all devices that are used in this demo system. You could use a private, local IP address, but then you would need to ensure that your phone and the RaspberryPi are behind some kind of a NAT relative to this IP address. Note: the demo will probably work without the NAT, but then there is no point in setting up a TURN server. We are going to use 2 VPS (Virtual Private Server) that are located somewhere far far away, both having public IPv4 address. Let's say MongooseICE is bound to 1.1.1.1 , and MongooseIM to 2.2.2.2 .","title":"What do I need to begin?"},{"location":"user-guide/ICE_tutorial/#general-architecture-of-the-environment-built-with-this-tutorial","text":"This is the architecture of the system we are building: As we know by now, MongooseIM is bound to 2.2.2.2 / myxmpp.com and MongooseICE to 1.1.1.1 . We also have a RaspberryPi that is connected to a private network (so is behind some NAT) and an Android phone that is connected to an LTE network and also is behind the carrier's NAT.","title":"General architecture of the environment built with this tutorial"},{"location":"user-guide/ICE_tutorial/#ice-notes","text":"The end result of this tutorial not only uses MongooseICE and MongooseIM servers but also uses custom version of Mangosta-Android and [DemoStreamerICE]. Both projects are custom modified and custom made respectively in order to showcase the video streaming using the data relay capabilities provided by MongooseICE . The streaming itself, along with the signalling protocol, were prepared only for the case of this demo and are not a part of the platform . Those components exist only to visualize what can be achieved with MongooseICE and what can be built on top of it.","title":"ICE notes"},{"location":"user-guide/ICE_tutorial/#setting-up-mongooseim-signalling","text":"The ICE is nothing without signalling. The signalling protocol itself can be designed specifically for the application that is being deployed or can be implemented based on some standards, e.g. Jingle . Here, we chose to implement the simplest signalling possible, i.e. sending relay addresses via XMPP messages. No matter if we decide to go with this approach or with Jingle , we can use the MongooseIM XMPP server as a transport layer for the signalling. In order to enable signalling we need an instance of MongooseIM running with the simplest configuration, since the only thing we need from it is to provide us with means to communicate between two peers.","title":"Setting up MongooseIM (signalling)"},{"location":"user-guide/ICE_tutorial/#configuration","text":"You can find MongooseIM installation instructions on this page . Once you have cloned the repository and compiled the project, you need to modify the mongooseim.toml config file (you can find this file at $REPO/_build/prod/rel/mongooseim/etc/mongooseim.toml , where $REPO is a top-level directory of the cloned repo). 1 2 [general] hosts = [\"localhost\", \"myxmpp.com\"] This sets the virtual hostname of the XMPP server, so that you can register users in this domain. After that, you can start MongooseIM with 1 $REPO /_build/prod/rel/mongooseim/bin/mongooseimctl start","title":"Configuration"},{"location":"user-guide/ICE_tutorial/#users","text":"After we finish setting up MongooseIM , we need to register some users. For this demo we need two users: movie@myxmpp.com and phone@myxmpp.com , for RaspberryPi and the Android phone respectively. In order to do that, type: 1 2 $REPO /_build/prod/rel/mongooseim/bin/mongooseimctl register_identified phone myxmpp.com xmpp_password $REPO /_build/prod/rel/mongooseim/bin/mongooseimctl register_identified movie myxmpp.com xmpp_password on the machine that has MongooseIM installed. As you can see here, we have created those two users, both with the password xmpp_password for simplicity.","title":"Users"},{"location":"user-guide/ICE_tutorial/#setting-up-mongooseice-turnstun-server","text":"Now, since MongooseIM handles the signalling, we need the TURN relay and the STUN server to send peer-to-peer data. For that we are going to use the star of this tutorial - MongooseICE .","title":"Setting up MongooseICE (TURN/STUN server)"},{"location":"user-guide/ICE_tutorial/#how-to-get-and-configure","text":"The whole documentation that describes all options and deployment methods, can be found on the project's github page . Let's get to it! (this command assumes that we are on the server for MongooseICE and that it has Docker installed): 1 docker run -it --net = host -e \"MONGOOSEICE_UDP_RELAY_IP=1.1.1.1\" -e \"MONGOOSEICE_STUN_SECRET=secret\" -e \"MONGOOSEICE_UDP_REALM=myrelay\" mongooseim/mongooseice:0.4.0 This command starts the MongooseICE server in the Docker container, attaching its virtual network interface to the network interface of the host machine the Docker deamon is running on. There are three important configuration options we have to set via environment variables: MONGOOSEICE_UDP_RELAY_IP - This is the IP address that MongooseICE provides data relay on. This should be set to public IPv4 address. MONGOOSEICE_STUN_SECRET - This is a secret password that TURN clients need to provide to connect to this server. MONGOOSEICE_UDP_REALM - This is just a name for your TURN relay. And that's it! MongooseICE is now ready to roll!","title":"How to get and configure"},{"location":"user-guide/ICE_tutorial/#setting-up-mangosta-android","text":"","title":"Setting up Mangosta-Android"},{"location":"user-guide/ICE_tutorial/#how-to-get-and-install","text":"The source code of the video-stream-demo-enabled Mangosta-Android can be found on the ice_demo_kt branch. If you want to tinker with it and compile it yourself, you can do that. All you need is Android Studio 2.3+ . The compilation is pretty straightforward, so I'm not going to explain it here. If you are interested in how it works, most of the code is in the inaka.com.mangosta.videostream package. If you don't want to compile this application from source, you can just install this .apk on your phone and that's it.","title":"How to get and install"},{"location":"user-guide/ICE_tutorial/#how-to-configure","text":"Right after you start Mangosta-Android for the first time, you will need to login to your XMPP server. In order to do that, just enter the JID you have created for the phone ( phone@myxmpp.com ), the password ( xmpp_password ) and the server address ( 2.2.2.2 or myxmpp.com if you've set up the domain to actually point to this IP address), and then confirm by clicking \"Enter\". After we log in, we can start setting up the connection to the MongooseICE server we set up before. The process is shown on the screenshots below. On the \" Configure ICE \" screen we have to set 5 fields up: TURN server address - IPv4 address of our MongooseICE TURN Server port - since we did not set the port while configuring MongooseICE it uses a default one - 3478 TURN Realm - Realm name we have set via MONGOOSEICE_UDP_REALM variable. In our case it's \" myrelay \". TURN username - Current version of MongooseICE ignores this, so you may leave it as is. TURN password - The password that we have set via MONGOOSEICE_STUN_SECRET variable. In our case it's \" secret \" And that would be all. Now you can click \" TEST CONNECTION \" to, well..., test the connection. If everything works, you can \" SAVE \" the settings. Now your Mangosta-Android is ready to play streamed video, but we still need the source...","title":"How to configure"},{"location":"user-guide/ICE_tutorial/#setting-up-raspberrypi","text":"Let's configure the video source now. In our case it will be a RaspberryPi with Elixir and ffmpeg installed running our ICE demo application .","title":"Setting up RaspberryPi"},{"location":"user-guide/ICE_tutorial/#the-software","text":"For this demo we provide a simple XMPP client that also is able to send live video stream using ffmpeg whenever other peer asks for it via XMPP. This client is written in Elixir , so we can run it from source quite easily.","title":"The software"},{"location":"user-guide/ICE_tutorial/#how-to-get-and-configure_1","text":"You can get the client's sources here . For now we only need to run it, so let's get to it (on our RaspberryPi): 1 2 3 4 git clone https://github.com/esl/ice_demo.git cd ice_demo mix deps.get iex -S mix After a while we should get into Elixir shell. In order to enable the streamer, we need to start it, providing some configuration options (in the Elixir shell): 1 2 3 4 5 6 7 8 9 10 opts = [ jid : \"movie@myxmpp.com\" , password : \"xmpp_password\" , host : \"myxmpp.com\" , turn_addr : \"1.1.1.1:3784\" turn_username : \"username\" , turn_secret : \"secret\" , video_file : \"/home/pi/sintel.h264\" ] ICEDemo . start_movie ( opts ) The first 3 options are all about connecting to the XMPP server - we use \" movie@myxmpp.com \" user that we created earlier. Next 3 options are about connecting to the MongooseICE server. Those are similar to ones we set in Mangosta-Android . The last one points to the video file that will be streamed on request. This file has to be raw, H.264-encoded, video-only file. If you are not sure how to get one, you can just use this one (pre-rendered Sintel, OpenBlender project ). With this configuration, our RaspberryPi is ready to stream!","title":"How to get and configure"},{"location":"user-guide/ICE_tutorial/#the-end-result","text":"","title":"The end result"},{"location":"user-guide/ICE_tutorial/#playing-the-video","text":"Now we finally can get out phone and start streaming the video! In order to do that, we have to click the \" New video stream \" button as shown on the screenshots below, enter the JID of the RaspberryPi and confirm with the \" Stream! \" button. Hopefully, now you can see the video on your own mobile device.","title":"Playing the video"},{"location":"user-guide/Jingle-SIP-setup/","text":"Jingle/SIP setup proof of concept This tutorial will show you how to configure MongooseIM, Routr (a SIP server) and client applications to demonstrate how the Jingle/SIP integration works. Prerequisites We are going to use the following open source software: MongooseIM - https://github.com/esl/MongooseIM see How-to-build for details on building. It's important to remember to run the configuration script with with-jingle-sip flag set: tools/configure with-jingle-sip . Without this, third party dependencies required by the Jingle/SIP translator will not be included in the release. Routr (SIP server) - https://routr.io I recommend downloading binaries for your system from official source . Jitsi (XMPP and SIP client application) - https://desktop.jitsi.org Otalk - web based XMPP client - https://github.com/otalk/otalk-im-client Folow the instructions on otalk-im-client#installing to run it We will use 2 users xmpp.user@xmpp.example and sip.user@sip.example . Configuring Routr First the domain sip.example needs to be added to domains served by Routr. To do it, paste the following content to config/domains.yml in the directory where Routr was: 1 2 3 4 5 6 7 - apiVersion : v1beta1 kind : Domain metadata : name : SIP domain spec : context : domainUri : sip.example Then the sip.user@sip.example needs to be added to config/agents.yml like below: 1 2 3 4 5 6 7 8 9 - apiVersion : v1beta1 kind : Agent metadata : name : SIP User spec : credentials : username : 'sip.user' secret : '1234' domains : [ sip.example ] Now Routr can be started with 1 ./routr If all goes well we'll see the following output: 1 2 3 4 5 6 [INFO ] Starting Routr [INFO ] Listening on 10.152.1.27:5060 [udp] [INFO ] Listening on 10.152.1.27:5060 [tcp] [INFO ] Starting Location service [INFO ] Starting Registry service [INFO ] Starting Restful service (port: 4567, apiPath: '/api/v1beta1') It is important to remember the IP address as it'll be used in next point. A side note In Routr's logs you may see messages like 1 [WARN ] Unable to register with Gateway -> sip.provider.net. (Verify your network status) or 1 [ERROR] java.lang.RuntimeException: javax.sip.header.TooManyHopsException: has already reached 0! They can be ignored for the purpose of the tutorial. Configuring /etc/hosts In my case the IP reported by Routr was 10.152.1.27 . Now we need to use this to update /etc/hosts file like below: 1 10.152.1.27 sip.example xmpp.example Configuring MongooseIM At this point I assume that MongooseIM was built with make rel , that it is running and the current working directory is _build/prod/rel/mongooseim . Similar to Routr, MongooseIM also needs to know which hosts to server. Please replace the default host defined in etc/mongooseim.toml ; the line: 1 2 [general] hosts = [\"localhost\"] should be changed to: 1 2 [general] hosts = [\"xmpp.example\", \"sip.example\"] Now we need to enable mod_jingle_sip , please add the following line in modules list (somewhere around line 740 in the same file) 1 2 [modules.mod_jingle_sip] proxy_host = \"sip.example\" More details on MongooseIM configuration you can find in Configuration and in Modules configuration Now we are registering both users in MongooseIM by calling the following commands: 1 2 bin/mongooseimctl register_identified xmpp.user xmpp.example test_pass bin/mongooseimctl register_identified sip.user sip.example test_pass Yes, we need to have the sip.user@sip.example registered in MongooseIM. This is needed because a Jingle call can be initiated by a regular XMPP client only when the app knows the other user's full JID. The easiest way to achieve that is to exchange presence information between these 2 users. This can happen automatically if 2 xmpp users have each other in the roster. The roster can be set by us with the following commands: 1 2 bin/mongooseimctl add_rosteritem sip.user sip.example xmpp.user xmpp.example xmpp.user none both bin/mongooseimctl add_rosteritem xmpp.user xmpp.example sip.user sip.example sip.user none both Adding users to Jitsi Now the sip.user@sip.example has to be added to Jitsi app. When the app is opened for the first time it will display a window to configure the user. Later users can be configured from the Preferences page. Adding a SIP user In order to add a user who connects to the SIP server we need to choose the SIP protocol from the available networks in Jitsi. In the SIP id field we put sip.user@sip.example and in the Password field we put 1234 as in the agents.yml file. Now we need to switch to Advanced options and go to the Connection tab. Here we need to unselect the Configure proxy automatically and put the IP of our Routr server, port number 5060 and TCP as the preferred transport. Adding an XMPP user Now we have to add sip.user@sip.example to Jitsi's XMPP network in order to connect this user to MongooseIM over XMPP. It's very similar to adding a user to Jitsi's SIP network, the only difference is the password, for the XMPP conection it's test_pass as set when registering the user in MongooseIM. Here we also need to go to the Advanced window and the Connection tab in order to put the IP addres (the same as before) in the Connect Server field. Remember to check the Override server default options box. To connect sip.user@sip.exmple to MongooseIM over XMPP is to cheat Jingle a bit, so that the client app for user sip.xmpp@xmpp.example can start the Jingle call. When Jitsi connects this user, it will likely display a warning about the server's certificate. This is because by default MongooseIM is configured with a freshly generated, self-signed certificate. We can click Continue anyway button in order to proceed. Adding user to Otalk Please follow the instructions on https://github.com/otalk/otalk-im-client#installing in order to compile and run the app. If all goes well, you should see the following message printed in the console: 1 demo.stanza.io running at: http://localhost:8000 This means that the app is hosted on http://localhost:8000 . At this point I also recommend opening wss://localhost:5285/ws-xmpp in the same browser. This endpoint works correctly only for WebSocket connections but most probably you will be prompted about the certificate. This is again due to the self-signed certificate. We need to add an exception for this certificate in order to successfully connect from Otalk. Now let's open http://localhost:8000 where the Otalk app is hosted. In the Log in section put xmpp.user@xmpp.example in the JID field and test_pass in the Password filed. The default WebSocket endpoint in the WebSocket or BOSH URL field needs to be changed to: 1 wss://localhost:5285/ws-xmpp Mind the wss protocol, Otalk will not connect the user over WebSockets if for example https is put in the field. Now we can hit the Go! button and the xmpp.user@xmpp.example will connect to MongooseIM. Making a call On the left side we can see that the user already has sip.user@sip.example in the roster and there should be a green dot indicating that the user is online. When we click on the contact, the Call button should appear allowing us to initiate the call. In Jitsi, the following window should pop up: Behind the scene the following SIP request was send from MongooseIM to Routr. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 INVITE sip:sip.user@sip.example:5060 SIP/2.0 Via: SIP/2.0/TCP localhost:5600;rport;branch=z9hG4bK1HMB3o-3mbahM From: xmpp.user <sip:xmpp.user@xmpp.example>;tag=aVEBue To: sip.user <sip:sip.user@sip.example> Call-ID: ae602f16-d57d-4452-b83e-36e54bb6d325 CSeq: 159913767 INVITE Max-Forwards: 70 Content-Length: 2243 Contact: <sip:xmpp.user@localhost:5600;ob;transport=tcp>;+sip.instance=\"<urn:uuid:f45950f1-70cd-229d-6c2b-8c85903ce14e>\" Content-Type: application/sdp Supported: outbound,100rel,path Allow: PRACK,INVITE,ACK,CANCEL,BYE,OPTIONS,INFO,UPDATE,SUBSCRIBE,NOTIFY,REFER,MESSAGE v=0 o=- 1531401304 1531401304 IN IP4 127.0.0.1 s=nksip c=IN IP4 127.0.0.1 t=0 0 a=group:BUNDLE sdparta_0 sdparta_1 m=audio 1436 UDP/TLS/RTP/SAVPF 109 9 0 8 101 a=sendrecv a=mid:sdparta_0 a=setup:actpass a=fingerprint:sha-256 44:84:41:8F:B7:A3:B7:37:BA:00:26:5E:B1:D6:AB:D0:56:56:CF:53:F2:05:DB:99:DE:D4:1C:63:A4:68:58:EA a=ice-pwd:49ad0f02b4f5181c9af3c4006575e071 a=ice-ufrag:a3cc96e2 a=rtcp-mux a=extmap:3 urn:ietf:params:rtp-hdrext:sdes:mid a=extmap:2/recvonly urn:ietf:params:rtp-hdrext:csrc-audio-level a=extmap:1 urn:ietf:params:rtp-hdrext:ssrc-audio-level a=rtpmap:109 opus/48000/2 a=fmtp:109 useinbandfec=1;stereo=1;maxplaybackrate=48000 a=rtpmap:9 G722/8000 a=rtpmap:0 PCMU/8000 a=rtpmap:8 PCMA/8000 a=rtpmap:101 telephone-event/8000 a=fmtp:101 0-15 a=ssrc:1698222108 cname:{ce7fa171-069e-db4f-ba41-cfa4455c1033} a=ssrc:1698222108 msid:{788b64bb-c4fc-b644-89b0-89f69c78f8b0} {2ba61f91-abca-3e48-84b7-85b57e8fdfb5} m=video 1031 UDP/TLS/RTP/SAVPF 120 121 126 97 a=sendrecv a=mid:sdparta_1 a=setup:actpass a=fingerprint:sha-256 44:84:41:8F:B7:A3:B7:37:BA:00:26:5E:B1:D6:AB:D0:56:56:CF:53:F2:05:DB:99:DE:D4:1C:63:A4:68:58:EA a=ice-pwd:49ad0f02b4f5181c9af3c4006575e071 a=ice-ufrag:a3cc96e2 a=rtcp-mux a=extmap:5 urn:ietf:params:rtp-hdrext:toffset a=extmap:4 http://www.webrtc.org/experiments/rtp-hdrext/abs-send-time a=extmap:3 urn:ietf:params:rtp-hdrext:sdes:mid a=rtpmap:120 VP8/90000 a=fmtp:120 max-fr=60;max-fs=12288 a=rtcp-fb:120 goog-remb a=rtcp-fb:120 ccm fir a=rtcp-fb:120 nack pli a=rtcp-fb:120 nack a=rtpmap:121 VP9/90000 a=fmtp:121 max-fr=60;max-fs=12288 a=rtcp-fb:121 goog-remb a=rtcp-fb:121 ccm fir a=rtcp-fb:121 nack pli a=rtcp-fb:121 nack a=rtpmap:126 H264/90000 a=fmtp:126 packetization-mode=1;level-asymmetry-allowed=1;profile-level-id=42e01f a=rtcp-fb:126 goog-remb a=rtcp-fb:126 ccm fir a=rtcp-fb:126 nack pli a=rtcp-fb:126 nack a=rtpmap:97 H264/90000 a=fmtp:97 level-asymmetry-allowed=1;profile-level-id=42e01f a=rtcp-fb:97 goog-remb a=rtcp-fb:97 ccm fir a=rtcp-fb:97 nack pli a=rtcp-fb:97 nack a=ssrc:823938224 cname:{ce7fa171-069e-db4f-ba41-cfa4455c1033} a=ssrc:823938224 msid:{788b64bb-c4fc-b644-89b0-89f69c78f8b0} {a7f87c8d-6002-fd4c-badb-13383c759e48} And Routr sent the Ringing response code to MongooseIM as soon as the Jitsi app displayed the incoming call window: 1 2 3 4 5 6 7 8 9 SIP/2.0 180 Ringing CSeq: 159913767 INVITE Call-ID: ae602f16-d57d-4452-b83e-36e54bb6d325 From: \"xmpp.user\" <sip:xmpp.user@xmpp.example>;tag=aVEBue To: \"sip.user\" <sip:sip.user@sip.example>;tag=9b4c72a3 Via: SIP/2.0/TCP localhost:5600;rport=54071;branch=z9hG4bK1HMB3o-3mbahM;received=10.152.1.27 Contact: \"sip.user\" <sip:sip.user@10.152.1.27:53697;transport=tcp;registering_acc=sip_example> User-Agent: Jitsi2.10.5550Mac OS X Content-Length: 0 Summary The example above showcases how you can use Jingle/SIP switch with the available open source software. Sonetel, who are this feature's sponsor, operate on a slightly different use case and utilize more of the functionality with their proprietary software. Current implementation makes following assumptions: The peer-to-peer stream is always encrypted. This means that MongooseIM expects element <fingerprint> as described in XEP-0320: Use of DTLS-SRTP in Jingle Sessions to be in the content description. Not every open source XMPP client supporting Jingle supports this encryption. MongooseIM expects that the 200 OK response contains at least one ICE candidate to set the peer-to-peer connection up. This makes the current implementation a bit limited, but on the other hand the basic integration between XMPP and SIP world is already there. Based on the current state it can be improved and extended if needed.","title":"How to Set up Jingle/SIP"},{"location":"user-guide/Jingle-SIP-setup/#jinglesip-setup-proof-of-concept","text":"This tutorial will show you how to configure MongooseIM, Routr (a SIP server) and client applications to demonstrate how the Jingle/SIP integration works.","title":"Jingle/SIP setup proof of concept"},{"location":"user-guide/Jingle-SIP-setup/#prerequisites","text":"We are going to use the following open source software: MongooseIM - https://github.com/esl/MongooseIM see How-to-build for details on building. It's important to remember to run the configuration script with with-jingle-sip flag set: tools/configure with-jingle-sip . Without this, third party dependencies required by the Jingle/SIP translator will not be included in the release. Routr (SIP server) - https://routr.io I recommend downloading binaries for your system from official source . Jitsi (XMPP and SIP client application) - https://desktop.jitsi.org Otalk - web based XMPP client - https://github.com/otalk/otalk-im-client Folow the instructions on otalk-im-client#installing to run it We will use 2 users xmpp.user@xmpp.example and sip.user@sip.example .","title":"Prerequisites"},{"location":"user-guide/Jingle-SIP-setup/#configuring-routr","text":"First the domain sip.example needs to be added to domains served by Routr. To do it, paste the following content to config/domains.yml in the directory where Routr was: 1 2 3 4 5 6 7 - apiVersion : v1beta1 kind : Domain metadata : name : SIP domain spec : context : domainUri : sip.example Then the sip.user@sip.example needs to be added to config/agents.yml like below: 1 2 3 4 5 6 7 8 9 - apiVersion : v1beta1 kind : Agent metadata : name : SIP User spec : credentials : username : 'sip.user' secret : '1234' domains : [ sip.example ] Now Routr can be started with 1 ./routr If all goes well we'll see the following output: 1 2 3 4 5 6 [INFO ] Starting Routr [INFO ] Listening on 10.152.1.27:5060 [udp] [INFO ] Listening on 10.152.1.27:5060 [tcp] [INFO ] Starting Location service [INFO ] Starting Registry service [INFO ] Starting Restful service (port: 4567, apiPath: '/api/v1beta1') It is important to remember the IP address as it'll be used in next point.","title":"Configuring Routr"},{"location":"user-guide/Jingle-SIP-setup/#a-side-note","text":"In Routr's logs you may see messages like 1 [WARN ] Unable to register with Gateway -> sip.provider.net. (Verify your network status) or 1 [ERROR] java.lang.RuntimeException: javax.sip.header.TooManyHopsException: has already reached 0! They can be ignored for the purpose of the tutorial.","title":"A side note"},{"location":"user-guide/Jingle-SIP-setup/#configuring-etchosts","text":"In my case the IP reported by Routr was 10.152.1.27 . Now we need to use this to update /etc/hosts file like below: 1 10.152.1.27 sip.example xmpp.example","title":"Configuring /etc/hosts"},{"location":"user-guide/Jingle-SIP-setup/#configuring-mongooseim","text":"At this point I assume that MongooseIM was built with make rel , that it is running and the current working directory is _build/prod/rel/mongooseim . Similar to Routr, MongooseIM also needs to know which hosts to server. Please replace the default host defined in etc/mongooseim.toml ; the line: 1 2 [general] hosts = [\"localhost\"] should be changed to: 1 2 [general] hosts = [\"xmpp.example\", \"sip.example\"] Now we need to enable mod_jingle_sip , please add the following line in modules list (somewhere around line 740 in the same file) 1 2 [modules.mod_jingle_sip] proxy_host = \"sip.example\" More details on MongooseIM configuration you can find in Configuration and in Modules configuration Now we are registering both users in MongooseIM by calling the following commands: 1 2 bin/mongooseimctl register_identified xmpp.user xmpp.example test_pass bin/mongooseimctl register_identified sip.user sip.example test_pass Yes, we need to have the sip.user@sip.example registered in MongooseIM. This is needed because a Jingle call can be initiated by a regular XMPP client only when the app knows the other user's full JID. The easiest way to achieve that is to exchange presence information between these 2 users. This can happen automatically if 2 xmpp users have each other in the roster. The roster can be set by us with the following commands: 1 2 bin/mongooseimctl add_rosteritem sip.user sip.example xmpp.user xmpp.example xmpp.user none both bin/mongooseimctl add_rosteritem xmpp.user xmpp.example sip.user sip.example sip.user none both","title":"Configuring MongooseIM"},{"location":"user-guide/Jingle-SIP-setup/#adding-users-to-jitsi","text":"Now the sip.user@sip.example has to be added to Jitsi app. When the app is opened for the first time it will display a window to configure the user. Later users can be configured from the Preferences page.","title":"Adding users to Jitsi"},{"location":"user-guide/Jingle-SIP-setup/#adding-a-sip-user","text":"In order to add a user who connects to the SIP server we need to choose the SIP protocol from the available networks in Jitsi. In the SIP id field we put sip.user@sip.example and in the Password field we put 1234 as in the agents.yml file. Now we need to switch to Advanced options and go to the Connection tab. Here we need to unselect the Configure proxy automatically and put the IP of our Routr server, port number 5060 and TCP as the preferred transport.","title":"Adding a SIP user"},{"location":"user-guide/Jingle-SIP-setup/#adding-an-xmpp-user","text":"Now we have to add sip.user@sip.example to Jitsi's XMPP network in order to connect this user to MongooseIM over XMPP. It's very similar to adding a user to Jitsi's SIP network, the only difference is the password, for the XMPP conection it's test_pass as set when registering the user in MongooseIM. Here we also need to go to the Advanced window and the Connection tab in order to put the IP addres (the same as before) in the Connect Server field. Remember to check the Override server default options box. To connect sip.user@sip.exmple to MongooseIM over XMPP is to cheat Jingle a bit, so that the client app for user sip.xmpp@xmpp.example can start the Jingle call. When Jitsi connects this user, it will likely display a warning about the server's certificate. This is because by default MongooseIM is configured with a freshly generated, self-signed certificate. We can click Continue anyway button in order to proceed.","title":"Adding an XMPP user"},{"location":"user-guide/Jingle-SIP-setup/#adding-user-to-otalk","text":"Please follow the instructions on https://github.com/otalk/otalk-im-client#installing in order to compile and run the app. If all goes well, you should see the following message printed in the console: 1 demo.stanza.io running at: http://localhost:8000 This means that the app is hosted on http://localhost:8000 . At this point I also recommend opening wss://localhost:5285/ws-xmpp in the same browser. This endpoint works correctly only for WebSocket connections but most probably you will be prompted about the certificate. This is again due to the self-signed certificate. We need to add an exception for this certificate in order to successfully connect from Otalk. Now let's open http://localhost:8000 where the Otalk app is hosted. In the Log in section put xmpp.user@xmpp.example in the JID field and test_pass in the Password filed. The default WebSocket endpoint in the WebSocket or BOSH URL field needs to be changed to: 1 wss://localhost:5285/ws-xmpp Mind the wss protocol, Otalk will not connect the user over WebSockets if for example https is put in the field. Now we can hit the Go! button and the xmpp.user@xmpp.example will connect to MongooseIM.","title":"Adding user to Otalk"},{"location":"user-guide/Jingle-SIP-setup/#making-a-call","text":"On the left side we can see that the user already has sip.user@sip.example in the roster and there should be a green dot indicating that the user is online. When we click on the contact, the Call button should appear allowing us to initiate the call. In Jitsi, the following window should pop up: Behind the scene the following SIP request was send from MongooseIM to Routr. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 INVITE sip:sip.user@sip.example:5060 SIP/2.0 Via: SIP/2.0/TCP localhost:5600;rport;branch=z9hG4bK1HMB3o-3mbahM From: xmpp.user <sip:xmpp.user@xmpp.example>;tag=aVEBue To: sip.user <sip:sip.user@sip.example> Call-ID: ae602f16-d57d-4452-b83e-36e54bb6d325 CSeq: 159913767 INVITE Max-Forwards: 70 Content-Length: 2243 Contact: <sip:xmpp.user@localhost:5600;ob;transport=tcp>;+sip.instance=\"<urn:uuid:f45950f1-70cd-229d-6c2b-8c85903ce14e>\" Content-Type: application/sdp Supported: outbound,100rel,path Allow: PRACK,INVITE,ACK,CANCEL,BYE,OPTIONS,INFO,UPDATE,SUBSCRIBE,NOTIFY,REFER,MESSAGE v=0 o=- 1531401304 1531401304 IN IP4 127.0.0.1 s=nksip c=IN IP4 127.0.0.1 t=0 0 a=group:BUNDLE sdparta_0 sdparta_1 m=audio 1436 UDP/TLS/RTP/SAVPF 109 9 0 8 101 a=sendrecv a=mid:sdparta_0 a=setup:actpass a=fingerprint:sha-256 44:84:41:8F:B7:A3:B7:37:BA:00:26:5E:B1:D6:AB:D0:56:56:CF:53:F2:05:DB:99:DE:D4:1C:63:A4:68:58:EA a=ice-pwd:49ad0f02b4f5181c9af3c4006575e071 a=ice-ufrag:a3cc96e2 a=rtcp-mux a=extmap:3 urn:ietf:params:rtp-hdrext:sdes:mid a=extmap:2/recvonly urn:ietf:params:rtp-hdrext:csrc-audio-level a=extmap:1 urn:ietf:params:rtp-hdrext:ssrc-audio-level a=rtpmap:109 opus/48000/2 a=fmtp:109 useinbandfec=1;stereo=1;maxplaybackrate=48000 a=rtpmap:9 G722/8000 a=rtpmap:0 PCMU/8000 a=rtpmap:8 PCMA/8000 a=rtpmap:101 telephone-event/8000 a=fmtp:101 0-15 a=ssrc:1698222108 cname:{ce7fa171-069e-db4f-ba41-cfa4455c1033} a=ssrc:1698222108 msid:{788b64bb-c4fc-b644-89b0-89f69c78f8b0} {2ba61f91-abca-3e48-84b7-85b57e8fdfb5} m=video 1031 UDP/TLS/RTP/SAVPF 120 121 126 97 a=sendrecv a=mid:sdparta_1 a=setup:actpass a=fingerprint:sha-256 44:84:41:8F:B7:A3:B7:37:BA:00:26:5E:B1:D6:AB:D0:56:56:CF:53:F2:05:DB:99:DE:D4:1C:63:A4:68:58:EA a=ice-pwd:49ad0f02b4f5181c9af3c4006575e071 a=ice-ufrag:a3cc96e2 a=rtcp-mux a=extmap:5 urn:ietf:params:rtp-hdrext:toffset a=extmap:4 http://www.webrtc.org/experiments/rtp-hdrext/abs-send-time a=extmap:3 urn:ietf:params:rtp-hdrext:sdes:mid a=rtpmap:120 VP8/90000 a=fmtp:120 max-fr=60;max-fs=12288 a=rtcp-fb:120 goog-remb a=rtcp-fb:120 ccm fir a=rtcp-fb:120 nack pli a=rtcp-fb:120 nack a=rtpmap:121 VP9/90000 a=fmtp:121 max-fr=60;max-fs=12288 a=rtcp-fb:121 goog-remb a=rtcp-fb:121 ccm fir a=rtcp-fb:121 nack pli a=rtcp-fb:121 nack a=rtpmap:126 H264/90000 a=fmtp:126 packetization-mode=1;level-asymmetry-allowed=1;profile-level-id=42e01f a=rtcp-fb:126 goog-remb a=rtcp-fb:126 ccm fir a=rtcp-fb:126 nack pli a=rtcp-fb:126 nack a=rtpmap:97 H264/90000 a=fmtp:97 level-asymmetry-allowed=1;profile-level-id=42e01f a=rtcp-fb:97 goog-remb a=rtcp-fb:97 ccm fir a=rtcp-fb:97 nack pli a=rtcp-fb:97 nack a=ssrc:823938224 cname:{ce7fa171-069e-db4f-ba41-cfa4455c1033} a=ssrc:823938224 msid:{788b64bb-c4fc-b644-89b0-89f69c78f8b0} {a7f87c8d-6002-fd4c-badb-13383c759e48} And Routr sent the Ringing response code to MongooseIM as soon as the Jitsi app displayed the incoming call window: 1 2 3 4 5 6 7 8 9 SIP/2.0 180 Ringing CSeq: 159913767 INVITE Call-ID: ae602f16-d57d-4452-b83e-36e54bb6d325 From: \"xmpp.user\" <sip:xmpp.user@xmpp.example>;tag=aVEBue To: \"sip.user\" <sip:sip.user@sip.example>;tag=9b4c72a3 Via: SIP/2.0/TCP localhost:5600;rport=54071;branch=z9hG4bK1HMB3o-3mbahM;received=10.152.1.27 Contact: \"sip.user\" <sip:sip.user@10.152.1.27:53697;transport=tcp;registering_acc=sip_example> User-Agent: Jitsi2.10.5550Mac OS X Content-Length: 0","title":"Making a call"},{"location":"user-guide/Jingle-SIP-setup/#summary","text":"The example above showcases how you can use Jingle/SIP switch with the available open source software. Sonetel, who are this feature's sponsor, operate on a slightly different use case and utilize more of the functionality with their proprietary software. Current implementation makes following assumptions: The peer-to-peer stream is always encrypted. This means that MongooseIM expects element <fingerprint> as described in XEP-0320: Use of DTLS-SRTP in Jingle Sessions to be in the content description. Not every open source XMPP client supporting Jingle supports this encryption. MongooseIM expects that the 200 OK response contains at least one ICE candidate to set the peer-to-peer connection up. This makes the current implementation a bit limited, but on the other hand the basic integration between XMPP and SIP world is already there. Based on the current state it can be improved and extended if needed.","title":"Summary"},{"location":"user-guide/MongooseIM-High-level-Architecture/","text":"Inside MongooseIM Modules At its core MongooseIM is a huge message router you can customise to fit your system's needs. You can choose and enable behaviours and functionalities by configuring any of the available modules. A wide range of options includes authentication, privacy, storage, backend integration and mobile optimisations. See ' Extension Modules ' for a full list. Modules can be configured and started either for all virtual hosts served by the instance or with individual configuration for only some of them. Modules may include dependencies on services and on other modules. If a module depends on other modules, required modules are started automatically with configuration provided by the dependent module. If a module requires certain services which are not started, the module refuses to start. Services Services provide certain functionalities not specific to virtual hosts but rather applied to the whole instance or to modules started for various hosts. They are configured globally and launched on startup, before modules, so that needed dependencies are satisfied. A service can require other services to be operational; required services are started automatically. The required service must also be present in the server's configuration file. Modules which are not host-specific are gradually being refactored to services. Databases MongooseIM manages two sets of data: transient for session data management, and persistent for archive and configurations. Please refer to ' Database Backends ' doc for more configuration information. Transient databases In the MongooseIM architecture each MongooseIM node host has an accompanying Mnesia node. Redis on the other hand forms a separate cluster and does not utilise MongooseIM nodes. There is no need to set up any backups for transient data since it naturally rebuilds as clients reconnect massively. Persistent databases Both RDBMS/SQL (MySQL/PostgreSQL) and NOSQL (Riak KV) databases are supported. Backups should be regular, and tested. LDAP directory LDAP will also run on a separate cluster. Backups should be regular, and tested. Outside MongooseIM: ecosystem in a datacenter Frontend Native clients on platforms such as Android, iOS, Windows, Linux, macOS, will preferably use a plain XMPP over TCP connections. Since web clients cannot use TCP connections, they will preferably use XMPP over websockets, or the now less relevant XMPP over BOSH (using long-lived HTTP connections, more and more used as fallback). Any client could use the client REST API, which is using HTTP request/responses. All these client connections will hit a frontend load balancer before reaching the MongooseIM cluster. Backend MongooseIM supports bilateral communication with other backend services in the datacenter infrastructure. MongooseIM REST API is available for control/management of MongooseIM's operations as well as the functional aspects. An HTTP notification enables forwarding of the events to any other external HTTP service. Management and monitoring WombatOAM enables the monitoring and management of MongooseIM clusters, as well as Riak KV, RabbitMQ, and any other Erlang and Elixir based system. MongooseICE (STUN/TURN) Available on: MongooseICE MongoosePush (APNS, GCM) Available on: MongoosePush MongooseIM in a worldwide, multi-datacenter configuration The MongooseIM platform enables a service to scale worldwide, with proximity servers across continents and datacenters. It leverages the use of the open standard S2S (server-to-server) protocol. We advise contacting us in case of such a big deployment.","title":"High-level Architecture"},{"location":"user-guide/MongooseIM-High-level-Architecture/#inside-mongooseim","text":"","title":"Inside MongooseIM"},{"location":"user-guide/MongooseIM-High-level-Architecture/#modules","text":"At its core MongooseIM is a huge message router you can customise to fit your system's needs. You can choose and enable behaviours and functionalities by configuring any of the available modules. A wide range of options includes authentication, privacy, storage, backend integration and mobile optimisations. See ' Extension Modules ' for a full list. Modules can be configured and started either for all virtual hosts served by the instance or with individual configuration for only some of them. Modules may include dependencies on services and on other modules. If a module depends on other modules, required modules are started automatically with configuration provided by the dependent module. If a module requires certain services which are not started, the module refuses to start.","title":"Modules"},{"location":"user-guide/MongooseIM-High-level-Architecture/#services","text":"Services provide certain functionalities not specific to virtual hosts but rather applied to the whole instance or to modules started for various hosts. They are configured globally and launched on startup, before modules, so that needed dependencies are satisfied. A service can require other services to be operational; required services are started automatically. The required service must also be present in the server's configuration file. Modules which are not host-specific are gradually being refactored to services.","title":"Services"},{"location":"user-guide/MongooseIM-High-level-Architecture/#databases","text":"MongooseIM manages two sets of data: transient for session data management, and persistent for archive and configurations. Please refer to ' Database Backends ' doc for more configuration information.","title":"Databases"},{"location":"user-guide/MongooseIM-High-level-Architecture/#transient-databases","text":"In the MongooseIM architecture each MongooseIM node host has an accompanying Mnesia node. Redis on the other hand forms a separate cluster and does not utilise MongooseIM nodes. There is no need to set up any backups for transient data since it naturally rebuilds as clients reconnect massively.","title":"Transient databases"},{"location":"user-guide/MongooseIM-High-level-Architecture/#persistent-databases","text":"Both RDBMS/SQL (MySQL/PostgreSQL) and NOSQL (Riak KV) databases are supported. Backups should be regular, and tested.","title":"Persistent databases"},{"location":"user-guide/MongooseIM-High-level-Architecture/#ldap-directory","text":"LDAP will also run on a separate cluster. Backups should be regular, and tested.","title":"LDAP directory"},{"location":"user-guide/MongooseIM-High-level-Architecture/#outside-mongooseim-ecosystem-in-a-datacenter","text":"","title":"Outside MongooseIM: ecosystem in a datacenter"},{"location":"user-guide/MongooseIM-High-level-Architecture/#frontend","text":"Native clients on platforms such as Android, iOS, Windows, Linux, macOS, will preferably use a plain XMPP over TCP connections. Since web clients cannot use TCP connections, they will preferably use XMPP over websockets, or the now less relevant XMPP over BOSH (using long-lived HTTP connections, more and more used as fallback). Any client could use the client REST API, which is using HTTP request/responses. All these client connections will hit a frontend load balancer before reaching the MongooseIM cluster.","title":"Frontend"},{"location":"user-guide/MongooseIM-High-level-Architecture/#backend","text":"MongooseIM supports bilateral communication with other backend services in the datacenter infrastructure. MongooseIM REST API is available for control/management of MongooseIM's operations as well as the functional aspects. An HTTP notification enables forwarding of the events to any other external HTTP service.","title":"Backend"},{"location":"user-guide/MongooseIM-High-level-Architecture/#management-and-monitoring","text":"WombatOAM enables the monitoring and management of MongooseIM clusters, as well as Riak KV, RabbitMQ, and any other Erlang and Elixir based system.","title":"Management and monitoring"},{"location":"user-guide/MongooseIM-High-level-Architecture/#mongooseice-stunturn","text":"Available on: MongooseICE","title":"MongooseICE (STUN/TURN)"},{"location":"user-guide/MongooseIM-High-level-Architecture/#mongoosepush-apns-gcm","text":"Available on: MongoosePush","title":"MongoosePush (APNS, GCM)"},{"location":"user-guide/MongooseIM-High-level-Architecture/#mongooseim-in-a-worldwide-multi-datacenter-configuration","text":"The MongooseIM platform enables a service to scale worldwide, with proximity servers across continents and datacenters. It leverages the use of the open standard S2S (server-to-server) protocol. We advise contacting us in case of such a big deployment.","title":"MongooseIM in a worldwide, multi-datacenter configuration"},{"location":"user-guide/client-certificate/","text":"Overview Clients connected to MongooseIM may authenticate with their TLS certificates. This method uses the SASL EXTERNAL mechanism. Server-side prerequisites Properly configure Client-to-server (C2S) listener A server must request the certificate from a client, so you'll need to enable verify_peer option and provide a path to CA chain that may be used for client's certificate check ( cafile option). Please check the Listener modules page for more information or simply follow the examples at the end of this section. Properly configure http listener SASL EXTERNAL authentication is also possible for WebSocketSecure and BOSH connections over HTTPS. Similarly as in the client-to-server case, the server must request the certificate from the client. In this case it's enabled by adding the following options to the tls option of listen.http : tls.verify_peer = true - this is to tell Erlang's SSL to request the cert from the client tls.cacertfile = \"ca.pem\" - this is to tell Erlang's SSL where the CA cert file is in order to check if the cert is correctly signed Please check Options: Listen for more details regarding http listener configuration. Enable SASL EXTERNAL mechanism A SASL EXTERNAL authentication mechanism is disabled by default. In order to enable it, please configure auth.sasl_mechanisms option in the MongooseIM config file. 1 2 [auth] sasl_mechanisms = [\"external\"] Obviously the list may be longer, if the system should support both the certificate and password based authentication. The SASL EXTERNAL authentication mechanism requires a digital client certificate. This digital certificate should contain xmppAddr field(s), which is always checked first. If there is more than one JID specified in the xmppAddr fields, the client must include the authorisation entity which corresponds to the one of the specified JIDs. When no xmppAddr is specified, the cn (common name) field might be used to provide the client's username, but it is optional and can be configured with the sasl_external option in the auth section. If the client certificate does not contain a JID, the client must provide one in authorisation entity. For the details please refer to XEP-0178: Best Practices for Use of SASL EXTERNAL with Certificates . Enable compatible authentication method You need to enable one of the following authentication methods by using the auth.methods option in the MongooseIM configuration file. \"pki\" - accepts user credentials, \"http\" - accepts user credentials if the provided certificate is known and valid \"ldap\" - accepts user credentials if a corresponding user account exists in LDAP. Self-signed certificates By default MongooseIM doesn't accept self-signed certs for the SASL-EXTERNAL authentication. For development purposes, it is possible to tell MongooseIM to accept them. Self-signed certificates for regular TCP/TLS connections In order to tell MongooseIM to accept self-signed certs, the listen.c2s.tls.verify_mode option needs to be configured like below: 1 2 3 [listen.c2s] tls . verify_mode = \"selfsigned_peer\" tls . disconnect_on_failure = false where the tls.disconnect_on_failure is a boolean with the following meaning only for just_tls : true - the connection is closed if a certificate is invalid, false - the connection isn't closed, but the certificate is not returned if it's invalid. This leads to an authentication failure but allows the client to choose a different auth method if available. For fast_tls backend, the configuration is the same, only the disconnect_on_failure is ignored. Self-signed certificates for WS or BOSH In order to accept self-signed certs for WS or BOSH connections, the tls options for http listener must have the following configured: 1 2 [listen.http] tls . verify_mode = \"selfsigned_peer\" Examples Certificate authentication only. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 [listen.c2s] port = 5222 (...) tls . cacertfile = \"ca.pem\" tls . verify_peer = true [listen.http] port = 5285 (...) tls . cacertfile = \"ca.pem\" tls . verify_peer = true [[listen.http.handlers.mod_bosh]] host = \"_\" path = \"/http-bind\" [[listen.http.handlers.mod_websockets]] host = \"_\" path = \"/ws-xmpp\" [auth] method = [\"pki\"] sasl_mechanisms = [\"external\"] Authentication with a client certificate (validated with provided CA chain) or password (validated with data stored in RDBMS). 1 2 3 4 5 6 7 8 9 [listen.c2s] port = 5222 (...) tls . cacertfile = \"ca.pem\" tls . verify_peer = true [auth] methods = [\"rdbms\", \"pki\"] sasl_mechanisms = [\"scram_sha1\", \"external\"] Client certificate prerequisites SASL EXTERNAL will be offered by the server only when a client provides a valid certificate . Please check documentation of a specific authentication backend you're going to use. Usage example - Gajim Verified with Gajim 0.16.8, installed from package gajim-0.16.8-1.fc25.noarch . Generate client certificate 1 2 3 4 5 6 openssl genrsa -des3 -out rootCA.key 4096 openssl req -x509 -new -nodes -key rootCA.key -sha256 -days 1024 -out rootCA.crt openssl genrsa -out client.key 2048 openssl req -new -key client.key -out client.csr # Remember to provide username as Common Name! openssl x509 -req -in client.csr -CA rootCA.crt -CAkey rootCA.key -CAcreateserial -out client.crt -days 500 -sha256 openssl pkcs12 -export -inkey client.key -in client.crt -out client.p12 Configure MongooseIM See examples in the section above. We recommend using the first snippet for simplicity. You don't need to pre-create a user account in order to log in with a certificate. Add an account in Gajim Edit -> Accounts -> Add. Pick \"I already have an account I want to use\". Jabber ID is [Common Name from certificate]@localhost (domain is different if you've changed it in hosts option). Press \"Next\". Untick \"Connect when I press Finish\" and press \"Advanced\". Unfold \"Client certificate\" and choose the .p12 you've created earlier. Tick \"Certificate is encrypted\". Click \"Close\" and set status to \"Available\". Tell Gajim to ignore the unverified server certificate (by default it's self-signed). If Gajim fails to connect, try to restart it. Version 0.16.8 sometimes \"forgets\" to ask for the client certificate password.","title":"Client certificate authentication"},{"location":"user-guide/client-certificate/#overview","text":"Clients connected to MongooseIM may authenticate with their TLS certificates. This method uses the SASL EXTERNAL mechanism.","title":"Overview"},{"location":"user-guide/client-certificate/#server-side-prerequisites","text":"","title":"Server-side prerequisites"},{"location":"user-guide/client-certificate/#properly-configure-client-to-server-c2s-listener","text":"A server must request the certificate from a client, so you'll need to enable verify_peer option and provide a path to CA chain that may be used for client's certificate check ( cafile option). Please check the Listener modules page for more information or simply follow the examples at the end of this section.","title":"Properly configure Client-to-server (C2S) listener"},{"location":"user-guide/client-certificate/#properly-configure-http-listener","text":"SASL EXTERNAL authentication is also possible for WebSocketSecure and BOSH connections over HTTPS. Similarly as in the client-to-server case, the server must request the certificate from the client. In this case it's enabled by adding the following options to the tls option of listen.http : tls.verify_peer = true - this is to tell Erlang's SSL to request the cert from the client tls.cacertfile = \"ca.pem\" - this is to tell Erlang's SSL where the CA cert file is in order to check if the cert is correctly signed Please check Options: Listen for more details regarding http listener configuration.","title":"Properly configure http listener"},{"location":"user-guide/client-certificate/#enable-sasl-external-mechanism","text":"A SASL EXTERNAL authentication mechanism is disabled by default. In order to enable it, please configure auth.sasl_mechanisms option in the MongooseIM config file. 1 2 [auth] sasl_mechanisms = [\"external\"] Obviously the list may be longer, if the system should support both the certificate and password based authentication. The SASL EXTERNAL authentication mechanism requires a digital client certificate. This digital certificate should contain xmppAddr field(s), which is always checked first. If there is more than one JID specified in the xmppAddr fields, the client must include the authorisation entity which corresponds to the one of the specified JIDs. When no xmppAddr is specified, the cn (common name) field might be used to provide the client's username, but it is optional and can be configured with the sasl_external option in the auth section. If the client certificate does not contain a JID, the client must provide one in authorisation entity. For the details please refer to XEP-0178: Best Practices for Use of SASL EXTERNAL with Certificates .","title":"Enable SASL EXTERNAL mechanism"},{"location":"user-guide/client-certificate/#enable-compatible-authentication-method","text":"You need to enable one of the following authentication methods by using the auth.methods option in the MongooseIM configuration file. \"pki\" - accepts user credentials, \"http\" - accepts user credentials if the provided certificate is known and valid \"ldap\" - accepts user credentials if a corresponding user account exists in LDAP.","title":"Enable compatible authentication method"},{"location":"user-guide/client-certificate/#self-signed-certificates","text":"By default MongooseIM doesn't accept self-signed certs for the SASL-EXTERNAL authentication. For development purposes, it is possible to tell MongooseIM to accept them.","title":"Self-signed certificates"},{"location":"user-guide/client-certificate/#self-signed-certificates-for-regular-tcptls-connections","text":"In order to tell MongooseIM to accept self-signed certs, the listen.c2s.tls.verify_mode option needs to be configured like below: 1 2 3 [listen.c2s] tls . verify_mode = \"selfsigned_peer\" tls . disconnect_on_failure = false where the tls.disconnect_on_failure is a boolean with the following meaning only for just_tls : true - the connection is closed if a certificate is invalid, false - the connection isn't closed, but the certificate is not returned if it's invalid. This leads to an authentication failure but allows the client to choose a different auth method if available. For fast_tls backend, the configuration is the same, only the disconnect_on_failure is ignored.","title":"Self-signed certificates for regular TCP/TLS connections"},{"location":"user-guide/client-certificate/#self-signed-certificates-for-ws-or-bosh","text":"In order to accept self-signed certs for WS or BOSH connections, the tls options for http listener must have the following configured: 1 2 [listen.http] tls . verify_mode = \"selfsigned_peer\"","title":"Self-signed certificates for WS or BOSH"},{"location":"user-guide/client-certificate/#examples","text":"Certificate authentication only. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 [listen.c2s] port = 5222 (...) tls . cacertfile = \"ca.pem\" tls . verify_peer = true [listen.http] port = 5285 (...) tls . cacertfile = \"ca.pem\" tls . verify_peer = true [[listen.http.handlers.mod_bosh]] host = \"_\" path = \"/http-bind\" [[listen.http.handlers.mod_websockets]] host = \"_\" path = \"/ws-xmpp\" [auth] method = [\"pki\"] sasl_mechanisms = [\"external\"] Authentication with a client certificate (validated with provided CA chain) or password (validated with data stored in RDBMS). 1 2 3 4 5 6 7 8 9 [listen.c2s] port = 5222 (...) tls . cacertfile = \"ca.pem\" tls . verify_peer = true [auth] methods = [\"rdbms\", \"pki\"] sasl_mechanisms = [\"scram_sha1\", \"external\"]","title":"Examples"},{"location":"user-guide/client-certificate/#client-certificate-prerequisites","text":"SASL EXTERNAL will be offered by the server only when a client provides a valid certificate . Please check documentation of a specific authentication backend you're going to use.","title":"Client certificate prerequisites"},{"location":"user-guide/client-certificate/#usage-example-gajim","text":"Verified with Gajim 0.16.8, installed from package gajim-0.16.8-1.fc25.noarch .","title":"Usage example - Gajim"},{"location":"user-guide/client-certificate/#generate-client-certificate","text":"1 2 3 4 5 6 openssl genrsa -des3 -out rootCA.key 4096 openssl req -x509 -new -nodes -key rootCA.key -sha256 -days 1024 -out rootCA.crt openssl genrsa -out client.key 2048 openssl req -new -key client.key -out client.csr # Remember to provide username as Common Name! openssl x509 -req -in client.csr -CA rootCA.crt -CAkey rootCA.key -CAcreateserial -out client.crt -days 500 -sha256 openssl pkcs12 -export -inkey client.key -in client.crt -out client.p12","title":"Generate client certificate"},{"location":"user-guide/client-certificate/#configure-mongooseim","text":"See examples in the section above. We recommend using the first snippet for simplicity. You don't need to pre-create a user account in order to log in with a certificate.","title":"Configure MongooseIM"},{"location":"user-guide/client-certificate/#add-an-account-in-gajim","text":"Edit -> Accounts -> Add. Pick \"I already have an account I want to use\". Jabber ID is [Common Name from certificate]@localhost (domain is different if you've changed it in hosts option). Press \"Next\". Untick \"Connect when I press Finish\" and press \"Advanced\". Unfold \"Client certificate\" and choose the .p12 you've created earlier. Tick \"Certificate is encrypted\". Click \"Close\" and set status to \"Available\". Tell Gajim to ignore the unverified server certificate (by default it's self-signed). If Gajim fails to connect, try to restart it. Version 0.16.8 sometimes \"forgets\" to ask for the client certificate password.","title":"Add an account in Gajim"},{"location":"user-guide/iOS_tutorial/","text":"Build a complete iOS messaging app using XMPPFramework Read our blog posts: Build a complete iOS messaging app using XMPPFramework - Tutorial Part 1 Build a complete iOS messaging app using XMPPFramework - Part 2 YAXT??! Yet another XMPP tutorial? Well, this is going to be another tutorial, but I\u2019m going to try to make it a little bit different. This is an XMPP tutorial from an iOS developer\u2019s perspective. I\u2019ll try to answer all the questions I had when I started working in this area. This journey is going to go from no XMPP knowldege at all to having a fully functional instant messaging iOS appusing this cool protocol. We are going to be using the super awesome (yet overwhelming at the beginning\u2026) XMPPFramework library, and the idea is also to also mix in some iOS concepts that you are going to need for your app. What\u2019s XMPP? From Wikipedia : Extensible Messaging and Presence Protocol (XMPP) is a communications protocol for message-oriented middleware based on XML. This basically means XMPP is a protocol for exchanging stuff. What kind of stuff? Messages and presences. We all know what messages are, but what about presences? A presence is just a way of sharing a \u201cstatus\u201d, that\u2019s it. You can be \u2018online\u2019, 'offline\u2019, 'having lunch\u2019, or whatever you want. Also there\u2019s another important word: Extensible meaning it can grow. It started as an instant messaging protocol and it has grown into multiple fields for example IoT (Internet of Things). And last, but not least: every piece of information we are going to exchange under this protocol is going to be XML. I can heard you complaining but\u2026 Come on, it\u2019s not that bad! Why do we need XMPP? Why not just REST? Well what other options do we have? On the one hand, a custom solution means building everything from scratch, that takes time. On the other hand, we have XMPP, a super tested technology broadly used by millions of people every day, so we can say that\u2019s an advantage over a custom approach. Everytime I talk about XMPP, someone asks me 'Why not just REST?\u2019. Well, there is a misconception here. REST is not a protocol, it\u2019s just a way of architecting a networked application; it\u2019s just a standarized way of doing something (that I love btw). So let\u2019s change the question to something that makes more sense: \u201cWhy not just build a custom REST chat application?\u201d. The first thing that comes to my mind is what I already explained in the previous paragraph, but there is something else. How do I know when someone has sent me a message? For XMPP this is trivial: we have an open connection all the time so, as soon as a message arrives to the server, it will send us the message. We have a full-duplex. On the other hand, the only solution with REST is polling. We will need to ask the server for new messages from time to time to see if there is something new for us. That sucks. So, we will have to add a mechanism that allows us to receive the messages as soon as they are created, like SSE or WebSockets. There is one more XMPP advantage over a custom REST chat application. REST uses HTTP, an application level protocol that is built on top of a transport level protocol: TCP. So everytime you want to use your REST solution, you will need HTTP, a protocol that is not always available everywhere (maybe you need to embed this in a cheap piece of hardware?). Besides, we have XMPP built on top of TCP that\u2019s going to be always available. What\u2019s the basic stuff I need to know to get started? Well, you know a lot already but let\u2019s make a list. Lists are always good: XMPP is built on top of TCP. It keeps an open connection all the time. Client/Server architecture. Messages always go through a server. Everything we send and receive is going to be XML and it\u2019s called Stanza. We have three different types of stanzas: iq, message and presence. Every individual on the XMPP network is univocally identified by a JID (Jabber ID). All the stanzas are cointained in a Stream. Let\u2019s imagine the Stream as a white canvas where you and the server write the stanzas. Stream, iq, message and presence are the core of XMPP. You can find everything perfectly detailed in RFC6120 XMPP can be extended to accomplish different stuff. Each extension is called XEP (XMPP Extension Protocol). What\u2019s a JID? Jabber ID (JID) is how we univocally identify each individual in XMPP. It is the address to where we are going to send our stanzas. This is how a JID looks like: localpart : This is your username. domainpart : Server name where the localpart resides. resourcepart : This is optional, and it identifies a particular client for the user. For example: I can be logged in with andres@erlang-solutions.com on my iPhone, on my Android and on my mac at the same time\u2026 So all these will be the same localpart + domainpart but different resourcepart I\u2019m sure you have already noticed how similar the JID looks to a standard email address. This is because you can connect multiple servers together and the messages are rooted to the right user in the right server, just as email works. Pretty cool, right? Sometimes you will see we have a JID with just the domain part. Why?! Because it\u2019s also possible to send stanzas to a service instead of a user. A service? What\u2019s a service?! Services are different pieces of an XMPP server that offer you some special functionality, but don\u2019t worry about this right now, just remember: you can have JIDs without a localpart. What\u2019s a Stanza? Stanza is the name of the XML pieces that we are going to be sending and receiving. The defined stanzas are: <message/> , <presence/> and <iq/> . <message/> This is a basic <message/> stanza. Everytime you want to send a message to someone (a JID), you will have to send this stanza: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 <message from= 'andres@erlang-solutions.com/iphone' to= 'juana@erlang-solutions.com' type= 'chat' > <body> Hey there! </body> </message> ``` ### ` <iq/> ` It stands for Info/Query. It\u2019s a query-action mechanism, you send an `iq` and you will get a response to that query. You can pair the `iq-query` with the `iq-response` using the stanza id. For example, we send an `iq` to the server to do something (don\u2019t pay attention to what we want to do\u2026 you just need to know there is an `iq` stanza and how the mechanism works): ```xml <iq to= 'erlang-solutions.com' type= 'get' id= '1' > <query xmlns= 'http://jabber.org/protocol/disco#items' /> </iq> And we get back another iq with the same id with the result of the previous query: 1 2 3 4 5 6 7 <iq from= 'erlang-solutions.com' to= 'ramabit@erlang-solutions.com/Andress-MacBook-Air' id= '1' type= 'result' > <query xmlns= 'http://jabber.org/protocol/disco#items' > <item jid= 'muc.erlang-solutions.com' /> <item jid= 'muclight.erlang-solutions.com' /> <item jid= 'pubsub.erlang-solutions.com' /> </query> </iq> <presence/> Used to exchange presence information, as you could have imagined. Usually presences are sent from the client to the server and broadcasted by it. The most basic, yet valid presence, to indicate to the server that a user is avaiable is: 1 <presence/> After a sucessfull connection, you are not going to receive any <message/> until you make yourself available sending the previous presence. If you want to make yourself unavailable, you just have to send: 1 <presence type= \"unavailable\" ></presence> If we want to make the presences more useful, we can send something like this: 1 2 3 <presence> <status> On vacation </status> </presence> What\u2019s a Stream? Before answering this, let\u2019s refresh our mind. What\u2019s a Unix socket? From Wikipedia: A socket is a special file used for inter-process communication. These allows communication between two processes. So a socket is a file that can be written by two processes (in the same computer or in different computers in the same network). So the client is going to write to this file and server too. Ok, but how is a socket related to a Stream? Well, we are going to be connected to a server using a socket, therefore we are going to have a 'shared file\u2019 between the client and the server. This shared file is a white canvas where we are going to start writting our XML stanzas. The first thing we are going to write to this file is an opening <stream> tag! And there you go\u2026 that\u2019s our stream. Perfect, I understand what a stream is, but I still don\u2019t understand how to send a message to the server. Well, the only thing we need to do to send a message is writting a stanza in our shared file. But what happens when the server wants to send me a message? Simple: it will write the message in the 'shared file\u2019. Are we ok so far? I\u2019m sure at this point you have questions like: \u201cWhat?! An active TCP connection open all the time? I\u2019m used to REST! How am I going to do that?!\u201d Easy, you don\u2019t have to care about that any more! That\u2019s why we are going to use the library, and it will take care of that. \u201cYou said nothing about how to connect to the server!\u201d Believe me, you don\u2019t have to care about this either. If we start adding all this info, we are going to get crazy. Trust me, I\u2019ve been there. \u201cWhat about encrypted messages? We need security! How are we going to handle this?\u201d Again, you don\u2019t have to care about this at this point. Baby steps! You just need to be able to answer: \u201cWhat\u2019s XMPP?\u201d, \u201cHow do you send a message?\u201d, \u201cHow do you change your status in XMPP?\u201d, \u201cHow do you ask something to the server?\u201d, \u201cWhat\u2019s a Stream?\u201d. If you can answer all that, you are WAY better than me when I started. First steps: installing the XMPPFramework library Let\u2019s create a brand new Xcode project and install the library. In this tutorial we are going to be using Swift 3 . The easiest way to integrate XMPPFramework to the project is using CocoaPods . Let\u2019s create our Podfile using the pod init command in the folder where our .xcodeproj lives. There are thousands of forks but the maintained one is the original: robbiehanson/XMPPFramework . So let\u2019s add the pod to our Podfile and remember to uncomment the use_frameworks! . 1 2 3 4 5 use_frameworks! target 'CrazyMessages' do pod 'XMPPFramework', :git=> 'git@github.com:robbiehanson/XMPPFramework.git', :branch => 'master' end Then pod install and CocoaPods is going to do its magic and create a .xcworkspace with the library integrated. Now we just need to import XMPPFramework in the files we want to use the library and that\u2019s it. Starting to build our Instant Messaging app The most important thing in an XMPP application is the stream, that\u2019s where we are going to \u201cwrite\u201d our stanzas, so we need an object that is going to hold it. We are going to create an XMPPController class with an XMPPStream : 1 2 3 4 5 6 7 8 9 10 11 import Foundation import XMPPFramework class XMPPController : NSObject { var xmppStream : XMPPStream init () { self . xmppStream = XMPPStream () } } We are dealing with a highly asynchronous library here. For every action we are going to have a response some time in the future. To handle this XMPPFramework defines the XMPPStreamDelegate . So implementing that delegate is going to help us answer lots of different questions like: \u201cHow do I know when XMPP has successfully connected?\u201d, \u201cHow do I know if I\u2019m correctly authenticated?\u201d, \u201cHow do I know if I received a message?\u201d. XMPPStreamDelegate is your friend! So we have our XMPPController and our XMPPStream , what do we need to do now? Configure our stream with the hostName , port and ourJID . To provide all this info to the controller we are going to make some changes to the init to be able to receive all these parameters: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 enum XMPPControllerError : Error { case wrongUserJID } class XMPPController : NSObject { var xmppStream : XMPPStream let hostName : String let userJID : XMPPJID let hostPort : UInt16 let password : String init ( hostName : String , userJIDString : String , hostPort : UInt16 = 5222 , password : String ) throws { guard let userJID = XMPPJID ( string : userJIDString ) else { throw XMPPControllerError . wrongUserJID } self . hostName = hostName self . userJID = userJID self . hostPort = hostPort self . password = password // Stream Configuration self . xmppStream = XMPPStream () self . xmppStream . hostName = hostName self . xmppStream . hostPort = hostPort self . xmppStream . startTLSPolicy = XMPPStreamStartTLSPolicy . allowed self . xmppStream . myJID = userJID super . init () self . xmppStream . addDelegate ( self , delegateQueue : DispatchQueue . main ) } } Our next step is going to actually connect to a server and authenticate using our userJID and password , so we are adding a connect method to our XMPPController . 1 2 3 4 5 6 7 func connect () { if ! self . xmppStream . isDisconnected () { return } try ! self . xmppStream . connect ( withTimeout : XMPPStreamTimeoutNone ) } But how do we know we have successfully connected to the server? As I said earlier, we need to check for a suitable delegate method from XMPPStreamDelegate . After we connect to the server we need to authenticate so we are going to do the following: 1 2 3 4 5 6 7 8 9 10 11 12 extension XMPPController : XMPPStreamDelegate { func xmppStreamDidConnect ( _ stream : XMPPStream !) { print ( \"Stream: Connected\" ) try ! stream . authenticate ( withPassword : self . password ) } func xmppStreamDidAuthenticate ( _ sender : XMPPStream !) { self . xmppStream . send ( XMPPPresence ()) print ( \"Stream: Authenticated\" ) } } We need to test this. Let\u2019s just create an instance of XMPPController in the AppDelegate to test how it works: 1 2 3 4 try ! self . xmppController = XMPPController ( hostName : \"host.com\" , userJIDString : \"user@host.com\" , password : \"password\" ) self . xmppController . connect () If everything goes fine we should see two messages in the logs but of course that\u2019s not happening, we missed something. We never told to our xmppStream who was the delegate object! We need to add the following line after the super.init() 1 self . xmppStream . addDelegate ( self , delegateQueue : DispatchQueue . main ) If we run the app again: 1 2 Stream : Connected Stream : Authenticated Success! We have our own XMPPController with a fully functional and authenticated stream! Something that may catch your attention is how we are setting our delegate, we are not doing: 1 self . xmppStream . delegate = self Why not? Because we can \u201cbroadcast\u201d the events to multiple delegates, we can have 10 different objects implementing those methods. Also we can tell what\u2019s the thread where we want to receive that call, in the previous example we want it in the main thread. Getting a Log In Our app is super ugly, let\u2019s put on some makeup! We have nothing but an XMPPController and a hardcoded call in the AppDelegate . I\u2019m going to create a ViewController that is going to be presented modally as soon as the app starts, that ViewController will have the neccesary fields/info to log in to the server. I\u2019m going to create a LogInViewControllerDelegate that is going to tell to our ViewController that the Log in button was pressed and that\u2019s it. In that delegate implementation we are going to create our XMPPController , add the ViewControlleras delegate of the XMPPStream and connect! 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 extension ViewController : LogInViewControllerDelegate { func didTouchLogIn ( sender : LogInViewController , userJID : String , userPassword : String , server : String ) { self . logInViewController = sender do { try self . xmppController = XMPPController ( hostName : server , userJIDString : userJID , password : userPassword ) self . xmppController . xmppStream . addDelegate ( self , delegateQueue : DispatchQueue . main ) self . xmppController . connect () } catch { sender . showErrorMessage ( message : \"Something went wrong\" ) } } } Why are we adding ViewController as a delegate of XMPPStream if our XMPPController alreay has that delegate implemented? Because we need to know if this connection and authentication was successfull or notin our ViewController so we are able to dismiss the LogInViewController or show an error message if something failed. This is why being able to add multiple delegates is so useful. So as I said I\u2019m going to make ViewController to comform to the XMPPStreamDelegate : 1 2 3 4 5 6 7 8 9 10 11 extension ViewController : XMPPStreamDelegate { func xmppStreamDidAuthenticate ( _ sender : XMPPStream !) { self . logInViewController ?. dismiss ( animated : true , completion : nil ) } func xmppStream ( _ sender : XMPPStream !, didNotAuthenticate error : DDXMLElement !) { self . logInViewController ?. showErrorMessage ( message : \"Wrong password or username\" ) } } And that\u2019s it! Our app can log in to our server as I\u2019m showing here: Logging! We\u2019ve been talking a lot about XMPP, stanzas and streams\u2026 but is there a way I can see the stream? Yes SR! XMPPFramework got us covered! XMPPFramework ships with CocoaLumberJack , a pretty well known logging framework. We just need to configure it, set the logging level we want and that\u2019s it. Logs are going to start showing up! Configuring CocoaLumberjack This is a really simple task, you just need to add to your func application(application: UIApplication, didFinishLaunchingWithOptions ... method the following line (remember to import CocoaLumberjack ): 1 DDLog . add ( DDTTYLogger . sharedInstance (), with : DDLogLevel . all ) I\u2019m not going to paste here all the connection process log because it makes no sense to try to understand what\u2019s going on at this stage of our learning. But I think showing what some stanzas look like is a good idea. To do this I\u2019m going to be sending messages from Adium . I\u2019m going to send this <message/> : 1 2 3 <message to= \"test.user@erlang-solutions.com\" > <body> This is a message sent from Adium! </body> </message> Let\u2019s see how it looks like when it reaches our app: 1 2 3 <message xmlns= \"jabber:client\" from= \"iamadium@erlang-solutions.com/MacBook-Air\" to= \"test.user@erlang-solutions.com\" > <body> This is a message sent from Adium! </body> </message> Let\u2019s send a <presence/> from Adium: 1 2 3 <presence> <status> On vacation </status> </presence> We are receiving: 1 2 3 <presence xmlns= \"jabber:client\" from= \"iamadium@erlang-solutions.com/MacBook-Air\" to= \"test.user@erlang-solutions.com\" > <status> On vacation </status> </presence> No doubts at all right? We send something and we receive it on the other end! That\u2019s it! Test Time! I want to be sure that you are understanding and following everything and not just copy and pasting from a tutorial (as I usually do \ud83d\ude4a). So if you are able to answer these questions you are on a good track! Why am I sending a presence after successfully authenticating? What happens if I don\u2019t send it? What happens if I write a wrong server URL in the Log In form? How do I fix this problem if there is a problem\u2026 How do I detect if suddenly the stream is disconnected from the server? (maybe a network outage?) How do I detect if the user/password was wrong? If you need help leave a message!","title":"How to Build an iOS messaging app"},{"location":"user-guide/iOS_tutorial/#build-a-complete-ios-messaging-app-using-xmppframework","text":"Read our blog posts: Build a complete iOS messaging app using XMPPFramework - Tutorial Part 1 Build a complete iOS messaging app using XMPPFramework - Part 2","title":"Build a complete iOS messaging app using XMPPFramework"},{"location":"user-guide/iOS_tutorial/#yaxt-yet-another-xmpp-tutorial","text":"Well, this is going to be another tutorial, but I\u2019m going to try to make it a little bit different. This is an XMPP tutorial from an iOS developer\u2019s perspective. I\u2019ll try to answer all the questions I had when I started working in this area. This journey is going to go from no XMPP knowldege at all to having a fully functional instant messaging iOS appusing this cool protocol. We are going to be using the super awesome (yet overwhelming at the beginning\u2026) XMPPFramework library, and the idea is also to also mix in some iOS concepts that you are going to need for your app.","title":"YAXT??! Yet another XMPP tutorial?"},{"location":"user-guide/iOS_tutorial/#whats-xmpp","text":"From Wikipedia : Extensible Messaging and Presence Protocol (XMPP) is a communications protocol for message-oriented middleware based on XML. This basically means XMPP is a protocol for exchanging stuff. What kind of stuff? Messages and presences. We all know what messages are, but what about presences? A presence is just a way of sharing a \u201cstatus\u201d, that\u2019s it. You can be \u2018online\u2019, 'offline\u2019, 'having lunch\u2019, or whatever you want. Also there\u2019s another important word: Extensible meaning it can grow. It started as an instant messaging protocol and it has grown into multiple fields for example IoT (Internet of Things). And last, but not least: every piece of information we are going to exchange under this protocol is going to be XML. I can heard you complaining but\u2026 Come on, it\u2019s not that bad!","title":"What\u2019s XMPP?"},{"location":"user-guide/iOS_tutorial/#why-do-we-need-xmpp-why-not-just-rest","text":"Well what other options do we have? On the one hand, a custom solution means building everything from scratch, that takes time. On the other hand, we have XMPP, a super tested technology broadly used by millions of people every day, so we can say that\u2019s an advantage over a custom approach. Everytime I talk about XMPP, someone asks me 'Why not just REST?\u2019. Well, there is a misconception here. REST is not a protocol, it\u2019s just a way of architecting a networked application; it\u2019s just a standarized way of doing something (that I love btw). So let\u2019s change the question to something that makes more sense: \u201cWhy not just build a custom REST chat application?\u201d. The first thing that comes to my mind is what I already explained in the previous paragraph, but there is something else. How do I know when someone has sent me a message? For XMPP this is trivial: we have an open connection all the time so, as soon as a message arrives to the server, it will send us the message. We have a full-duplex. On the other hand, the only solution with REST is polling. We will need to ask the server for new messages from time to time to see if there is something new for us. That sucks. So, we will have to add a mechanism that allows us to receive the messages as soon as they are created, like SSE or WebSockets. There is one more XMPP advantage over a custom REST chat application. REST uses HTTP, an application level protocol that is built on top of a transport level protocol: TCP. So everytime you want to use your REST solution, you will need HTTP, a protocol that is not always available everywhere (maybe you need to embed this in a cheap piece of hardware?). Besides, we have XMPP built on top of TCP that\u2019s going to be always available.","title":"Why do we need XMPP? Why not just REST?"},{"location":"user-guide/iOS_tutorial/#whats-the-basic-stuff-i-need-to-know-to-get-started","text":"Well, you know a lot already but let\u2019s make a list. Lists are always good: XMPP is built on top of TCP. It keeps an open connection all the time. Client/Server architecture. Messages always go through a server. Everything we send and receive is going to be XML and it\u2019s called Stanza. We have three different types of stanzas: iq, message and presence. Every individual on the XMPP network is univocally identified by a JID (Jabber ID). All the stanzas are cointained in a Stream. Let\u2019s imagine the Stream as a white canvas where you and the server write the stanzas. Stream, iq, message and presence are the core of XMPP. You can find everything perfectly detailed in RFC6120 XMPP can be extended to accomplish different stuff. Each extension is called XEP (XMPP Extension Protocol).","title":"What\u2019s the basic stuff I need to know to get started?"},{"location":"user-guide/iOS_tutorial/#whats-a-jid","text":"Jabber ID (JID) is how we univocally identify each individual in XMPP. It is the address to where we are going to send our stanzas. This is how a JID looks like: localpart : This is your username. domainpart : Server name where the localpart resides. resourcepart : This is optional, and it identifies a particular client for the user. For example: I can be logged in with andres@erlang-solutions.com on my iPhone, on my Android and on my mac at the same time\u2026 So all these will be the same localpart + domainpart but different resourcepart I\u2019m sure you have already noticed how similar the JID looks to a standard email address. This is because you can connect multiple servers together and the messages are rooted to the right user in the right server, just as email works. Pretty cool, right? Sometimes you will see we have a JID with just the domain part. Why?! Because it\u2019s also possible to send stanzas to a service instead of a user. A service? What\u2019s a service?! Services are different pieces of an XMPP server that offer you some special functionality, but don\u2019t worry about this right now, just remember: you can have JIDs without a localpart.","title":"What\u2019s a JID?"},{"location":"user-guide/iOS_tutorial/#whats-a-stanza","text":"Stanza is the name of the XML pieces that we are going to be sending and receiving. The defined stanzas are: <message/> , <presence/> and <iq/> .","title":"What\u2019s a Stanza?"},{"location":"user-guide/iOS_tutorial/#message","text":"This is a basic <message/> stanza. Everytime you want to send a message to someone (a JID), you will have to send this stanza: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 <message from= 'andres@erlang-solutions.com/iphone' to= 'juana@erlang-solutions.com' type= 'chat' > <body> Hey there! </body> </message> ``` ### ` <iq/> ` It stands for Info/Query. It\u2019s a query-action mechanism, you send an `iq` and you will get a response to that query. You can pair the `iq-query` with the `iq-response` using the stanza id. For example, we send an `iq` to the server to do something (don\u2019t pay attention to what we want to do\u2026 you just need to know there is an `iq` stanza and how the mechanism works): ```xml <iq to= 'erlang-solutions.com' type= 'get' id= '1' > <query xmlns= 'http://jabber.org/protocol/disco#items' /> </iq> And we get back another iq with the same id with the result of the previous query: 1 2 3 4 5 6 7 <iq from= 'erlang-solutions.com' to= 'ramabit@erlang-solutions.com/Andress-MacBook-Air' id= '1' type= 'result' > <query xmlns= 'http://jabber.org/protocol/disco#items' > <item jid= 'muc.erlang-solutions.com' /> <item jid= 'muclight.erlang-solutions.com' /> <item jid= 'pubsub.erlang-solutions.com' /> </query> </iq>","title":"&lt;message/&gt;"},{"location":"user-guide/iOS_tutorial/#presence","text":"Used to exchange presence information, as you could have imagined. Usually presences are sent from the client to the server and broadcasted by it. The most basic, yet valid presence, to indicate to the server that a user is avaiable is: 1 <presence/> After a sucessfull connection, you are not going to receive any <message/> until you make yourself available sending the previous presence. If you want to make yourself unavailable, you just have to send: 1 <presence type= \"unavailable\" ></presence> If we want to make the presences more useful, we can send something like this: 1 2 3 <presence> <status> On vacation </status> </presence>","title":"&lt;presence/&gt;"},{"location":"user-guide/iOS_tutorial/#whats-a-stream","text":"Before answering this, let\u2019s refresh our mind. What\u2019s a Unix socket? From Wikipedia: A socket is a special file used for inter-process communication. These allows communication between two processes. So a socket is a file that can be written by two processes (in the same computer or in different computers in the same network). So the client is going to write to this file and server too. Ok, but how is a socket related to a Stream? Well, we are going to be connected to a server using a socket, therefore we are going to have a 'shared file\u2019 between the client and the server. This shared file is a white canvas where we are going to start writting our XML stanzas. The first thing we are going to write to this file is an opening <stream> tag! And there you go\u2026 that\u2019s our stream. Perfect, I understand what a stream is, but I still don\u2019t understand how to send a message to the server. Well, the only thing we need to do to send a message is writting a stanza in our shared file. But what happens when the server wants to send me a message? Simple: it will write the message in the 'shared file\u2019.","title":"What\u2019s a Stream?"},{"location":"user-guide/iOS_tutorial/#are-we-ok-so-far","text":"I\u2019m sure at this point you have questions like: \u201cWhat?! An active TCP connection open all the time? I\u2019m used to REST! How am I going to do that?!\u201d Easy, you don\u2019t have to care about that any more! That\u2019s why we are going to use the library, and it will take care of that. \u201cYou said nothing about how to connect to the server!\u201d Believe me, you don\u2019t have to care about this either. If we start adding all this info, we are going to get crazy. Trust me, I\u2019ve been there. \u201cWhat about encrypted messages? We need security! How are we going to handle this?\u201d Again, you don\u2019t have to care about this at this point. Baby steps! You just need to be able to answer: \u201cWhat\u2019s XMPP?\u201d, \u201cHow do you send a message?\u201d, \u201cHow do you change your status in XMPP?\u201d, \u201cHow do you ask something to the server?\u201d, \u201cWhat\u2019s a Stream?\u201d. If you can answer all that, you are WAY better than me when I started.","title":"Are we ok so far?"},{"location":"user-guide/iOS_tutorial/#first-steps-installing-the-xmppframework-library","text":"Let\u2019s create a brand new Xcode project and install the library. In this tutorial we are going to be using Swift 3 . The easiest way to integrate XMPPFramework to the project is using CocoaPods . Let\u2019s create our Podfile using the pod init command in the folder where our .xcodeproj lives. There are thousands of forks but the maintained one is the original: robbiehanson/XMPPFramework . So let\u2019s add the pod to our Podfile and remember to uncomment the use_frameworks! . 1 2 3 4 5 use_frameworks! target 'CrazyMessages' do pod 'XMPPFramework', :git=> 'git@github.com:robbiehanson/XMPPFramework.git', :branch => 'master' end Then pod install and CocoaPods is going to do its magic and create a .xcworkspace with the library integrated. Now we just need to import XMPPFramework in the files we want to use the library and that\u2019s it.","title":"First steps: installing the XMPPFramework library"},{"location":"user-guide/iOS_tutorial/#starting-to-build-our-instant-messaging-app","text":"The most important thing in an XMPP application is the stream, that\u2019s where we are going to \u201cwrite\u201d our stanzas, so we need an object that is going to hold it. We are going to create an XMPPController class with an XMPPStream : 1 2 3 4 5 6 7 8 9 10 11 import Foundation import XMPPFramework class XMPPController : NSObject { var xmppStream : XMPPStream init () { self . xmppStream = XMPPStream () } } We are dealing with a highly asynchronous library here. For every action we are going to have a response some time in the future. To handle this XMPPFramework defines the XMPPStreamDelegate . So implementing that delegate is going to help us answer lots of different questions like: \u201cHow do I know when XMPP has successfully connected?\u201d, \u201cHow do I know if I\u2019m correctly authenticated?\u201d, \u201cHow do I know if I received a message?\u201d. XMPPStreamDelegate is your friend! So we have our XMPPController and our XMPPStream , what do we need to do now? Configure our stream with the hostName , port and ourJID . To provide all this info to the controller we are going to make some changes to the init to be able to receive all these parameters: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 enum XMPPControllerError : Error { case wrongUserJID } class XMPPController : NSObject { var xmppStream : XMPPStream let hostName : String let userJID : XMPPJID let hostPort : UInt16 let password : String init ( hostName : String , userJIDString : String , hostPort : UInt16 = 5222 , password : String ) throws { guard let userJID = XMPPJID ( string : userJIDString ) else { throw XMPPControllerError . wrongUserJID } self . hostName = hostName self . userJID = userJID self . hostPort = hostPort self . password = password // Stream Configuration self . xmppStream = XMPPStream () self . xmppStream . hostName = hostName self . xmppStream . hostPort = hostPort self . xmppStream . startTLSPolicy = XMPPStreamStartTLSPolicy . allowed self . xmppStream . myJID = userJID super . init () self . xmppStream . addDelegate ( self , delegateQueue : DispatchQueue . main ) } } Our next step is going to actually connect to a server and authenticate using our userJID and password , so we are adding a connect method to our XMPPController . 1 2 3 4 5 6 7 func connect () { if ! self . xmppStream . isDisconnected () { return } try ! self . xmppStream . connect ( withTimeout : XMPPStreamTimeoutNone ) } But how do we know we have successfully connected to the server? As I said earlier, we need to check for a suitable delegate method from XMPPStreamDelegate . After we connect to the server we need to authenticate so we are going to do the following: 1 2 3 4 5 6 7 8 9 10 11 12 extension XMPPController : XMPPStreamDelegate { func xmppStreamDidConnect ( _ stream : XMPPStream !) { print ( \"Stream: Connected\" ) try ! stream . authenticate ( withPassword : self . password ) } func xmppStreamDidAuthenticate ( _ sender : XMPPStream !) { self . xmppStream . send ( XMPPPresence ()) print ( \"Stream: Authenticated\" ) } } We need to test this. Let\u2019s just create an instance of XMPPController in the AppDelegate to test how it works: 1 2 3 4 try ! self . xmppController = XMPPController ( hostName : \"host.com\" , userJIDString : \"user@host.com\" , password : \"password\" ) self . xmppController . connect () If everything goes fine we should see two messages in the logs but of course that\u2019s not happening, we missed something. We never told to our xmppStream who was the delegate object! We need to add the following line after the super.init() 1 self . xmppStream . addDelegate ( self , delegateQueue : DispatchQueue . main ) If we run the app again: 1 2 Stream : Connected Stream : Authenticated Success! We have our own XMPPController with a fully functional and authenticated stream! Something that may catch your attention is how we are setting our delegate, we are not doing: 1 self . xmppStream . delegate = self Why not? Because we can \u201cbroadcast\u201d the events to multiple delegates, we can have 10 different objects implementing those methods. Also we can tell what\u2019s the thread where we want to receive that call, in the previous example we want it in the main thread.","title":"Starting to build our Instant Messaging app"},{"location":"user-guide/iOS_tutorial/#getting-a-log-in","text":"Our app is super ugly, let\u2019s put on some makeup! We have nothing but an XMPPController and a hardcoded call in the AppDelegate . I\u2019m going to create a ViewController that is going to be presented modally as soon as the app starts, that ViewController will have the neccesary fields/info to log in to the server. I\u2019m going to create a LogInViewControllerDelegate that is going to tell to our ViewController that the Log in button was pressed and that\u2019s it. In that delegate implementation we are going to create our XMPPController , add the ViewControlleras delegate of the XMPPStream and connect! 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 extension ViewController : LogInViewControllerDelegate { func didTouchLogIn ( sender : LogInViewController , userJID : String , userPassword : String , server : String ) { self . logInViewController = sender do { try self . xmppController = XMPPController ( hostName : server , userJIDString : userJID , password : userPassword ) self . xmppController . xmppStream . addDelegate ( self , delegateQueue : DispatchQueue . main ) self . xmppController . connect () } catch { sender . showErrorMessage ( message : \"Something went wrong\" ) } } } Why are we adding ViewController as a delegate of XMPPStream if our XMPPController alreay has that delegate implemented? Because we need to know if this connection and authentication was successfull or notin our ViewController so we are able to dismiss the LogInViewController or show an error message if something failed. This is why being able to add multiple delegates is so useful. So as I said I\u2019m going to make ViewController to comform to the XMPPStreamDelegate : 1 2 3 4 5 6 7 8 9 10 11 extension ViewController : XMPPStreamDelegate { func xmppStreamDidAuthenticate ( _ sender : XMPPStream !) { self . logInViewController ?. dismiss ( animated : true , completion : nil ) } func xmppStream ( _ sender : XMPPStream !, didNotAuthenticate error : DDXMLElement !) { self . logInViewController ?. showErrorMessage ( message : \"Wrong password or username\" ) } } And that\u2019s it! Our app can log in to our server as I\u2019m showing here:","title":"Getting a Log In"},{"location":"user-guide/iOS_tutorial/#logging","text":"We\u2019ve been talking a lot about XMPP, stanzas and streams\u2026 but is there a way I can see the stream? Yes SR! XMPPFramework got us covered! XMPPFramework ships with CocoaLumberJack , a pretty well known logging framework. We just need to configure it, set the logging level we want and that\u2019s it. Logs are going to start showing up!","title":"Logging!"},{"location":"user-guide/iOS_tutorial/#configuring-cocoalumberjack","text":"This is a really simple task, you just need to add to your func application(application: UIApplication, didFinishLaunchingWithOptions ... method the following line (remember to import CocoaLumberjack ): 1 DDLog . add ( DDTTYLogger . sharedInstance (), with : DDLogLevel . all ) I\u2019m not going to paste here all the connection process log because it makes no sense to try to understand what\u2019s going on at this stage of our learning. But I think showing what some stanzas look like is a good idea. To do this I\u2019m going to be sending messages from Adium . I\u2019m going to send this <message/> : 1 2 3 <message to= \"test.user@erlang-solutions.com\" > <body> This is a message sent from Adium! </body> </message> Let\u2019s see how it looks like when it reaches our app: 1 2 3 <message xmlns= \"jabber:client\" from= \"iamadium@erlang-solutions.com/MacBook-Air\" to= \"test.user@erlang-solutions.com\" > <body> This is a message sent from Adium! </body> </message> Let\u2019s send a <presence/> from Adium: 1 2 3 <presence> <status> On vacation </status> </presence> We are receiving: 1 2 3 <presence xmlns= \"jabber:client\" from= \"iamadium@erlang-solutions.com/MacBook-Air\" to= \"test.user@erlang-solutions.com\" > <status> On vacation </status> </presence> No doubts at all right? We send something and we receive it on the other end! That\u2019s it!","title":"Configuring CocoaLumberjack"},{"location":"user-guide/iOS_tutorial/#test-time","text":"I want to be sure that you are understanding and following everything and not just copy and pasting from a tutorial (as I usually do \ud83d\ude4a). So if you are able to answer these questions you are on a good track! Why am I sending a presence after successfully authenticating? What happens if I don\u2019t send it? What happens if I write a wrong server URL in the Log In form? How do I fix this problem if there is a problem\u2026 How do I detect if suddenly the stream is disconnected from the server? (maybe a network outage?) How do I detect if the user/password was wrong? If you need help leave a message!","title":"Test Time!"},{"location":"user-guide/release_config/","text":"Advanced release configuration It's now possible to install MongooseIM from source in two modes: system - it's used internally to generate Linux packages (.deb, .rpm) user - which is the default mode and used for testing on travis and in development You can also build OS specific packages by using the tools in [MongooseIM repo root]/tools/pkg - refer to README.md therein. Configure script The tools/configure script can be used to specify which 3rd party dependencies should be included in the final release or to set the installation prefix and installation mode. More details can found in the tool's help. The help is printed when the script is run without any parameters tools/configure : 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 configure: OPTIONS Specifies which 3rd party deps will be included in the release. Writes configure.out file as output - this file can be sourced with: . configure.out Writes rel/configure.vars.config which can be used as Reltool input. 3rd party apps: with-none include no 3rd party drivers with-all include all drivers with-mysql include mysql driver with-odbc include an ODBC driver (requires unixodbc to compile) with-pgsql include pgsql driver with-redis include redis driver with-riak include riak driver Options: prefix Installation PREFIX directory. Default: /usr/local system Install files into $PREFIX/{bin, etc, ...} instead of a completely self contained release. Default: no user System user to run the server as. Default: This script is also accessible via the make configure target. Example If mysql and redis are the only drivers that should be included in the release, run the following command before make rel : 1 $ ./tools/configure with-mysql with-redis You only need to run the ./tools/configure command once (unless changing the release's config is needed to include some other dependencies). System install To manually test the installation run tools/test-install.sh . This script is intended for careful inspection by a human user, not for automation. Results should be similar to those described below. On Mac: 1 2 3 ./tools/configure with-all user = erszcz prefix = /tmp/mim-sandbox-system system = yes cat configure.out rel/configure.vars.config RUNNER_GROUP = staff make install Overriding RUNNER_GROUP on a Mac is necessary, as users by default don't have private groups of the same name as their usernames. Generated build configs: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 $ cat configure.out rel/configure.vars.config export MONGOOSEIM_CONFIGURED = \"yes\" export APPS = \"mysql eodbc epgsql eredis riakc nksip cqerl tirerl erlcloud\" export PREFIX = \"/tmp/mim-sandbox-system\" export RELTOOL_VARS = \"rel/configure.vars.config\" export SYSTEM = \"yes\" export RUNNER_USER = \"erszcz\" export BIN_DIR = \" $PREFIX /usr/bin\" export ETC_DIR = \" $PREFIX /etc/mongooseim\" export LIB_DIR = \" $PREFIX /usr/lib/mongooseim\" export LOG_DIR = \" $PREFIX /var/log/mongooseim\" export MDB_DIR = \" $PREFIX /var/lib/mongooseim\" export LOCK_DIR = \" $PREFIX /var/lock/mongooseim\" export PID_DIR = \" $PREFIX /var/lib/mongooseim\" export STATUS_DIR = \" $PREFIX /var/lib/mongooseim\" { mongooseim_runner_user, \"erszcz\" } . { mongooseim_script_dir, \"/tmp/mim-sandbox-system/usr/lib/mongooseim/bin\" } . { mongooseim_etc_dir, \"/tmp/mim-sandbox-system/etc/mongooseim\" } . { mongooseim_log_dir, \"/tmp/mim-sandbox-system/var/log/mongooseim\" } . { mongooseim_mdb_dir, \"/tmp/mim-sandbox-system/var/lib/mongooseim\" } . { mongooseim_pid_dir, \"/tmp/mim-sandbox-system/var/lib/mongooseim\" } . { mongooseim_status_dir, \"/tmp/mim-sandbox-system/var/lib/mongooseim\" } . { mongooseim_mdb_dir_toggle, []} . { mongooseim_lock_dir, \"/tmp/mim-sandbox-system/var/lock/mongooseim\" } . Installed tree: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 $ tree mim-sandbox-system/ -L 3 mim-sandbox-system/ \u251c\u2500\u2500 etc \u2502 \u2514\u2500\u2500 mongooseim \u2502 \u251c\u2500\u2500 app.config \u2502 \u251c\u2500\u2500 mongooseim.toml \u2502 \u2514\u2500\u2500 vm.args \u251c\u2500\u2500 usr \u2502 \u251c\u2500\u2500 bin \u2502 \u2502 \u2514\u2500\u2500 mongooseimctl \u2502 \u2514\u2500\u2500 lib \u2502 \u2514\u2500\u2500 mongooseim \u2514\u2500\u2500 var \u251c\u2500\u2500 lib \u2502 \u2514\u2500\u2500 mongooseim \u251c\u2500\u2500 lock \u2502 \u2514\u2500\u2500 mongooseim \u2514\u2500\u2500 log \u2514\u2500\u2500 mongooseim 13 directories, 4 files Files which change after starting and stopping such an installation: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 var/lib/mongooseim/DECISION_TAB.LOG var/lib/mongooseim/LATEST.LOG var/lib/mongooseim/last_activity.DCD var/lib/mongooseim/muc_registered.DCD var/lib/mongooseim/muc_room.DCD var/lib/mongooseim/offline_msg.DAT var/lib/mongooseim/passwd.DCD var/lib/mongooseim/privacy.DCD var/lib/mongooseim/private_storage.DAT var/lib/mongooseim/roster.DCD var/lib/mongooseim/roster_version.DCD var/lib/mongooseim/schema.DAT var/lib/mongooseim/vcard.DAT var/lib/mongooseim/vcard_search.DCD var/lib/mongooseim/pid var/lib/mongooseim/status var/log/mongooseim/crash.log var/log/mongooseim/mongooseim.log var/log/mongooseim/erlang.log.1 var/log/mongooseim/run_erl.log Caveats Running make install will blindly overwrite any configs it encounters on its way. Mnesia database and log files are preserved only due to the fact that they're not build process artifacts.","title":"Release/Installation configuration"},{"location":"user-guide/release_config/#advanced-release-configuration","text":"It's now possible to install MongooseIM from source in two modes: system - it's used internally to generate Linux packages (.deb, .rpm) user - which is the default mode and used for testing on travis and in development You can also build OS specific packages by using the tools in [MongooseIM repo root]/tools/pkg - refer to README.md therein.","title":"Advanced release configuration"},{"location":"user-guide/release_config/#configure-script","text":"The tools/configure script can be used to specify which 3rd party dependencies should be included in the final release or to set the installation prefix and installation mode. More details can found in the tool's help. The help is printed when the script is run without any parameters tools/configure : 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 configure: OPTIONS Specifies which 3rd party deps will be included in the release. Writes configure.out file as output - this file can be sourced with: . configure.out Writes rel/configure.vars.config which can be used as Reltool input. 3rd party apps: with-none include no 3rd party drivers with-all include all drivers with-mysql include mysql driver with-odbc include an ODBC driver (requires unixodbc to compile) with-pgsql include pgsql driver with-redis include redis driver with-riak include riak driver Options: prefix Installation PREFIX directory. Default: /usr/local system Install files into $PREFIX/{bin, etc, ...} instead of a completely self contained release. Default: no user System user to run the server as. Default: This script is also accessible via the make configure target.","title":"Configure script"},{"location":"user-guide/release_config/#example","text":"If mysql and redis are the only drivers that should be included in the release, run the following command before make rel : 1 $ ./tools/configure with-mysql with-redis You only need to run the ./tools/configure command once (unless changing the release's config is needed to include some other dependencies).","title":"Example"},{"location":"user-guide/release_config/#system-install","text":"To manually test the installation run tools/test-install.sh . This script is intended for careful inspection by a human user, not for automation. Results should be similar to those described below. On Mac: 1 2 3 ./tools/configure with-all user = erszcz prefix = /tmp/mim-sandbox-system system = yes cat configure.out rel/configure.vars.config RUNNER_GROUP = staff make install Overriding RUNNER_GROUP on a Mac is necessary, as users by default don't have private groups of the same name as their usernames. Generated build configs: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 $ cat configure.out rel/configure.vars.config export MONGOOSEIM_CONFIGURED = \"yes\" export APPS = \"mysql eodbc epgsql eredis riakc nksip cqerl tirerl erlcloud\" export PREFIX = \"/tmp/mim-sandbox-system\" export RELTOOL_VARS = \"rel/configure.vars.config\" export SYSTEM = \"yes\" export RUNNER_USER = \"erszcz\" export BIN_DIR = \" $PREFIX /usr/bin\" export ETC_DIR = \" $PREFIX /etc/mongooseim\" export LIB_DIR = \" $PREFIX /usr/lib/mongooseim\" export LOG_DIR = \" $PREFIX /var/log/mongooseim\" export MDB_DIR = \" $PREFIX /var/lib/mongooseim\" export LOCK_DIR = \" $PREFIX /var/lock/mongooseim\" export PID_DIR = \" $PREFIX /var/lib/mongooseim\" export STATUS_DIR = \" $PREFIX /var/lib/mongooseim\" { mongooseim_runner_user, \"erszcz\" } . { mongooseim_script_dir, \"/tmp/mim-sandbox-system/usr/lib/mongooseim/bin\" } . { mongooseim_etc_dir, \"/tmp/mim-sandbox-system/etc/mongooseim\" } . { mongooseim_log_dir, \"/tmp/mim-sandbox-system/var/log/mongooseim\" } . { mongooseim_mdb_dir, \"/tmp/mim-sandbox-system/var/lib/mongooseim\" } . { mongooseim_pid_dir, \"/tmp/mim-sandbox-system/var/lib/mongooseim\" } . { mongooseim_status_dir, \"/tmp/mim-sandbox-system/var/lib/mongooseim\" } . { mongooseim_mdb_dir_toggle, []} . { mongooseim_lock_dir, \"/tmp/mim-sandbox-system/var/lock/mongooseim\" } . Installed tree: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 $ tree mim-sandbox-system/ -L 3 mim-sandbox-system/ \u251c\u2500\u2500 etc \u2502 \u2514\u2500\u2500 mongooseim \u2502 \u251c\u2500\u2500 app.config \u2502 \u251c\u2500\u2500 mongooseim.toml \u2502 \u2514\u2500\u2500 vm.args \u251c\u2500\u2500 usr \u2502 \u251c\u2500\u2500 bin \u2502 \u2502 \u2514\u2500\u2500 mongooseimctl \u2502 \u2514\u2500\u2500 lib \u2502 \u2514\u2500\u2500 mongooseim \u2514\u2500\u2500 var \u251c\u2500\u2500 lib \u2502 \u2514\u2500\u2500 mongooseim \u251c\u2500\u2500 lock \u2502 \u2514\u2500\u2500 mongooseim \u2514\u2500\u2500 log \u2514\u2500\u2500 mongooseim 13 directories, 4 files Files which change after starting and stopping such an installation: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 var/lib/mongooseim/DECISION_TAB.LOG var/lib/mongooseim/LATEST.LOG var/lib/mongooseim/last_activity.DCD var/lib/mongooseim/muc_registered.DCD var/lib/mongooseim/muc_room.DCD var/lib/mongooseim/offline_msg.DAT var/lib/mongooseim/passwd.DCD var/lib/mongooseim/privacy.DCD var/lib/mongooseim/private_storage.DAT var/lib/mongooseim/roster.DCD var/lib/mongooseim/roster_version.DCD var/lib/mongooseim/schema.DAT var/lib/mongooseim/vcard.DAT var/lib/mongooseim/vcard_search.DCD var/lib/mongooseim/pid var/lib/mongooseim/status var/log/mongooseim/crash.log var/log/mongooseim/mongooseim.log var/log/mongooseim/erlang.log.1 var/log/mongooseim/run_erl.log","title":"System install"},{"location":"user-guide/release_config/#caveats","text":"Running make install will blindly overwrite any configs it encounters on its way. Mnesia database and log files are preserved only due to the fact that they're not build process artifacts.","title":"Caveats"},{"location":"user-guide/push-notifications/MongoosePush-setup/","text":"Push notifications with MongoosePush MongoosePush is a simple RESTful service written in Elixir. It provides the ability to send push notifications to FCM (Firebase Cloud Messaging) and/or APNS (Apple Push Notification Service) via their HTTP/2 API. To take advantage of MongoosePush's functionality, you will need to enable the mod_push_service_mongoosepush module: this module acts as a bridge between the push_notifications hook and MongoosePush itself. Getting started To enable integration with MongoosePush, it is as simple as the next two steps. First, you need to define a pool of HTTPS connections to MongoosePush in the outgoing_pools section: 1 2 3 4 5 6 [outgoing_pools.http.mongoose_push_http] scope = \"global\" strategy = \"available_worker\" [outgoing_pools.http.mongoose_push_http.connection] host = \"https://localhost:8443\" And second, you need to add mod_push_service_mongoosepush to the modules section in the config file: 1 2 3 [modules.mod_push_service_mongoosepush] pool_name = mongoose_push_http api_version = \"v3\" Here, we assume that MongoosePush will be available on the localhost on port 8443, which is the default one \u2014 note the server option in the outgoing pool definition. Next we enable mod_push_service_mongoosepush . The first option is the name of the HTTP pool to use and the second one is the version of MongoosePush 's API (\" v2 \" or \" v3 \" are supported). And that's it, we've just completed the entire MongooseIM configuration. All we need to do now is to set up MongoosePush . Starting MongoosePush The easiest way to start MongoosePush is using its docker image . But before you can set MongoosePush up, you need a FCM application token and/or an APNS application certificate. You can get the FCM token here and the easiest way of getting an APNS application certificate is by running this script (please note that you need the certificate in pem format). After you get the FCM application token and/or the APNS application certificate, you can prepare to start MongoosePush . Firstly, prepare the following files structure: priv/ ssl/ rest_cert.pem - The REST endpoint certificate rest_key.pem - private key for the REST endpoint certificate apns/ prod_cert.pem - Production APNS app certificate prod_key.pem - Production APNS app certificate's private key dev_cert.pem - Development APNS app certificate dev_key.pem - Development APNS app certificate's private key fcm/ token.json - FCM service account JSON file If your FCM app token is MY_FCM_SECRET_TOKEN and you have the priv directory with all certificates in the current directory, start MongoosePush with the following command: 1 2 3 4 5 docker run -v ` pwd ` /priv:/opt/app/priv \\ -e PUSH_FCM_APP_FILE = \"MY_FCM_SECRET_TOKEN\" \\ -e PUSH_HTTPS_CERTFILE = \"/opt/app/priv/ssl/rest_cert.pem\" \\ -e PUSH_HTTPS_KEYFILE = \"/opt/app/priv/ssl/rest_key.pem\" \\ -it --rm mongooseim/mongoose-push:2.0.0 If you don't want to use either APNS or FCM , you simply need to pass PUSH_APNS_ENABLED=0 or PUSH_FCM_ENABLED=0 respectively as additional env variables in your docker run command. For more advanced options and configuration please refer to \"Quick start / Configuring\" in MongoosePush 's README.md . When your MongoosePush docker is up and running, Push Notifications can be used in your MongooseIM instance.","title":"How to Set up MongoosePush"},{"location":"user-guide/push-notifications/MongoosePush-setup/#push-notifications-with-mongoosepush","text":"MongoosePush is a simple RESTful service written in Elixir. It provides the ability to send push notifications to FCM (Firebase Cloud Messaging) and/or APNS (Apple Push Notification Service) via their HTTP/2 API. To take advantage of MongoosePush's functionality, you will need to enable the mod_push_service_mongoosepush module: this module acts as a bridge between the push_notifications hook and MongoosePush itself.","title":"Push notifications with MongoosePush"},{"location":"user-guide/push-notifications/MongoosePush-setup/#getting-started","text":"To enable integration with MongoosePush, it is as simple as the next two steps. First, you need to define a pool of HTTPS connections to MongoosePush in the outgoing_pools section: 1 2 3 4 5 6 [outgoing_pools.http.mongoose_push_http] scope = \"global\" strategy = \"available_worker\" [outgoing_pools.http.mongoose_push_http.connection] host = \"https://localhost:8443\" And second, you need to add mod_push_service_mongoosepush to the modules section in the config file: 1 2 3 [modules.mod_push_service_mongoosepush] pool_name = mongoose_push_http api_version = \"v3\" Here, we assume that MongoosePush will be available on the localhost on port 8443, which is the default one \u2014 note the server option in the outgoing pool definition. Next we enable mod_push_service_mongoosepush . The first option is the name of the HTTP pool to use and the second one is the version of MongoosePush 's API (\" v2 \" or \" v3 \" are supported). And that's it, we've just completed the entire MongooseIM configuration. All we need to do now is to set up MongoosePush .","title":"Getting started"},{"location":"user-guide/push-notifications/MongoosePush-setup/#starting-mongoosepush","text":"The easiest way to start MongoosePush is using its docker image . But before you can set MongoosePush up, you need a FCM application token and/or an APNS application certificate. You can get the FCM token here and the easiest way of getting an APNS application certificate is by running this script (please note that you need the certificate in pem format). After you get the FCM application token and/or the APNS application certificate, you can prepare to start MongoosePush . Firstly, prepare the following files structure: priv/ ssl/ rest_cert.pem - The REST endpoint certificate rest_key.pem - private key for the REST endpoint certificate apns/ prod_cert.pem - Production APNS app certificate prod_key.pem - Production APNS app certificate's private key dev_cert.pem - Development APNS app certificate dev_key.pem - Development APNS app certificate's private key fcm/ token.json - FCM service account JSON file If your FCM app token is MY_FCM_SECRET_TOKEN and you have the priv directory with all certificates in the current directory, start MongoosePush with the following command: 1 2 3 4 5 docker run -v ` pwd ` /priv:/opt/app/priv \\ -e PUSH_FCM_APP_FILE = \"MY_FCM_SECRET_TOKEN\" \\ -e PUSH_HTTPS_CERTFILE = \"/opt/app/priv/ssl/rest_cert.pem\" \\ -e PUSH_HTTPS_KEYFILE = \"/opt/app/priv/ssl/rest_key.pem\" \\ -it --rm mongooseim/mongoose-push:2.0.0 If you don't want to use either APNS or FCM , you simply need to pass PUSH_APNS_ENABLED=0 or PUSH_FCM_ENABLED=0 respectively as additional env variables in your docker run command. For more advanced options and configuration please refer to \"Quick start / Configuring\" in MongoosePush 's README.md . When your MongoosePush docker is up and running, Push Notifications can be used in your MongooseIM instance.","title":"Starting MongoosePush"},{"location":"user-guide/push-notifications/Push-notifications-client-side/","text":"Using push notifications on the client side There are just a few things the XMPP client application needs to receive the push notifications. Depending on whether you plan to use PubSub-full or PubSub-less configuration, some of the steps may be unnecessary. Registering with a Push Service provider First, the client application has to get a device-specific token from the Push Service Provider (FCM or APNS). This process is different, depending on the platform, so please consult your Push Service Provider's manual to see how to get this token. For example, here you can learn about setting up FCM on Android platform and here you can learn about setting up APNS on iOS platform. After this step, your application shall be able to receive FCM or APNS token - it will be required in the next step of this tutorial. Setting up an XMPP pubsub node This step is specific to the PubSub-full push configuration that you chose for your MongooseIM server. If you're running a PubSub-less configuration, skip to this point . Creating a new push node In this example mypubsub.com is a domain of the MongooseIM server that has mod_pubsub enabled with the push node support. The client sends the following stanza to the server: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 <iq type= 'set' to= 'pubsub.mypubsub.com' id= 'create1' > <pubsub xmlns= 'http://jabber.org/protocol/pubsub' > <create node= 'punsub_node_for_my_private_iphone' type= 'push' /> <configure> <x xmlns= 'jabber:x:data' type= 'submit' > <field var= 'FORM_TYPE' type= 'hidden' > <value> http://jabber.org/protocol/pubsub#node_config </value> </field> <field var= 'pubsub#access_model' > <value> whitelist </value> </field> <field var= 'pubsub#publish_model' > <value> publishers </value> </field> </x> </configure> </pubsub> </iq> The pubsub.mypubsub.com will be used as a gateway for all notifications and will pass them through to the APNS and/or FCM. The most important and only difference from the standard node creation is the type='push' part of the create element. According to XEP-0357: Push Notifications , a PubSub node is required to route the push notification mechanism. This implies you need a node that will handle your push notifications, hence we create a node called punsub_node_for_my_private_iphone . This node should be unique to the device and you may reuse nodes already created this way. The token obtained from APNS or FCM is a good option to ensure this uniqueness, by either using it directly or within some custom node name generation. It is also important from the security perspective to configure the node with: access_model set to whitelist so only affiliated users can access the node. publish_model set to publishers so only users with publisher or publisher_only role can publish notifications. Adding the server's JID to allowed publishers Push notifications to the push node are addressed from your server's JID. If the push node was configured with the above recommended options, you need to allow your server's JID to publish notifications to that node. Considering your JID is alice@mychat.com , your server's JID is just mychat.com . The following stanza sent to the just created push node will allow your server JID to publish notifications: 1 2 3 4 5 6 7 8 9 10 <iq to= 'pubsub.mypubsub.com' type= 'set' id= 'wy6Hibg=' from= 'alice@mychat.com/resource' > <pubsub xmlns= 'http://jabber.org/protocol/pubsub#owner' > <affiliations node= 'punsub_node_for_my_private_iphone' > <affiliation jid= 'mychat.com' affiliation= 'publish-only' /> </affiliations> </pubsub> </iq> Enabling push notifications The next and the last step is to enable push notifications on the server that handles your messages (and has mod_event_pusher_push enabled). Let's assume this server is available under the domain mychat.com . To enable push notifications in the simplest configuration, just send the following stanza: 1 2 3 4 5 6 7 8 9 10 11 12 <iq type= 'set' id= 'x43' > <enable xmlns= 'urn:xmpp:push:0' jid= 'pubsub.mypubsub.com' node= 'punsub_node_for_my_private_iphone' > <x xmlns= 'jabber:x:data' type= 'submit' > <field var= 'FORM_TYPE' ><value> http://jabber.org/protocol/pubsub#publish-options </value></field> <field var= 'service' ><value> apns </value></field> <field var= 'device_id' ><value> your_pns_device_token </value></field> <field var= 'silent' ><value> false </value></field> <field var= 'topic' ><value> some_apns_topic </value></field> <field var= 'priority' ><value> some_priority </value></field> </x> </enable> </iq> We have now enabled push notifications to be send to the pubsub.mypubsub.com domain on the node punsub_node_for_my_private_iphone created previously, or in the case of PubSub-less, for whatever unique node name we give here, for example any variation of the token obtained from APNS or FCM . Please note that publish-options are specific to various XMPP Push Services. Publish options For mod_push_service_mongoosepush the next publish-options are mandatory: device_id - device token (here: your_pns_device_token ) that you received from your push notification service provider (as described in Registering with Push Service provider ) service - push notification service provider name ( apns or fcm ) there are also some other publish-options supported: mode - which may be either prod or dev (default to prod ). Decides which connection pool type on MongoosePush shall be used. This may be used when APNS on MongoosePush is configured to work with both production and development certificate. click_action - action to perform when notification is clicked on the device. activity on Android and category on iOS . Please refer to your platform / push notification service provider for more info. topic - currently only used with APNS . The value is passed to APNS as topic header. For more information please refer to APNS documentation. silent - if set to true , all notifications will be \"silent\". This means that only the data payload will be send to the push notifications provider with no notification. The data payload will contain all notification fields as defined in XEP-0357: Push Notifications . priority \u2014 which may be either normal or high , and if not given, defaults to normal . This value will set the push notification priority. Please refer to FCM / APNS documentation for more details on those values. sound - sound that should be played when a notification arrives. Please refer to FCM / APNS documentation for more details. mutable_content - only applicable to APNS . If set to true , sets \"mutable-content=1\" in the APNS payload. time_to_live - only applicable to FCM . Maximum lifespan of an FCM notification. Please refer to the FCM documentation for more details. Any other publish-options are ignored by mod_push_service_mongoosepush Disabling push notifications Disabling push notifications is very simple. Just send the following stanza to your XMPP chat server: 1 2 3 <iq type= 'set' id= 'x44' > <disable xmlns= 'urn:xmpp:push:0' jid= 'pubsub.mypubsub.com' node= 'punsub_node_for_my_private_iphone' /> </iq> You may skip the node='punsub_node_for_my_private_iphone' to globally disable push notifications on all nodes that are registered with your JID . This may be used to disable push notifications on all your devices. Communication overview One picture is worth a thousand words, so here are two diagrams showing the typical communication when using push notifications: PubSub-full PubSub-less","title":"How to Set up Push Notifications on the client side"},{"location":"user-guide/push-notifications/Push-notifications-client-side/#using-push-notifications-on-the-client-side","text":"There are just a few things the XMPP client application needs to receive the push notifications. Depending on whether you plan to use PubSub-full or PubSub-less configuration, some of the steps may be unnecessary.","title":"Using push notifications on the client side"},{"location":"user-guide/push-notifications/Push-notifications-client-side/#registering-with-a-push-service-provider","text":"First, the client application has to get a device-specific token from the Push Service Provider (FCM or APNS). This process is different, depending on the platform, so please consult your Push Service Provider's manual to see how to get this token. For example, here you can learn about setting up FCM on Android platform and here you can learn about setting up APNS on iOS platform. After this step, your application shall be able to receive FCM or APNS token - it will be required in the next step of this tutorial.","title":"Registering with a Push Service provider"},{"location":"user-guide/push-notifications/Push-notifications-client-side/#setting-up-an-xmpp-pubsub-node","text":"This step is specific to the PubSub-full push configuration that you chose for your MongooseIM server. If you're running a PubSub-less configuration, skip to this point .","title":"Setting up an XMPP pubsub node"},{"location":"user-guide/push-notifications/Push-notifications-client-side/#creating-a-new-push-node","text":"In this example mypubsub.com is a domain of the MongooseIM server that has mod_pubsub enabled with the push node support. The client sends the following stanza to the server: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 <iq type= 'set' to= 'pubsub.mypubsub.com' id= 'create1' > <pubsub xmlns= 'http://jabber.org/protocol/pubsub' > <create node= 'punsub_node_for_my_private_iphone' type= 'push' /> <configure> <x xmlns= 'jabber:x:data' type= 'submit' > <field var= 'FORM_TYPE' type= 'hidden' > <value> http://jabber.org/protocol/pubsub#node_config </value> </field> <field var= 'pubsub#access_model' > <value> whitelist </value> </field> <field var= 'pubsub#publish_model' > <value> publishers </value> </field> </x> </configure> </pubsub> </iq> The pubsub.mypubsub.com will be used as a gateway for all notifications and will pass them through to the APNS and/or FCM. The most important and only difference from the standard node creation is the type='push' part of the create element. According to XEP-0357: Push Notifications , a PubSub node is required to route the push notification mechanism. This implies you need a node that will handle your push notifications, hence we create a node called punsub_node_for_my_private_iphone . This node should be unique to the device and you may reuse nodes already created this way. The token obtained from APNS or FCM is a good option to ensure this uniqueness, by either using it directly or within some custom node name generation. It is also important from the security perspective to configure the node with: access_model set to whitelist so only affiliated users can access the node. publish_model set to publishers so only users with publisher or publisher_only role can publish notifications.","title":"Creating a new push node"},{"location":"user-guide/push-notifications/Push-notifications-client-side/#adding-the-servers-jid-to-allowed-publishers","text":"Push notifications to the push node are addressed from your server's JID. If the push node was configured with the above recommended options, you need to allow your server's JID to publish notifications to that node. Considering your JID is alice@mychat.com , your server's JID is just mychat.com . The following stanza sent to the just created push node will allow your server JID to publish notifications: 1 2 3 4 5 6 7 8 9 10 <iq to= 'pubsub.mypubsub.com' type= 'set' id= 'wy6Hibg=' from= 'alice@mychat.com/resource' > <pubsub xmlns= 'http://jabber.org/protocol/pubsub#owner' > <affiliations node= 'punsub_node_for_my_private_iphone' > <affiliation jid= 'mychat.com' affiliation= 'publish-only' /> </affiliations> </pubsub> </iq>","title":"Adding the server's JID to allowed publishers"},{"location":"user-guide/push-notifications/Push-notifications-client-side/#enabling-push-notifications","text":"The next and the last step is to enable push notifications on the server that handles your messages (and has mod_event_pusher_push enabled). Let's assume this server is available under the domain mychat.com . To enable push notifications in the simplest configuration, just send the following stanza: 1 2 3 4 5 6 7 8 9 10 11 12 <iq type= 'set' id= 'x43' > <enable xmlns= 'urn:xmpp:push:0' jid= 'pubsub.mypubsub.com' node= 'punsub_node_for_my_private_iphone' > <x xmlns= 'jabber:x:data' type= 'submit' > <field var= 'FORM_TYPE' ><value> http://jabber.org/protocol/pubsub#publish-options </value></field> <field var= 'service' ><value> apns </value></field> <field var= 'device_id' ><value> your_pns_device_token </value></field> <field var= 'silent' ><value> false </value></field> <field var= 'topic' ><value> some_apns_topic </value></field> <field var= 'priority' ><value> some_priority </value></field> </x> </enable> </iq> We have now enabled push notifications to be send to the pubsub.mypubsub.com domain on the node punsub_node_for_my_private_iphone created previously, or in the case of PubSub-less, for whatever unique node name we give here, for example any variation of the token obtained from APNS or FCM . Please note that publish-options are specific to various XMPP Push Services.","title":"Enabling push notifications"},{"location":"user-guide/push-notifications/Push-notifications-client-side/#publish-options","text":"For mod_push_service_mongoosepush the next publish-options are mandatory: device_id - device token (here: your_pns_device_token ) that you received from your push notification service provider (as described in Registering with Push Service provider ) service - push notification service provider name ( apns or fcm ) there are also some other publish-options supported: mode - which may be either prod or dev (default to prod ). Decides which connection pool type on MongoosePush shall be used. This may be used when APNS on MongoosePush is configured to work with both production and development certificate. click_action - action to perform when notification is clicked on the device. activity on Android and category on iOS . Please refer to your platform / push notification service provider for more info. topic - currently only used with APNS . The value is passed to APNS as topic header. For more information please refer to APNS documentation. silent - if set to true , all notifications will be \"silent\". This means that only the data payload will be send to the push notifications provider with no notification. The data payload will contain all notification fields as defined in XEP-0357: Push Notifications . priority \u2014 which may be either normal or high , and if not given, defaults to normal . This value will set the push notification priority. Please refer to FCM / APNS documentation for more details on those values. sound - sound that should be played when a notification arrives. Please refer to FCM / APNS documentation for more details. mutable_content - only applicable to APNS . If set to true , sets \"mutable-content=1\" in the APNS payload. time_to_live - only applicable to FCM . Maximum lifespan of an FCM notification. Please refer to the FCM documentation for more details. Any other publish-options are ignored by mod_push_service_mongoosepush","title":"Publish options"},{"location":"user-guide/push-notifications/Push-notifications-client-side/#disabling-push-notifications","text":"Disabling push notifications is very simple. Just send the following stanza to your XMPP chat server: 1 2 3 <iq type= 'set' id= 'x44' > <disable xmlns= 'urn:xmpp:push:0' jid= 'pubsub.mypubsub.com' node= 'punsub_node_for_my_private_iphone' /> </iq> You may skip the node='punsub_node_for_my_private_iphone' to globally disable push notifications on all nodes that are registered with your JID . This may be used to disable push notifications on all your devices.","title":"Disabling push notifications"},{"location":"user-guide/push-notifications/Push-notifications-client-side/#communication-overview","text":"One picture is worth a thousand words, so here are two diagrams showing the typical communication when using push notifications:","title":"Communication overview"},{"location":"user-guide/push-notifications/Push-notifications-client-side/#pubsub-full","text":"","title":"PubSub-full"},{"location":"user-guide/push-notifications/Push-notifications-client-side/#pubsub-less","text":"","title":"PubSub-less"},{"location":"user-guide/push-notifications/Push-notifications/","text":"How to set up Push Notifications Push notifications are the bread and butter of the modern mobile experience, and MongooseIM has support for them. When used together with MongoosePush , you get out-of-the-box push notifications for FCM ( F irebase C loud M essaging) and APNS ( A pple P ush N otification S ervice) providers. And it's easy to extend it to any other protocols of your choice. You might also want to read about the push notification's client side configuration . All push notification mechanisms use mod_event_pusher_push as a backend implementation, read the relevant documentation to know more about it. XEP-0357: Push Notifications Server side push notification support is fully compliant with XEP-0357: Push Notifications , which defines several components that need to work together in order to provide clients with working push notifications. However, there's just one non-optimal detail required by the aforementioned XEP: that push notifications being a PubSub service \u2014 we can do better than that . If you're already familiar with the workings of XEP-0357: Push Notifications , make sure to have a look at our PubSub-less enhancement . As it is always said, one picture is worth a thousand words: Who does what is highly configurable. You may use MongooseIM as the XMPP server clients connect to, and send the push XMPP stanzas to a different server that will take care of the push business; or you might use MongooseIM as the remote XMPP-PubSub server that does such business. Note that the XEP doesn't enforce the push IQ stanza format, so whichever setup is used, you need to take care of the producing and processing of these stanzas. You might also use MongooseIM as both, or you might even do both things within a single MongooseIM node (the most common setup!). Or, for the best performance, you might just skip that PubSub node altogether. While the whole setup can be incredibly extensible, we see the following straightforward uses of it. XEP-0357 compliant with local PubSub This is, historically, the most common setup. It allows your clients to enable push notifications via a local PubSub, and the IQ stanza is routed internally. A direct connection to a push service (e.g. MongoosePush) must be configured on the same MongooseIM node. Check out this tutorial on how to setup MongoosePush . 1 2 3 4 5 6 7 [modules.mod_pubsub] plugins = [ \"push\" ] # mandatory minimal config [modules.mod_event_pusher] backend . push . backend = \"mnesia\" # optional backend . push . wpool . workers = 200 # optional backend . push . plugin_module = \"mod_event_pusher_push_plugin_defaults\" # optional Advantages Completely XEP-0357 compliant, and therefore compatible with any compliant 3rd party client library No need to have two different servers Drawbacks Less efficient (PubSub has a considerable impact on heavily loaded systems) More load within a single node Harder to customise MongooseIM as a PubSub-less XMPP server PubSub is completely bypassed and clients don't need to create a push node \u2014 if they attempt to do so, and PubSub is not configured, the server would respond with an error stanza. They only have to provide the virtual PubSub address in the enable stanza, and node name can be anything unique. In order to ensure uniqueness the APNS/FCM token can be used. Note that the token must be provided as a publish option anyway. A direct connection to a push service (e.g. MongoosePush) must be configured on the same MongooseIM node. Check out this tutorial on how to setup MongoosePush . 1 2 3 4 5 [modules.mod_event_pusher] backend . push . backend = \"mnesia\" # optional backend . push . wpool . workers = 200 # optional backend . push . plugin_module = \"mod_event_pusher_push_plugin_defaults\" # optional backend . push . virtual_pubsub_hosts = [\"pubsub.@HOSTS@\"] Advantages No need to use PubSub at all More efficient (PubSub has a considerable impact on heavily loaded systems) Simpler client-side usage \u2014 Read about the client side configuration here Drawbacks If the client application is built to create the push PubSub node, this might require a migration for such client \u2014 as he attempts to create the node, the server will answer with an IQ error stanza. If migrating the client side is a problem, there's a solution for that in the module section Virtual PubSub hosts These domains will shadow any identical domain configured for PubSub, stealing any notification published to it. It enables easy migration from PubSub-full deployments to PubSub-less variants. Read more in the relevant section . Overview of all the involved MongooseIM components The components that make push notifications possible in MongooseIM comprise the following architecture: PubSub-full setup PubSub-less setup mod_event_pusher_push The first component that we need to configure in MongooseIM is the mod_event_pusher_push module. mod_push_service_mongoosepush A connector to MongoosePush application. You can read more about it here . mod_pubsub 's push node According to the XEP-0357: Push Notifications , all notifications generated via the module we have just enabled (i.e. mod_event_pusher_push ) have to be send to a push enabled publish-subscribe node. In order to allow clients to allocate such a node, we need to enable it in our mod_pubsub on the MongooseIM server that will communicate with the XMPP Push Service .","title":"How to Set up Push Notifications"},{"location":"user-guide/push-notifications/Push-notifications/#how-to-set-up-push-notifications","text":"Push notifications are the bread and butter of the modern mobile experience, and MongooseIM has support for them. When used together with MongoosePush , you get out-of-the-box push notifications for FCM ( F irebase C loud M essaging) and APNS ( A pple P ush N otification S ervice) providers. And it's easy to extend it to any other protocols of your choice. You might also want to read about the push notification's client side configuration . All push notification mechanisms use mod_event_pusher_push as a backend implementation, read the relevant documentation to know more about it.","title":"How to set up Push Notifications"},{"location":"user-guide/push-notifications/Push-notifications/#xep-0357-push-notifications","text":"Server side push notification support is fully compliant with XEP-0357: Push Notifications , which defines several components that need to work together in order to provide clients with working push notifications. However, there's just one non-optimal detail required by the aforementioned XEP: that push notifications being a PubSub service \u2014 we can do better than that . If you're already familiar with the workings of XEP-0357: Push Notifications , make sure to have a look at our PubSub-less enhancement . As it is always said, one picture is worth a thousand words: Who does what is highly configurable. You may use MongooseIM as the XMPP server clients connect to, and send the push XMPP stanzas to a different server that will take care of the push business; or you might use MongooseIM as the remote XMPP-PubSub server that does such business. Note that the XEP doesn't enforce the push IQ stanza format, so whichever setup is used, you need to take care of the producing and processing of these stanzas. You might also use MongooseIM as both, or you might even do both things within a single MongooseIM node (the most common setup!). Or, for the best performance, you might just skip that PubSub node altogether. While the whole setup can be incredibly extensible, we see the following straightforward uses of it.","title":"XEP-0357: Push Notifications"},{"location":"user-guide/push-notifications/Push-notifications/#xep-0357-compliant-with-local-pubsub","text":"This is, historically, the most common setup. It allows your clients to enable push notifications via a local PubSub, and the IQ stanza is routed internally. A direct connection to a push service (e.g. MongoosePush) must be configured on the same MongooseIM node. Check out this tutorial on how to setup MongoosePush . 1 2 3 4 5 6 7 [modules.mod_pubsub] plugins = [ \"push\" ] # mandatory minimal config [modules.mod_event_pusher] backend . push . backend = \"mnesia\" # optional backend . push . wpool . workers = 200 # optional backend . push . plugin_module = \"mod_event_pusher_push_plugin_defaults\" # optional","title":"XEP-0357 compliant with local PubSub"},{"location":"user-guide/push-notifications/Push-notifications/#advantages","text":"Completely XEP-0357 compliant, and therefore compatible with any compliant 3rd party client library No need to have two different servers","title":"Advantages"},{"location":"user-guide/push-notifications/Push-notifications/#drawbacks","text":"Less efficient (PubSub has a considerable impact on heavily loaded systems) More load within a single node Harder to customise","title":"Drawbacks"},{"location":"user-guide/push-notifications/Push-notifications/#mongooseim-as-a-pubsub-less-xmpp-server","text":"PubSub is completely bypassed and clients don't need to create a push node \u2014 if they attempt to do so, and PubSub is not configured, the server would respond with an error stanza. They only have to provide the virtual PubSub address in the enable stanza, and node name can be anything unique. In order to ensure uniqueness the APNS/FCM token can be used. Note that the token must be provided as a publish option anyway. A direct connection to a push service (e.g. MongoosePush) must be configured on the same MongooseIM node. Check out this tutorial on how to setup MongoosePush . 1 2 3 4 5 [modules.mod_event_pusher] backend . push . backend = \"mnesia\" # optional backend . push . wpool . workers = 200 # optional backend . push . plugin_module = \"mod_event_pusher_push_plugin_defaults\" # optional backend . push . virtual_pubsub_hosts = [\"pubsub.@HOSTS@\"]","title":"MongooseIM as a PubSub-less XMPP server"},{"location":"user-guide/push-notifications/Push-notifications/#advantages_1","text":"No need to use PubSub at all More efficient (PubSub has a considerable impact on heavily loaded systems) Simpler client-side usage \u2014 Read about the client side configuration here","title":"Advantages"},{"location":"user-guide/push-notifications/Push-notifications/#drawbacks_1","text":"If the client application is built to create the push PubSub node, this might require a migration for such client \u2014 as he attempts to create the node, the server will answer with an IQ error stanza. If migrating the client side is a problem, there's a solution for that in the module section","title":"Drawbacks"},{"location":"user-guide/push-notifications/Push-notifications/#virtual-pubsub-hosts","text":"These domains will shadow any identical domain configured for PubSub, stealing any notification published to it. It enables easy migration from PubSub-full deployments to PubSub-less variants. Read more in the relevant section .","title":"Virtual PubSub hosts"},{"location":"user-guide/push-notifications/Push-notifications/#overview-of-all-the-involved-mongooseim-components","text":"The components that make push notifications possible in MongooseIM comprise the following architecture: PubSub-full setup PubSub-less setup","title":"Overview of all the involved MongooseIM components"},{"location":"user-guide/push-notifications/Push-notifications/#mod_event_pusher_push","text":"The first component that we need to configure in MongooseIM is the mod_event_pusher_push module.","title":"mod_event_pusher_push"},{"location":"user-guide/push-notifications/Push-notifications/#mod_push_service_mongoosepush","text":"A connector to MongoosePush application. You can read more about it here .","title":"mod_push_service_mongoosepush"},{"location":"user-guide/push-notifications/Push-notifications/#mod_pubsubs-push-node","text":"According to the XEP-0357: Push Notifications , all notifications generated via the module we have just enabled (i.e. mod_event_pusher_push ) have to be send to a push enabled publish-subscribe node. In order to allow clients to allocate such a node, we need to enable it in our mod_pubsub on the MongooseIM server that will communicate with the XMPP Push Service .","title":"mod_pubsub's push node"}]}